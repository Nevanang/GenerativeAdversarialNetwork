{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0KCGW9pljVh"
      },
      "source": [
        "<h2>DCGAN CIFAR-100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeBrX5fVv0YE"
      },
      "source": [
        "<h3>References\n",
        "<h3>__________________________________\n",
        "<h5>https://www.mathworks.com/help/deeplearning/ug/monitor-gan-training-progress-and-identify-common-failure-modes.html\n",
        "<h5>https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-a-cifar-10-small-object-photographs-from-scratch/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dt89j5WMljVj"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import cifar10\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Flatten, BatchNormalization,Conv2D, Dropout,Dropout,AveragePooling2D,Reshape,Conv2DTranspose,LeakyReLU,ReLU\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import random\n",
        "from numpy.random import randint,randn\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6FpeRtBljVl",
        "outputId": "44f1174b-9971-4628-e4ca-dd951cb329e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 14s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(X_train,y_train), (X_test,y_test) = tf.keras.datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3lBW9snljVl",
        "outputId": "9b9d55cc-6491-4ea1-ced4-736e95912e66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data shape:  (50000, 32, 32, 3) (50000, 1)\n",
            "Testing data shape:  (10000, 32, 32, 3) (10000, 1)\n",
            "No. of Unique Labels: 10\n",
            "Labels: [0 1 2 3 4 5 6 7 8 9]\n",
            "Data Type: <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "labels=len(np.unique(y_train))\n",
        "print('Training data shape: ', X_train.shape, y_train.shape)\n",
        "\n",
        "print('Testing data shape: ', X_test.shape, y_test.shape)\n",
        "print('No. of Unique Labels:',labels)\n",
        "print('Labels:',np.unique(y_train))\n",
        "print('Data Type:' ,type(X_train[0][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "eyGDIL7kljVl",
        "outputId": "d34d1098-a5c5-452b-c9c2-42d683bc2889"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABZgAAAHACAYAAAAvPw1NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9eZQk2VXff29E5J5ZmbVvvU5P90zPKo2k0S5kCVliFYsRZpPAYNnnZ8A+8ANzjPmhHwaOMOeHORzABoM8CBDISAaEkNACWkajGWkWzT7Ty/Re3dXVtWTlvkTE+/0RUXnvfV1VXVt3Z0/fzzlz5lXHy8gX8W7cd9/LuN+HxhhQFEVRFEVRFEVRFEVRFEVRlM3iXO8GKIqiKIqiKIqiKIqiKIqiKDcmusCsKIqiKIqiKIqiKIqiKIqibAldYFYURVEURVEURVEURVEURVG2hC4wK4qiKIqiKIqiKIqiKIqiKFtCF5gVRVEURVEURVEURVEURVGULaELzIqiKIqiKIqiKIqiKIqiKMqWuGkXmBHxi4j4E9f6s8qNycvJXvqtPTcDaj/Kdnk52ZByZbS/rwwiPoCIv7rO8Roi3rKRui831H6ujNrPtaVfbBIR34yIRzb5mVOI+M078f3KlekXW1FeHvSLPSGiQcRb1zj2Q4j42Z34HuXq0C92dCNwwy8w9/ugj4gfQMRuHKiu/Pfz17tdNyv9bC+I+D+YjXQsu/n09W6fovajbJ9+tiEAMWZV4/+OIuLvIuLk9W7bjUi/9/cKiPij8eTn+zf5ub5deDPG5I0xJ653O7aD2s/14+VgP1eDfrfJVeZdLyDi964cN8Y8aIy57Xq28WbhBrGVP1vl39dcCFSuHzeAPZUQ8UOIOMvi51/YyGeNMX9ujPnnV7uNSv/bEQAAIh5CxL9CxHlEXEbEpxHxZxDR3cBnr3tcdcMvMN8gfDQOVFf++692hY0YjPLyxhjzb1dsBAB+HaTdfMtKPUT0rl8rlX5F7UfZQT5qjCkAwBAAfDcATADA41djkVntsW94HwAsAsB7r3dDlBsStR+ln/goi4f+AwD8GSKOX+lDOh4p20Ht56bnvwFAHgAOA0ARAL4TAI5f1xYpNxyIeAAAvgYAZwHgbmNMEQC+DwBeDQCF69m2jfKyXWBGxEFE/CQiXkLEpbi8y6p2ABG/jogVRPxbRBxin38dIn4VEcuI+BQivnWH2/cAIv53RPwUItYB4J8h4uH4FfoyIj6HiN/J6g8j4t/FbX0UEX8VEb+yk226mbkB7OUUIv5HRHwaAOqI6Nm/sNu/WCHiuxHxybi9LyHiu1Y572T8q9jP7WR7bzbUftR+tks/2pAxpmuMeQ4Avh8ALgHAz7Lv+/bYPsrx997Djk0h4sfjazmJiD/Njn0AET+GiH+GiBUA+NHttvNGpJ/6GxH3AsA3AcD7AeCdiDjBjv2oHWus+A5EfD8A/BAA/DxGbwr+XXx8vVjmAUT8fUT8dPyZhxBxAhF/O74PLyLiK1n9Nc8VM4KIn8PobaEvxdci2rnGNa9pvzcCaj9qP/1GP9kkxxjzGQCoAsCB+Hveiojn2PeuFh/9CCKeRsQFRPzFnWiHQvSrrazR1lTsX87H//02IqbiY29FxHOx/cwCwP9CxJH4esqIuIiIDyKiE9dfMzZStk4f2dNrAOAjxpglY0xojHnRGPMxq843I+Kx+Lt+DxExboMYK+Px56cR8QRGb7H+5oodKVeHPrKj/xcAvmqM+RljzAUAAGPMEWPMDxpjyvF3/RVGb8ovI+KXEfHO+N9XjauuNS9nQ3UA4H8BwF4A2AMATQD4XavOewHgXwHAJAD4APA7AACIOA0Afw8AvwrRG1z/NwB8HBFH7S9BxD2xIe3ZQht/EAB+DaJfI74GAH8HAJ8FgDEA+CkA+HNEXEnj+j0AqEP0Jtn74v+UneNGsJcfAIBvA4CSMcZfryIi3g8AHwaAnwOAEgC8BQBOWXX2A8CXAOB3jTG/uYX2KITaj7Jd+taGjDEBAPwtALw5PscrAeBDAPBvAGAYAP4AAD4RT8QciMaypwBgGgDeDgD/ARHfyU75bgD4GES29ecbbcfLjH7q7/cCwGPGmI8DwAsQBadXxBjzhxD133+N3xb8DkRMwPqxDADAewDgPwPACAC0AeBhAHgi/vtjAPBbcds3cq4fAoD/En/2SdiAPa1nvxu57j5B7Uftp9/oJ5tcqYuI+G0AkASA59ep2ouPAOAQAPx3APgRAJiCqI/tRQZle/SdrazDLwLA6wDgFQBwLwDcD5H/WWEibsdeiH5k+1kAOAcAowAwDgD/CQDMBmMjZWv0iz09AgC/hog/hogH16jz7RAtRN8D0Vi2Xv9/N0Rvrd4HUdz8r9apq2yffrGjb4YollmPTwPAQYhimycgjl1Wi6uucJ6rwst2gdkYs2CM+bgxpmGMqUK0kPtNVrU/NcY8a4ypA8AvAcB7MJKq+GEA+JQx5lPxL1CfA4DHAOBbV/meM8aYkjHmzDrNeU9sSCv/TcX//rfGmIeMMSFEA1ceAD5ojOkYY/4JAD4JAD8Qt+l7AeCX4+t5HgD+ZMs3R7mMPrOXtfgdY8xZY0xzA3V/HAA+ZIz5XNymGWPMi+z4HQDwBYhs6g+30BaFofajbJcbwIbOQxQ0AUSTqD8wxnzNGBMYY/4EooWe10EUOI8aY34lHstOAMD/BIB/yc71sDHmb+K2bsQeX3b0WX+/FwA+Epc/AtuTOXgdrBHLsDp/bYx53BjTAoC/BoCWMebD8Q8ZHwWAV27iXH9vjPmyMaYN0ULA6xFx9xXauJ793hCo/aj99Bt9ZpPvQcQyANQA4BMA8OsmfvNrDXh89C8A4JPMLn4JAMKN3QVlI/SjrfD/rOM/BAC/YoyZM8Zcgujtwh9hx0OIYuF2bD9diBaf9pooC+xBY4yBjcVGyhboI3v6KYgW934SAJ5HxOOI+C1WnQ8aY8rxOb4A0frPWvyGMWYxrvvbIMcuZYfpIzsaBoALV2jrh4wx1XiM+gAA3IuIxc1c79XkZbvAjIhZRPwDjFKcKgDwZQAoodQ6PsvKpwEgAdFbDHsB4PusweZNEA0YW+F/x4a08t/5Vb5/CgDOmmixmbdpGqJfQT2rPi8r26TP7GUtNtPnuwHgpXWO/xAAzMCVfyFTNoDaj7JdbgAbmoZIYxXi7/tZ6/t2QzSO7QWAKevYf4LoTZ7VruOmpF/6GxHfCAD7AeAv43/6CADcjYjrTXrWY71YZoWLrNxc5e/8Js7Vu0fGmBpENjoF67Oe/d4QqP30UPvpE/rFJmNW5l05iKQx3ouI/2ad+pfNx1b+iBcSFrbYDmUV+tRWev9Zx6fi7+dt4c/6pfjHrhV+EyLd3c9iJG+wssnbRmIjZQv0iz0ZY5rGmF83xrwKokXC/w0Af4VMRgEAZlm5ATRerYbd5pt6jLna9IsdQTTerPk5RHQR8YMYyVdWgDKMR7bwXVeFl+0CM0QpKrcBwGuNMQMQpXgDACCrw99S2APRr47zEBnPn1oDTs4Y88EdbqNh5fMAsBulvs4eiBZxLkH0Gj5P0brSGxbK5rjR7AUgGpiy7O8JVj4Lsd7cGnwAorZ/BHWDyZ1A7UfZLn1rQ/G49B0A8GD8T2cB4Nes78saY/4iPnbSOlYwxvBf8W1bvBnpl/5+X/ydT2KkIfk19u8AkTRXz08g09eNsftyvVhms2zkXL17hIh5iN6yPw/rs5793iio/VwZtZ9rS7/YpMAYcwqidOL1UoW5HV4AaRdZiBaLlJ2jL21lDc5DtHjE28J9hPBh8VuFP2uMuQWiTd5+BhHfDhuLjZSt0Xf2ZIypQLTheg6iH2G3gt3mK41NyvboFzv6PETKBWvxgxBJpnwzRJtJ7rPaed3nWC+XBeYEIqbZfx5EusZNACjHvxz98iqf+2FEvCMOHn4FAD5mohS7PwOA70DEd8a/EqQxEvK/mhpcX4NowefnETGBkTD4dwDAX8Zt+j8A8IH415XbQXfq3g4vB3sBiPQCfzD+zneBTOP4YwD4MUR8OyI6iDgd280KXYh2JM0BwIdRNw7YDGo/aj/b5YawIYw2OzoMAH8B0Q8QvxUf+p8A8G8R8bUYkUPEb0PEAgB8HQCqGG16k4nbcxcivmY7bbnB6cv+RsQ0RBqA74coTXPlv5+CyDd4EOlF3omIr4jrf8A6zUUAuIX9vWYss5m2beJc34qIb0LEJERauo8YY670hvx69tuPqP2o/fQbfWmTqxGf410A8NwGP/IxAPh2Zhe/Ai+f+fL14IaxlTX4CwD4z4g4iogjAPD/xG1YFYw2AL0VEREAlgEggEhGQ2OjnaFv7QkRfwkRX4OIyXi8+/cAUAaAI1u81p/DaOO53fG5PrrF8yiX07d2FH/vGzDa2HECACD2KX+GiKW4nW2I3nTOQvRDBseOq645L5cB81MQGcTKfx+ASKsmA9GvCo8AwD+s8rk/BYAHIEpXSAPATwMAxMHluyFKXbkE0a8SPwer3C+MhLpruL0NBMAY04Eo8P2WuM2/DwDvNaR7+pMQ/UoxG7f7LyAyLmXz3PD2EvPvIbKZMkSSBX+zcsAY83UA+DEA+G8QBThfAvkL/IrNfQ9E6VkfQl0k3ChqP6D2s0363Ya+HxFrEPX9JyAKYl5lYnknY8xjAPCvIdr8YgmidNAfjY8FEG1i8goAOBlfzx9BNH7drPRrf39X3J4PG2NmV/6DaAMzDwDeZYw5ClEQ/XkAOAYAX7HO8ccAcAdGKYF/s4FYZsNs8FwfgSgYXwSAV0Gkg3el865pv32K2o/aT7/Rrza5wvfHdWoA8CgAPASRdu4VMcY8BwD/DiLbuABRH5/byGeVVel3W7kSvwqRlurTAPAMRBtq/eo69Q9C5O9qEG1A+vvGmC9obLRj9LM9GYg2iZuH6G3jdwDAt5lIfmkr/C0APA7RC0F/D9F4qewMfWtHxpiXAOD1EL2Z/BwiLgPAxyHyQ1UA+DBE8hwzEG1e+4h1ChFXXelGXA3QmOv+FrWyBRDxNwBgwhjzvitWVhRFURRFURRFURRFUfoWRDQAcNAYc/x6t0VRNou+cXaDgIi3I+I9cTre/QDw4xDtnq0oiqIoiqIoiqIoiqIoinJd8K53A5QNU4BIFmMKIm2V/w+i1AlFURRFURRFURRFURRFUZTrgkpkKIqiKIqiKIqiKIqiKIqiKFtiWxIZiPguRDyCiMcR8Rd2qlHKzYHaj7JV1HaU7aD2o2wHtR9lq6jtKNtB7UfZDmo/ylZR21G2g9rPzcWW32BGRBcAjkK0Q+Y5iHbp/QFjzPM71zzl5Yraj7JV1HaU7aD2o2wHtR9lq6jtKNtB7UfZDmo/ylZR21G2g9rPzcd2NJjvB4DjxpgTAACI+JcA8G4AWNNYEomESaXTAAAQBIE45gAtdLtI/5705EvWCfa357q9MiKKeojsc+yQ78vv5cvrLj+ftfAempA+E9IxdOT3is+E8rv4+dc6d9RcXLXsWJ93HbpGfv2h1XYDq7fR/nFh5a/FchVqjdbaF7YzbMp+CgNFMzw2DgAAnVZDHPM7rV7ZGGp2IpkW9ZIp+ttNJHtlx+rDVrPWK3faTTq3ZbNr9Q060mZz+UKvnGJtMIEv6jWb/LrWtr9Wk9oUWOfgfcq71/eljYUhr0fHPE+6BM+j6zIQsM+IahDGp2g2mtBud/rKdgAARkZGzL59+65ys64tYSj71PfJFni/AUif5XC/cZn/or/Nqv96dTl16hTMz8/3nf04DhovHnsca6wB5P5aHLDOsvqPub49FrKxi3sS268D6zveJsfyP65LzzT3F9wH2Bj7GK5avGzcddngnWC+pNvtinoBuxbevsv9Ct2bZGL18Y7/XW90oN3x+8p+BoolMzo2Gf8lL5DHKXwcMlZymXwWmb2t3U3yU7jmEXnuy144YG1ihy6znPXu+BZeYtjoJ+Sp17Hn9WrFJ1mYOw/VylJf2Q4AQCGdNiOFKIa47Jnlz2Uy0Sv7lg/Isuey06A4o1xvinoBP/8azzyAjHFc9py7Vk5kmrWpkM/2ynbs6Qc0lqEjx65mu9MrV6v1NRvFTdzl/tCqF65lyPat5TE1O2iFUr1nsNFuQ6fb7T/7KaXM6FQOAABqVemHHWQxsbP2fIr7Js+lPvWcpKjH5zhdn/qt7cuY3U2wmDNJPh7RjlP5Meb30Jq6irjXnnfxWJ+NISDrBQHrY9aNYSjtMQxXT/z1g65Vj64lZGO8sQwtiG2/Xm5Dq95f9uO4rvESUX+jsZrGbCKZJpuwn8tOi+4Ln4u6rh2nsLGQnSORSIh6AbuvfsBjXmkTIXtQwy7df/t7E0myjxCk/QUspg64j7JHWmZ/fG3Dce1x3Kz6mfVe9EPhy1b/3k67A363v+IeAIBcccgMju+K2mrZvVl9qLnMX681JwmseyY+xua09vyer5vwU6wTDm84Hrn6rD6/3zrRvSnPnYPG8mLf2U82mzGlUhEAAILu2v41Wrte+UOeI5VKrVq26XRovGrVKc5ot9uyopwA9YqXzbvYeMrHRXsdUMRP1jHHWf2Y7Vd4PMbnj+BsTKRiXVNaL8aOr//C+RkoL10eO29ngXkaAM6yv88BwGvX+0AqnYZX3PcqAAAolxflMYeMZShJF7FnOCvqjQ7leuWRUr5XTrpyEPJSGfqDTWAXl8qiXsen7xqMDRkAwLGCBW5krRYtaKYzchEzYEFLgy1UAgAUSwP0BwuCOiyABgBwga6FG1Uhnxf1cjm6F4kEtaNpnc8Ig6N7YX+vHwcQv/HHH4drwKbsZ3hsHH7xt34/qvji4+LYpZMv9MpBQNc3vud2UW/PgcO98uDEnl45nZGPwdHnvtornz7+dK/crcr+dNl3DQyS7XhpabP3v/EtvfKth6hNrWX5DDz37Dd65TCUfdPpks09/9wzvXKlPC/qtTtkp90O2c7iggzwaw06nx/QZ0ZHh0S9wSGyucBU6TPy8YBWM3qOvviFR+AasGnfs2/fPnjssccA4PKF2b5HrBORD2/WZZ8uLJItDA0NimMB+xEmkyX7dJNywOW+IuSTgU02eavcf//91+JrNm0/nufA+EjkYzOZjDjG+8RjQYUdcPj8B0f2mfJyRdRLs0l7jvnralsuBjlZ6rtMin2GjQsAAMViqVdeWiKf06nLwImHDt2O9YDzxRv24wVf9AUAKOZoHJocJRucuXhR1Kt36F4MDFA9vysDmHp9uVfeNU3jZyJh/xAW/f35B4/CNWBT9jM6Ngkf/O0PAcDlvifDAt5kmu5d6Mrn0jfsh3X2NLpyjQQS/PR8Amv9UN9lK9P8jjuBFUAatmjJ+iZwrC9eZ2qy5kTaXvhjM7xgjUmlfQ5+P+2XFsRnWNm3f1iPJ6O/8jPvWfPzO8imfc9IoQC//D3fDQAAzboVK7J+xd2TvXI5K33UPUXyD2eepjjj7x5+UtQrt+m55wsx9oJjgv1QPjQ60isPZKSdHdwz2iu/9Y3k231rsji/TLFVoiDHrheOn+6V//GLD9MBy6ZTzBcV2aJU0pN20WHfzRcSwXrRI8WewYah+77UkvbjxKd78Kln4RqwafsZncrBf/nztwMAwEP/JP1wIU3xaC7L/Ku1gJvP0f0cKU71yoPZXaJeqUhx8IX5M73yiUtPiXoD09Tfw9M0mU+kZEzTrNN8LZ0mG3axJOqFAV8IrIpjgwPUxlSKYh8PZL3lCo2HCxfp+lu1oqjXaFNMzBfNlhYvyHoNOl+ltsw+I18KWVqM7sWn/+BpuAZsyn68RALGd+0DAADHyDm2m6VxaPdt5Hvs399PvXS+Vw5Duq+FYkHUKxTJp+STdO7JyQlRr1yjflsoL/XKQ8Mjol5nieKl2sWFXnmwIL93Yu801fNb4tjyAn2uxn7ccq2lk26bfMxyhfo6Myj9cJetK/Af3QPrZTQjflin78qk5XrDyqLYsaf6L+4BABgc3wX/7vc+AQCXXyP/oYBbVtKKm5H9QNQJybiqHRkPizU39hLaQFbGUgN5uofs9wOodq3FPWbIXbauE1o/tFz2w8s2EfGS9YMHj+nkCyfrBWBrH1oZ1//gp79zM03cKpu2n1KpCD/xEz8CAADLs9K/tur0rHopNuex7OfArQd65VsOUNleoZ85R017/tFHe+VTJ06IegFfTmPPZioj131KBRpPB9i4yMsAAINsrl4syvWXbJ6OFQr0uUxefleazenTGboXblL6Hz6nF1OF9dahg9XjbQBa6H7vD37fqh/dzgLzhkDE9wPA+wGiVfbnnn8OAADK83JhbIj5TRymP0YCORhgZqxXroc0Wa5ZEyOD5JQaLQoOG005qe6yXyXn2Vseac96w4L9GuqySb/9i0ijRYOQby0SYmu4V+YvaXStX0gyHl1/jS0CL1pvq2azZEjokItGa7GdP3CNFg+uZZDvetG1dFvScV8vuO0MDo9AJV4cGS7Jh9CMjlPZo4d6cs8tol4Q0vU6IQ1AYUPe19YSBRWmSU5semRM1Nuz+9Zeefete3vlqWkZdI+NUfsSCbIXvySdxO5dFEj5vrSdFuuT8hIF5/PzcpHa429ts1/1BoelnaZzdL7lCgVpqbT1FoChe5Pw6ByVZeuHmnb0vJg+Wrzl9rNnD/2gYC/83ai0G8vi78VzNBCefUEeW66QX3rj297eKw9YP5Dxd2bFG/rbaegNCrcf10VIxD/2BdavKyF/s4W9DdP2pV/hC7N8FlYqSD8wwBaIO2xSEzalT8gmKHgosgWlrNWnefYW4Twb/0Ijx510mp7v0VE5WVtaIh/Bf1SdmpQ+0WXR7NgY+emE1aaTZ2nSmUywe1GSi+N59ucwC8zsN4jqjfg+9cmrJtx2RkbHYWVe5KXk2Nxhk676Mk2cEznrrRvW12B4kCjr+WzhOGBjfWtZjulJ1tcBCzVr1o/iDlK9fI7uvz3x4W/o2YuR4iVRFtTbb1/zBeZwjTeno3osm2yNN8fsdvA3UO1MgH78wVHEPpk0LM2cBAAAL5BtTbA4dYY9z8ea0kfdc5hioZD9CD0+Ip/zjPgc6yurTxssZl1eJN9QQ9kHbRa33HsfzSW7DbmQM79A5xhPW5OiDv0Al0lxG5H3YqxAC3933UKx2aW5GVGv2aTnrFZj9u7IZzPlkf+emiDb7yalzzv+/Kno4+tkM15rhP+ZzMLKWnluRD7fTz9OL1PsnrivVy7kZB+02MsKzSr1QbNk+x+KqwenKJY8uFvGlc00LXRXQ4olw4p8IzoV0ABgWN93A7kQ7bnU90MD0qaz7IWlbp3mk5X6pKhXXSA7O3OUftRwU5Z/SNAzcm5mtlcu5GXba1V6FnyfH7P9z6r/fN2QcY8HJv5h0V4gbLLF0tkL9PyOjcgxPO3xt+vIrhLWm+HtJWY7oxQT7RofFvVy7IWgRoXNf9rStg8fpoXjiTfQDyn5jJwLpfL0d9uas7fbNJerlNn4bP0Ac+n8pV755Gmyl+TQgKjnpumaA6TvygzI+CjNXhgopNmLZPZb2vGYefG09HHXE24/xbFpMPF6hB2r8ElFs02+thXIesk1MsY9R94LDHm8zV6UsRaA6+wFQZetE6Hl//k80eFttzNYdiC/U/zIz8quNaY4bKG7y97K764Twqy7/r0yrvfP0CVjn8FBGByNftAcHR4X9fbsojWXwSHy+R2U/Yge9TGPF1vWOtdtE/t65QO339Mrnzgqf7xZZi/plBepfOb0SVHv7Bn622P3N5O0MjI65PcSVuZxOk0LzB77UT9dkD42w2Kf0jD9qF8amhL1iiU6X75IvqlQlH4qw7LuXfajrGtnuMdz4rXMZzvrBjMAsJv9vSv+N4Ex5g+NMa82xrz65bKwo+wIV7Qfbju5gnwAlJuaTfue0dFR+7By87Jp+7EDPeWmZlNj10BRvpGp3NRs2vfkrAmJclOzafspDK2dFqzcdGxq7LJlGZWbms2PXaVh+7By87J5+8nn7MPKDcR2VnwfBYCDiLgfEZMA8C8B4BM70yzlJkDtR9kqajvKdlD7UbaD2o+yVdR2lO2g9qNsB7UfZauo7SjbQe3nJmPLEhnGGB8RfxIAPgORROeHjDHP7VjLlJc1aj/KVlHbUbaD2o+yHdR+lK2itqNsB7UfZTuo/ShbRW1H2Q5qPzcf29JgNsZ8CgA+tdH6DgBkVsRIrKytvUx3ed846Z2NWZuOZbjuMN/wqi013Vpd0ogzrF7S2qAJ2CZ/JqTPFIekLibf4CbJ9BDtfWX4plntjmwT3+Q1y+p5lt5Zmh3zkTQ4HWsTEp9vwsUyuPM52fYa2wysy/RD7azvarw5QbjOZjk7yabsxxiAWDO605b6go0GaVntO8Q2bGA7gQLIjfKGRtimfNZGVQcPHuqV3/C6V/fK0+NSW7lYJNmFLttIJpuWxs3lvJHpsjbrUjOszTSxs5Zg/GCJdP8O3HJHr/zCC0dEPUA6R7tN/V4ckGnaCSYJt1whPTwDUoOM62IuLdH9bDasDcLMyv+vjZDcZn2P9dkdbs3VhbfXYcKls2el5tPTD3+5V+42pUZhgm0W0GSbkAwMSf8qtE/Zhn831h27Mpu1H0SEZKwliCj9xeAIpQHW2X1PBDK91GfPPrI+nZyQmp4To3S+k8df6pVHPLk5xMQUabY7Ptc5lI6d62wPs411jCvHnSLTOM5aY4jrUNtHx0nvLG2l71eZbfmGfFGxJNs+zcZdtgcveAlpaXyjrZBvDGhJJplYhM6+9qvFZuwnCAOoxL6+a29udon0/s/NzPXKbtrSomYbn6Ucuie2vl6Hje9hl/qsYW1Qm2F7AQDbYLnakRtfdTr0BbfsP9gr33pgr6jHNx+yNY3F33xPNUu5LeSizLx42aZ8G/NGPD50xOYm11dzebO+pxM6cLIV9VejKbX1k8hizIBtUo1SD3b+NI3xj58/1yu/OLck6hmmhcnvX9raXKrrsxiRSd+lLX3TcpPu9defOdYrTw5Lf9D2uS1YPoD5h0RibS3M29gGPvv2kH3aGvezF07RKVhMmB+UmrwBi/OzKXp+pkbkZttn3ej89rhwtdis/XS7PszMRX5mar+MA12XxoOhPN+zRPqpmZO0v8PJGTI4fJEAACAASURBVNpsaXpKxhl1Q+cb9Mi2/IEXRT0nT36v3aUxpFqW+xYMedR3SaalPFCUfVDIUGzetnxsx2eb6LK9dJYvStm0pRNkaEcfo80vc7tlm6ZvpfE6zTY/rFTlZr3tFvsc0wWdX7gk6q3MS4JrpAW/GftBREglo/tiLG3cgO975FOsMzYoNbBbi2QjzRrdk7QVf2TZRlWHbyMN9YOH9ol6y2yTv0Sa77gl/cYdd9Pn9u8jLdJOW84LDYttHEsRxGObhfL4o2ttttqpUyz2uhZtJo8J6TcdtjFikGRzcemiwGF+Lslsx45vVsbCv3ngH+BasFnfY4yBbvzMGWufLH4lDrvxXd+OH9h94mODa/lbtj9Bkq+hWBsmN1hclGFzf8eT3yvikzX2fYjANcqw9sTJ6kceI4m4xRpT5AaAfPPkNb4H1o+XDE3c1z7BDrJZ+0mnM3Dotuh5OnbkmDg2z/YsybIN8FIZOSdptWjsTrI9ckJrk8g6Wy8ZHaNY4PXT+0S9mTOneuUG24vq9W98k6h34SKpfyRZvF3Ky33lnn2aNhT80j/KWxPM0bjL93gwlv24TLOdX6MbynoJdsxj+8dlrTXIItO7LgzR2Do4KNcLhoejuWqjKucNvTav+q+KoiiKoiiKoiiKoiiKoiiKcgV0gVlRFEVRFEVRFEVRFEVRFEXZEtuSyNgsiAbSGKUnFAryqw9NU+rWcIbSJRKhlJmoLVJqShDS+nizIdOYHJYhOFCidCovaaXwsdfsPdakISutrlqhtJpOi0kFtGQ6Fk+ryOdkmmuXvZLvBPRliZRsUxDQOT2mfdG2pCGSTOfACen62zWZ9ggsNSXFUoB8KyVruR7JHgRh/yXEmzAEvxXdP/SlhEcqSa/3L8/P98rDE1LSYs+dlHY1tptSphIJmU4KLM2465P9vXhhQVRrnKBUt65DdnnkmadEvdccJkmLt9z/ml7ZTl2psPTyM6fPi2NJlmqVTFJ6+MjotKh35iylkSTTZMO1pkwLq1ToPnksHWtgQNp9k6X8B+wR8600plSconGNMtS3Bd4IjWQYlgvcZWk858+eFvUGsiyltyTTcOaWyM8tXKDUnfHde+SXsVQ1bp1o6+ncZLiuA8WB6J6mMzLtcWyMUmbnFshHpC2/vrxE6VTjI5Sem0rJvMwMS/Ga3k2pl7nLxhN6IJNAPixljXGNJo07u6eorSYhn+EkS7PqdGQK6AhLafeYpELbSjctMP/RbNP3VpflmNRukw8fHiFbzeRkXOAh1fM61L5WXaa3+fHY2I/yN7V6Hb76yMNxWUpVOEB93WxT21uBHGsSSfrbZXGPlbUMLeOzY3S+XFLabAbpPqeZ/QWO7Pd6ncbCx57+Rq88Ny/Hp1v27++VR0ZkinSGpT4bFlsElhRXyCTAkF3jVtM3DU9rZT7ftpGV9NR+tB0AgBABmnEcuOjIe4YBSVUNswA2b0liteoUW5Sr9JmKHb+y8/P+ca16Hn83hcnH1TtSOivP7unXn3q6Vz50662i3u0HaBzykjIG2bePpC/qIT0vFy9IqYFKlfkEJjHz6rfcI+o9+eiXeuUmky2qduX3LtTpHg41KQ6cdmU6aKsW9Y25vsora9JqBXD0aNTmfbdIWYj9t9F9P3HseK9cb0g/lWPzoSqTaXn2yDOiXn6KZHSGC+RLfEfenHMnmH8zdO7B5JSoZ4BJKiSp7UPFcVGvtkxjw4svyLngYI7G0MIA2W13WI679RmqN3ux1Cvv3yXrZfN0Dj+ktnda8p55Saq3tEg206jLOS2unL4P3Y/rIuRKkV/xQvk+WiGgMSWTojLKIQSyHh1rtUhGpFGbF/VMls4/d54+841AyrC0mI8ZZrHX5K4JUW9yisahTInNn2TzgIU9kE7KvuayDt06820ZeZY262vTJlvn8/zoy2gcyoxRTOVnZOe32U00bBy/TH4qdjqO27/x+cq4unFpK0uqgn/OdVf/d5Dzui6LPZOW7GOS2aMUU5B02bxLzIXWu9WXqWdsvl94H3fta+T1DH8e1x581pvv9qHLEbiuA4OFaH5wy60HxbFzbP67uEgSYAMFKb+VStO8OOnymFj6s2aLPXMssPblcALFIsUFHWZnfiDtbDeT7MqkaTzJZ0ui3shuip0bVn9/9q8/2iu7TFYw6UrLTYT03WGTyk4g47YWm8eHzC4uWfZjjjM5EpfGONfSEErFc9wlS/ap9/2r/quiKIqiKIqiKIqiKIqiKIqiXAFdYFYURVEURVEURVEURVEURVG2xDWVyPAQYTDeEjpjpQ8X2S6GowP0+ncQypRA/pfrsde1HblW3mY7j3osddCz8tgC9oq7YbuSzs2VZb0ufXO1QSk7Deu1+HyG7W7flm132WvoDkt7cVMyfbXJUqiyCTqfZ70+32Kv9DfZzqihlfhQrtH5yg26LzVLVqTVja6/4/dfrp8JQ2g3onTsvJWiPjBEqXP33fuKXnn3LTKlospyHY6cONsrVxoyBatWpr5fKFMq34VZmeY9UGTphg6lT33yox8X9RLvIbv6ptfTTqOJhExfmJhg6YFGpo+VmcTBE9+gVFMvIZ+jXIHsxWfpXZ2atGe+Ae/oKO0MGlj2vLBI7XCAUiX4MwUAUCpFaSnimVS2hJ36xX3FpUWyx1Onzoh6bXaskJYpfI0apSa++BSluk+w9GMAgNIEk1zhOxZbuVQ3mszIdvE8D0ZGoh1z7TTFTov86/gEpWxm03Jn3hRL75scJd/R7Ur/szA/1ysXBkg+wkvIMS7sUDsSHtt52tpNvdlgu9uzbnPS8lltMwmntpXqnmLjda1CviiXl2nlPK1+YZH8ZSoh5T24+XTYd1VrtoQEVexUAvYZ6TtX5KhMH8o7BUEI5Vp0b42Rzw2ysdpLUtyTRelfXYf+5nIoLZAxhs/eGag2mJRXXUqZpJD6Pm+ob10rIkykyIZbLI546eyMqHf6wmyvXBqQKYq7d5FU1Wj8DAEAlAaljIPH0u9cs96u7QTfmD60dnAXO66z84WXSWT0n81wEHxI4SIAAExmZcxWYkm+Q4PUVyeNlHHIZej6U2w8se2smyNb6DKpsFZb+oOA2RmXQEmmZOrmxG7ajX1q1+5eeb4mZQJmK+R7Xvva+8WxxYtkW9/zvW/slT/1yc+Ieg9/9ZFeec9d9/XKb7vnVaLeSzO0M/vJh2gH9+WOlJWqsTj48GvofM2ujANHRqJ41PPs5Pv+oNMxcPZM5CcMSGmhyjDFwR2HpC8CT/rXEts9/uBtlNJ7cW5Z1Kt3qV+ffo7iEd+SdimNsNic2WoiJe1icIi+N58lyYNqRT7r8xfJPsOOtOk0G0MrHfI5z7RuEfXaQ+SbnDFKv86mpVzRUnmxV75wntrut+Wz2W3TtdTqNAb7Vs51ekXSqg9jqmTGg313RnIkqZaMe/wq+ZGZGZpfHHla3i/HUH+0KxTroC9t0WHSEicfY3KBSdmfPvPlI+MUby1ZEhm5kKRxxgYO98oTk7JeNsUkJFGOBR0mu1NjkmSdipwn1U5RinhljvxDpyrtuQn0XI0cIn/oDMpYMT1Gsp5YonHRlqpLxGNm/1lOhAGAbhzj4DpyD7zsWM9Bl61tuC6/FzIeDlgsxOe32YQ8H1tqAp/N/duOjGXbsPpc1r7XRqwp7ez81459zDrHtgZa/+8vWo0mvBBLjg4Mj4ljGY9JEC3QnKnZlM/mGJ/TsnGoa6T9dJgEBbKY0LHiw0SC/NHgIK23PPTQF0S9QoZiqTvupJim7Uo767ChcWBU+qauR8a6tER+JetJX5xlkhkptjaDnlwf4lfCL8ualkib7lTZv8t7UW1Ef/u+jBdW0DeYFUVRFEVRFEVRFEVRFEVRlC2hC8yKoiiKoiiKoiiKoiiKoijKltAFZkVRFEVRFEVRFEVRFEVRFGVLXFsNZhdhtBTplRUSUqsmzfQgHZd0PjIZqU3U9UmwhGvuGSN1V7ieSsD0GkMjtUIM05w1TEOt2pGahUFA7WsEpE/iB1ILpVqn888synMkHKo7UKO2d2el3m5zmXSB9ozc2iuPje0S9bBAOlXtJdK9qtXk9y4zHaj5ZdKUOnVW6qcFsQBjuyM1wvoBdBBSsb5f15Vaec0M6VWdZFp+T37l66Le4gLpe86cv9grJ1xb14r6qe2TfXDNawCAyVF6fOZmSbNtICW1+Kpl0l87evIkfX5yRNTj2j6Tu6UWzxT7+8ws6eYdeeasqDc2Sdqup84wu+pKO+X6rYFHz1RPDy4m5ZG2T7NF9QYGBkQ9L9b6Qf3NagewdLcM3feZc+d65ZNnzol6Z4+TtuRIIS+O7RohDdwLZ8hWn3nsUVHv1W8t9cpZrqXanxJd1wwEACfW0O+0pa5ewDSEfe47WlJb2WPCcBWm44iWjq5hOsYzFy70ysW89HtZNl5V2uTLbZ2sZJr8CtdV7Vo6y1zTLvRlm0KX/k4xrWDLVKHRpHMmU0yb1dKKz6bJoFLMXy6XpVb8cpmuK58me0RXxg8rtuq4/acBHxoDzdjfch8fwWKYgPrGgIxTkN1/LhPZ6Upb7LLTF7LkA6oVaYsVrrfNNMWTSTl2FZJsrwiXjtV9aTtuSLbTnpdxRblM424uT/Hc5OSUqHdgP2mi5tk4lLLa1O0yG2bDmrH0D8M1dJxt6cIVHWfTp04OHYRkLurYWwpSh3A/0zctJtneFMtybMiW6H7Wk2QLYUI+569+BWkNj4/Rd504flzUO3uGNLgdpv9nfGmPaaZ5+PrX0rkvSXOEr3/pi73ykSN7xLGgySrnSEO3XJc2WOuSDR6/QPFwPZR2UffZXitlOkc7LcfMg3vJHkvjZKuXFqTG7NvedicAAHzm8c9DP2IMgt+O+qg8J2PYboPp5OfowRicGBL1TIrmBGO30n2qhFIzv8b0LzNA51hYkHZRSJIvn9pFMUcX5kS95ZA+V2f7gaRdqfNeY3K+hQE51vhJusa5Otn0p/5a3ovQnO+VDySpnmuk/cyfp3i+02L+0ZP+o8X8lGG6svmCbDvGApj9GDsXSwV413e9GQAA6qdk3zz8adI8d9s052xUrH2TAqbXzgKGYlbqteeYLxpmOqWlrLxfwPd56bJ1g5mKqPbkJx/qlU8/+Xyv/NZ//gZR767b97E2yL5OLpPd4zzbX+LMoqjXepHitPos6TG32lJn+nyF4pvTx2ju5g3La8zuIT93xzvu7pUTWWnb3Xj9wfTftkk9VvRdLflocHnsw/cGQfkc8GOG71lhxVJ8vw6XrSF1A2uvqRppytbOU7+NHLpL1Ouy55FvS2Xv2cDbh6G9DwQ7BquXbdbTWV5Td3nDcsxWxd75+nMfCj/owmI5ep6effJr4liCdcrE/r29sr2HWDZPc99slvaEMJa/5R9rNMlGHGtKwedNLz71eK/8xBc/K+rlcvS9k6P0veO75Zpmktnx3XfcK455P/J/9cozZ2nevlyWa4bVCvmjGvMxdWvvlWaT/BGPo43V/8iewSTTgU4mpM/OxvtvuBfl96zQfyOaoiiKoiiKoiiKoiiKoiiKckOgC8yKoiiKoiiKoiiKoiiKoijKlrimEhkJz4Wp0ei18YGkTFvIZykNEoWMhfXqNssFabPUOcdKOhhmaUi5HKUOVpblq+VFlupfbdH3np6R9Wptek8+yV6ln87KW+glmATFgkz3bbNUqwTLcy0OyNTnN9zxamrvBUrLMQ15L4oj9Lp6u0HtqNXk7wYp9lr77gn6rrGxcVHvYiVKR1s4Ogv9huN4kM1G7Z0rS9s5fpZSjZ5/7ln6jJVCE7Spf5tVeqXfdWRKRbNNqVblKpWrdZkOeOrcC71yLkP39bYDt8nGM5mNhx78Yq+8d/9+Ue3QbYd65WErZSrF0tyLLAXQ8WU6cr1Nfd9sUCpHs1wV9YKAUg/TGbKPWkXWGyjQ85FiMjadjkzhbjSiZzEM+zhXq4fdxrUSljaYMm1nHfF/4LlrKM+3dkqkrBeGZO9c4qDakGmn5y5SmszFizKFLwgo5XPXGH3vi49KGZmxCUrlOfSa+9kRKx2N5YXxlH37kkT6WD/n8V0RAxj3azIp7wVPW/OZzEG7JdMjBzOUMpVg+YKeI9OOWh021qRo7Oq0LRmoCvmwJJMesGUOkKV9BkzaIJO25KfYM10YKIlj6TS1A5HGpGpN+sRuh0k5MFkM/vmoIrtPzE8FHWlASY/SsQeGKOW625VjQKUe+Z+gD/1PaAw0Y1mVdldeHzKfwO+RnbDIn6OQPXAhypp1NkalM0yGxEr9Dbp0jKfx+ijvn2HnT/JcwctcF0td9eR38XNUG9S+5WMviHrzCxRzFZgcyq5pKQ02OEjpw8kUt2HLb/pkIzz90bcaH8QSRP0qkREahFon8hFFNyeOdecp/f9smWQr3nTv7aJek0m+TbN7kc5K+3ldic5/xyhJeDWstOD5FD3bjWVqQyBdFHgdiif2niF5sIwVww2NMpmEZ78hjnEJjoefJ5s5cv68qNdivm2GyUfNLVwS9e5/5euoTaXdvfLvfORvRL1Ok+Lgxx8l27x48SVR7763R/faDaVkR7/gAEIKY3m5powZBidIem3mIsnGVVozop5xjvbK995Fcerr3yml3HJJioO7DSofPSrHwsoS9UkmQ7YUJKW8wrnKmV55uEBjxtSgJeUzxMY/6/muM7nEl85RmvGJr8jYuVOlfsXddKwxJ6UXJveSfEOmxNrhyHvrMEmhLJOD6DTlQ5JwovMh9t/7XplsAu56xTQAABxvSvteXqL593CW+trvyrnBfJVi0Ul2v24tyXmvx6TCEkgx1uCAjB2SLI4KWF+nrXgmlyN/vjxHbTjyyS+IeqXZe3rlsUEp/eczWcSwQ+dLNKU/TDH/2ODp61Y4EjD5y/I8+cbsJZli3mXztfYrSarH3WfNaeWt7ju67Q7MnIyeYdeKLRIsTkAmu4auvX5BNuOEzEbasl7o0b1Jc9lLS+7NN3S+1MS+XnmpIe27zp5Hjz3Lxoq5uBSXPadzmOwc8DH0MqkLJhciypK1hCzQ1h/hsYyhNthSCCF21z3v9cZ1XRgoRrHgyYaca8zP0njVDNncZUTKiPEYO8Ni7OFRKdHmMTlQvraYycix5thRikEe/sqDvbITSDsrz5MfOH+O1qhShWFRL8mk7ErFQXHszW99G52f9XGzJf1Fo0H+ol6lsesiG+8AAE4xidZjTPaMy3kAAOzaRXHR8DCtE9qSxUPxnOzEr/0arEb/jWiKoiiKoiiKoiiKoiiKoijKDYEuMCuKoiiKoiiKoiiKoiiKoihb4ppKZHguwlAhesXa60j5iBSTM8iy3efbTZkD0mXp4qUSvU5u767ZYTvXdtlO69m83Cn6/CVKi3jpNL1afqkqU/ga7M+9GUrt+K43v0LU2zVJ5//Y4yfEsYePU8qdH1LqjefItlfLlD7WqFH7CgWZSg0BT6+lY8m0TFHNIh3z2Y6qe3bLFIHCYvSa/dMnZUphP+C6HpSGopTN42ePimMXTtFr/9kE3a/l+pKoV6vQLsjIUqnLVZl6UWZphF6K7t3IuEy9yDAZlul9tPvnbuv+n3zqYboOpH7vWikVl+Zpd/K77z4sjt16kNKkdk+O9sr5171S1Hv6RUopbLcoHaSdkOlJIVAqWGjIJmZnZdppkqXCFgf59a++O2l4Q8ggbCwhaN2UabnVrzzE/jbAdqG2f89jqTsIvGxD/7Jn375eOVuQ6XyVOktDtdItnz1Ltp/xqE+9lkzXfO6rX+qVh6cpNWZw1y2iHrK0UzSrp3cBAITMtzn9moe1IbCX7masdPFMjtKGWiwNMGmlHQV1loLHUkAnxqVUkb/Azs/kdXJJuYN4m/mt4gTJR6zI1azGyDj5jnZN9r3LxolEQn5XmkkRtJr0vamkTJlykjT+LbPr7Xalr3PZONRi0lQQSt/JU9o8Jv3R6sq2X5qPxqyuL8ftfsAYA53YL2Jg+WE2DoWXpTkyUuwZYymkoSOvl2WJQrdD/iDpyTTjPEv7a3RovPNBnq/NTLHNnvmUI0NHF6jf7N25eczmszRokT4KALOL5KPOt2ksPH76jKg3yqQbpqYolS+flynXaSYvY5i8R9dYEhnxOByE/emgPHBg1I2uZRrk8zHA5NWeXCJZiKW2TP/fy6SP/sUcSXMlKnIcHz5G50i9dKFXDkIZh+9jpppgcahj2VnAfEr760/0ykVfpiOHIyzt3doFHipkMwMu+Ze2tUP6ELs1WUO2X5mVaaLTh0niocDk8+4/MC3qzS2Tj5mtkU9tNKT81Iljx6L2tPtTIiMIQqguRT57YETa+EKF+jidp36s1aUf6LI08xefp3j7wox8NgsFup/j4/Rsju2TacaN09R3Zy+RNEWmIPt+eJRinMEB8lOOc07U85L0vUlHysv5HfIXIZMGglDODw7fTc/M7fupXMjKfh0cpTY2GmS3nY68xuoCpXAHHfpMJpkV9SCI+6QP3Y/rIhSL0TM8z+YnAAAJh64979L9XwqlHAoY6rckixX3FGR8lEkxCT7motsdeb4qk5lIMmlCk5DjZxapTWMjZANJT97oxlmal1+Yk3Nfn2n+OA6LdYz0wx4bn7lcS7sibSfLxqTFGpNhsSTtigU6Rx6ZhIw13nd6ptOHxgMA9U4XnjgT+xgjY0A+/ie4HIU1h+DSBVxa1FL9ghb72FiR/Ma+ITlPmmByk/ks2WCzJSVukMWiSxXqq2ZH1gtYzOkmpA9Ispid95Hryfip3SI74XNBx5JVbHfIHvn3egm5NsTl7xw217CtxI9vu+nXeTs6APF8tTQ4JA5dPHGqV04zSYvKOTkmXWTST48/QTHIHXfcK+plc2QnnTYba6yw/OknSFZyuULrmL4lxRIGXDqFsNcquTRhzciYJsuGilSC+jSTkzbN12bSTG4mackvVpjvfNvbDvTK49YcNM/WFrw0NcKWQF2R9ePrRBx9g1lRFEVRFEVRFEVRFEVRFEXZErrArCiKoiiKoiiKoiiKoiiKomwJXWBWFEVRFEVRFEVRFEVRFEVRtsS11WD2PBgbGgYAgOai1LHhOjG1BmmSNDuWxiCSLk6D6TraK+VNptFYGmTaKoHUPzlxjjRnF5nWm/Gklo7LdA8H0lRvzKuKeulF0tI5ODAhjl0YonNcLJPeYLsh9SS/cZQ0hh2mR9e1dFegyHRTmCZisSg1vgpMW7DF9F5MpyLq7RuN9IhSif773aHdrsNLL0XaNy++dFwcO3+BNNyCKmnYFIpS4+u2g/t65bsO39UrX7gkNb5OX6JzjE7QPd57YL+oVxgm3ZuLS/QZM39S1DvDNCQvlUnH7PAdohq84xDpLtdrsk0hk/cxTIfpuUceFvUO3kaa4OPTpV75ka9/WdSbvUh93+0yPdSmtMWlJbLvTJ7OZ2st1xvR9dsaPf3Jxuwb15E1EzpKlnZnyLTGukxDN5mUPgXFF3AdY7sh5PMGB0lL7k1veauo9syTL/bKp05K3cmA6UMdd0lzLr1P6rAHR47R+b70UK/82u8YFfUyWdLCZBKcYEmGCe0pfx2duBXdsf5Ukos0KGcuRTpstoZWrk02n2c+p9WRmlxcp3B6kvYPSGXlTXOZNORglmymlJX6poUJsoU2E7g+aumol0o0brSZLn2rIcfWBGtftyKPtZi+aMjs0bWE8Go18hc+c2H2uDtaojFqaIDuxbGq3LdgeJCOsa+FgZzUfg67kRaj50qdyH7AAIC/hsZdwPSJW+zeeZZGH3/GPId8irGetwTTofR4eGf7ZeZ78kyzzbdcY8j+7rJzcG1KAACHaSgaS0M3YLrLgWv4AQF/rJDvG9GV56ucJxs+feFUr5xKyucjywTs0kzLO2X54USsX9hpr61dfj1Juw7cXoiuJbcwL465Dt2bQ7t29crVi9Y+GsxQplnfZ5OW72H6wsjGNdnbAG2un810JhOWb/SYLSQcij27Bek3TIP8i9+W5wjYKDLObP9tGRnfdZD6NZiiuC196pSo1+DdzzSs77z9VlFvksXlkyxGOnRAjpm3jkRjYfozX4G+xABgGN1Dx5P9XWuShuQ422PEBaljfP489V3F0LNUWZKW4aXJ7hbqVC4WBkW9dJ7898Aw2W0mJf3e+OAkO8Ztxtqbh80Fu105Bhg2n6ksURwzYE2n3vqO4V45BTQ/m5yQ+/YkWTuOPkP2vbgk/UerQgOgYfFXcUSerxeb9WHwg+hAJn6+0dIYrS6R7TgsdvBQ9o1hg4rv07V3u1IfNJdlvoLNt6tVqUuaZPqyhTx9byIpfUq9zvbWCciuhkrSb/DYxtoWB7psTGjVyTdWq7KvszlyKoNsn6e5inw+0kzP1IQ03vN5OQDA2TMUo+8/S8/R2L5dol4QRm23Y9J+AR0XMBfPG+29aliZu3x7rAl4TbZfUNaad3UDuoe5Bq0vmbzUhy0NkS1MFsgfuiX5XM4vk929NEf9fXxB2iO63O6kXfA5XsplWtKOtFWu+cvnUPauHFyDudul67X3s0gLDWa2P4YVh648Mu22tL9+wRgDrTiGSKbluhbXsfbZep/x5L2dPU++/KWTZ3vlhx9+RNRzWP94Lp17dKgk6gHb081jt71akWuBwwWyp2SK/ANafRWwxZ3QmjMmmKZ3ke05F1p7ubSYfvjRIy/0yg998Z9EvVOnaH41NUV7TswvWWMmszwvTf7S1vr2Yxus1uQ+Ziv030qioiiKoiiKoiiKoiiKoiiKckOgC8yKoiiKoiiKoiiKoiiKoijKlrjGEhkJGByJUpQG8zLF1XHo1etyhVIgu3X56rXDclhCoNfETUJeSp6lznSByi+cOCrq1duU7pBOUypFOinPl8nR6/mDLqVpPH78oqjnd+hz7aKUyBgdpHYgUH5W15dyIY0OpVbVGyxN0Zdpy8jSAnguRcKRiRWGpWMkeFoBSw0CADBxGnM/ZtvUs73OnQAAIABJREFUaxV45MufAwAAb/w2cezA4bt75UyHbOLwHQdFvdsOUXpR0GJpI46Uo6gDpaF6Ceoz15WpEl2f7KVepfSpoiXr4rP08DNzZNvp/IyoV2Sp4rcc2CeOGfZbULNMaTgvfu1JWa9J13/XO9/VK999zy2iXvMxksh46fipXjmblWlCxdIw+4uevQp7RgEA2nEqmbkRJDLsvHI7D6lXz07por+F9IOR/X3sOMlMNJvkX24/fFjUS7FUS8fWlmCEhuqFzGW/4Y1vFvXOnCR7+qP/8UfimM+kT85cotTGVFamjx1kMj5HHnysVx7dJe3n9jfe3ys3gK4/EcrfLJPsuhYby71yuyN9z0qaaKcr/71fMMZAO07VWlxcFMeyLB1viPnkhDW8pvNMPqNBz1/NkqrgxuUyn9+uynszylKwjhwjWZ68lUqWz9BY226TrxucHJJfGzBZgob8rjS7lGqL/EAqJWUJZi8yeY6QvjdflL6z1SQf5rNUv0xaprcVWOrpYpVigVZbjpmFOC3VceXn+wFjDLRju0DrOQ9ZmidPc/XbckxqslTdBJO0cFE+bymPjhkkX4xG3hcuZWR4ip419jcCsr8Oi7ccO8WTXVfC2PEHk/lymAyZ9V2i75D618ooFKm1IfM3naaMFSt1lm7IJT3ast5KnzQbUjKsXwi6bVg8H6U2tn15b5su3dtGkfxBpiFTXlsvMBkxl+6Ln5M+ynHpPqWYvAWCfM591scBtyUrhdKsUfbG5HhSKFM/tuRXQWcvxUWDPvVdriWTqf0y2WptjsaaxvmHRL0Ljz3VKw/ceahXXpiVsiKdLPlHLvfTWJCxTyURtSMILD/eJ4RhCLVqlL7r1uXDVGDzpm6DfIxjpXpnUjQeOEgdVBiUfj1gc6Nmh+5n46Lsq/3Td/bKxQyT3+paae/LZNODbA4GCXm+RoulrXuyH0KW7nziONnn4LiMfe57FcW6GaC5QzeQ/qJVJ9v3uzT/6zRlinTKpfNnclS2hyiM/SOup8l2vTAGIJaHSVjyEQk2JykVSWomG8oH+GyF+qbNpCp4HAEAkEiQzXkpul88/R0AYNdumscVh+kZnV+Qad5d9jmfubluR54vxdLQW00rLmVxSqNCxyqLcqwwPot1RslfcflBAIBanfxyo82l9GTft+bJlk4epbT+kddLeR4vliiz44p+wRgDJl5nMFZwwdscitHBnp/xv5lMF8q5ZppJEzpMemx22ZKbZMdOsbl0O5QPZpn11TKL0RuW3FuF9bFjvbPJr9lz+Ofk+Mw/h0zG4rK1GEO2GoZk1MZqE/g8zuL6mnYfRP9v25/vE1wvAaWRSLrp4rEXxDGPOVI+nwBr7S7BZKG4BFPNmuPweUjIJHIrZSlLFrCxplii8a9j2TeX3qkxCQkuvwEAUGtRvYGC1G0KmTzc/CyNNfW6HGuOHKV789ijX+uVT5w4IurVWTtOnqaYMGGtn4YsvnNcuheuNXj58fy0XJYxUe+zq/6roiiKoiiKoiiKoiiKoiiKolyBKy4wI+KHEHEOEZ9l/zaEiJ9DxGPx/wfXO4dy86L2o2wHtR9lq6jtKNtB7UfZDmo/ylZR21G2g9qPslXUdpTtoPajrLARiYwHAOB3AeDD7N9+AQD+0RjzQUT8hfjv/3jlUyFALIWBViodJ5WmY1mQO756bE2c75zZBZkukcrQLsjzs/Q6eWNevsp9yxCl8/Cs23ROphnfdoB2XHRYRd+V18GlAzx3WRwrJOlahgcP9MoHDu4R9U6eebRXfvEopb0nPUvSwtDr7j7LAXI8a5d0llLLU2NDKxUF43TbHU62eQB2wH66HR/mzkapCq+899vEsVSKUuyG2Bv8k1My3WCxTHZw9jiluXdCmSrnIKWUuB7dr8BY6fvsngcspdlYO3zmiyO98kKN0iucpLTt0KyVUAo8MwjyabqufVO7RbW0S59zgOzj7rv2i3olltrxieZne+XZC/L5mB6jlKyApS3bKRWVSpQy9kLiLOwwD8CO+Z+I0E4T4psUs2PGSnkV2egsbevszBlR7+8+9cleuVIhH/CG+TlR759909t65RRLCbTbx63JZ7aVLxREvW9/97f3ysePSCmgz3/6c9QmltL14sysqDeIlOqXbtEFP/IPnxX1vGFKXXXGyZbqZenzEiz9/kLlXK+8XJX1VnbBre1smvoDsEO243kujA1F99tvyZTZAtul2viUful68vfbTIb8Mu/iRlOmbHbYrusppk1x+LZbRb1ZljLVZttwj4yOino+2107BDa25qX/6TTIttyMHAVcJm1QX6S+W27IfiwOkG+qMXmnIJQpgSk2/neZDMj0HunP+Bi1VKH7HlpSPKWh6Jrt3bS3yQOwA/YThiE0Yvv27PaxNEdg19SsS+mtZJLu5dA4pQhnrLRlh/ksl9ubI+//Mts1ulmjZ27vfik/Ve2SjSwtUV+nUjI+4unICLJRwp/5a/w7APAszSRLIXVcS3Kqy+UZ2P205EIMkz8LyzQuLcycAFkx+ly3ufpO2NvgAdgB+/GDABZqkazR2bqUhvFZum8SSZItOzgi6i2w9P0JnrrfkvcsqNB9b3eYzYzI8+UOkS9qMdmK2rz036mQ+splKaPtSzLFE1I038SSlOny2AAdVuj6M3dKmQ1I0ueyc0xmbkZKkZVfPE7nO0PPWWFIjqeLJXoeF2bpGi/MnRP19icnAQAg8OUztk0egB0auxAB3FTUz82WbGPtNPVDe57u2diUfDZzGbKZ5SZJbBWsOcnQOAXgly4xWYhA9mnQZunNNUpvTqEckxwmS7c4zyQUctLHLDD5qKa9o71H5zg7Q/52cpccu9J5sl2Pya80m9LXmTadb9c01Stac8bZ0+R/cnk6Zhw53mM8FHqJPhy7fB8qsSRM3ZKGGczS85JOUl932tLGQo/6qoFkY0ttS65lgGKCBIuvB3JSTrNUpHtZyNMYt1y2bILF3i6Q/Y1azzmn1bLmeB0mUcnkF2s16YdrTMozlaI2BZZc5XyVnrcl9l2troxnWkwq7vwMpehffm9jWUt7vrg9HoCdmnMZA0EvvrPmXezeiHjOnp+xmAlZPOhbkjIFFqOmmWnN16TcT6tLduYwaaZGR54v7bL2MXvMOdLOOl36OwjkWgKXkTEsLgpdSyqNy2Igly8DCZMu4LfJjqUEuPa6wsr5+9V+kskk7N69DwAAjj76VXFsYZme7+YSPS+79sn1NC4/yecHtqqMYTc7ZLKXfkf2dy5Da4YV9jxX69J3ZNh3Pf7EE73yqTlrXbBIsU8uK8e/JJKtHj36Yq+8VJZyXqdOHWPHKLYPjGy7kKlh1x8Edj1e5jYn7WTlfna7q8c+VxzRjDFfBoBF65/fDQB/Epf/BAC+60rnUW5O1H6U7aD2o2wVtR1lO6j9KNtB7UfZKmo7ynZQ+1G2itqOsh3UfpQVtvqT6bgx5kJcngWA8R1qj3JzoPajbAe1H2WrqO0o20HtR9kOaj/KVlHbUbaD2o+yVdR2lO2g9nMTsu2cHBO9M73m+/WI+H5EfAwRH6s2WmtVU25S1rMfbju+3587dCvXl43az6VLl1arotzEbGbs6naDtaopNykb9T1Bp71aFeUmZ6P20/DV9yiSTY1dbbUfRbJR37O0uOOyQcoNzmZ8j7+zknfKy4DN2E+5XF6rmnIDsBEN5tW4iIiTxpgLiDgJAHNrVTTG/CEA/CEAwJ6JYbOiAYbdplWTFhDrdXJKna5cA/cd0j+pNUj/pNKQmm7Tu+nSjE/H9o5I4ZUDU6Rx0mjRselD94p6SUOL40vLpDeSKQ3Ly1ggbbHdE5PiULlOmly33H6wVx4YlNpdA4OH6buYVt3SsqVvyjR8HUPaP93Q0kBkeioB0191LtOgWdFzuupsyH647eTzAyabHwIAgITVwHKZPp4aIn20hm/pWrHfNzKDpMPFdQKjinT/DHtCWl2p5ZTOMN1rJF210JGPVX6YdIyThjJH3IzUuTdJsp0Q5XdhwPrapfMnclJvO8M0yfw22c7CjNT0HM6RTuu7v/WdvfJjT50S9WpMH7bVpkXadlM+v6VCdN8914VrwKbt59WvfjWzGmvCxbQ7l5g26fKSzPJBpps1e4m+8uHHvi7qPf7cU71yZZEGyHZXau/defddvfLYKGlcuq6lb10lW+AD7r5du0S9qV1jvfKP/usfFsfOzrzUK3/tqaepTXXZX8fOkSZzdoKOLTz7rKjX+D9UPvDG+3rlpZr0ww0WYLaR2t7pykW3MNaG6vryHl0FtjR2lQayJp+K7sfhA1LjK5Ml/82fzdmzF0Q936drzuWpr8qWnp+L9Axzzbnqsry3l+ZIm09KYMl9AWpMkzI0VLHRqMt6TN90ICt1CjtME9cg0/m1NIUHmC54Jkv3wvOknRUKNI67DvN7lrbyyTOknYtsb4Gk5WdWfrwOwqs+em3a96SKQ6anQ2g1bzBF+pIDTMOzmbVCMza+JGrke9O+vP9jY2RXLaYV17H0YTNp+i43S23IDsh9C0o5imEmRsh+7X5qMW22hnVs9hKNPd06+YCEkW3yfLI/N6Tr7Xal3XsutT0EukZ73AWmO1w5f6pXbi/JsbBWi67L923Bw6vCpu1nLJs0S3HwMtuQCz7dCj3DI+M0ppvdY6Jeisc7FXp+vfPyh9cO06usMfX/IC91UBN7yQd6bM+KXEnGLd2jtD9Bl2k6tyxN8MJb7uiVG+V5cQyOkPYgcHu/IOu1Q2ZbExRzTXzT60S9VIZ8x+JRGhdLDelTinsppj7D9O4zrnyIE4nIL6Et6rjzbGnsyg+nDMaakqYlY5/RARZ3NJnuZFWOIWGKnq1Oi56r+Xk5hpgE0ypNUMw6yvbyAAAYG6bvHS0xW+3KPki4SXaIbL9Sl3Z77uLJXnn2nHy+F9mffvueXrlQkueYnX++Vy4i+Zhs8g5Rb2zqUK88NU3PFfppUa96mJ6ZDtMpD6zYvhHv35LOfA2uMpv2PYfv2m3C+LntVmW7h/J07ctlivMuNeU8dWQvzXMGc2RXs+fk/h8DLRprUh7VG2ZzOgCAfJbus+eSjxoYkPf//BkaT+r1NfR+AaDGfF6rIa+RDUOwxOKjclXGqaGhv71Z8kvJgtRUrTHN/GX20lTbSN/RZnPSVkjPhG/FN8HKnGI9Dd6dYUu+JzN1q3HihYbL/CP7mx+zdV7F50TR2j/AsL1LHKaX7cmxq8L0rnNsrxEvKb83xfYZWm7SeJVLSB+VT1K9U0vSLhqsjQk2f7TbLraP4NdvDym8ieyY/aao2Eso7IsfGLdkP4fvuNNk3ei5noy1mFfosn0B/DbfO0L2Y5k9t132nCUy0l8g298oYProviPHQsP2sPBSdMyzfshtM3t89hhpJC88/qSol82QPnzSkzGsYe1tNsk3hba2MhNNdsW+cNZ6jMPsgtmIY605ANcIN6t/JiJ+ttfYuW2rbzB/AgDeF5ffBwB/u8XzKDcnaj/KdlD7UbaK2o6yHdR+lO2g9qNsFbUdZTuo/ShbRW1H2Q5qPzchV1xgRsS/AICHAeA2RDyHiD8OAB8EgHcg4jEA+Ob4b0W5DLUfZTuo/ShbRW1H2Q5qP8p2UPtRtorajrId1H6UraK2o2wHtR9lhStKZBhjfmCNQ2/f7JcZMBDE6XQmkJq6/NXrTJpSGvIFKR9x/hKlh548RylOnqWbkLx4vlduXaR6B8fk6+5vfytJVbw0QynxhelRUW9keKJXnmMpn6WSTIFxQjp/0pGvp89dmqH2pimd71JZplLPXKB0qkSCrr80IFN7mk326rpHvxWgpX0RshQJh6elOHaKCew4O2U/yWQKJvfsB4DL291qUXrWxQqZdLI0Iup1fZZ6nqB+atastFOW2uB5LA2DpUYAyHTisWHqT7Mo5SM6TJYEQzp3JiNTd7i5hEY+H0HA+pCl6BhX3otandIXkaWCpax7VmE2nMkO9cpvef09ot6Rl073ys8+TylttYpMjUwmonSTcIdT1HfO/xgAiNJeQjtliD0uyxVKb3vwq18R1U6fP9crz1eov5fqMoXbYbIl6Tb5h7kFmdL74Fcf7JX37dvdK6dS0s5mmJ/rdigFq9mQ+lS1KksRtjz74dfc0is/efyZXrlTlf11jqU6ZpPUjl1FmU508rEnemU3RbblTA2Jess+pfUIb2iktEu7HfWN2cEs9Z0cu1wEyMcSNrms9PmJJPmSYomuP2NlDS0tkPzKcy8c7ZX9UD6bqSSlTA3lKL30/MyMqLcwT/bUYum5FUtKg+ff8ftbLi+JalzBpdOWqX7ZLPXe0HCRTo2y7W2mF2uYL2i2pE80wFLQeKpoW0qnBOxZzVj3neNdhTT1HbMfYwBi6ZeiJT1SYlIYMxdITqCZlD6gzeIlnCWfvH9YSiGM7Z7ulV88TzGQsWSgsnXqj2KObOeZs0+JevkJ8vN5lg548ujzol7A7LR0UI4h+albe+X66Rd6Zbcm9RkHDI3DjRr5skZVZlMmE/R8VFpkl5mSjNmG2QNYYxIvdjZfL57AnZXI2LnYJwm7d0dySM5J6QMy7LEKWGpoCmWcu8Rk5756lsaxqZb0FbcDnbDNJC2alu/pPEH932R5uzg9Leq1DlHc3PAplr3ngJQdqDvUp00mZwIAkFymFFd/gMaNzpkzol73ItlqYoxspjEun5HEEPmvwbeTvFPZkjQqjZBt3Zff2yt/7ivSb6Ziu7sszXQb7OTYBcYAdKN7mPSkXeSZn0kE1H6/I2MkTFEfZNP0mYU5KXUSMLWnw7dQTDM9vF/U85jcUatObUqAjIm5LFmN2feRk7LvL5Tpb8faLyEs0/mHDNn3oUFLfpHtEdTxmIRTV8ZtfP6RzNBnxkcOinojAyQjU6mTzbQtebCcF8ksZpIfhZ1ip+wHAcGL30NLoLTvTpOuo1Il3920pI/e9I439Mp33kEyGF/580+JevMz1DeTRZpbFQt5Ua/ToXveZrFDGMjvbfMYhqW/LyxK6TsI6TpsOYF6jT5XZn4oQDk+O+y5ml0gXztZkpJTwOSoqiH53rYVA/pIvsfN0vUHl6lM7PykfUd9DwCsDLhmneD+8tT7NY6xmDKwYr0W62O/Rs+swaKol0jR/Rxn40nGmkvvHaH1g/1jNHbl0rIeU2mBB49L2ZcvHqN2LHaova6llcbjVt/nkgSwZj0pXbB23LvelPxqqDrtpP2EQQitWJpnemq3OJZnc63mRfIdi0tSoqfeWH2uYWvEcv8Rsni7Y/XVUoWe7ySb+9nrbk3mf2pt5rMs/++zOZNrvfPLu5WPOw7aa3xkhLy/nXX8QxCsF++u/rnL5WtWaq9ef9ub/CmKoiiKoiiKoiiKoiiKoig3J7rArCiKoiiKoiiKoiiKoiiKomyJncvp2gCu60CpFKUn+J6UAKjV6BVyw1KclqvydffTZy6yz1BaTsZKW7hwkl5jH09TGsT09F5RrzRFqVuJKntlPC1TyXbdez8dmqV0wYwvdyIOgO9c2xLHJrOUwtlhr6djTqYA7crRjsuFEqUYVhdk+sXcRUq57rKUyFZHvoLPd47MpdjO8k0pDbGS6n0NdsPeNAYBTJw21O1K22lUKdUoxWQnqhWZCtVhO4M2KvSZhHW5hRylP40OUhrGwJBM0R4t0XcFHqXhNFOyfYt7qT/bAUvD7ModiwOfUipCK6U5YLviIpPIKA0NinphQOcM2H0qFmXqYZKlTpSZtILpSpt4xWGyv1KB7ssnP/lZUe/SxSgVyLf6pl9othrw3AtR+rdnpYly2YmlMt2Lck36njMX6Lkvjg33ykPWvR0eoef80kvU3y88+4yo97nPf47ON0DncD0prcN3xe2wVJt/+Iz0LwnmAqd2ybTg7Ahd872vuL1X/sZXjoh6DSA7O7rAZFQCafuDPqX6H3/k8V65PCqlNBaZ3SY6dMy2k0a8e3e1IqUU+oVkIgG7JqJ7GlhplIMlegZdltqYGJHP5sQo2cw/fuFLvXIYyv4uFejZn73AUnAH5b0tFWncKM/RfZufk+NEaZDSNHNMvqU4KNM3CznydYWiTCvM5cl+/CZ914njp0U9l6U+N1iKWKcjJTc6bMdll6UmIsi0rQxLxw7YGNftynTYbvxcmHBnZQ52BGPAidPvJvJyrL+4RKn8XdbvXkFKaTjMrvwupVvvve9OUW+J3b/OIKV1ulZ6szNAtlRmY2HVkjIJmQxPu8XGkwFpi2dZLFa/tCCO7S2VeuWp20g+o/y89F/1GbKlpYtUrtTl+QKf7GW5SfcsMyglMgq76W+/QfFgqynjIyfWplprJ+zrTSLhwcTU+P/P3psGSXZdZ2Lnrbln7XtV7wvRABorCRJcQUqUqCG1WhrbivE4PI75MxHj7YcdY/+w/9l/Ro6YsccxoxnFWBp7ZFtDiRIlSxQXcAFFEiBAbA30vlR17VVZuedb/SOz3/nORXejVVUEUsb5IhC42e/kfffde+65577K77tERNRYkXT94hhyKEHuwKBrrm5xH/72T97IymcnpD/+wzzH+SKsJ2lL5gU7r7FExs4Ux4qrPSmdhfTS+TOcBx0Zk/ElWOW1pmxIVVgJxI4GP1fOlutuHU5Zj69e5bbflvFwF/KY0tlFbt/xk8Kuu8ZtmgJ5niceOSXslo736/ByUvZpWOA4NlVH+rEgX5J9lrrcn6VR9oUoNmm8PK7NPZC9akpqbM6F+juQZ3WkXJ3l8tyMI75vzpP+GAJteQ+USdL6Q8KuEII0VSrzu5zDsi1rtRez8jFX5kiL+Uf4vjbIw7Sl7+8F7J/JDueIViIlf0ZL/Dmx2ecadZk/+AN5ofuoBLxvsMimXNr3ndkpOT9einl+7BL7xPzDsl+f/QzL4XzoIY4BE0W5Jv2//+fXs3K9BnJJLZl77mxxvwZAN0eZSCKiRg/lVXg8x4z4nyMejziSeWmtwc8VgHSB58v1rwv5yG4Xc145qB0HpICI51Rg5D3tiJ/fgXhVLMn7xgOnMen5w4I0TbM5bP6a0Ubptvs5/71kIYwKQeGHPOL+e3pUypk89tTTWXm6yl9KjApR4nRpimOKbeT/UcR27tkZca3eYds/vwL77NSQIIL3QS7keqltSiZgX4DPGJKzuEfBGt4hZZBmGgdDiTRNqDfISV1DgmqsyvurCPNW41nasF/xYW/d6cr8M4E57II0k/k6zIb3ad0uxwfbkAvEL5r7HwT6fmL4hRhv2NsYIp/3rs/oDNvG53qwmCHmpjFP381t9BfMCoVCoVAoFAqFQqFQKBQKhUKh2Bf0BbNCoVAoFAqFQqFQKBQKhUKhUCj2BX3BrFAoFAqFQqFQKBQKhUKhUCgUin3hPdVgTuKIGrW+FpwbNMQ1D/VLQJLSdaQ+ZRt0UccqrM00amgTdXZZp2l6nrUvF85/Wti9vszaKBcvc/nZuXFhV6vxtZmTj2Vlm6SObtBjTebRVOoq1TdYB68AmlBz48a9YtDSO886M52a1Kb73p9+JSsv3+L7Or7UICPQFuyAaEpo/H3BHmjQ3FcP6f1CmhINNIrdROrZjMDQL43ws37oxKiwK+dB5xb8rVWvCbtum32sUOJxOntajtPSUdbvsz3W9m7WZH1Lc3NcxzXW3KyOS58dB01U15V6fgnK4MCUyJeKwi4CnUyQCiLP0HLqEuuQTUyyLlizLf25VWP9woUp1s375S99Xtj94Vf/ctBuOV+HBa1Wk1744QtERNSpS53IEuhOfvGLv5SVo1Rqd7302ltZeaQC8zKRWk7z06zDFa6z/tNeS/Zt+xLrH4/leHxKI1JzrgzaovkSx5SRUdnXI1X2n2pVahkWyuwnn/nsM9ymLakz/frrrF0ZhzyXbtYMvWePY4y7xj7X2JVaYFGF55xdYB3GFUNnsz4Yk6B7b62q9xMppZQO4nnOiK+oIRy22LdyjtS4SkHsPU74O7Yt6xMzNeH4c/TocWE3CfNxcZU153I5WV8V/MmBNm1srAi7Z5/hcwZm5+fFtSjl8a9v81qzu7Ur7LZr/PyuwwFoalJqriYQ0JKYFcVGDI3i3T3OE1LQDws60h/v6M2n6fBpMLuOQ+PVvqbyZFlqK9d2WMdyHM59yBkHA6Bm+fTJs1n5xNySsHvjJs/fUdCEjUI5r6ZneW20If63DB1Lu8J17G7yWnB0elHYtX3QsY9lfN3ZZX+x545k5cVzHxV2K8scX7ugp+uZ8yhm33FgfvRqG8Juk9h3IljXbEc+Y3w/QbshQJzGtBf355mbynjtuZzCBzDfapHU0t6BxC9K+Tt1T2ryrni8Toym7HOBLeN6mnL+sJdw3y5vyLGv2pzj7MKtvrLyFWF3doF1ck8aedFEjs+BaF3nmBV35L1S0KHcBZ9DfyEiCkDXPdxjTevg1UvCrggKgz2Ym0fPSd3z8HZfLzwNh3PtojQlp9d/ltiS4ximPH/a0E3tpuxbz+eLVYt9JGfLHMSPQO/f4ZzY6Un93qTDOVLBgzw9lnPTgsk5V+H6Zkdl7OjEPNdbO9L3r22wnvuYy/rjI6nMnY9McxsvrF3JyrYlz1LwLO4zPEug25GBpFP+QVaOfXb+elf6d2Owr+sZ558MA5I4pXZ9oKGbk2c29GA+zx/ldejn/7Ycm1NnOe/zC+xHD3/inLCL4G3Ed//FH2flV65cFXZWjw3jCNZ7X/riDmgtj8P5FW5B7q06eAbBnhyDFkxpBzRge5Gc63ug59qGOXFhRZ7RdHOLv9cA3d3E2HP3YM9ehdypbOz3drJ5OoR7diKilCgdPGdqaL6m9t3bbL5/wHM18JyE1NCtdlweY6dyjL9TlDGl1+I1dMfl3LhSlPPy0ia/Q/rRW7ynb23fFnbFWc7L7Vg+Y9jmWFGG82i6xhlLKZyRIaJIKs8aifGMEdTajaRdAnZCT5gk0iwXGE7/SZKY2u1+7nPjulyfC3C22miV8+qecT4rYHH1AAAgAElEQVSLDa9jpib4HY6pi9yBHDGAOoJA1ofvOMTezzhXKIpA2/0e40YkdbHfcYQMnJWFms7mHEE9ZTFfDkGbHe/1Di95l3eF+gtmhUKhUCgUCoVCoVAoFAqFQqFQ7Av6glmhUCgUCoVCoVAoFAqFQqFQKBT7wnsqkUFEdOfX+nFHUlFS+PG+TfxT89iStJdd+LV6vQ4/3e7Jn7vPAS34w889l5UXz0r6zr/7nX+VlWdLTBV1AkmzWrnKlKnZE0ztyU+cEnallOk27R1J2SwkTLUKgAK61ZDU+dEpplxMzB7Lyp2mpCjZ8DH2maJj/iw+BOqeBT/bt1JJ6YoGHKVhlMiolIr06Y89RUREJ849Jq7dXmHa5MI8UyDOnJa0vNmp6azspNxHjYaUtOiFPB7Yl+WSIV1QBkoOUOA8Q8Kj02Ka1JOPMM3v2Jljwi4Eum9q/O0nSnhOpEB5cTw5hcMu0C2AsmEb1GcrDz4C10x6ieswNTQOuJ+mJiWV/ROf/DAREX3/h6/RMKLXC+jq9T7Vbm9D0vpPHz+dlQsFHuPbt+X8vXHtZlYul3i80V+IiKw6x45ODWgzxrw8dfJEVj45xTS4ypic5xsbIAs0zmM1tyT9sVHndvgG1SafcBytwr1+9uefE3Y7IC20vszPv9WTFRb3QIIIpDlcS8aOhQrPx9IMU51Xrl8XdkG7HzfTZDj56kEQ0s1by0T0zjjQaDCdGGUJAjLobS7PpWKFKV1BR1Krpqd4ncjZ7EsnTywIuxzcywaqu29IZBQK/NkGH0w7UqaqV+c1ORyR69/EHPuMDfT7o0tSKiGXZ7+otzhe+L6MUy5QAiOIOY4hsRPDuu6AlE0a9YRdudT3s5x3g4YNvufQ0dl++371C58V125cPZaVG13u/54hFRP12EeOzbPMRJoYdLtJnmN7sO632jLfWpzktTACWZFmS0qPpCAnUE7ZLx1jns6MsP+1NiQtuLnCcSmEOFKakb4z//Ans3IScszbuH1F2LWb4LfQjmpJ+o5L7KegCkFhW7b9Tu45jHkPEZFFKfmDMXITGVMmQV4ncNhHXEOuod3lfkepq8XjUmJlpQnzHvrDz8uYYgGfPUh4Ls5NTAo7F0JbHSRW0h25Zt7e5hi6V5QU9iM9fmZ7C2R9jLhpRzZc4vraseyLFGQ7ih2Oh6sry8KuCLTTVsT3Gu3J+06eP9MvGLnT0CAkSjb6Y5kU5Doe2DzffZAO8L0JYWcH/L0U5AGSSMb16fnHs7IXs5TP5m0pxYLSLlEB9nuBjOudDt8rX+Bxs42d68goy9D5VUMqYYrb7oPEQL0r88D1zutZuTzLvpSPpURGrwv7xJilpFKDgL6283JWznm83o+Pnxd2dtivbxjl5cIopOXt/rx94bUXxLWpk5wT/Mbf/9WsfOKcjAGWyzGl1+N5GQQyDj/y1ENZ+caPOeb/5e9/Q9j5AecBIUiUJKmclyOwx1mag9zJyFGb4HO7XTk/aj1e/3AH5XmyjobHdXij7GO3lreF3VqD7SaP8Bp8e1mumVHIvmBbPC/ruzJn6w7yoCQZ1rWLyLnH+ooyDoKGb0oIwGeUAjDp+VbCa9StNpff2pNx+c3tW1l5ZJznZWJIKdX22G/D5Tezsrt7Xdj98m/y+5rNFSmfcRLeQ9l5vtcLN2TsAXUrGoFcuZKTMSHnsy9YIB/bM2QcOm2QZuzyHNns3euV38GlFH4aaLUa9MMfPU9ERCs3r4lrnsud1mryXsPNy7WmDLJ7iyBXurcj3/vsghxTocDzfteQPEW10QhkbjqGZJdDkMc8YG5pmcOA/3AfiQzEg0YC6z71PWgu/G52+gtmhUKhUCgUCoVCoVAoFAqFQqFQ7Av6glmhUCgUCoVCoVAoFAqFQqFQKBT7wnsqkWERs1Nig05mwe/Okc2fdgw7YLCMTzAVZbYo6TFPPn0mKz/0LMti7G5IqmguYirmiUWmbCaWpMrMTjOtMOryvdo1Sb8LgEoXdmT3xsQ/1b8CdLzXXn9R2D37Ua5zYpapavWGpOzDgd80eYypGIltnJIOVKQIKMd7m4Y0RKNfYZKaR1m+/ygWC/TU+Q8REdHDT0iJjM4jLIVRGmG6vvkUeIqtDdIP46VZaQfdhz2ZGEd8RnhqKPhzryfp5SdPMaW54PM4dVryRPgUeX+W9J0UaF144nBscCqQKhV0uB1xImn9touSNPyUjW1JXb1xjelEH//EE1m5HUqqVnFARzuEQ0t/KkjimFp7/f5ud+X45OD04L0Gj8mNW9eF3Sj4VgxUcqsraZ2ra5e5fJtPqbdsafcbv8a0wqS5k5W/8d1vCbsbrzIteGKEaTdrl2RnLwB1fi9cF9fI49gxPsEnuD969hFhFvwy+92/+pe/m5U7DUmdv12DOOpym3qBnCPNLaYIzkP/+QVJuZ6c7p8kv7VhtHtIkCQJtQenkicGnSwA2aHxqXH4jlyTul2OEUtLTE1/8/W3hZ0Hc3NultedqSlJ1XVgjfKgO/2cjB1F8G8H5HWoI+Nep87yFjubcq1JgUpdAOpp0Th5u1rh+FNvs0+nsVzHC0Bjs8B/QoPaXy3wIhdDv1QNGr03YAu+g2I2BHCslKpOv/8+9uQRce0jDzN1t9Hm+BCmcg0PI+7XCOiPHSP2HA+4vjbQh5stGfM8kFbahXHPH5f92ulx/ekoU59X1laF3SWQDzo3Ni2u3dxkPyCQ6omBMkpEVD76ZFb+5MljWXnnlpTIePvHL2XljTWeOyVL0k4J6NjdmO9rGeu4O3CeIB5OiQM7sanQ6c+D29GIuDYN83KsAzTRDTk+UYP75qFzTOk9cva0sNv5CffnHMrTGZRwD/yz0OR+dg2CZrHI8/ziletZebIl/fvEMY6by74ch/XL/CyFBvuSFRkUaRjjLsiFBEY+HLT42k7MeUyxKKWpGkCdb/X4Xjsrco1yj/TjaBwPp7xT3i/RucW+vFxczIlrMSwcczC/8yOyL6yEA+vmJs/1nZZc45w8SwZ2u6NZuRPK/CFf4DwrCPhapyXzz1aLfQv7N47lfasgOVUoS4r0CsSfrsPryWpLyhKUt3mMnTGuI6xfF3ZFm2PkWOFYVnZ9ufhEPbYr5Xgftzgr55xH/Zid8+VaOgzwcj7Nnuzvi6OyXJsff5r3Yace41wiTuUeO4x5fEWMdWR/+WVek448yn3U/PI3hZ0bQo7R4jnqGzKAj3+IJeiOHefyXku2r7XBa+Na24g9bV4rHIf9z3Hl/qc8y7Hn47/wLH//j38o7G6HLKHwS7/5M1n529/4vrD7q+dZ6msF5DPCnswfrCxGD2HiM4Az2K8mxtrgOyCTA+8cepGc25KGD2UjR7KIx6cH8WrbkD3xwe8qXYgv8rZU7vLerZtyjhQa70eiXV6f1m7JXD4C2ZaPPffzWXmyIOf6dJnj8NIExDJj3c2DLJ4LMkOx+W4C8rZra5wX/PZ3rwu71YF8xrDKg/W6Hbrydl+6aGdrS1w7cYLlRnPQn91ADiSuLx7ECPQXIiIHNg8NyLFT25Apgb1L1OI4kBrrfwD7P6lgc++5ao4Cyljcq/zTwIP6g23f/zfK+gtmhUKhUCgUCoVCoVAoFAqFQqFQ7Av6glmhUCgUCoVCoVAoFAqFQqFQKBT7gr5gVigUCoVCoVAoFAqFQqFQKBQKxb7wnmowpylRMtCr7PQMXZwS6xO7LuvROLbUfTo1yzqU+QK/Hz92dEnYPfaJ57Ly3NnzWfmV7/+OsDuyxPXNPvwot2fqpLBzi6x91+6yhlOnLrWY1m+zZu3u+rK4FoesL1aosGbM5KTUI711++WsPDPHmopRW2pHpR3W2bFarLEXp1JvEfV7Czm+lz8r71vPDXR031OveDDYtk2FUl9HuJyXOnKlIjTYZb2cxJCRQd0aG8qm5nQSJnCNK7EMvZkIVJ5Rezi1pF15lPUFo5i/EydS24dANyo19IFsvEHM5diVY5iiik/Ec8dKZH05uLcXc3tLXdmmdJ19afMqaw8unl0Udlt23zeHVoM5TSgYaGO3QZuTiOjyNdZM/vIf/kFW/u7zzws7K+WHW6/zXNy8cUvYeeBOIfS7Pyv1M7/37e9k5V6d9aXevHRR2LXWWcuptsn1jU5IHa/NNbar78lnHBtl3agg5vq/9a0fC7tClbUCxyZZS3Ur3BZ27R7fawX0mdOcdIAitMMBXd/RCdkXzkCP7cqlqzSMsCwr023vdeWalBMa1ByTc3kZB2yIK3HA86qxK7Xw203Wezt+hNehgtG35SJrtY2gZmQkdQTjmNvrONymyUmpgbsBWoSrqJtLRC+9/mpWPgWa8hubdWF3e5X1AiPivhitynt5EDtzOfbjyJXxp9dl34LwSMXxUWFXb/bn4zCGnySKqLnTX5+Xr70uri0usB7uwhxro7tF2V8JaPLXQYuuVpO6wxPjPH9bcH5FuyN9tgW6uY0mz8WzJ09IO9BA7YKm/1RBrsFej+/11DPPims7oGt5fQ20V20Zv+IO6LSOsfb4/Pnjwm7q/M9m5WiX16SdCz8Qdtde/1FW3rrCMc/2ZWy03b4vWqEhwjgkiJOU9lr9PvzWnmxjxMNNH094jAsba8IuD7nnE099NivPL50Sdn/8w9ey8l6PxyN2ZUwJQZ+5AOtid1ne1xnn3OfEGGv8dmN5/oRb4hh6/hMfEdd2QGZ85yVeQ3pGgpe47JMdaFOpNCHsqADnYPiQL05Ijfsu8bU1iId7NakFufvWJSIianWlzvCwoFgo0/nHPkNERPaIjCt2mftiNM/6xE5Ozm+HOM98420+M2b7ptSjvrbGfua5oNtflnHdhzM80pDHvrUn9y5RChq7Preh3ZT7rqvXWae9nJc68nHCsbMJGv+bDZnTnAyPZeWdFfb3m9cvCDsv4GcZLfPzzx+TOc1exD6TjHLfjnuG9nOuPybpEJ5943gOjc715/B/+l/8x+KaD/vv0ObxsM29C7xmKBTY/9JU2kUJj/X8UdZ0PvOQ1Kxefo37L435O44ntbcDl9eXV66wpvFGTcaetU3I5ffkOlmHOGc77JvlvIyHzzz3yaz8kS88k5W//5Nrwq59mfcKpVH20y/96qeE3cU3vsxtf5Fzhs98SfbF7LF+zHLeRQv1/YJlWeQPznuwbDneI5BDtEFP33yngk92P2lYH3LbFDJB15hXR6p833MznEfuGHn4XoNjGe7jNuryPcy3YJ/4yNMfE9dycB7KWJljwNLMlLCbAg3mUdDJt42zwIoQ22x43iCQ/lhrctvfvsW637GhhW9l7wGGU4M5CkLaWu6fQZTERnYPcb1Q5HHc2JTv3coFfrfYaHK+7Bma+V1YvzFdLhhnM+ztcR0p7LWKBXnOVb3DPpOAf9vv0E/G9z7pPa48uO7y/fSTbdCTRrsH1Vw22/BubRrOqKRQKBQKhUKhUCgUCoVCoVAoFIqhh75gVigUCoVCoVAoFAqFQqFQKBQKxb7wnoohWJZF3oAKvQv0AyKiuMs/tS4Umeri2PKn29MTTDO4tcqUhpNP/rywW3wUPzP1LWxIeuRIhWlNU2cez8otd1zYvfEy0y17Ha6jXpe0iq2Vm9z2WNJt8nnu7oXjLH1x/oykKUYO/9Tec/in/54vaRAu/KS/fWMlK9+RIcnqgz8jNB3+iXxxQv6kf2a+TyX0vOH7u4PjOFQZ6Y9J6khZiHaP+zntMWWq17s3LTgAqlyvJ/s1ipiWEoYhlGV97Tb7cLvFtJ4okbSWyjj7WGWEx3O0Mins8j7TX+JE3osspsbaxOVKRdKMtzf4e90OU3mSRNI/LeJ7JUAzq1YkNfLoEaZtd9rcf2kiqbojlb4vDStVy3EdGhmMQ2g0sQ6SBG++8kpWXr8m6W1I9SuCNIlvS0pmGgTwHY5riyB3Q0Q0XuEx2W0z/e7EsbPC7kbMlJzaDtM645yUCVhvQTxoyxhQ22EqpwUxoGtJin2tzVRT2+c4nDjGMwK1uA1yB3Ekfb8EdZRH+HlRqoGIKBnQJR3HkI0ZEniuR7OTfdpmzoiPxRz3TaHI4x0Z8d8DSnc1z/Pn5MKMsBuF9W9+mse4nJN9Uy3x3O/a/B0/kWNVB1p9vsR2XlHGUaSK3tqR6/Pbl9l/1jbYz+p7ki4Yhvz53ENz3Pa8vFfcBt57cnfaFhFRHmjRMaxrliNTlyjuP6NJMRsGOLZDowP6XGNbSgiswloxOcu+M2I8X6kCcx1o7o4l164KsIRHykBHNmJUBGvZhTffyspTU5K6WSyyHEob1s/HjslY9umnn8zKnUiOQRuWitNLPIbr25IOf3uNKeVr15hKfDOW9XVBPqQwylJNo4/IHPDxs0xXXbjGEi+vvvCnwm5zrR/nU0v6/LAgjUMK6n2a6+VtKUnQAXmB0UXOJx7zDL9weRCOL7GcXLUs89wexKxem8u+J9eTbgrXwLf8QOYFnR0eU9tln04cOabrMC92L7wprhXzHB8aeaC7ForCrgf+jtIuxUn5jDsBx68GxBQ7lP64usaxzM5zrlw38sBSvU+5j2LZR8OCXLFEp85/mIiIUs+QpQHpE9cBOatY2lkFWO9f5+dcuSVlJna6/LlS5rGK1qQ/FnN8bXqcpbgmqlJmogk5ZwDjFhoyVc0a53BdIze1IZdudjmuNA27esI5vAX7Ts+S6/OblzlHGpnk7+y6hgxUiZ+5CZIg27tyzTw+8zQREfUiuTcdBiRpQq1ev+2lcekTCfHzodyFZeR2EchhpqkQPBB2AdD3R2e4L7/0a18Qdv927StZuV3DfFPmR9sgrzk5zX7VjKRERi/k77klGVMKDvvI9BT7wTMfOyfsPvozT2Vla5Sfcf64jD1JwvnM5cu8v/jS35KyQGfPcu700o/fzsrL11eF3dFT8/17WkO677JtKg361DFi/g5IDbQDvhYb6z3BnlJQ8g3pCxtkLGKY208uyn3Sp07zmCQg9bdnvA2LQWKy3WCfKRsx6rGnns7KT3/0E+JaGeQuAngf8Q4pSZB0Ql0E35AqwvcRy9dZCuLbL/5E2L24yvHmQo37ZS+Q73xs1zJvOVSIk4TqA+m0orF21Wv87s0t8LViQdp5MK69Lu87ykXZF90ur/8pvBMKU7nWpOAXuF2Jjb0LyqFiD5tz9UHlKR7U7n7fwfczKP8a7zN3SZL7yzoNZ1RSKBQKhUKhUCgUCoVCoVAoFArF0ENfMCsUCoVCoVAoFAqFQqFQKBQKhWJf0BfMCoVCoVAoFAqFQqFQKBQKhUKh2BfeUw3mNEmod0dPJSdvbYHOmmezLk4aS52sQpntfvFv/2JWfvYLnxN21UnWS1q/eiErO7asrwbaOpvXWevodkNqknzrD/8wK5cLrKPU7Uk9rdkZ1uepVqTGy7Vl1v8KoB3j88eE3ZlHWc+JYtbg2aktC7s26Fbvdrg+K5V92+2wTkoTdFfSZlfYPTSQKkqGT8aSarU6/eFX/oyIiGLvO+La7i7rEjb3trKyId8tNJnX1/k7sfHA41OsCTc2OZGVc4YuZmuHNYAuXmIfqzelTywdP5qVHY99p1qZEHbHj7Pe5eLSrLx2gjUvx3M87hVD2zQZqfIH0LMNjXnkuPy3JQfqmzlm6EJX2f9C0FkzJHlpfLx/X9cdTg1dx3GoPNBgdo15GWyz9t3WRZ6jS2WptWWB1mSjw3Ona8QUCzSgchb3x+b6jrB76QesmzVTYc257V2p677XYW2oJkgedbbqJMHj6BoDVPDYx7ugEb1Zk/eKbdBod1nQ1TK0te08jjM0KpVai60Wt71e5/LYhNRFo+RO24dTDSy1iNJBH+QN7U8P5pKX43K30RN2YcjzZ6TC8/Txx+Wcw7HyPB5H15VjGqP+lc3+mPNlnCqXQS8c5nqaSDsPxvjNt94W11ptGNeY54upX++DPr5tc+xILTmuic19UQf/brTlmoR+HIC+a9STdsFAez99F02w9wOe49DcIPZYgeyvnfWNrPyTVy9n5Zdfl/0/s8C6uZ/89Key8sKUjFHdXdYRdmD+kqHB7IIe7pF51kYvGOtJzmefqPrg9xVZXxhzHY2OfMZOzGN/4dL1rLzb2xR2T55g/efmNLfv2qrUrb5wgzWjf3KV+6xhaNJPVrm952Z4/Xz6Uz8r7F7+/teIiOjG5eHTQCUiquZs+vzR/pq1uVMW1350jcf7a9c5ly2ckGtcscxzseJwv4QNOY9ii+dlC+ZY3sh9YtRZBU3BxFgndlqcC6Vdnr9+S943rIGu4ZWb4loRfgcTFDluvhbJ+Hp9i+dSHsKAn0htZQ/OQrFC9s1uTa7PrZTXZBdiaOzJWHZ0rO93viPz82GB7ThUHOnHiSiR4xPjo3g8Pkkq9cjzsO8KWzxv1y9Jvey0zH43NftwVr789m1h17Egt2jxOLoLMhe3QKd39eb1rNxqy9yn3WY/cww9SSuFeZ3nfCf1ZKy7tca539gIP8fSkUVh1+tx2zsB3zcw9oKVcdwnskMGdakBnKO+pnNo+PMwIE0Tigaao4n5czTYD7igYxwZup8pvGZIYW8aRjIGpDb3UeRxXyydPybsCrMcA/Yu8NlDlivHc+mZ41n5F3/j81l5dV3qGG9ssE80WsZ5PHD2zcIc52lHjkwLuwC0zHc7rEO+eFRqMLs2+9XVi9z20q/LvOXpJ/lcppd/fCkrd1pSDzYOB98bwj07EVGcxFSv9+dq1tYBAsj1U1g3/Pu8lcIzNkx3dCy+dmqG+/k3P/2wsNuDtWd3j8d+zHgntdLkeXr+EdbcfuYTnxV2Y+OQPxk+mIP90FiV94V54yF92ENub3F8fcPIw7/z/b/Kyt/7zvf4OVyZ+4w/+8Ws3I64TYllaO0md84uGU4kaUqdQc7skNxn72zxmjI1w+9LFubl3MzDGTk72/x+aGtTnh+QxDxWRZvLvi3faUzP873WtthHdusy/t9bg/nee1zzGn4+DA1m3DPa99I2J6nJbN/nXK37PQvRA/yC2bKsJcuyvmlZ1puWZb1hWdZ/Nvj3ccuyvmZZ1qXB/8ferS7FBw/qP4r9Qn1HcRCo/ygOAvUfxX6hvqM4CNR/FPuF+o7iIFD/URwE6j+KO3gQiYyIiP6rNE3PEdFHiegfWJZ1joj+GyL6epqmp4no64PPCoUJ9R/FfqG+ozgI1H8UB4H6j2K/UN9RHATqP4r9Qn1HcRCo/ygOAvUfBRE9gERGmqarRLQ6KDcsy7pARAtE9EtE9JmB2b8mom8R0X9937oopSQdUDwSg8YUAT0GaAWWJX/inc8BtfgplpLIGXSnN195OSvv3r6SlXsGtbaxy7S4W5eZ7tVMC8LOi/l7ZZABqOYlFXFqjCmrq+uS2hmF/FztBv+c/tY1SQkkeoPb0Wxk5bwr+yLKMRVgO+J+KQBFn4ioWOFnKbhMlWwYNLPop0CXOCz/qTea9LVvvkBERKOLZ+U9Yu7Ll1/4ZlY+uiipbZMTLEmxssxjExm+WBxnukkAtK11kDghIvrcRz6WlR8/zzSctuFjtgd035s3svLFS1eE3Wuvs8+Ojkgq7K/9e7+SlT/+8Jms7Kfyb0SLc0ylDkAiw7INijpQJ0ICOoQr+yI3yr5UAKpE4kiq1p3Z9y6Mib8WDjX2WETJgO6dxrKRPtB9PZAxOFKV9LYIqDINoPU7VTlWts991llnCk2vJmmnjW2e21vAP6z1pN2xJ89n5TWg9dR2JdWyDPTUblvSvUOP29TtMdWoY9DWbPCTPDxHaknqYAyyGA7Q7e1IRo8EKDkbm0xHiwymlutbg38/PImDQ/WfhCgI+/3WaMnxsStMOe/UeEzDSPZZscCUawckC2rbchx7IJGx12Q/QxkCIqIUxtFzedw8g9LVjoF6C/0edCQlF2Wr1tYkjbSXsi/0HKCPGbIdDkintNt8syiQ8SLn8/f2uvyMa9u7wi4leJYUaWbSgQp32n6IAeiw/KfTbtGrL/+oX+f2DXFtZIJlIV56g6Uf3gIpCSKijz/HEmC/929+Nyt/6XOfEHZjefadPPib60lZl06XfXhqgvOIJCfzmd3e3WnbliPXnRB+q2B5Mv+4fIOlA37rH/9WVt7akJIEz3yUn+WLv/53svL07JSwK0XsL/MRj/cbNRk7EqCdbsC6e/rIjLA7cbZPf11bvkyHhcOMPXnPojPzff/+T4pHxLWlHNOsv/E250Ffvy5jz+NH57Ny88q1rFwzfmPiQLyuBeAjxYqwi1OQTEj4XpupHIOtIq+NXZfHo2LJrUdphOtPAkmFpW3OU3Pgn8tdKX2xHbPvz8J+oFiS63OlxHWkIHW1Fcj6XAfkZna4/EgqY1650X9++xC15Q7Tf4iI7iwJpuRgGHJcjmCPk/hy3icN2JM1OQeJmuvCbmyKZQl6m3yttSFz5yjheRs2eXy3N2V9To79rNNpQFnuXRptbpNjG9tah59r8Thfm56rCrMib40EtbgVyn3c8WM8B92YpXfawRvCznY57gUx78FKZbkvuTN99sGAvisO13cssgb0bty/Ekk5PFSmarel76RCspENYyM/8kCeKYCwVBiV+Ux5nvdnay32iZEROZ7TJzlfGjnGMSA/f1TYnbL4c9iReUqzy8+SwNyxbVOGhZ8r57AjTU5JGcQKyCT4HsehYkVKXT32kdNZeezLz3MbZJdlec+7UdX/OjjUvDlNKRjQ7VNjbXAhZ7UckAIw9gYRrFE+SgYYm4iZMsflX/nIiay8OCrjdRukDGZGed0Zy0k/myzx/v6hsw9l5eqI3BcGAftIzpFtsuFd1s4G59Q3rsu9/w9f/HFW/tGPWTrx8pWrwq4BsTKG3HjsmV8Wdp2Y/cyK2Kc9I2+jwfuDwxQmPNx9V0xRp78/Sszfw8aQc6Y8N11X+tnsHEtaTIN07p9d+VNhNz/HORKo4FK7K2NCC94RRLDmm+2zQaP1frEd5+795jHupU3pC/m99C6ld9ZxP7pT8WgAACAASURBVOkLvIZl877vJtvx1zrkz7KsY0T0BBH9gIhmBo5ERLRGRDP3+JpCQUTqP4r9Q31HcRCo/ygOAvUfxX6hvqM4CNR/FPuF+o7iIFD/URwE6j8fbDzwC2bLsspE9AdE9J+naSr+fJz2X2Pf9VW2ZVl/37KsFy3LerFl/HVQ8cHBfvwHfQf/Sqj4YOEwYk+72bmbieIDgMPwn65xOJvig4ODrl29UH3ng4rDiD2b7ehuJooPAA7Df2q7u3czUfz/HIfiO8CyU3ywcBj+E7XVfz6oOAz/iQ+RFaR47/GuEhlERJZledR3lH+Tpum/G/zzumVZc2marlqWNUdEG3f7bpqm/5yI/jkR0dJ0Jb1DkUki+bIZKZwxUB8C4+TImRGmvfz5V/4kK4/PSHrSNEoFtJmC7Hk5YVcuMa3GBWpxyZDcmJ1mqkunwQlbwZH1bW/yKZVhIOkSlTzTpIIm0zQuvfyisFt962JW7gEdlDxJ4YixvYtAbS3JvrVzcBp4wv05RlIG5KGH+/S2Ql7SMg6K/foP+s6x46fTX/8P/iMiIspNnxZ27QZT2C69xvSSudklYYc/9S/kedwD45TxM48APWmO6cPtSUlR/+IXfiYrowxJy5DIADYgRUAT6hqnKG8AZfjGNXnqdhFOT19bZjrg9TcuCTu7y3VeXeMu/cjnnxZ2R48xHSRE6lde0onIYx+2wHfIoKj7Vv+5DlMio1/f4cSemYXptDaQL+i15fwoBTyPpma5X7ZvyGovX2ea9WbI/Tw+LilTNszzVsKxIg5l50RAJez2gHZjyAJtrnFMaTWZqpuG0q6Y4xgadKRvWTmOUxHQ/vySpMSnIFHR7XE/Jba8VwDxO+exz/h5I74CRboA5dBoezY3DzmfOCz/Ga0U0q3dvsTH/LSkPaJkRpSAX0xIv2jUwS7ics+Qj8Cc6q3LTGe3LUn9QmmXIzCf7bIcg26LfSuGe0UGJTwH9ZnyKxdX2PePT81l5XGD2umOc5xqwYnsu5Gsz4VTtBvgq7uG3yYgAWRBuuJZMi9oDeZSZGqvHBCHsXaVi8V0cyCP85a3KeycDY7lN1eZQvmpz31G2P2j/+6/zcr/5J/+r1n5q3/8FWH3oQX2Tc+H/KAi6cN4SvQ4UD6nxuWPSlyQv/FB1sQ2JA6asIYErvzdwj/7334nK7/51mtZGeMGEdGXv/J/Z+XFs49m5UdPnxF2hRzTP6tAjZyXSggUQTtaIIuUGn+sPrrQp7y/aLTnoDis2PPEbCHtDeQqxvNyDfnYmcmsvNXi+PDSipxvF9Z5HToN0hKBcZp9ClJNDVgn0p7sGy/vwncgYBkbQhyrRspzu27IlEw8/KGs7BgqSa/9OVPEl6BNi2NSOoVgvcoDTXYvlHGutc2xdxbWpPlJGdd9kFrwdrg/jzbkafFLo33Kvu8cbvJzWP7z0LmH007Q7/ugI+NjF9aAOOVyFEn5moi4b9t7/NLIzslndkvcZ7Utfqewtbos7ALwhSjm8SiPzgm7qAsyDCDZ0u7IONqNuRssX+7dXJCcmlzk+k+dOS7s1rZZnsOHcGnZUrYjaHHfzI5xnCJ7XtilZX7+t9/i+Tc3JX2/NMjbXPuHdFg4LN85e/5o2gn6/ecY9Hof1oYIErd2T+YznS74i6Bly1hRcnguxhZStGVOMDrH+7DI4bG2jb39+Djb4R4nIPkHXzvimGIZ1wikMAKQk7FS6fcpPIvvcKwsV2VMGZvk9s4tsL/EtszDJ45wfUdOch2mvJ872HAd8rbr0PynMHsitbK+kTmbBdIpGGtHinKt6cHTRRHX4YQyli2W2WfOgo90DIkDCyTjSiBxevS4lE6xT7D8Tc5n34qNvLmxxe8fXrosZbbeeIPfS738E343ceWqIX3RAOkLeMYkls/owJTJT3AcqUwtCLsU64B9u5Cc61/t//th6fMMcFj+Uy166ZHJfnycGJcyb6Nj/PwevB/pxnK8N7f4NkcXTmblpQUpNzY1ydI7Ucxx4PYbF4TdFsggBpCrWIbkhJT3fbD+vd84SBkMy7hGd71mkSk5+WByHBinHZBaxfn3IHjXXzBb/Vb8SyK6kKbpP4ZLXyGivzso/10i+qO/1p0VHwio/yj2C/UdxUGg/qM4CNR/FPuF+o7iIFD/UewX6juKg0D9R3EQqP8o7uBBfsH8cSL6O0T0mmVZrwz+7R8R0f9IRP+XZVl/j4huENFv/HSaqPgbDvUfxX6hvqM4CNR/FAeB+o9iv1DfURwE6j+K/UJ9R3EQqP8oDgL1HwURPcAL5jRNv0v3ZmB87h7/rlAQkfqPYv9Q31EcBOo/ioNA/UexX6jvKA4C9R/FfqG+ozgI1H8UB4H6j+IOHkiD+dCQWpQMBGl9V2rBoGYa2aCX50htogQOW9oC7Zvm5pqwK4SsaZOA7sz4mNREGp1nHbcItHlWbsv6UGPJBr2gwNAkcSzWWCrlpWZMBI/o4AdDczUOWO/NBgHfelse1hHkWAuoMs9tbxVqwq6RsCZNt8WqKBPVE8JucqAt6nrvrVs8CCyLKOf3237xrdfFtfoejxVq2ISGtmmz2YL6uF/zOanZFsLBBHubXN/6zVvC7s/+/M+y8m4DvtOU+oeVKusDjYyx3mWpKjXDlpdZd3l6Umoq5ausBf2dr/J9dy69KuximB+X11g7brklD1s4/RDrTI9U2U9HxqSmaqHIGoojJe4nLy/nb7HYf5Y0vde68j4jsYg6g/Yb50VGFmt+teCxVi35jKswZ5sovrQtx9vxQCswYbs0kX3TgdiRpqy15RtaoCug6x6BRrJlrOGbeJiPoa+UgpaXV2CN6Kov74X69ziXHENXtUCgfQfafJ7RdgvqT6EvLEPPL9N0PWwR70NCEIZ063Z/fnqGFj5qGS8tzWblVls6Wr2JGszQt7asrw361hcus1aba9jdvsWavZOgNzgyMirsLl1iXThcx37xb31M2OVSjlNjoxVxrVDnuLJd4/UlCaTGF/ZNvclxpdVrCbs29JkN+nbdUNZnObwWJeA/u0aMnazI8wSGCX4uRwvHThERUUwyDoeg5e6XWINybsnQ1IMcYWl+MSv/5R/9gbBrrLEfFAvcr7mC2T88z3Iuz2XUTO/XwWOIcSnvy/pS0F7f7MhnfOPCm1n5Z36G9xePPf6YsPsXv81azd//Nq9xJ2alP/tF9rGtNV77f3LporDzStzGmSrXERs6tIVBXjGckacf5+/MAyuSMWVulNfnZ4/z2l0PpG7p9RqsSaAVPL0kz6lwfB7vLsSobkOOqRviesX9LLMHomidtXKroIPaAz16IqIdmPejY/Ksi1HQY/W6/L0F4/wAHxT/rBL7o+VJO7vJ8XXG5ec15K3JhnMR2vD8I45s+8kj/THIvfTAZ6a/p0iJKB7kHuaZSXmf43wIMTqorQq7nZBjfnGC59KnP/9JYXcb9ii3dlay8tRJmesmMKZxyP0ZkNS3LlVZp3YD1rtuIDWYTz8O5x0U5ENu77HO/eg0xC1L5v2dJjvA+BT7TJTKfdfkDHv51BRqBU8Ku1qHfWtqlO1yjtwXbtzur4VRaOplvv9IU6LuYOm3E9m+EHS5wxB0jI39rJ/jdQPzy8RwRjzzowt5RWhsRysjvEY5cM6Al5drUs7j8ei1ub7IljE06bH/uYnMsRJYKlLUAg7lvr/dgTM1bH7enR2Z93RAR7wI69PWjsxnIoivJTjnotWSa1e73R8csy+HBZZlUe6OTrYh/3tmnve0J+f4PczR8bywq8G+fQ/KvnGGUSXkeRp0uZ96PTlWlQrPPzy3xjjihEolbsfuLuv4fvOb3xF2L7zwg6x84a0r4trWNrQJ1u7YmEsU312v13Gk8+P67E2whrDly5hiwzsfzKHTVN43zc6wGE7/yfkunVzqz+NiReamXonXoRu3eY+83RDnCVK7xX2xeQT08xek3v8mvEO8ep3f9aysybWG4L1AimVjDt5P4/hBgXtwG9+LmuOFe2sh1SzbkKS4v7+3Hr7Ihu/3GO/yiMOZESkUCoVCoVAoFAqFQqFQKBQKhWLooS+YFQqFQqFQKBQKhUKhUCgUCoVCsS+8x1oIFtlWnyqVzxkUS2IaQwlomaWKpB21gVI6UWEqikuSBhHssTxAApSVticpAjMzx9kOJBXOnl8Udi988+tcd8o0F8/4CXoHaNDVSlVc813ubgf4GM2upHpcW2VaRa0GtEJL0m2mzvDfBxZGuT+DVNLUd7e4TX4XJDwWpFxIp93/+bzJ3hgGJFFIje0+heEbf/RVce3W2nJWtkOmXr/6qqRKIF0gQmkTgxvztT/5Rlb2Pab2Pf7Ek8IuAHphHWhWV29uCLvt7Qv8nS7f6/badWF37TrbPf3EU+LaP/wH/2VW/uFffZ+fA+h//XYwDacDtIerL0p5j++8xHTDksv0d8+XPCYnx89fAYmMxaPHhN0v/dq/T0REQTScf7OyLIvcASUyTCUdpNnhPtups8/sBJJKF4F0TBpxP3U7cv5aQPULgZJkGxIHpRGOD47D1xxXhmVksgjZCscYK/iMdJr+Zy4n8ME26wCpohj4galZn7gXUJNNWhBQYROoz1AW4vmYDidVKyWiaNC27T1JZ6yCjAzKYJjjiFJNLaBU2saUSROQPirwdzZ2JDX7ldduZOVSgWlcvW5IEjymPkjbXLh0Q1jNFHmtxblORDQ7y9e2bzCVzHLleG9scjsWF3l9iQ15mB7Q79sg3xMZdjH2RZUpcoFBR2sNKLXxELpPSilF1Pf9ODHpw5DrQLqAfkREtL7B/bq1w/nB8pqM/2nEY485VhhKai22IgdxrWTIRTkgZVbIs5/nDfmvBGQXbm6ui2sEskm//Cu/kpWfffZZYXbrFq/jX/7KH2fll39yVNjFXY6vu+s8F4PtFWHnxrw+tyOm3l/dlWthcUDh7vU6NIxIiaWn0kSOo5/wGnVunMdxc07SSVuQF0SwXk1OTAm7fJnp2DXw1TCQMSWCzz2H67MNWakqxDYkPgd1GUMJcuB0TeZPi8DD9BxeOCodWce0w/6+C5IguYqU3EhCblTUZukHzOGIiEAhgxKQj5g7Ny3sjh/p92HOHz5pOaI+dTcYxEfL2PJZCQxQzNe8vJS0yINkUrnF5cZVOZeefpj96eTD4Av2jLALOnzfH32b69jakvGnUIE53OE5PDIu7c5/mGPEtY23xTWqsP/MH2EJq7ExSZEul1iOoxNxDGsYUldJyvde3mK5vvFRuVfttXkujRTYB0NDoqfX7Q3qHb7FK06IWkF/zkWhlBx0PR7DRoPnUaUkJQ6mJjgPSD1+xtR43g7E9U6bY3HsyP1ZnHAMsH0e21pT7vduXON1cmyO/cgpSBmWNOZYloQyfjW63I4u7AfMtoch1xHBM968JaVm9oC+b0P/1ZuyTTbs4Ttdru/SZbnG7Q2ky8y8YlhQKeTo0+f7coyjRdnGk1Oc8JRAwm/ElZuDEHKQDuSlUUu+D+m1IZZhUm1IthR9kFyy+Vpz67awa97msfr6D17Oyr/3/8j3D1uQm5nvThL4DWcCa6OdyvU0hRzdgncOmB8SEfk+P787DTJqrpxzqO2SEMrXGPuzTDJhOP3HcWwqjfTliuyclEprx9C3ILnoWvL9VyHH/d5occ7QCuV6f/X6tay8s8NjH71jbllQAtmKd8Rv+67XTLv7SmmA76L6qGvsxxMYP5SiTAwNCwv24yFIlsWGdApWb0POkLzDT+7vN8P5NkihUCgUCoVCoVAoFAqFQqFQKBRDD33BrFAoFAqFQqFQKBQKhUKhUCgUin3hPeV02RaR7/bfabd7knbk5PnU3sRhikA7lLRFB+gnOTjJ3DNOivaLQE+q8rU1g77ZXmApjOmlU1l5ZWNL2D384Y9n5eYmUymuXnxD2LWaTBVyHdn2EaDEW0CJWF2R1IybN/hn/HaO216dkXSJqXGoDyiG1o7si7FdHuaFaT5teXFUyoBcfrNPfe51TIr1+w/P82lupk9pO33suLiG9BLX5rJjmbR+oCwA7cHPy/4ij+km8/NMQ/nMz/2cMKsUeTxG8kyBe/P1nwi7i5f5ZNnZhWNZuZvKv+84IA3z+sW3xLU3L17MysVjD2Xl27cl/XNslD9P+0wVKZalJM3OGtPjt1cuZ+XNLTk/usA5D4G+vlqToePZz/WvRZL9NzRI4piajT4NrV6X1KpWk+dpqwXzyGCuVEd5vuUKkkKKsICeVXB5DDxffgclLTygqZvSCnjisKTXSHoKXnJM3QWg2sQxSlVIOhrWH8K12LgXUuddF08plnZ5oNUjFd+keucGUiyHcfLuTwOu49LYRJ8CW63KeJGH59qps9xDoSDjdRjwMwcwUZBqSiRPXQ+Avrmx0xB2XZCjGa8wfWzxhKTqhnDieR2orNeX5enI/hTT7+xU+kW5yG2ypjnGVAtSBqpZY2rZ9RvXs/LJM0eEXQB8ryAGiRmDYojyGUdgvSvkJQ2u17lDrx0+/4mimLZqfSmL0Dj53IV5moJPvPzq68Lu0ceegmuvZeXQ+I1A4IJUFtB9V1dlPtPtcTtQusszTnrH3vSAnonxikhS7JpdmfeMTzI9fhLo0o26pDTPzjF9fWeXffMv/uJPZdvhJPntbaYWtyzZFy7EaAf8bWxGykJMz/TvG8VDuniRRcng2WIyBggkUUZAruaJJRkDtht8enqwzrTt0KAZ+yX2ny7SKY1cxU74vjHIr1ixnH8R1BF4eE3GFwt8P3bk3Ea+ZgxrUmpIy+Vj9s8U6Pxr+ZqwCyG+JrAke4YsULvNdfjg31Mgs0BElB+s8faQrl1pShQP1p7Y6DPX5fXaclGOSOaLcYf7cOUmS7ldev2ysKvkP5SVu+MspdQx5BUmCrwe2Am3aWrsjLDLFXit7YU8BiOTki4dRlx/oyFj3cIiz3cL1prnv/EDYecVuf7pI+yPviPztrXbHJuCmCWKdprzwm48z3uHkTKvXZEr51I0yO8cd/h+75UkMTUG8g2+J+dlzuX54kNua1uGDAt8DgLu/3ZbUtSFjFN612LfDnITJ899VqvtCruv/ulfZuXqxC9k5WMnpHxQTCBvEcu41Ab5vAbIWJh5M66NdsLl1XUpYSXyvpx7138nIopBjiOC/P/2Tfmu4M76Fw3pxmuslKPf+HB/v+7n5EjeWOV59MLz38nKD0/L2GOB3wWwj7nytsyRTp3m2GHD+lJbuSLsWrv8fmVtleWYLl2Rdre2eOyiIsf88QXj/QPEhziQfoGKkT2IgVFb5vIFWBvtlMey25brc5zndb0wxlJNKPNCRBShvCHB+mysUfHA39MhlVhxXI9GJvt9f3NV9hn6TwzPFXTkGHQ73O813N8bOWwP4g92h2tKHUKOk6AchSkta91da9bcI+NnM4Vw4Z1VAjlIakpdgaxKGt/7HViCe/8YZTsMKQ3I9zB+W+YzWYP67pH6DN+KplAoFAqFQqFQKBQKhUKhUCgUir8R0BfMCoVCoVAoFAqFQqFQKBQKhUKh2Bf0BbNCoVAoFAqFQqFQKBQKhUKhUCj2hfdUg9l1LZqZ6r/TDrelNlEHdENQFi61pbYQ6qFUq6zn53tSP63TYn2/AmqtBPKRX3zhhax84izrzy4vrwk7G3Tgijm+l2PocxVAMwy1XYmIOh3+HIFmWNnQc332CdYSyldAu8uR2jJxyBpWnVusLWM38sJuuljJyk+ceZj/fXRG2L20eq1/n1DeZxgQRRHtbPZ1BD/6zLPi2rOf/nRWzuVAG9YxdAPtu+vZOIauIWqldgLu4+3la8Jup8u6RztbrHF49bLUcrq9wb5UngadtpwcJ8tnzdYgkhrlX3v+u1n56MlHs/LS+IKwy9vs30XQ5el1pX7R1Tprh5fBx2JDe3Vtl3XHJiePZeV2KLV4vvH8D4mIqNGQmlHDgiiKaGsQc3B8iYi6XZ6LQcBlLy9jige6rziX7Xf4GfgTlE2dI9R7s0F/r1CU8QA1nVFoOX6H6BN8x9Besu4hkmTq4KE+s4uaybZRn40aTXzN1JcS4kxwKZ+XOmt3NJhtUzt6SBAnCTUGfZUkUu9sfoa10HzQXW73pO5kqQia+S7oojmyzzyfx9UCEbd2R/qtX+D4UZ5gXcHQNnTgXP6cH+X2Ja7070aTfeH0iaOyjjXQH2yx7+81d4Td6VOns/LyrUvcJkMj0ILUo1nn+ybG37zLoHOPOtCtlvRb584aZxsatUOA1EopHmiXWYa+bBPmXwc0Htc2ZX70P/+Tf5qVb1xm/fymEcsur7AuHerqxYa+cAj5lhXzWuMY/Y9xwwL/Sy1DQxc/GDGgUOL6tyHvy/myL+p7nLP1elz/9evL8l7gS7gMpXmpeY6tQP3QUk5qcLZb/fqSIdUhtGyb/EFe6RjPGNTYZ1ALeX5U2j26x/nhhRrnuWu3bwq7eofHoAnrS9eIyx70VQSakXYq8+sWrA1tWP9cw8+SHmgZ9qROsIVrD9y360qfTkAXtYV2OZlLEewp8pAjJbERrxP+3qkZzqHHfOkn7e3a4P7DqYNqWSl5Xn/NCpsybro+x8tuzNrFt9dfFXZvvci67xWH508plDnshW+9kpVzx3jctg3t5+JJ1lA+tsi+urwuxwo1TV2IFzNHjLFPeR4kbRlXijaP8bW3eU164QcyriyeY99NKuyfXjQh7KI61z8+xd+5fk3m/W/t8dr4+ec+mZVnF2Xu04r6MdGy753PvV+wLYsKA83yvHHugQ9nR+TH+MyjnCvtOh0e+73aHvy79MUy6FTjGR1mjoqhozTCvvPEh58UZtch//gX/8vvZuVPf+ojwu5D55ey8siMzL3TFPeT7OsWSf+LwE8391iv/PKV6/dsO+614kTm1x3YhxTK4IsNI74O9GWHde1KU4s6gzVhpyVjwFugqfu919/MystFOQ8m4PygEY/7rFqpCLtChX1wGc6cuHRD5lIvvfJjvrbMmtaNrjH/XPaFzz5xLiv/wkMnhBnIgFPeOGdnZYM1npfhXK+68W7o4husJ/32S/xOKjHyNn+O82s8qyxuyzycLPZbG3Kfd2ow36l/OP0nIaI7qeDy7Q1xbXkNtPDR/xND4x7mZrHE7+fcSI53HIImMdRnG2fkwKsjocH8zp0vf+9++1qcu6YGsyXE6O+dzzuw78G9uW/kWalz9716YrxLSGB/kIAevJ1KO3uwd73X6RPDuZtXKBQKhUKhUCgUCoVCoVAoFArF0ENfMCsUCoVCoVAoFAqFQqFQKBQKhWJfeE8lMnzfoiNL/Z/rj1iSWnX5FtNg1jf5p9tBLCkH5TI3udVmuk2cNIUdUj13gG7aaEpqZzfkOpyUy5XymLBbX2MKwjJQPRKD9j4zxXQqy6BS79Z2s3KuxM81OiKpHj5Q7ntIgTUoza0e2wVNvlYyKAKnlmaz8vwst+/W8rqw297sj0EUDSFVy7aoNJAO2K5Lqs3Lr76UlaenedxmpieFXRjyeOzuMo2JDPqeC+O2cJwlLZbG5DitXFzNyq0m0wimZ2aFXXGC6YBOnmlg7Y6879zckay8dlvS97a22Tfn5lmGwjLoyM0e+BxQfMJEUipyIOWSA15GsL0p7Mhmv5pZOMZ2Bv3/TjOGk2hDlKQpheGgzamcHy7MqxyEm1xBUhmRB2JB5HQcSctHtk4M8eF+tBbHR0qTbJ8P7UvvQ5N5pzwFtAlMka4zOjoq7HCO9ICmF1uy7nvJYkSRIc8QgT/GGA9lfXeeJY6HL/YQ9WVQiqU+HTOOpO/3oM9cj8fR8yRVVPoJ0KdkWCfXu3sf9Iz1xHK5vuII36vRkHI4BfDjzU1ex1xXxrOxArepOFoV18p5pvTNTDEVcSvdFXbFIj/M9DSvNY16XdjhsoYM+OqI9MdKldteB+rp1taWsEvtPm3b9L9hgOu6ND4xPvgkY0WnybG8V2LquW3JGFCD9WpiiiVZRsanhF0EwSdJ2U+j0KCeQz+FIK2QhHefl0REPYj5iRlrgDpnG79bqMHYf++F72Xl5557Tti98eYFuC//e2DQf1HSKoF+Co3YEeNaGHAdt27ckvXl+vMgDOT8GioM1grLksHChSWqa3P7PUPG4cgcU8mvLYMkVE9KWsUJX6tBnNuy5FahArEMcxCTgrsHQ7IGk970bye9F8lS/grGg7FfN+LhHtDWm3DfBUPeaRT83dnhWDnjyj3JU5A3n1ziji525F6jN5DWMOnMw4I4DWg37Pt80JPUbFQaWq+xDMbt3eeF3dYax59Zj2X2JiwZz+odtvPWeA3xOzIuL8cXs/LZz7Ic03ZSE3a7t9nvpua4f89/WPpPvsRjt7V1RFzDNa9U5jXvoYcWhV11kTsjjbmf4lD6/toKz5nWDl8LDGmXWpNz9pWHeC9SqkwLu9WtvhxJGMmxGQZYROQN5pVtSMjkHZ4TKSG93KRb87UcyAL6hkQSyks2GiD9E0uJjHyR64iI/erkWSnrdeZRloD86u+zP3/5//iesPt8i6U1nv6crCMBycEI4oZlxC+Uv9vYwPcN0ieWjh6Baxx71jbkvsuF+45McNn2pO80B3qiJsV9WNAMI/qr2/0csdeVOcjqOj8/KKHRTlvmr9fWWBphvsI50q/+8ieF3blHH8vKfoHn+cTckrCb/tDZrPwcyCdMj48Iu9ECjAFI3+Xycp0owWfPkEJo9viZd9o8f1Zr0i++PcXxoQP5zm1DSjYFOb32Dst7xMbyWShyP6Uon2Csz/fbMw4DkjihzmCRwr0pkcwh4hBjk5wLKJXqwPO6xqP7sMFP4EVA8A7pK+zD9K5FIil3gRK795uqtilFCc/iQH5jGzezY/YnB+oouHLtcl30BS5HRt9GIpfGa7LxzkByY/se6Zv+glmhUCgUCoVCoVAoFAqFQqFQKBT7gr5gVigUCoVCoVAoFAqFQqFQKBQKxb7wnkpkOK5F1bE+xa+zwzIfNAAAIABJREFUKWkvY9NAtSoxHWHLOFW4C7Rt12cKViDZO5QAnSWEU9L3OpLSWyrwT+G7bf6ZeacrKbgB1IendeMps0REzTo/V7UqKfbVKlMw8ATdrW3ZpnKZqUJ4IqQVyZ/F+8CPBOYR+b5s07FTx/i+ba7j299+U9i9erFPRel0h49mbFtEuQF1vNeVNLoXXvh6Vk5DHsNqUfZ/GPJzdTtMRzNPND96jCk1j3yUT489eWRe2NVusYzF2i77i1+Qsi4nJ5hqubnJ1K9Hzz4i7B5+lKk7//b3/ndxzSWmk4Ug0RIEkmqTIp0jz8/r5GSbjh3nk3A3br3NF2zpOwWQcnnooTNZuduWNNGluT5163nf4PsPCVzXpYmJPmXfJtnGGCh8IcjDmLIQ3S77jAWnsZp0OaSrBUA1cRLZtwiUT0hSScnBNln3PK9VUnLMU6Uj8AukLDquY9gBdR7LiYwJtnN32pVJucLnQlqPKe9xp8/SdDipfrZlUb7gD8rGKelwym4OxvjO6et3YAGd0wcpDXLkmFZHxrNyt84028CVi5yb477qQBxwHHlfVEcIOjwGq8YaN76wwN9ZlSc2F2Au5Cvc9qkRSdnc2r7J9Y2AzIahA9KMuFFn5ziuJsZ62m4zPavd4vK4IaVxJ7Q79r3nx/uFlFKKB9Qyk8rqgo/kcpz3uAa1bWwM5J5wLhvzHOdlFHCOkRj0ZpSiESdhGzS/CNbMZotjfq8n87IQKIqxQSlE2z/56lez8utvyvzjxZf4dHcL/CU2Yl6EMkEQL9LIpGZz2zF62cYal0/7fpUmw5f39GFlJ6P3OjJvRmkJC3w/NeQ+ynB6+mSVx2pnU87zBtCR94Ba+oIhRzEGflIF2Y6SQcENbTasQ/7aJekj+C3HoBn74NNFaSnsXIvHvwj3TUI5rgHwiQvQjpGyMf4hS7s0d7nuelXGMmsgAxUnw0k3jpKQdpt9ObdWfU1cizss91BrXsnKSVfKNYwUgZq9dzkrl8blGNhljvlenmna1VDSz+0ZjnVjU7x5qY5I/7n5Nuf6Foz3zrr0kV7Ea9nMrJS+uLXCc2Z7i5839WRMnIY9VC6H+Z1sU6/HvrB6kX2k5Enq/JnHj2flJshlbO1KP/Fy8eA+w+c/aZpQNMgtokC2D1PHIuy13iENBnIPPlwzc0WUUEhQTieW8y3qwd4ekpudXSkn8LFPPZSVn/nE01n5r55/Q9hdu8H7uNlbcp+UK7MPj0BeFoTSd+p19qtGk/3t9LmTwm50lPeC1THuwNqelBBD+bwjpzkv67al37eD4ZbIiOOYdnf67zdM9TILJPN8yKkDW47B7Dj7yeKpx7Pyicc+LOwqoyyLgTKA1bIhYzrB+2wfZQyMvYcF+xXcd8VmkgTvlwIjB7FBhqAIe+OZEZnfPfM0+2euzLntn3zj68Lu5u0bfNuEY3RkxB7b4XvhuwMz97kT24ZVKSNNYuoOpGSijlyTLNxbi72ldDSUgkghXrjmXgE+pvBCLUplrhuAI6f32Y/HMCdRUu5+fZ0aUmEJ1I8zv+hKPyt6bFct8vwpFk2/4L7APYZtm5I/8M4BmoRyI0REnt//vL57ne4G/QWzQqFQKBQKhUKhUCgUCoVCoVAo9gV9waxQKBQKhUKhUCgUCoVCoVAoFIp9QV8wKxQKhUKhUCgUCoVCoVAoFAqFYl94TzWYLcsiN9+/Zb4qdZrGy/yu2+2w5olXkFoj9V1ocszfKeSlFmTsgZZqj3W8/KJ8ZM/ldjgO64L1DD0e1FxCnRRTNisFLcxYyuOS54KWlM86KbVdqcHcAf28kVHWNHMNnRQb2t4GlcH1rYaw223ytUaLtcD+8ltvCbv1gXRUNxg+LcIkSah9R3/Q6Ief+8IX2S5gLSzH0N5LQLMnBS0ax5W+mAcN8LUa6/40aheF3U6H67fyrHXz9itXhd329zez8onjrP/04VOnhV3QYYcp+FKHKg1BixTsbEf6cwJ6OR3QAHINXaKji6zB3G2ydtm5aknY/fCll7Py7Rus1dxptYRd2u77cGBocw4LHMeharU/l5LY0E1K2Z96MPfqhs60C7q5DpRNPWGUl/TAV6PE1AgFLVXUXTY0nS3UZbqPziPqPKGvExGl8LfEBGJb0JFaciH4WQK6VmToVWErhIYryfYVYV74INpnG7qGd/SgTC2oYYFlWeQP9KeKxaK4huPvwOA7hrZyDJpzUQTriaFr1WhwP3XqrM3nGLql+TzP/QBiXdiRc729x3MSdfsr41LHGNeksC31zhw/BTPQUfRk/KnAuQM5GO/R8Slhl9Z3srJl83N1GzKudNp8LQ/9bupi3hE2c5zh8x+LrEwHzvOMuY0+AnHJ8wwte5hWKTx7zjF03eGaD0NjkdRiQ21l1IozBeJQs21ikjUoQ2NtRc222Ig9ScJj2GqxPuXa+rqwO3aMNUsbLVzvpC9iZ9xLj5mIKIXnwucwY4w9iG0bXZk3DRPu6PumRvy3wN99yGPSjtRMRv+ZLrHdj197XZht3+ZcJbLYgTYNrcE6xK8ijHfRmJY5aF/qoxakMQ/Ab13XOCMBxrUuYqiMh+iDPlZv5oHQJtuFNZNkn9WavG9wUq4jZ1eEnZX0+ykeUh3UJA6p0+hrL1vOprjmVTiXHIHB612Va1xlivsmnITY7Y0Lu/lxPldkeYX1nvcu7Qm7cwt8tkm5zGOwtCjzke3bfK+rb7Jdpy7jnlPkuOIXZLyYmec2ri2zVnMvkWsNxj6LeCyrozIXP35yLCtvXr6VlaNQxtj6Dq+7a6u8jvdieYbMxGR/HbYMfdRhQJyk1BqcgxBGcn6EEc+jIGDfKRZkjBL5MeSyjrF3iUF3OYT41W7K+bu+wvuVmSk+m2DMOJehDXqrRx/l/GO3K3MR3+XnaEopZAptODejAGumcR6SC+cnzCywBvixE9J3AthbY5ofhHLs9+DsjVKZc6pC3rhvcRArnXtrwb6f8Byb5kb6e8rQ2CeFFo9XrsTlm8YW0h/hMf7kp57KyuOVsrDDs2pwP9U0wjKOd0Vu/QVc8FUb1ox3nPOBA5kYaxJsyIXmuLGNG63ymnL2JOdBb749J+xWVliDOYJ7OUbsEFq+eNvE3Bfeo0FDgjRNKYn6a9S4cfaBCzrEPQgRaSIH1QM9ah9yC9/oszjha3ugs5w39jhRnvs2CLgNUSj7ELs6FuecGDkcYUw0z1mDMyJKvL7MjMszDUYK3MY8nMFmu/fOszD+mjkX2llwnoVj7Dfu7Ld8f5nuhuHbjSkUCoVCoVAoFAqFQqFQKBQKheJvBPQFs0KhUCgUCoVCoVAoFAqFQqFQKPaF91QiI0ksajbvUDokvaFcYqqWBxSbUk7SjkZG+KfmzXoHypJu2QRqbdjlcsWfEHZ5oKJGQO93jZ+WI+XOy/HPxC2Dzl4sc5faRu9GMdJt+GJ1VNLRdnaYqtkA2l91XLa9DTTFS9eZNvTWa7eE3cw4y2zMLMK9bEmXmBzp0zTWGwa9cghg2xaVyn3qw4jB5qhMncnKPRjDvPH3E98CCmkBqNxFSalIuiyN0GgARb1YFXbTJ5nWc7LI1LtL167IBlrsL16RKVMrqzeF2cTk2F3LRERBh+l8vR7Tp1otqcPSA1mHsMe0QTcvfWxmnmliN1Z57qzflG3vNvleV954hds3YVDex/o0RJP+MUywBv5gGbo2AVDpuj2OKWEo6ZpIs0a5mtSghAdAr+kBjdcyqFUW1IGSESZ9OInuTmQySXHYitSQEBAUHQuo4660QzoRIn2HIgFQ02OgGZvDD/HLxlhp0NmjMB7UO5w0Y9uyqDSQkHCNnsfRyoMkSLMpJVaQXuTnOA4USnJuimtQeWdPUmtnpo9k5S7IZ4yW5JrpTUHcg+4NSXIRcX0qlKVUjocxEh4/NPxscorXdT/hNc4xKFg5WNfTlNtRLMq8oID3hf7rGLIJdz4PY/xJyaI07bcdKZNEkh6HXZkYVEYhmeFi/mH4In4GO8eIKR5MVJTFeYfcDzIt4TuOJccTfcdU7UCZoEKF18yFI8a6C/V3kC5tShxA36BEhDn2aIdzz3zGOznD3s4WDSUsi+zB+HuGe+NSZiHl3HjGuMWxaK7C8WbCk3Zel+dVFXy1a+S5GMsjoKq2DL/tYHtB3sKJ7k0TtSO57uK44tplrn8e5lnQFwWj7aDGRyWLn9/oCkKtqx7kXy0Z1qlo9/vTlC8ZFqRRlzo7fTk8Jydjfg/6069wTJ57eF7YhSH3RZQDua09mRPXNzjnbNa43FmV8fq1H7Hc3EQV9kyejP8f/Qz76rHjM1l5fEo+R3Ua1swJuf7Z9mxW3lph+vnGzmVhl+QgHw8hvhmUax/WJAsUECplUxqI93FNkHmIbBnP8vn+XsSUNRsGxHFCtT1ToujONZ6n7Q7kuYl8vh7EFKRl5/JynHyQ6Gq2eV8TGrGiMs5yAh/7NEsmHDkm5QRsL4LvcD7z+IfPCbuizz52R0YvaztB22FDbxnvB3JIt4fmdgO5P8O1Ng970EpFyu5gDuiA1pUpQXjHzraG87eCOdehE5P9Po0TGddrsG60Qd7k9Jjc+5586rGsvLDAOW8QyvcUKEknPMYIy5hn3MnLiIhcQ17Ngcxe7t1khfeTvpD3BQkPY61AOblqkefFqSNHhN2Vqyy/ubzD7yZS14h5kJ9ZYm9pSB0O6Zp1BxalZA2kq6bGZRyemuBnRBk2m6QsjWO+iMu+Y8ZreNfWZl/1cnIvhH3Yg3eLgSHtci9ZDDNPtSF2+IaEXsFnHy/Du6NiQe4ZHSHhAu8VDOkc7Avbxhxe3ldIXYpLht3Af+4Vf941KlmWlbcs64eWZf3Esqw3LMv6Hwb/ftyyrB9YlnXZsqzftyzrPmo2ig8q1H8U+4X6juIgUP9RHATqP4r9Qn1HcRCo/ygOAvUfxX6hvqM4CNR/FHfwIH/26hHRZ9M0fYyIHiein7cs66NE9D8R0W+laXqKiHaJ6O/99Jqp+BsM9R/FfqG+ozgI1H8UB4H6j2K/UN9RHATqP4qDQP1HsV+o7ygOAvUfBRE9gERG2v899x1SmDf4LyWizxLRfzj4939NRP89Ef2z+9UVBETLg0MwezX5k/7KFJzaWOCfhY9IxhSNj3OTm3AieQ3oWEREu9s+lPnfnUTyNxNB9QaOnHEaKL6JR7qE48ou7MRA2ZRMIfISOAG7zacjxx3Z9hjoxLUmXwsMCt8OSIRcv8wPWduWpyMHLf7i7AjTxR46uiDs7lR3ac04SvcAOCz/SZIutRsDWl1i0H0tdpL1dZZ0uPTmdWGXd5mS5AMlZ3JaUnLmJ/mETpRCmBiREiXIaOt2drPy9LSkWS3AKdara3yy9sWLF4TdsYDpez2DCtVo8HO12yxpUd+TY4USGXEA9C6D5vHG63wyb9BjOsj09IywWzjPp4JPT/G1yalZYZcf1P/1732TDguHGXsoZQpMryepWiiFEQClLTDsAqBqJylSdQ0aCtCx80B1s13j1FqQ0kDajEndwdPFBZXYoL37Jjcd0O3yc0VwX5M6j23HNpn+2G6zbyEFK2/QHrH+CDhEJqUmn8+9o66D4jD9xyIib9AfdiwDuw+0z/uND46rj9JMkSkBAGsh1DFinJqNbLc80DwTY6EolvlaCD7dNdYdlHMp+nJd84C+2mrz9/IVGes6cEp6B+7lpVJSAU+9th32mdj4k3e7w31Wq3GMNfvM9++s98PnP2mSUjCg0pn+jaxMlJIwYwDmGRbEkdTgZCbwGeW7bEPSwivw59ThvCTn3O83B/c4EZ3keISBjJsYK9GuHchnxPyrG3Gb3hETkAoL3zFPSGefIHLde6e6xWJ/fpjz9SA41LWLiOxB+53UaCNq3giJDOPEdQgWZYvH51OGFMIeUENfvsmSIVs9Od+6QK3tgV8kjuznBDLnGL5jGzJVOMS2fW/argM+7RpmBaB/FoH+WTFkoCogDTcBzS0afuYRSNpBm1Ij/ncHEgDJIco7Hab/eLZFswNJvnZOPqNLIFUEtH9/TMoiBLtM4W9v8L/vXtgWdn6T16hqj/PlyKD+9lL2syTm9Wl3XUoKNCA3O3Gcc9aeIZuzc4vbYTc3xLU8aKIcP850+5mFgrDb7fIat7nJ8hZJYOQ0PvfhY88c43+Pd4VdQiAREkG+RLI+645vHd7SdYj+Y1NC/TjqGTJXBHOs2eLniw2ueKvJ+1EHfGxsVOarDtL8IW/OF+V9ZyE3KU3yfqdQkT4Wwz7RTbg+d0zWV4K9kWesE2EHctaYBygKZY5Vh/1ZD57flNJwoe0YLnJ5Set3IT9staENtrRrNvrzJT5EeZXDjD2ubdNkpT/PwkD2bbPNc7j4CEudLE3KnPLsCZZj9GE9sT0jR4X544FrGdsukaO7Fq5Jhp1Yk+C+95GZSEn6Bb4DCuFDatThEDeyVOAxPv/oQ8KuB/ndX3z3xay8sSfjJkqlOWKvZUi0DezMPexBcNi5Dw1yTVO2Fj97/x97dx4kSXYXeP73izMj76zKuo/uUre6utVqNS2JBgFixApG4mZAgBBIYnZ2mTHb2RkMlsM07KKdFRg7LLPYGMsMmkWgQYBgJNCFtEiApiWEjm7dfahb1dVH3VdW3hEZh7/9wyPj/d7LjKhMj+ysyM7vx6ysPNJfeHi4//z58xf+fl70dUcxHx4j3dqtcaq0et1eF/vYGhsP01Ek5tylYoMrDDTNmbRBQXtn/X0gEqW4k6jfUe10vIzcuvPy+R7XXab+Vg2PJRvjtr/Txfckt3Nn2jQf3da/K1XNq+qXROSyiHxMRJ4UkVnnOkfMWRE50u392N2IH2RF7KAfxA/6QfwgK2IH/SB+0A/iB1kRO+gH8QORDXYwO+dazrlvEJGjInK/iNy50Q9Q1Z9R1YdU9aG5xdqN34DnnazxY2NnYWH5xm/A885W1T3xQ8GwO2xV/KzUmzd+A553tuLcFd/Ri91hq+qeq0vEz260VfEzv7hy4zfgeWcrzl1L80s3fgOed7aq7pkd1Afn4jm1ZdftK1x37WSbGhPonJsVkY+LyCtEZFL9fdVHReRcl/e83Tn3cufcyydGh9Yrgl1is/FjY2dsbDiejV2k37qnUqmsVwS7RL/xU45SRmB36efcVSzxLJPdrN+6Z3qE+NnN+o2f8dF4yDB2k37OXSPjI/Fs7CL91j2Te6bXK4Jdou/r9jLXXTvZDfeequ4TkYZzblZVKyLyXZIm6/64iLxORN4tIm8WkfffaFlOC9IqphVOo/TyYN5KYvIMNf2vXkMTYa6RyX2+k3oq53/d2LMc5iCanfEdSrNXfX6Q6lL4lVtN03g3+e2SZri8WtXffW1z++WjBD8LNf++anTHdtHkbhnL+ZxmSS7Mo9to+HUsj/jcLUPFsKE4WTL5ycTnFL7n3rBRcPIlPu/Yrbff3pm+/5vDu4LPnk/T5nzqya371XHL4idxkrTz4+ai30UKDb8Pxot++3/+Mw8E5S5e8t9Lzba8//6XBeW+7RU+NufmfG6tr3zhs0G5JZPX9olnz3SmTz/9dFCuanKWOmfy1Y7vC8rNz/u8bwvXw32wNO/zu9kjopAPj48J0xF/+ITP6Ty191BQbv9hn0P58H33dKb3RA1Km9fX5ucVjXLutI+dbrl4stjSusc5aTTSvJ4257JIlM/V5Ghak7czyIXs5aPcxzZfl8211Yjyxtrl23xQGuVVtXmU7PaN8zDZ/FK98pHa9bO5mUXCbVE0eeB6fUe77mty45rccsNlH5txxq/nIhfYVsZPTlUqpXR7xLm7nMnXb/fV+HiYS87m1bX7zuYWTpfnt+GE+WFkNOrkduZ5AtUVEz9JGD9Jw9clYyM+R2aURjfIHrcU5VEsNvz3qpq8hM1cODLg6pyvwxav+fPa5GR4oXFtyX/noYo5Xlz4Ha/P+LpzwdSj8Q9Gq6/j3MX92Nr6Z3V/h/HdMnmvRf10uRye61frLhGRVstPF0thjjX7/Qvi57WinKVNs++D/O9R3RPkYlObly16DkLZnCeKYYeofZ89duJ91TB5l3PmGEii461pXufN+TSJ6p6gPoyD3fB12WDWPZLLiZRW273hd1T7vcz5pGm2pYhIYpr6Nofwoeh3+++7149aPWDaUqcuhW3US0t++debfrvVomecrJjVa6rJQRnl4M91a2dIuFeKpm4rRIf6iMn/XDbLL2tYcDzv42fK5GceifKPD5kcn7aZb49FEZHl9nE7qHVPweVlupk+Z2TlUHhOunx21kz7Z3s0h8P6v1D3zyXJnfPbb2gmusPM5oht+s8auT0MtL23+f2YN8uWy7NBuYun/Tq1rvv6f/+JiaBczsRdZSVs687M+btwi61n/TocCJ83cnDPi/xn1Xzfx5lzl4JyFfNMg6l9/vs2a+ENVAWbFPaqyVk+F9ZnjVq6DV3SvY7arK2KH+ec1BvpejWjuK9W/esl8zykclT/5wsjZtosO7qGsM+AWDE5hRv18C5qm+e2PG7qPA3bsqvPPRARaa345a0shbFdz5tnRUR5pq/O+Hzee6b8NXYSnU+uXrjSma6ZEUvTh8Jn1bTMuXBm3rb7ovOu2VAXzvtySRQjrXbbs9kMY6ofW3rucom4Zrq9a9FzXComL/vdtx/vTB+eCo+jisllmzPXu/koj7/dhDmzf+JiNs+tPX+6aBMmufXbD83oQSG2TdNohR+2ZJ4zsVjz37+6Ej1/wrR7q2ZftqIcuoeO3tKZ3jv1dGf62vyZoJzdNmqfF+TWXHm1/x+8uqezvHb7LG4XlEzbd2jITxeibWavKe05eu11nJ83XPTXF8Woj8W2P9U8zyF+fEmYx9jkSI7bmfZlHNLmdZgTPLoeDxI0mxWJy9kczJpf9+/pa7+MvP3+0TNAtN0XF+eOXrWRnwcOicg7VTUv6R3Pf+6c+5CqPioi71bVt4nIF0Xk9zewLOw+xA+yInbQD+IH/SB+kBWxg34QP+gH8YOsiB30g/iBiGygg9k59xURuW+dv5+WNLcK0BXxg6yIHfSD+EE/iB9kReygH8QP+kH8ICtiB/0gfrBKew0d3PIPU70iIksiQub31LQM5ra4xTm378bFtk87dp6Rwd1m221Qt8PAxY4I8bOOQd0Ogxw/nLs84meDqHvWGNTtMHCxI0L8rGNQt8Mgxw/nLo/42SDqnjUGdTsMXOyIED/rGNTtMMjxw7nL21Hxs60dzCIiqvqQc+7lNy75/Me22Dy2WYrtkA3bLcV22Dy2mce22Dy2WYrtkA3bLcV22Dy2mce22Dy2WYrtkA3bLcV22Dy2mbfTtkXuxkUAAAAAAAAAAFiLDmYAAAAAAAAAQCY3o4P57TfhMwcV22Lz2GYptkM2bLcU22Hz2GYe22Lz2GYptkM2bLcU22Hz2GYe22Lz2GYptkM2bLcU22Hz2GbejtoW256DGQAAAAAAAADw/ECKDAAAAAAAAABAJtvawayqr1XVx1X1lKr+8nZ+9s2kqsdU9eOq+qiqPqKq/7r99z2q+jFV/Xr7/6mbva6DjPghfrIidoidfhA/xE8/iB/iJytih9jpB/FD/GS1W2NHhPjZCrs1foidrUH87Oz42bYUGaqaF5EnROS7ROSsiDwoIj/hnHt0W1bgJlLVQyJyyDn3BVUdE5HPi8gPichPi8iMc+432gfPlHPul27iqg4s4of4yYrYIXb6QfwQP/0gfoifrIgdYqcfxA/xk9Vujh0R4qdfuzl+iJ3+ET87P3628w7m+0XklHPutHOuLiLvFpEf3MbPv2mccxecc19oTy+IyGMickTS7//OdrF3ShpAWB/xI8RPRsSOEDt9IH6E+OkD8SPET0bEjhA7fSB+hPjJaNfGjgjxswV2bfwQO1uC+JGdHT/b2cF8RETOmNdn23/bVVT1VhG5T0Q+KyIHnHMX2rMuisiBm7RaOwHxI8RPRsSOEDt9IH6E+OkD8SPET0bEjhA7fSB+hPjJiNhpI34yIX6E2OkD8SM7O354yN82UtVREXmviPysc27eznNprpLtyVeCHYn4QVbEDvpB/KAfxA+yInbQD+IH/SB+kBWxg37s9PjZzg7mcyJyzLw+2v7brqCqRUkD5Y+dc3/R/vOldq6V1Zwrl2/W+u0AxA/xkxWxQ+z0g/ghfvpB/BA/WRE7xE4/iB/iJ6tdHTsixE+fdnX8EDt9I352ePxsZwfzgyLyQlU9oaolEXm9iHxgGz//plFVFZHfF5HHnHP/3sz6gIi8uT39ZhF5/3av2w5C/BA/WRE7xE4/iB/ipx/ED/GTFbFD7PSD+CF+stq1sSNC/GyBXRs/xM6WIH52ePxoepf1Nn2Y6veIyG+LSF5E3uGc+7Vt+/CbSFW/TUQ+KSJfFZGk/ee3SJpT5c9F5LiIPCMiP+acm7kpK7kDED/ET1bEDrHTD+KH+OkH8UP8ZEXsEDv9IH6In6x2a+yIED9bYbfGD7GzNYifnR0/29rBDAAAAAAAAAB4/uAhfwAAAAAAAACATOhgBgAAAAAAAABkQgczAAAAAAAAACATOpgBAAAAAAAAAJnQwQwAAAAAAAAAyIQOZgAAAAAAAABAJnQwAwAAAAAAAAAyoYMZAAAAAAAAAJAJHcwAAAAAAAAAgEzoYAYAAAAAAAAAZEIHMwAAAAAAAAAgEzqYAQAAAAAAAACZ0MEMAAAAAAAAAMiEDmYAAAAAAAAAQCZ0MAMAAAAAAAAAMqGDGQAAAAAAAACQCR3MAAAAAAAAAIBM6GAGAAAAAAAAAGRCBzMAAAAAAAAAIBM6mAEAAAAAAAAAmdDBDAAAAAAAAADIhA5mAAAAAAAAAEAmdDADAAAAAAAAADKhgxkAAAAAAAAAkAkdzAAAAAAAAACATOhgBgAAAAAAAABkQgczAAAAAAAAACATOpgBAAAAAAAAAJnQwQwAAAAAAAAAyIQOZgAAAAAAAABAJnQwAwAAAAAAAABtTGs4AAAgAElEQVQyoYMZAAAAAAAAAJAJHcwAAAAAAAAAgEzoYAYAAAAAAAAAZEIHMwAAAAAAAAAgEzqYAQAAAAAAAACZ0MEMAAAAAAAAAMiEDmYAAAAAAAAAQCZ0MAMAAAAAAAAAMqGDGQAAAAAAAACQCR3MAAAAAAAAAIBM6GAGAAAAAAAAAGRCBzMAAAAAAAAAIBM6mAEAAAAAAAAAmdDBDAAAAAAAAADIhA5mAAAAAAAAAEAmdDADAAAAAAAAADKhgxkAAAAAAAAAkAkdzAAAAAAAAACATOhgBgAAAAAAAABkQgczAAAAAAAAACATOpgBAAAAAAAAAJnQwQwAAAAAAAAAyIQOZgAAAAAAAABAJnQwAwAAAAAAAAAyoYMZAAAAAAAAAJAJHcwAAAAAAAAAgEzoYAYAAAAAAAAAZEIHMwAAAAAAAAAgEzqYAQAAAAAAAACZ0MEMAAAAAAAAAMiEDmYAAAAAAAAAQCZ0MAMAAAAAAAAAMqGDGQAAAAAAAACQCR3MAAAAAAAAAIBM6GAGAAAAAAAAAGRCBzMAAAAAAAAAIBM6mAEAAAAAAAAAmdDBDAAAAAAAAADIhA5mAAAAAAAAAEAmdDADAAAAAAAAADKhgxkAAAAAAAAAkAkdzAAAAAAAAACATOhgBgAAAAAAAABkQgczAAAAAAAAACATOpgBAAAAAAAAAJnQwQwAAAAAAAAAyIQOZgAAAAAAAABAJnQwAwAAAAAAAAAyoYMZAAAAAAAAAJAJHcwAAAAAAAAAgEzoYAYAAAAAAAAAZEIHMwAAAAAAAAAgEzqYAQAAAAAAAACZ0MEMAAAAAAAAAMiEDmYAAAAAAAAAQCZ0MAMAAAAAAAAAMqGDGQAAAAAAAACQCR3MAAAAAAAAAIBM6GAGAAAAAAAAAGRCBzMAAAAAAAAAIBM6mAEAAAAAAAAAmdDBDAAAAAAAAADIhA5mAAAAAAAAAEAmdDADAAAAAAAAADKhgxkAAAAAAAAAkAkdzAAAAAAAAACATOhgBgAAAAAAAABkQgczAAAAAAAAACATOpgBAAAAAAAAAJnQwQwAAAAAAAAAyIQOZgAAAAAAAABAJnQwAwAAAAAAAAAyoYMZAAAAAAAAAJAJHcwAAAAAAAAAgEzoYAYAAAAAAAAAZEIHMwAAAAAAAAAgEzqYAQAAAAAAAACZ0MEMAAAAAAAAAMiEDmYAAAAAAAAAQCZ0MAMAAAAAAAAAMqGDGQAAAAAAAACQCR3MAAAAAAAAAIBM6GAGAAAAAAAAAGRCBzMAAAAAAAAAIBM6mAEAAAAAAAAAmdDBDAAAAAAAAADIhA5mAAAAAAAAAEAmdDADAAAAAAAAADKhgxkAAAAAAAAAkAkdzAAAAAAAAACATOhgBgAAAAAAAABkQgczAAAAAAAAACATOpgBAAAAAAAAAJnQwQwAAAAAAAAAyIQOZgAAAAAAAABAJnQwAwAAAAAAAAAyoYMZAAAAAAAAAJAJHcwAAAAAAAAAgEzoYAYAAAAAAAAAZEIHMwAAAAAAAAAgEzqYAQAAAAAAAACZ0MEMAAAAAAAAAMiEDmYAAAAAAAAAQCZ0MAMAAAAAAAAAMqGDGQAAAAAAAACQCR3MAAAAAAAAAIBM6GAGAAAAAAAAAGRCBzMAAAAAAAAAIBM6mAEAAAAAAAAAmdDBDAAAAAAAAADIhA5mAAAAAAAAAEAmdDADAAAAAAAAADKhgxkAAAAAAAAAkAkdzAAAAAAAAACATOhgBgAAAAAAAABkQgczAAAAAAAAACATOpgBAAAAAAAAAJnQwQwAAAAAAAAAyIQOZgAAAAAAAABAJnQwAwAAAAAAAAAyoYMZAAAAAAAAAJAJHcwAAAAAAAAAgEzoYAYAAAAAAAAAZEIHMwAAAAAAAAAgEzqYAQAAAAAAAACZ0MEMAAAAAAAAAMhk13Uwq+p/U9X/Ybvfi52LmEFWxA6eC4MSV6r6SlV9fJPveVpVv3MrPh83NiixshUGbX12A+IH/SB+sNWeTzGF7TMocUO7eecZlNjZSXZsB/OgH2yq+lZVbajqQvvfE6r6O6p66Gav2261Q2LmXev83anq7TdjnZAidvBc2CFx1VDVxfa/x1T1R1bnO+c+6Zw7eTPXcbcY5FhR1f9kYqQexcxHbvb6gfhBf4gfbLVBjqlVqnqHqv5XVb2qqnOq+hVV/TlVzW/gvX+oqm/bjvXcTQY9bmg3D64dGDuLqvqLN3u9stixHcw7xJ8558ZEZI+I/BMROSgin38uOplVtbDVy8TORkwgK2IHxp8550adc6Mi8rMi8i5VPXCjNxFDu4dz7l+YGPl1MTHjnPvu1XLEBNZD/KAfxA+eC6p6m4h8VkTOiMg9zrkJEflREXm5iIzdzHXDwKPdjKzs+WvUOffv4gIb+YHrZnvedTCr6pSqfkhVr6jq9fb00ajYbar6OVWdV9X3q+oe8/5vVtV/UNVZVf2yqr6q33VyzjWcc4+IyI+LyBUR+Xnzed+nql9qf94/qOpLzLzDqvre9nd5SlX/lZn3VlV9j6q+S1XnReSn+13P3WoQY6bHupZV9bdV9Xz732+rark971WqelZVf0lVL4rIH6jqdPv7zKrqjKp+UlVz7fJd4wsbQ+wQO8+FQY0r59xfi8iCiNzW/pxXqepZ87lPt2PoKyKypKoFVX2jqj6jqtdU9d9sxXrAG9RYMctfLyaCkRUa3emlqj+oabtoXlWfVNXXrrPcQ5reTfYLW7m+uw3xQ/z0g/ghfrbaAMXU/y4i/+Cc+znn3AUREefc4865NzjnZtuf9V9V9aKmdzd/QlXvbv/9Z0TkJ0XkFzW9C/GDGdcBGzRAcROg3Tz4BjV2zPL/UFX/o6p+WFWXROQ7VPUuTdNvzKrqI6r6A6b8XlX9YHtdH1TVt6nq32/lOt3I866DWdLv9AcicouIHBeRqoj8TlTmTSLy34vIIRFpish/EBFR1SMi8lci8jZJ7zr+X0Tkvaq6L/4QVT3e3qnHN7pizrmWiLxfRF7ZXsZ9IvIOEfnnIrJXRH5PRD6gaUdQTkQ+KCJfFpEjIvJqEflZVX2NWeQPish7RGRSRP54o+uBNQY2Ztbxb0Tkm0XkG0TkXhG5X0R+xcw/2F6PW0TkZyT9MeOsiOwTkQMi8hYRcRuML9wYsUPsPBcGLq409b0iUhKRR3sU/QkR+V5Jz0t3iMh/FJE3ishhSc9zcaMN/Rm4WFlHJyacc81eBVX1fhH5LyLyC5LG0LeLyNNRmRMi8oCI/I5z7jczrA884gf9IH6w1QYlpr5T0mvsXj4iIi8Ukf0i8gVpX4s7597env537bsQv/8Gy0H/BiVubFnazTvDwMXOOt4gIr8m6eiJz0p6Hf5RSeue/1lE/lhVV1Ov/D8isiTpdf2b2/+21fOug9k5d805917n3LJzbkHSnfGPomJ/5Jx72Dm3JCL/q4j8mKa3m/+UiHzYOfdh51zinPuYiDwkIt+zzuc865ybdM49u8lVPC9pAIqknTi/55z7rHOu5Zx7p4isSNoJ9I0iss8592+dc3Xn3GkR+c8i8nqzrE87597XXtfqJtcDbQMWMz/Wrnw6/6L5Pyki/9Y5d9k5d0XSX9jfaOYnIvKrzrmVdkw0JK0Mb2nfSf9J55yTjcUXboDYIXaeC4MYVyKyKCIfEJFfX717p4v/4Jw7046h14nIh5xzn3DOrbTXM9nYVsBGDFisdGNj4kb+mYi8wzn3sfY6nXPOfc3Mf5GIfFzSuurtGdYFBvGDfhA/2GoDFFN7ReTCDdb1Hc65hXb75q0icq+qTmzm+2JrDFDciNBu3lEGMXbMv8Ptv7/fOfcp51wi6Y1ioyLyG+3r8L8TkQ+JyE+01+lHJD1HLTvnHhWRd2beOBk97zqYVXVYVX9P06EF8yLyCRGZ1DBfyRkz/YyIFEVkWtJfLn406qD5Nkk7WbbKERGZaU/fIiI/H33eMUl/sbpFRA5H894i6Z2E630PZDRgMfPn7cqn8y+af7j9+XZdDpvXV5xzNfP6N0XklIh8VFVPq+ovt/++kfjCDRA7xM5zYUDjakTSIX5vUtV/3qO8Xa/D9nW7YXYt43pgHQMWK91spq1yTESe7DH/J0XknNz4zjJsAPGDfhA/2GoDFFPXer1PVfOq+huaplGZF3+n+3SGz0KfBihuRGg37ygDGjur/86v8/mHReRMu7PZrtMRSUcdF6Ly295f+LzrYJZ0WPdJEfkm59y4pMObRETUlDlmpo9LeqfeVUl3wB9FO3bEOfcbW7Fimg4t/34R+WT7T2dE5Neizxt2zv1pe95T0bwx55z9RcRtxXphcGNmHeclrczsupw3r4OYaP+y/vPOuReIyA+IyM+p6qtlY/GFGyN2iJ3nwkDGlXPuaUmHhPYa7mnj6IJdT1UdlvSuIGydgYyVSNxWWRaRYfP6oJk+I+1chV28VdJ1/xPdAQ862QGIH/SD+MFWG5SY+htJ7wTs5g2Spqr8ThGZEJFbo/XkGn17DUrcBGg37wgDGTsRGyPnReRYu1/RrtM5SZ/11pQwrYpd922x0zuYi6o6ZP4VJM1NUhWRWU0TcP/qOu/7KVV9Ufug/bci8h6X5kd+l4h8v6q+pv3L5JCmydj7yn2jacL2u0TkTyVtyPz79qz/LCL/QlW/SVMjqvq9qjomIp8TkQVNE79X2uvzYlX9xn7WBTsjZnr4UxH5FVXdp6rTIvK/tddhXZo+RPJ2VVURmRORlqRDbYivzSN2iJ3nwo6Jq/YyXisij2zwLe8Rke9T1W9T1VJ7PXd6u+Nm2jGxcgNfEpE3tD/ztRIORfx9EfmnqvpqVc2p6hFVvdPMb4jIj4rIiIj8l6iBjd6IH+KnH8QP8bPVBjmmflVEvkVVf1NVD4qItNvE71LVyfZ6rkh6d+mwiPx69P5LIvKCDJ+LGxvkuAnQbh44OyZ2evispD+U/qKqFjV9qOD3i8i72+v0FyLyVk3vzL5T0vzR22qnB+yHJQ2I1X9vFZHfFpGKpL8qfEZE/r913vdHIvKHInJRRIZE5F+JiDjnzkj6a+RbJP0F4IykD3pYs500TdS9qL0Tdf+4qi5K2jnzAUlPQi9bvd3dOfeQiPyPkiYSvy7pcPSfbs9ricj3SZpn5an29/l/Jf2VFNkNeszcyNskze3zFRH5qqQPlXhbj/IvlPRX+EUR+bSI/K5z7uPEVybEDrHzXBj0uPrxdplFEXlQRD4laf7uG3LOPSIi/5OI/Imkd2Vcl/TBkchm0GNlo/61pI3hWUmHnL9vdYZz7nMi8k9F5P+WtO30gIQjL8Q5VxeRH5Y0Lc876OTZMOJHiJ8+ED9C/GyxgY0p59yTIvIKSe9MfkRV50TkvZK2oxckfRjkM5LeNfhoe12t3xeRF2k6bP59gq00sHHTRrt5cA167NxQ+xz0/SLy3e11/l0ReZPzzwv4l5Jek19sr/efSvpj2LZR5xjBAQAAAAAAAAA7nar+nyJy0Dn35u36TH51BQAAAAAAAIAdSFXvVNWXaOp+EflnIvKX27kOhe38MAAAAAAAAADAlhmTNC3GYUlzwf+WiLx/O1eAFBkAAAAAAAAAgEz6SpGhqq9V1cdV9ZSq/vJWrRR2B+IHWRE76Afxg34QP8iK2EE/iB/0g/hBVsQO+kH87C6Z72BW1byIPCEi3yXp0y0fFJGfcM49unWrh+cr4gdZETvoB/GDfhA/yIrYQT+IH/SD+EFWxA76QfzsPv3kYL5fRE45506LiKjqu0XkB0Wka7AUSgVXHiqnL6J+bTXTts87lw9vss7n8+sWbCVJ1+Wp+lcuLmfm5cy05oNiklO/Hkni1p1OVylcfrAMs+72s+JOfvtac/5zm41WUK7ZbPoXGnzjoJx2+ax4XZvNdPmtZlOSJAkXsvU2FT8jo6Nuz969IiJSKoQ7R8V/j5wJrFKpGJTL5Xy42005v1gNyrWafqaNt7lmeLjo0Jh/z/JMZ3pcl4Nye/fs7UwnObvu3WM23tdXrlz1n9Xy8w4ePBCUK5fLnemlpaXO9NDQUPhZOf9pebNOQUyJSGKOl0LBf3+7DiI+xs5fuCCzs7MDFTsiImNT027fkeMisvZ4s+xhFJdSea6/1k3wHKdIcsG0W/fv9g/Xzp+RxdlrAxc/OVW36eE+Pb7FTYsltZPd12Gro0K34Ov2CtXVYzpxThLnBip+hkYn3Nieg+l6RvPCFbXHR/wVTNvELiVpBKVy5vXwUKkz3Yrq9cWlRf9ZXep4kbDtELSVcuHRYM8vtq3UfqP0J9xq2mV5ver1jdxIceXKFVlYWBio2BERGRrf48b2HVt/ZrevteZbmDalOTziOHO6/gK7/HnDq7N2gVnfOLgWr5yR2sLMwMXP3r173bFjx9ef2e18oF2LRW/qteO6b4rnciO5OJi6rGK3NsiNSm6wWNeZSZcPPnvmrMzMDFbbp1IZcuNjoyIiUiqF54acuYZotvyXWl6uBeUaDX9OstfLa+vxbl99g5XDRs8zPfoe1i7DdSsZlrLX1bauXVNO1i3Xq3ET9AdE67c6r9FoSKvVGqjYERGZnJhwBw+kbZ/eu8e2Mza2MmvarxsMn3D/9Gykb+hzw/XNtgvW1Fl90iDObuzchfNyfQCv23O5nMu3+3uKcdvU9J8MFX0fRqVSCsqNDFc609UVXxddm50Pytm2b7nop3PxMWem7TqtOTZNXTc05NehGR3rK41612WUir4Pq1jw06VS2J9Tr/v2/fzionRj+4fsNcFyNeyzKuT99yqV/LYdHh4Nl1caERGRc+fPyPXra9s+/XQwHxGRM+b1WRH5priQqv6MiPyMiEipXJK7X353+vfoLJtr+WCxsyojI0G5iYkJX85cGC0sLITLM0fYkOlorC2FG7JidlSp5C+MyiPhpikXfblarWmm60G52orvrLSdeCIioyN+55TNBVmzGV4k1ut+meWyD8xrV2eDcpcuXelM5ws+cDQfdqzaTlJ7srefIyJy/fp1ERG5eumybIMbxo+Nnak9e+TnfuktIiJy/MCELSaFpt/3lbz/frccORyUq4zs60yfm/f75m/+/ktBucWZuc702PhUZ/ojV/cG5fIv+ked6fkH/7Qz/erCF4NyP/1Tb+xMV4f98pIkrAgK5nCcuXw9mPf2//QHnem56z4OfvGXfy4od+LErZ3phx56qDN9+x0vDMpVTIU3OurjcmZmJii3aCqr/fv3dy23+sPRT73pp2UbbLru2Xv4mPwf7/mkiIgkrWZc1L6nM92rg7lXI2ijF+ODYMtz8EeLS8yPWA3TIGhGP/RJI33jr73pu7Z2fda36fjJich4vksXs92GPTrhomVvqFzvH0PW7/zrpdd77Ov458VuaxGvX7flb3T9erHn+/hzV3/wmo3Ox8+RTZ27RqcOyA/9wttFRCRJoh/mghd+XivqpHViGprmu+eWLgTlRurnOtP3nfSdSnPXrgTl/v5Tn+pM12u+zbJnz56gnO04LpVK5u/loNxdd73IlytWgnl52x4JKsfuP/aH+zdqK+bWj6UkqlPsj6B2Oi63evz9yq/8yrrL3WKbrntGp4/ID/36X7fnRNvMdBYHF5W5+EYH/zqf+P2YRMdl08Sg/ZlmzeK61Ai9zybdOzA3/kPnxn7mC3/M7H7TR/ix0V0ldiWDDqToGG7H44fe8t0bWrc+bTp+jh49Kn/zt3+37sLsuafbdHt5ftrMc/kNnp+ieXnXfV43G/3ZMD6+bZUb3mATrnv8vm7lwpeuy9/DG3jssuvN6Eah9gXvD3zPP17387fYps5dY6Mj8vof+QEREbn1ln22mFRGfBzMzPnv9IUvPhGUO3ven6NWav76LF8Ir1PDTkZ7Q1fYXg/b6H6jBzefrVny+jempfNsvdS9gzk8BsJS9sacpjnXxEuzcdBs+rZKEt2w062tE7ejVss988wzsg02Xfcc2L9f3vG7v7v696Cc3V+92oq5LjVEvL+7taPj47rb9uzVHrZzirnwcws9Ohm7tXuTuP1qXif2fBX/GNJleRrHdGLPVzf2w29+440L9W/z1135nOzdn7ZJD+4P+1+KLX8D3R1Hfbv1JXcdCcrd/7J7OtMPn/J10Tvf99Gg3P79vn47cXC6M10phR3WLdNXaftE4g7wpOqP75N3+XWYqYf12alzZzvT+eimyFsOH+pMH5gy63firqDc6TO+ff+3n/y0X4coLl5424nO9PVr1zrTX/7yl4Ny03v9tj52xPe3veylrwjKnbj1m0VE5HU/9lpZTz8dzBvinHu7iLxdRGR4tOJW6mmHVTkf7QxnTxR+I8eNuaVl35lYLPodXxkOL3hWbEdvwR+UoxNhD3zJ3NUqSd38PayUxkf9hVZ10e/MnAvXr1Lx6xE3V+rmhCJmcng4vCDTnL1S8EsZHRsOyl296r9Xw5zg8lEj3Fao4a/J4RquVpRb0RmwFWzsnDx50t13150iIlKM9s3l8/4X88kDvnJJ1oS33y57J8c709/3mlcHpS6dPd+ZPnv+Ymf69nL4q9Fi0XeyHrjFL691IfzB4O8/5y/mK9NHO9N33BbelTQ6NdmZ/tRjnwvmPfDAA51pNfvtYx8NK8kf/pEf7kzf8+K7O9O1aniXtppWd8l0nI1FsThq4tn+EljKTwflGu1f4bpd/N8MNn5uu+elrpBP1y3pdZHaI/a73ekQv2PtxXiXgs+lXnd7BndO9LqLdWMX/baBHr/Hmft+c7aOjz43ya0ua3DY+Cmouq714gbrS/uVg+kei9vo/WHdL63Cks4enz1+mY/nZdkvwfbS+KJuY7de2puRe52XVi82BvHcte/4SacuPT/neo1wshc+0bzEtIPs7xylobDxWyz4OvojH/1IZ/rJR8IGpB3domovkLrXjfaH8CRq9xz+jG/UvvrV4Y9EL7773s50vWF/AIhHUK3fIZOPftix5eyFfa8fY4J2WrRx6+3l9Rp9tt2C+LntXpdfbRNGN2ao7RA257VE4tFbfrqV8+/JRT94jHS5w64Z7YOWqXGaQR0fdQZFY1jsnLDg5u8U7M3uy42NWFrbYu+ySvE6rC5kMKoeEQnj5957v8GtHifd7oCMp2NB543t/IpHF9hl96iLXdBm6C48J/Uo1+N72HOInder42kjf9/MPPtZ8ajXpH3j6XM/8GZjbOwc2DftVutFF/84avbvxQv+munrT54Ol6e+LiqYG6HyxfCa3SU2Jmybpfs2ttezGvUp5E3MBm2q+AcIs58qlfD6x+63YBRQdK6wy8/bc2i0S1stv74N09Fk/54uz8as/3shGr3b7UeRm8nGz5133NGpe3rdSGH16mC2ncprfyCyPyiv35aI1yMXxIh2LWc/N9+rI7rHvJ51rY0f2yfVY3R7rx8e7M2N9seLNddnnbpocO6KsvFTLhddpZDuh0LUF2jvsl2qmZtNl8P9Xa2Z9o5ZxrF9k0G5Q9P+9ZTpO0qqYZvm/Kzv/ysO+7g4eEvYsT1f9p/1xIrvK5qZDftiqqbdcXgy7J+cMP2V9q7qcimu6+y03/fNeliv2Bst7A9ha86ZZnrPHr9d9h8OR8zXi+kHdzt19fOQv3MiYnvIjrb/BmwE8YOsiB30g/hBP4gfZEXsoB/ED/pB/CArYgf9IH52mX46mB8UkReq6glVLYnI60XkA1uzWtgFiB9kReygH8QP+kH8ICtiB/0gftAP4gdZETvoB/Gzy2ROkeGca6rqvxSRv5Z0hO47nHOPbNma4XmN+EFWxA76QfygH8QPsiJ20A/iB/0gfpAVsYN+ED+7T185mJ1zHxaRD2/iHZ2cyq0odVBzZaUzPTTkcw3nkzCXXKXic5KMj/u8t4smp6CISL3p8/KWh33u3EqU98k+o2KlanK1RDkj52Z9DpXE5EsqFsP1a9hcOlHeOpvHx+ZSWqmHT921y0/Mg2HjdEvlss+/2DR5YnrlZbI5C+Ny252/cjPxUyoU5Nj+NO9vK3pIW7Pqt5/mfOy01qTK8/tqxGw7jfb1xAt8nuTjh30S99uLU0G5r13zMTt13Oc7Hr2yEpS7cMHn7FmeudqZdkcPBuXsAx2P3XIimHfLcf/AppUl/+C9e+55SVCuVvMPsayU/eE9Nhzmj242/TqeeepUZ3pkdCwoZx/s1Kj5YywfJRdrth/EsV0RtPm6R6TQzk2UuO55srZC1zSm23h49f6ojeU/DBMrbSxHl4s/2T7/zhy28UMpkva+6WdIzWZkiZ9ussRP94xXEub37pETN0hxbLZcr7WxD/Xqnd85PkZ6FN6Ate/fYM63DealHORzl4qve9Z+6/Uf0paP8sHm1Ocunr/sH+jz5OmvBuWunfUPWGrO+4f1jkW5mkdHfD1fb3TPxdY0D6QKHqoT5eM8bc4hi+8PH15bq/lzjT1fFeKHoiQmn6bZn61WnCu1+/paavJk1sw58+r18AG1l9ttu2r0nILnymbrHlXttBfXpIkOHszp908xOm7KTd8uKOZ8Rbx3LGxL7Sn6BxxfuujbLV+/GJYbmr7FL3vMt5EkF7aH43yn/Qpysveo6eyDkpxG7dwNnoi7Pcwtzni/+tC7QW77rOr1oK2e5cyDrcKHl3e/hggX0T2nf89j2JazeXR7PFx2bX7vbuvXPR91r793y4Mal7Pbtmeu3G1OvbyZ+HHOSbOd5zh+boI9tosmP+jISHgNsVz37yuV/HVIPheek+z+XVnx54JWdB1dNs/CyeX9ucDmKBUJ8zPbZ8MUSmHMr9T9+akRntZETZ2qZj00zuNsHkSY6/oQlvBas2CeNWWvy9slO1Nhv0H4HX3IbU8Qbbbucc4fF72Oo14PBNUNHr/hdlo/97FI9xzMcV1ot3XwnjVP8/STG32gYPysomA9zOf2ehCpzafr4g61bvmZ1zzwRbbVZuMnpyqVUrqSQ0Pxs8r8drpS89vvodNhO+6py5/3n9/yfUVzC9Fz1srmOT8kPE8AACAASURBVGZFX65eD/tzJkb9Q+9G874Ou/rUmaCcM+tXzPmHEOauhP19+WX/enQkXKcxU0eMjPi+rfiZWuOjI75cxdePtZXws8IV7JHD27xeMutXq4cVpBtZva5ZP5C263oeAAAAAAAAAPA8QwczAAAAAAAAACCTvlJkbJbmclJpp79o1MLbznPmdvLwdu3wlvF8wfeJJ2aoZJzmoDLibxOvN/3w0lIxHpbp3zc26W99L+TDISvnz13sTJfL/lb1XD4cEqhmnSQfDeEo+nVvmHVaWgyHlJbMcLSiSelhv7uIyPiETxdSb/plrNTDbWbTeNhhHysr4T4YG0uHNl3pMmzuZnLOSbOeDgtYXg6HB1SG/L4umG23ZhidGb5Zr/p0D3Mz14NyB/b7IZ9Dw355e4fC2DlS8csbMrs6GbsjKHd02j84dc6k80hW6kG5ptlvd784TH3xyle+sjM9PeVTw7zmta8Jyp0+7YcqXzp/oTM9NhymhqkuLXSmZ6777z8xGaYBselICoXuQ7qW20OQq8thqppBoSKyOsJN14yE3OBw/Q163vxqtwXDpxJzDCYmZnKtcKiNHYo4qJLVDdJjuwQDdXsMOwpHD4fnkJwdEmrrlVYcWXbYshl6KdEwpnCMsF/emjQM9nwaD/XrMgQqt2ZAo1lGjxQrXVJ/rBmlvP6qr1mcS7b2GN5KKiKrIzaTeHs5O2zS/7mgjaDYkw9/tjN9+it/35lenrkULq7mzyn7pnz74MD+Q0G5ghluWCz6OFpYmA/KNc1xmjcrWG+E5+DElLs+Gy7jg3/ln+Ny9rx/aPi999wblJuYmOxMl0ybZc0mM3kibKqn67NzQbkrl3yKh8sXz/ty0XestVOSVWs9hhPeRKoiudV2WyvcGAXnv3/OtAHzjTANyJT610MrfjudPHgkKDdU8HG3fPrpznTpSthGqi34uMtN+WUM7b89KFca8fs0UT+cND5cNaiLehzL5nhxa07k5lhytn6Jhg93S6cTD+EOZtlX6w9v3u40PRulurF1DIaBR2kJbFoMW+dr1NrJdR3C3j1thR323StdRrdUF/H74m/ozPp2G7Iez+uV+qLbe3qxw+/zcbqMdp7G+Bp2MDjJtY+fZiO+XvHfKWeOlkZ0bdBs+u1cN3nSytH1cavh59VNXZwUwvZRyVzDDpX8dU0huhZfXPDnqMqwr3vK0VD7lbqv82q18Dvaa2cb6fY6UyRM29Rs+m1hjykRETVttkLRpGmM0mTauLKxs8FwGxiq/jiLt4XdtkF6iqhpqAWTYsWkJMgnYcHlJZ8G6rq5pp2fD89ds9evdaarVf+e+FgeGfFpB2w61tGR8aDc2JjvN9q//0Awr1LxfUUNE2dJdAIMj31bR0nE1pV2Omrzb7A9vJrGdaNpo7abc05azfR7Dg1PB/OmDtzWmTabVnLlkaDcw09+uTM9c/HZznRjOWwvXjrv24XTY34Zk1NhetHjpl1ts+Hkon63ponblQW/fWu1sG1fL/k4vlIP29XD13w7a2xiX2e6urwclLPpi3Lm+i8XXbfZ1y7pkS7RHFq1qkkhVA3rqb2H0vp37XXgmsUAAAAAAAAAALBxdDADAAAAAAAAADLZ3hQZmpNiIR2eEo1ukJFxP2ylatIXxMMW7RBOe1t4Ej1eu2me6joy4pftouHDlWHzVFuTPqMV9b2PTZsnZZvNtjAfprdw5p75YjTMrOH8OrXMkIbpA+Gt/yUzjCYxTwdNoo3WqJvlmVQGSRLerm7TGdgUGfV6OBxoeDgdzhEPZRkE1eqSfOmrX0inl6KnvTf9NqqU/RCa8bHJoNieST8ktzrvh4yeefKJoJw2fcyNDPshLpViuK9Hhn1c5Qt+HQqTe4NyxVG/PWvPPtWZPn/hbFBu2Aw1vb4Y7puTJ092pl/7Xa/qTI9PhN9x714fS5fO+uEgs1fOB+XGzTGRM7G4PD8blKuY71g3QyXiITW6erwN6hguVcm1h+U7jdIzSLfhrxsbNhSXsqNFwqer9hr62/VF9Fl2WMtmtvXmh0D1HPHbZZPF6+QSv61b9mndK+EwSi2kx+1Gh5xuO1WfYyWeFZfrTEbDk2waEJMWQ4vhEKx8wZyTxvzxfPDebwnKjez3qXjOzfg6a+FqWK/kLj3WmS5c9/WP1sMhYo0gHUe4f3LBMWO/YzzUT7rYYPxFy3NdAm3NkD7t/uT2m05F8u0htXE7xZ7r8y1/Xnv8S58Iyj38mb/pTNcWfeqH+OHzBTFxlfNxtHdfOHRzbM+YXweTemtuPhxeaIedjpgnVbei+KiYVF7xITy75Ntzy1WfmumLX/xcuIwhf64tmDbI9N49YTnTZrtsUoScv3A1KHd9zp9Da6Y9ly+E6aKGKu0hrrlwiPWgyImT4UJ6fI8kYQqq5oI/nocafijwUBKmATly0G/DlSW/7yYr4SWAmu1eqvhz/6HDpaCcy/nXc0vPdKYXnroQlKuNHu5MVw76+qo0ti8o58z+iTMI2GPdpqBLctE5xKTFsNNuTToet/7khk+RceqjfPv/wRxmLKIi7XWMa8mc3bZmM+XidA2mflVTMB8Pwe2S+qgV7VQ159JSycdSoxEOH27ZVFpmlXqln1qbAW39IedxWyVoW/XYlzalR/C5Pdou9pqqVAzTK7Ta54RBjJ8kSXwKRxde1zRMygy75vkofUQwetpcl2s+3F7TU77+X1ry+312fiEotzLn68Ck5N/Tiq6PnTm3LpvrqaQZxphNFZlEcepM/LXMyTZuCjabvlyx2D0NpdWy6+GiBdp2grN1Y7h+rU7/wIC2m41nn302eH3unE+XVVvx7ddyKTo/m1QiruG3Z3U5PMfNzfvz//yKj5l6NdzfDfO6ZfpXbD0kIuLMtq6Z/bhUDffpyKhPmXEoSjl19913d6bvu+9lnemJyfC6PemS+iJORWlf2/qiUIhSDJoUGXHMWJ33DV7VIyLpuSafT+NhdDRMTSKmnlmp+VioRilREuf3d75s0nw2wrbPotlmQ0N+2eOTo0G5ZsHXOYt5n1K0OXk0KFcxKVZk1KS3SML0FmJS6jQaYQzW66ZtvuTrsHIpXPeqSa1Rrfnp+HzcJRPLOo0f/7o05I/HXC6sZ2avpu29VlSndsqv+1cAAAAAAAAAAG6ADmYAAAAAAAAAQCZ0MAMAAAAAAAAAMtnWHMxpLrA0B8roaJRnp+BzoxSLfroR5SspmnyBdZOPJ07+mJhcbUMVnzOlUQvz5yxVfb6SpZpfxvBomHclyflNtbTo31MZnwjKLS/53L42D46IyNi4z3u4YvIfx7mQncmHUjL5iFaifNRDFT8vMblO8/kwl6DNl2iXVy6H+2A1/9kg5kFdqdfl2bNpvsFC9LvIsMn/uGJyd+XivFQmAU2haPLIRemLbA5wMTm7XTHcTxNDfnnO5FR15UpQLm/y5Ry75Ra/3uNRTqEhEx9XwlyGL32pz980Nu7zN7XqYY6mw4d8rs3a/K2d6UKU+7NsvrPNRVdvhvmJiya3U5gPL9q27eUPDYX5ZAdKO2eTc+F3LIjZhkFOxo39/hanK7R5CVumXko2mCdNo0yJYVbo7rkG7fJ75Si067vh1FvRh9m83UEE5uOcjL5cY8XnMK+HVZmUh0rrfs5Aacd8r1yJPbenyRm2mnNaRCQf1cPDJj/pyVf/WGd64r7vCMpdu+hzzg0VTW66sduDcivTPvf8isnHPHTmU0G5wrLP3dzS8DyZc74OyyW23gtzbyVdcyFHWybIp9m9XLftuSZ/ZjvH5QCmsRQVlZym228k+katms8h/Mjnfd7lrz706aBcdeFaZ9rmBtRiGDsFc+4pmxxwJ15wIig3Ne3PIXmTGzyJ2ixV0z6qmzyEZ86Feb6XTZvoyP4w33PZ5Dyuj/hlxHle58zzNR47/WRn+vbb7wrKTUz5vOQXLvl8e1euh89IGB33x9HUqM+VNz4Rttkm2ufhzz/wdzKIyrmGnCylz1AYboV5phdLPo96zoSCa4RtwLJ59oYO+bgYHQvbII2m34+lsj+Xay6sD8rmPF8e8sueWAkr9llTpyw9dbkz3ZoI8xUOT7+gM10cC59J0lT/xQqmDeI0bLipOe/ao6yVi/KqdnnewYZzMEcFO3mrB7HykbSubHbqjLhdYNoMNldnnFvfrZ+8USXaB2YZeRNzuaiRPb/oc6SeP++fDzI9He77sTHfJrbPj4mvURIbF2uuX9ZvVKzZW7a5Z/bxRp9JE7SPo/UIpqM6ttnOZTyI111Jkki1ml6DN+pRHVDxbZgh04YpRvu6YNoEOZMP9fjh/UG5n3rD6zrTM1f8efFP/uhdQbklk0O3WvfnDOfCc2HLdG/Y62PXDL+HPefFOW+DPLcmt3ISRU+jUTPT/u9x7Nh8uPb8Z2NbJIwlu07x+rn2tcIAhs4acXzb/NTPPO3zM9eWZ4JyJefPeaW83y71RrgtFmtmO+V9LCwthG3Uy+f98uz2PHrkcFBu3z7ffnDmmmylEZ7jWkv+ey2eDp+R8NVHH+5Mf+ZB/8yJ173uR4Nyt9/u2+xxHnorb44tG5tx3nM1uXJtLHW7LlzzTJMB4Zx/zsg1UyeIiFQv+WeR2HqlHH2VMZP3/eBhv48XF6eCclWTW/vgQR8/h06MBeWmJnxcXCn69vZKM8yrXTLVzFDJr2syFvYjFav+2K+OhPMWTF75q3N+gXE/y/KK//5L5vlGhei5IuFZvNuzp0RE/TrNV/0yri6E5Q6N9K54uIMZAAAAAAAAAJAJHcwAAAAAAAAAgEy2NUWGcyKNVjrUIBd9cq3phx3Y292TaDjCihnqXzTDQfOlUlBu1KS4sMO4Wq3og81Q74JJBzA3uxAU05a/Pb226Idijo2FqTT2jPrhl5qEt7vnE397uc1EsLwcfsclM2xjcsKvU64Y/h7QMMuvmJQjy4vhEAvNmc81y45GakkymKMkRERkZLgiL3vJ3SKyTkoCM1TSDuUrl0eCcmqGSk7s8fvp9pN3BOUKJkWLHe41FAWtTb3izPApjcoVnd9vOuqHW+jInqDctQVf7u47wuEW+/b6OKuatBgr1XD45+i4X9/bzLCb1nI4fC9vhrY7k8ag5eKhkX75iR2eFaXcUJfOKxa3OevOBqn42NDodzV16//OttFRZ1FWCKmb4Z9qZpYqYeoUu61tOg7XY6htnBrAym3F74VdRs3EaxQOtTFzo23pnK+Xq0t+OHdtuRqUKxdXU2R0S7FwcznnOsMbNzpkds1wNOePn1zizycFDc9d4xX/vumaHz5ceuwTQbmqGTJ1R9kPdV/Ih/XemcQf6xeavs5Z3PeqoNxQ3afPKM18LZhXXPExnZgKuBmdRDRImGK/f/d0Rb2OM7ut7fDSNQb43KUiUm5/jfr1cPjnJz7+ns70wpWnOtPD0Ti/ytDBzvSIOYdURsN9nTNDOcdMXXwgSltRGfHthUrJL2OoHA69mzDpJBpNH0d7T58Oyj37pH89NRWmXSit+PPp3LxPeVaP2nbX5339MGPaX7ff8aKg3LHjt3amP/3ZhzrTk9PHg3JHj/nXeyb9sMbR0XDIY6F9jn9PVD8PipI05VA+jZvmUNi2y6tvg9j2ZlXDoZE5c35Rc77PR3WZM21gOyQ8p2FbNniPOfiGhsJtuM+MWh+t+3VfWHomKDe76NNnlPYeC+aN7PNpxYoVH4/NqJ1l18O2W4pR5RA2cUzKqR51SDi8e/0UGQOaIUNEVKS9X+Ph1zZdgxlJLPmoqrVhYqvhXDEcml0y12ELNuXN18LzySc/+cnO9KlTpzrThw4dCsrZoeN33OHb6SdORCl/pvxw5/j8bFMQtnql0jCvExMMcbluqS9idp49d8UpER986EEREVleCofXD4IkSaRWTevpxYXomjjvzxUN+5WiNoGz6SnMtf3RI/uCcseP7u1MD+f9eeIff/t9QbnzF/059OtP+6Hn56+G26+VM2nI8nY6PFDtNXEjOoZtahdbH+aja3GbrcemkiqVwnrYflaQxidKTditiZnPh3Ve0j5oB7bqEe2k/7DHskh4PDdMuota9XpQbnnRnyuuXfbTz0RtkNOnfVrJlaY58ZSj9vW4jy27PScmw74cMefJ2op/TyMJ69ClRd+OKRbCzyqY16ee+npn+s/+/N1BuX/yQz/cmb7z5J2d6SS6Hup+7RG1w83JyKacXfOu1TpqQAMon8/J2Hjaxmm1wvbi4oLfJ86kX9wzFvX7mG7Oqm9iykotTLFiu0NL4yaVbDP83APz/rOWT/r216cuh22anInpbxr1beKjF8JUbnmf/U7cwTB9z4L69s5w3aQHjto+tguxaa7Bi2vixV6r97oG8xXaYuKPiycvhdftwxPp+ra6XJtxBzMAAAAAAAAAIBM6mAEAAAAAAAAAmWzzeHbXuSV/JXoi7XDZ38Y/MuyH2bWK4c3bubwvVxjyt6dfvBI+XXt5xQ+XGRn2t6cPFcMhoM1G1cwzmyOJniZrhipUiv4281Y0zHPUpE2oV8OhUPWa/855MxRxKB46b9NYmL8PjwwH5Wrmid3j4/429qXFcFtUzFPDnXkqZSsaypTEuScGyFCpLHedSIfY2G0nEg5FC4ZUr0l94N83bPZTbjosZ1NklOyTsFvhMAC7vexH5aIBB3kzNF7MkJlGLtyfzWt+/MbISDiMt2y/s4nhazPhcVSb968nR3xcJRoObVBn4tYOf2yFY2Xs0NqceVJt0opiZ8OPYL85VJwUJT0ekySs9jR4Gr0fFpWLhifZb2zjbC56uu3f/qUf9j5mUvXccefJoFxlyg9/GTFPLB4eDVOntOxwTftEbgmFqT7i4Z+yrjW/MHbZjXHajlZu/c/KrRlO6rf19Wt+CNvTTz4clPuWV3x3+w3hUMFBoeI3jcbDYs22sVtlTTkTT67lzw2N6nxQ7NolX19c+5p/z6u+4Z6g3NFxP3R8oeHr/PNXHwnKLT/lt3u+6euO6l2vDMrN7n91Z7p++ivBvOGv/1VnurTwZGc614i/o4lVG3Qa7Vd7rrHFNB7O7rrO61Zu0CStuizPpOkvPv13Hwjmzc34/ZYv+Pr64LHwiealYT8EfLTsh+85CdsYNTNU8MC4b/c0W2F7xja/Zi759AT33RcOR56cMOcos/2HKmFdduSgr7OWG+FQ6tOX/NDBmvpYn58L04Ukw/59h475898dLwxTJtx37zd2pl3LH3GFKE1awbTT8jm/zeJhpqvD5gc1xUEul5PhduqJhWa4kiUzNLFhhlknEraREjNc05n3xEeNHU5rt9Pa1Ezrp4yI21yJOS5t+oSJaGOPmXWam3kqmDc7c64zPXLgVv+ew7cF5XTIx3tw6o7T+HTZ0b1qkOD7x9V/OwXdoMZPbaUmjz2epqg4cuRIMK9s9knOVNH5XBg/efvSnKMvnD8XlHv8az7N0hNPPNGZnp2dC8pNmLrp3nvv7UzHKTxOm2Hwjz76aGd6eDhsOx8/7tPhvOAFLwjm2e88OelTz8VDx21cJKatb9NqiHRPkRGncLKve6XVqLSv/zaaems7tZKWXF9M990nPnU+mFcwqRcl589dTsMh6uVhX5fXzDDvVnROShb9WPFnH32wM11cPBOU25/32694wAfm3vEwreCFOb9Os3XTjghDW9SkftJCGBN5kzKqYeIgyUXD6811Xc7UvS76MLv8oH2YhNdxtsrKme2ci3PXrK7SgFY+qv640ujiwqZnKpnjeWw0TLHlpm/tTB886NsP09OngnKFoo+Zy5d96pTaSrhtJyZ8fDZMuppcPgoMm2Yp79d1fDjsQ1qs+mtr2ycjEu7HfNG3QZ4+dzYo98EPf7AzXTHX7ceOhm2fIPWFiaVCtO5dE2lEdc9qHdWrbX0zlSsVuePuF4uIyNzVsF/r8sWLnemjh6c706Oj4bnhzGV/7lla9P2CS/NhSp3RMb9/anW/Dy4thn0n1aJvL59d8tv9XD4sl9/rl3cl5+Ns/OnwnDk+499XPRDWYW6PTxuUH/P7uzIUpnOp1XzcJXbv5+L9atNArX9+Svn3LZhLjGcvh9eqeyfS1/UGKTIAAAAAAAAAAFuIDmYAAAAAAAAAQCZ0MAMAAAAAAAAAMtnWHMy5XK6Tb6pVD3PV5E0OGTtdGQ1zjRRKPq9JIzH5aKJ8Ws7kS1q4Puvf78JyJZN4bGTcLzuv4aaprvg8Tfunfe7UWpTfrdny5QrROtn8PBWT26kgYf6SnMmH0zT5oebmonyLJu9KsehzQOUL0e8GJt9loejn5aN8eY2kvS0GMB3PSq0mpx55XERESpUw1+LohM/xNb3P5+LJmbyLIiJDZZ+bp2BDP0qnZfPU2Nx7Nje2iIjmzYZKbI61MGebzY5kc3oVojx3EyN+XinKteXMZ5+94nMHPX42zPtz7IjPHTQ+6qfzhTB2xOSYU/M7U5x7T813saHu4vzdzfT1wKZCdS3JJWm+oIJOBLM0mLb5KeN8wv51Xv2xPXv1YlDuK5/5b/49Nb/dn/pKmE9r/MiBzvSt97ykM/2KV74mXD/1cdEyOZjjHL9x/uOQyUFnvvHaQ93OMzEd58Y1ublbdR+Pl86HefoO7D9myvlcWE+f+mJQbnw4zYtWrYb5WwfJ6vbNxfnKbJ5gWz4q1y3FfS7K8ZhUfR7dp599ujO9cCgsV1j5Qmd6acafJ5JaeG690+T2HT90qDN9ZTrMi/kPpk44VwzzWOrkS/107XpnOt8M97fNOeiczacZ5ejqsi2y5lJefd8gVj9Li3Py2X/4aPoiF9bXL7zb59VumDZR4sJzTdPkJl00CZSb9cWgXNLy88ZN7tGR8TCv4dXLvs564jGf2/Tp82H+29Fh3/6y+dQvXQzzztfqy34dymGcfv2Sz5V4+FZf591yLMw3V7G5Dav+HL+08mxQzqnPE71v2i+jWg/PcUEO1JZfv1bU7HXrTA2SfKEge/ftFxGR5Fp4rplf8DnxWk1zjEXHUdHk2nUmf2hc/xfy6+d1dNHzCIK88/aj1uTg9++z+2PmVBhnBZNbemQqfAbBqMnJOX/Z5+Sdmb0clBvZ73PSjxzy01oJc8KKrW9tDt24Xjcvg7p7TQ7mdDsNah7Lixcvyf/1W78lIiI/8frXB/O+9Vu/tTNtcw23clH8mO/2dZNb+SMfen9QzrYZbrnF74O7XvSioNzIkHnOjvnc+Ai0MbO05NsZV65cCcrZXM1f+9rXgnmj5hpy716f0/L2228Pyp044c95e/b664h8lN/U5m1t2nVfE/vr513WKC/m3XffLSIiQ5Uwt+sgSJJEaitp3TlWjq6nzLV4oWTyHS+GdUXVtCua5pr96VNhDt2nv3awM33lWV8/5KJnVNjrtRNH9nemv+dbvyMo9hd/689rX37Cx4vtQxARqdX8ObkcVXOjE/78Mjvr+xE0euZMwVzXtZpmv0fPqmmY63n7fJvFKB+1M6/tEuI834Oae7nDmbpzzTNJzGTwXIAwD7vZTFIZ8XX5bS98SVBudNTvqy996bOd6YsXwpy3TfM8AtuHYuuXmH0uWJwrvWz6ea5HeX2TnG9rNMxx0GiF3/GRx32s/tl73t2ZfuNPvjkod+yIv57Kmbb2mpz5po7plSd+0LWck/l2u2Z+Idy2+/f6/W3z7OejfrerS/aZZr59fHTf8aBcYg7+Cwum/3B/2B45NeHrj9mab1ftGQ+fmyKmv+m0uaZbvPNo+D2KPhYWmuF+3L/k4zO/4GPk0FQYP4l5tlqjbvoIymGs2j4Nl3R/3pF9dsb0pP/+R46H58zJ8bQvpZBfvyuZO5gBAAAAAAAAAJnQwQwAAAAAAAAAyGTbU2QMD6e3jc/Wwtvdm3ZYiRmKGQ9PsqMslperXcvZ4TvS8LeMt8xQThERLfp5Byb8Le5PRUO9pyf9ML2pqanO9Hw1vM18uepvXbfDYURECiV/674dqNCKhi3YYQzVqhm+Ew1RsmlBkpb/raAQpchIzK3weTNko9mMhpSujgkcwJGiMzPX5c/+/D0iInLyzhcG8+572b2d6REzzHZkOIyJphkO4wp+XrkQlrND9nImrnoNRnJmiEq5GO6n65f8UM6Fi36Y1djhE0G5+Rlf7iMf/1gwb67qd8o154eSVSbDtAuHD764M503B0vTDKsWEUlaft/bITStRpT6wg7VMtMapQHpDIUd0CE4jUZNzp9Jh5gcOvaNwbzE2XQhNt1B99/f7LZoNcNtO1E2w4fNELmly2eDctfmL3Smr8z6IXyVQjic/SUv9cNYc2U7oDvcB7rB6tyO0IxjOkgLYod4JmFJm4bn7DOPd6Y/88BfB+Xuv//bOtPPPvlIZ/rK+WeCcg8up9twaWlwU2R0G45oh0b3GiatXafD9xTNS5f4c8jU3kpQ7q5xX/9/4ov+fDVcCeMnZ/ZpY9kPsS9/+S+Cci+ufMkvQ8K66Yz4ZS6P+fq20gj3V77h027Yb5W4eLuYIZF2+HCcVkTXH+qXNZXGzdBsNmXmappS4vjRQ8G863M+3cio2fHLUSqEhkmRND7m98WByTDdT1HN0POGP9+dOR8OExVT5xVM2+aahu2jU0/64fBPPe3XafbS1aDckGmLFKPzrhT9ehw65oeeT89dC4rZ9DjVJT+k8NlHHwjK5c0wwoU5v10mJqeCcnUzfLEy7rdLYSg8PmQ1VdiADjdWEdF2aiQXHUcrTZPWwKRRyUdfpVzxwzVbVb+P4zNc1zQ+3WZEy0jitFJdll1eCc+ZZTOsc24ljMGhg37468RBn2KlWQuHzi+de6wzvbjg21J7Dt8alBveY47Bskmf0YrbLqZe6vZFRETaQ6YHNUVGo1GXC2fT4/+9fxHW+cURn17urjt9GotymIVOnPnOo5M+5cTdLzoZlDt+222d6XEztNZe34lI0HIp2xR++fCD5036sZxJ2zEyGg5vLpXMUPQotpbmfb2yuOTPT3/7sQ8HLIwBjQAAIABJREFU5aamfd106wl/jXHwYDj0ea8pNzpiUjhqeDQ1g7Qypk0YtaU65/8158ibb3xsVP67b0/bn5XounJ01NcpdVMPPfCZx4Jy12d9HV0wX3FlPkzR9eADn+hMj5mh3ZViWF+vJH7/Hjrmj+Wh8XD7HbzVx/ZXT/m2dl7DdlTB7LdmEl6zi+mnKJprply0r51JT5QL0qZE6S/N8p1Jwxk3Z2wahpLpN2hEq5fPp2+M064MDPX1YhJ9yVbX9DLhts3bbR3Uw2G5/fv8dfGBAz4uatWwr2lu1sdd07Sr1qRZ7dLGzOWjclUfF0mcOtLZ60SbminaX3n/XR5++OHO9Pve95dBsTe+4U2d6T2mfq3Xw2vBounT6HlNMqDnrFXOOam1+6nKUZq3ZMX3s5w+59ujteggKeb9Ptk/4o+5PRNhP81c2W+zq42ZzvSFp8JUPhNjvs6fGPH9OfmDYX02fKs/N5am/PlqcTK8Bviq+GuAgythfTFZ9HXs0w8/6dd1KTzHHTDpOfImXUZB4z4Bmy6l+/WUjYrqdd+WOlML+wwPTvz/7L35k2XHded38m5vr1d7dVXv6AVoNEAA3CmSQyo40mgsW/JEKCa02bI8EYqwHWE7wo4Yhf8C/eSfxp4IRtimrFBogpYljRzSSENRFCkSJAiAAAEC6AXdXb1Vda1vX+/mH96re74nuwtLVQF6FM73l87ql3XfvXlPnsy8db+ffG78+49+7qNvMKtUKpVKpVKpVCqVSqVSqVQqlepAetcHzMaY/9MYs2mM+Qn836wx5hvGmOvjf2fe6Riqj640flSHkcaP6qDS2FEdRho/qsNI40d1UGnsqA4jjR/VQaWxozqMNH5Ue3ovnuqvEdG/IaL/G/7vd4nom2ma/p4x5nfHP//rdztQmqaZJcF+NR935m02uexOFUU946AVgF/rLhSk7SXsss1ufpZj2fXkbq0+7C4+BCtVryV3ey8Rv06/tcZ29npXvo7vwG6yfl7avdCKHwM+ozfoi3oB4BZwB+RSSe6G3YTzDXy+/m5HHq/RYLtpBN+LO4sTEUVD2TZHpK/REcRPt9+jH701stiXZivis2dT3k223WS7AUXytX3XcLsUYVdY19oBE+9NlHLZWBZKpElsNNgqsbldE/W6EEtlsKouOjJm//APuIme/97z8pzKvCP39DnGDjxXnBf1ertshQ6rbKHp7shdt4ch24YSsJzFVgzE0C/Rrp/aux6PLRZRKC0UR6Cv0RHEz6DfpRvXXiciopXjz4jPHAOWJ8QdWMdIwMYU9bnNrv34ZXm8kHPKIvTf1c11UY8M9+ekwXbfv/3zPxPVSj7Xe/K5p/kc7E3vcedg67MY7DAx4E08a0dkA7YztAG6lvU5GvD5Xn31+1n5zVf+XtRrNzge1+7cycr1huwj4RjjE0dHGj9foyMau8gQOePYcGxb2T6IDHuMS/H+QLsb17Jbgr2tB1F47YG0Rf0coIE+bnhH5Xvbcuy6s8HWrR3YkX0Y1UW9GcOok88WNsVnC+WFrHzT45zjOE+Leun2K1k5idhm9jBfiK/5nXa23g+LYf9O9tnRkjO+RkcQP4ZSCsZ9bnf1hvwM2qVY5VyxMlsW9aamGIWxsMD3olCQNr/+gO/95g4jKF5/fUPUK5Q5p9xt8mednkSedB7wuLG+yzZEz82Leu1d/j1nW96EwON889062z9LOcsOWOVjFsCuWH4gcSFvvPL/ZOVuh/PF8eNLot7OLo9RA5/b8zOf/xlRb3l5ZC9MoiOf/3yNjiB+UkopGcfPMLR3D+c2DPxA/A4K53qONd+UAiu/GAttCyX+nL6nepgCHNs6Dvb78pSM/QHcF7RV5yxLswfn2+9w/qpflXOf1hxjxWZPXczKU1W5WzxBjo4xD9Gjqx2x2/hrdERjVyHw6WOnR7bc3eau+OyPfp8P//nPfCkr/9J/+s9FvQDmyDOAHzwxJ9usVOA+3IJ1SLdnzZ0D/rkKaCB7HbezzTknXwD0jiMxPOUK/15rKOM7HXKfceAYeWOhCWHedv/+3ax89do1Uc+H619c4JxzFvAgREQLJ05kZcStedY6Yg9ld8TYp6/RUYxdxlB+3DfzvgzwJOaxJoJ+aS2nyEXcA/SeuaK8110Yr0rTvMbryW4u8CrtDp/Dbl0ic/pw3zuAmjQ9Od8awBontHJjs8FzJw9wiY4jT2oIWBbEyaRWjGESRKqFa88BYQKPOd6OkXi8DpvE2NnT3jzYPsd3mvdJcdvIQ8jjeYD/nIZcvlmQz5BSWAshisR+voKfNWB9ds/Cg7V7HDOOJ4Pfh5/LZY6Z1JoQR/AzojR+9PKPRL1CwNfya//yV7NytSrxEYj+QHysvSZxPhi809foiOInDIe0sT5aQ+asxFKF+5XDocFCniIyFuiV1O23Rb3dNt/jsyt8D06ek/ORhVOc8+eqPBfv7Mi4WNv5blaux4xvqRSOiXpLeY7HaiTzz7X7/Jzm2Dl+BjQXyOfzcQOemcLl2zQvxGLE8TvMd6Gd6tu8ht/aeVNUu3hxNJeK9jnWu77BnKbpd4ho1/rvXyai3x+Xf5+I/vN3O47qoymNH9VhpPGjOqg0dlSHkcaP6jDS+FEdVBo7qsNI40d1UGnsqA4jjR/Vng7KYF5K03TvdbwHRLT0TpVVKksaP6rDSONHdVBp7KgOI40f1WGk8aM6qDR2VIeRxo/qoNLYUR1GGj8fQR16k7905HvY159hjPkdY8xLxpiXwsGR2+dVP+V6p/gRsRPHj6qi+ojrvcZPp9V5VBXVR1jvZ+w6Wgei6h+D3mvuie2t31Uqeu/xU9utPaqK6iOs9zN2DQaD/aqpPqJ6r7mn230nnI7qo6j3k3vq9cZ+1VQfUb2f+InDDwTbqvqQ9F4YzI/ShjFmOU3TdWPMMhFt7lcxTdOvEtFXiYimZqpZUNm8m0EXOcE8qA0tpiuitwTCx2IYVYFZGAIvNW+xu9I+c7ce3GHu1vT0sqjXbzOvEnk87VD2k6klbtLIkYyhIXBxvBwz8YKcZCH3m/wwbGqK2Tpd4EoTEfk+fxcynHI5yYdKEv5e5D4FgawXpx8Ij+dRek/xg7FTLOTS3hgoE1p/FqnOMn90dorjKnBlu+LfU1zDD6zbTTkI9vscf9gSbiK/ODTc/n/5zb/Lyt/8zvdFPT9ghs9zT1zg88v9QNR77bXXs/LiidPis/zpz2XltMrH2L7/tqj3g28yD9j7GDPhWluSt1qa5riaqnA7uYnFeES2Thw++v+JeVrJh/OHgPcdP0snltPG9qha3JesNq+wmJUxpxgjc08K3LXdbf7KG6+9KOpVAo6Lao55fTvbkgUZAbd7tstfPDMv+9/Vl5jldPOtH2fl8rTkMD3ziY9nZb8gGakJspbh8Hvs4z0NenzNvRbn5HZ9R9S7e/uNrPzmS8xdTiyG6+b91azcguPlS5KL5njJQ+f2AelAY5fvOKk35qnZ+VFwl6GdH2I14z2ARIyMNCIiFxhijsecwlfuyLHmTf/JrPzp3/7trHxyTd6r3I+Ye0u3V7NiNJTjSQT3LmnJZnk2dy8rny7xePoKVUW9dp9zndvmvBrG8hqT9HB/bH6Ib/3h/QXgfeeeSmUqncmN7v1MUfLcVpaZx1YCXvv8vGSbJnh9UPYCaz4DY9IQeJJXr8pxAkGZ92u3s/LF47JfPrfCvO0TC/zZ9TXZz7fWwBFpPZPwgLe7ucUxl1jvNxjieHEIuKmOzFGey3nYBw5v4cotqx4w7oFpefeuZKru8Qt3tvdNBUep9x0/l5++nPI9t3IPsoGR72mx9ZGDil3HTrfIbgxx7m0xkw1w/El8ZPVD/D34yFj8zf6Qc0pQkOPaAObDzQ3mhS8tSJahga6APGrXyGVO2GSm9+5bzE1sLZwQ9RZP8hysOM1zzCR99D0wNvDw6HWgsev44kx6cXbU3q2CnBPfWOM1z9/8JbPNLz9xStT73Oc+k5V7XY6lYSrjrAn7veTLfB99V97vksP9G0m8t1dlH27UeI606PKc1bO4vFW4P526zE2Ox9e8tcF5asbINaiX8FxtZpbznjFy7pyH9do9YOqHA7n3QXmGx8ZcDvO+FT8fEMT7EXrfuWfl2FxK476O+3MQETnAvM3luez51roL1hQm5fxS9OT1BiHHyKDDcVQLZfvHxB299TrnqM+euiTqXXuT+3kSc8AYT15HAuvEkOT6B/ceyfkcH55r7X0Qcj5EHqmXk/Vw/xMXnkXkLXZvT+Rb2LvJWl8l47b9EOY/B8o9lx5/PIX/3/fgyIY1NhsdYoYSiBnrcHhXBwO+j/YfSbANcZy0x8xOB8adFq8ZA+uenpxnDu9D4ym+XABjXrcv/+jX6PC8yIfkFloH/Na3vpWVkdX8G7/+a6LeLOw7FgPz3V5rfEB7lzxKB1t35YJ0Z2PUj11HNkY0w+PB8iKv4YvW869un9up2X90LiIiCiqwv8NJzteN45IV35jm81jPcc6/8JQcMz/l8/mJ9XP3nqhX9nmu/5cv3hWfvbXBcXLmU5/NyufPyly38zrPaTfuwHMaa46N3PMI9ihLrPsvnnsZbqcolGvGvaXqfkPXQd9g/nMi+q1x+beI6N8f8Diqj6Y0flSHkcaP6qDS2FEdRho/qsNI40d1UGnsqA4jjR/VQaWxozqMNH4+gnrXB8zGmD8iou8T0ePGmHvGmH9FRL9HRD9njLlORP90/LNK9ZA0flSHkcaP6qDS2FEdRho/qsNI40d1UGnsqA4jjR/VQaWxozqMNH5Ue3pXREaapr+2z0dfOcgXxmNcg+VSIdcHWzDYT0ILQVGAenmworu+vJQU7DYtsNskrqxXzbHts9tjK0Xt7pqo54HNJ1/g8yvmpV1iGuwSGzsb4rMUfQhgqbFfL/fgGrvdDvy/PPdCnm3w7RbbSz0LF5IL2AI0HIINyWJi54KRFcA4R2fVOqr4cVyHcpXR9c4vz4nPfJfP1wPbVmpZutBOmhC3f6crERkDsKv021y+vylZiCFYWV78IeMu7ty4Luptd9lG8eZVRhz4RtpVlo6zJXN5SSIyNvp87tU5Ll+5+pKo13DYHnh2hm0jP3rpR6Lebp9tZ0uzlax8+fxjot6zH2MbfhoPoCxjJ45G/eMoY4fo6OInioa0uzOypty6+Zr47PHLX8zKxmE7jG/Fjwvxc3d1NSvX69LCd2qZ7ZXU4bxhO8RSsNL1OhyDM7OWRbjBbqKfvPjDrBwE8vxqb3Ns5S0EUaEMNh/ww9S3JE6hB6zqe3fuZOV2S9pOKeBjxBH3Eceyt0UOX2M5x3HWi2VjJMm4jxyh1e8ox658sUwXPvZpIrJwBUQUgtUoBgtSEltWP/gM7YIPXzH3IQfsm+1E9q0/+AvG4dDM2az48aeeFvV+ZpY/O1tji3C3JTd6bm3zmNfeXhefpQ3GuwRFjs9K/7io943vcbl/l3Os398W9aIUcx9fV2pZ8d+r9TOzNx5h+jmq+CkV8/TpZy8SEdHJFWnrTwD30GpyHysWZf+NAWWDceVYEykTojWUc/TqrfuiXnWO91hxwUL+iacl8uSpRb7Xf/Myj38VQHcREVXmee4UtuU9Q1JYLsVcQVIR/EcCmDSSVsZBwnO24hRb4y88dVLUu3SR+8HGXbaydwAJQkRUKo/O13WP1id6VPFjiOMbkSCjn3m+g3FhI2Rs+2/2/5Zltt7ke7y+xvkALeZEJPM09NmHWjB9dM4zZOd/tGtaOQDGyXqNx6vBUNYrlHl8KRR5Xm5bmn2cI6JldENaV9ebnB+nj61k5dnjEqWRq4xi8CEk0iF0lGOXSWNyk9H8YqYg7b6XVrj/XN1mG/j6FTlHqp1gZOD1+5xLfnhd4mYijEGYH9trjWrCa7KFKuecwsI5Ua8I8xjEJdpxJuLYwq8UEUfYA6SOL3FAicP1HAOYB8s/XAW8VwO61b1bct5/d5MRDeUqrwsX5uT+VqXi6J50exKxcRgd9bqdiCi13kdLYf3iBdwmlYqcv9Iaz18DWKtVihKlsZzndZ0P6Ke1bTl32NriOO1DJPzg2y+Lerv3eawpAoIiceV4kkI+iCK5xs7D8wIfLh9t40REhRxfVx+4BriWJyJyACnjAGonjuTxHIE04rKd//dC/Sixlh9E7BA9PAYJtBxO3GyyHOB1HFi3OyTbdn2Dx6vXfvJqVm7WZfwgxhHHnXfCrlVgbKla6E1EJqU2+gnnLnAfjYU6ceFnfF6T5mQ8eoDP+/6LjOJs9dui3m//1n+VlVeWOXfHQ4mA2XtGkh4hI+Mo48fzPJqbGc2Z7bbNF/iehCk/CyvlZV6frUAfhvVpty3vd2+G1zylU9CHZ+X8oZXyGrmV8Jh005qPbAEGauEY58TFksTftVscn3N9iba8uMjjdT2GtXlfxk8V6pWX4Rhda94HtxnPNrarwRwsByjdx85IDMjW2ugZQTR89D4Ph97kT6VSqVQqlUqlUqlUKpVKpVKpVB9N6QNmlUqlUqlUKpVKpVKpVCqVSqVSHUjvisg4SqVpQtFwZH1MXdsHwcUE7LM25qAHVquFKtunyhVpKb1/n/EUsQ9WlEDaG6ICv04fFNiqtfuWtDs5Eb/uvlSE19Fn5a7wMbRoUJSv6odoExMWcWuHZbCzt8Cabu/OG0b8WnocctnE0jriQhuGYJGILMyB742/94PfUfR9y3VdmhvvyrywIC1YKbyeL9yV1s68DnpvoIlsvArauAKwFH7nzo9FvZevXM3KuPu1b7VrErG1YaPB1t+ZwrSotwM7Zqd3JKIld5wtdoHDVrorV+U5eSfYst4zbGOeOSGth//xT/+Afwj5nK5cuSHqnTzDv7e0yMcLB9ZO3WMsy1FatY5SaRLTsDey/67df1N8duHxZ7Nyp81tGzXkRrdoR29vc34ZWPaQAdjZa9t8jEZX2pjQBu/BjtomtfAjgM9YKLFdxU3k99ZuvM7n0JO7vUaQH9DdXCjJ/DVb4ZyV7Nzk3+/Kc7rwxOWsnA8YxdK2vvf2FtuM6yFfvylJS2C+cvSIg6PUqdOn6H/76r8hIrnjNRFRCLl8GPJ1DYc2RoY/i/ex6RERpXB8/CixbHW7u9y2aNPbrkvsSRpzzi8GXG+zJePx7gNAIBRlXCSznDAxjo+VJTbomUucL16GWBhsXRX13AH3C8fwdcWpHQATOBi9T3meS/NjDNFUVc4JegO+9iFY0XIWemuAsQTMidDeVR5/BrSAITl3QOtlD+YEzz0tER4/e/l8Vv6//r8/zcpNI8fgYpltf91YWr0N4MViYltj7FjTT4HI4Gv0UnmNHqBiKmWO0/Nn5Bh3+iRjDWp1xh9EqURsVcdWbdf9UKfD71lJmmZ4AJt04cN9FPNLa06ZWj/vyVj/78CcqVRiq2U3tGzlYFVOEYtkY6AQCwTVwkDGd9jjczcdOa65MB9zAUfUbEm0WbvN1vkArOlLKyuiXq7A4y5SjAo52TdxzGzc5nmRa7XZyWdGfWFCpz4UpiltjO27+YLsSynk3semeK47fFvOA7+3/SdZ+flbPNf9SVNilnDswnufeHJNEvQ5RyxWuQ9/6styHbc4xXnLwNhg91UcQz2LvbP9AObSMM9ySxVRrwcxHcWIc5HH6zQ47hCH1x3KvHe3zuNk6vJ15fLye51xrO7syrF0MmSIxiiM1JFjiOPzfUvE+CLruXA/CpCvpqZkf5uBn3GubfIS6+K5PL+JAGvU2JYYqLLP65Upl+9tUJDnVwcMZ83GqwCGM5fyOOYZmaOSPCAyIj53i2pGbcxzLl9v3/pek2Csw/MLy8vumNGcwY7RnzYhosGkMlcQPM9ATOja/VVR7aUXv5uVGzVen0WRxELEEX8XYjvseTiuZR2Hz6FnoWwaDXhGYz1zCOB5UwPyho2kCGGs8SHmhsO+qAfDH+Xh2cSLL74g6j1YZ9zDb/76b2blz37606Ie438mM37mZhfov/yN33nkZy6iYKE5jWPFD/wYeFyxJ5uWrrS+nZWnVhgJGJfkmBn4nL/9HM/ZyzmZVwLi5z5xyvd36Mm11U7M+WzlcTk2NFxAtL7BONRwTY67s7OM7crP8VhTsc49TSIoQy6y5jStNo9dHrRnLi8RHjeuv0FERIOB1Zhj6RvMKpVKpVKpVCqVSqVSqVQqlUqlOpD0AbNKpVKpVCqVSqVSqVQqlUqlUqkOJH3ArFKpVCqVSqVSqVQqlUqlUqlUqgPpw2UwJwnFe+wtV3JSfIsvvCebi5MAT7LTZj7JMJRMpAh/D74rMpJ90wmZQzI/w5zbfE6ywFLg3iLPzvXl8QYDZpeEFpMrBSYick0EFJWIhgCHyQPDx7N41MjxiZC/l8i2Rfawh+wyi1XTH7OF0uTRvL5/SLmOoWJuxH8JLXiOA80HeMrsevhDYFkBELDeljxhA3y4Y7PMl108tizqvfYnf5aVc4ZZPCvHTop6u6vMskWuU7kgeTYpxMvitOSTlYCr8+Lf/01WbtW3Rb21Et/Tr//VH2flL3/mk6LeuWW+ltVbzNu7syY5Zm9ceSsrHzv2uazsWMBBd8yemlQGc5LENOyN7vOdW2+Iz25e52vMuZwD3v7h34l6lQLfYweYlFEkucMvvPZKVl4oM6u0Z7FEY+AczS/y98ahZPd22szmnpvm48VDq62HEPw9ycwsQifx8pxTls9I5qoLvPD7ec61zYHkmCXAhK2UOTZPzEu+6WyFOeP/7q++kZUXLyyKetPHR3x1zxoXJkVR2KPdeyPeeWoxHoOAWWhzc/NZ2a3I4dVAjvB9bjP3oWvm4ycwNkSRzdudhZ/4GJsPJDu8UWf2WxvGzHgg82O1zHHhBPIaX/kx57Afv8qsbzeWcRZAHykknN+SosydgxzHcdpjXpzbs/jR2Ba0v9J0clnNxhjKjZmzqZUDXGCgOsBuTyxuYALtjGOXzQMnOL4Lc52ctffEIAY+qMNzp7wvv5cS5NpCTETybnguM3VdI/OXY+DcE2Br2vxf3IcjRi63vMYUOKq9hGO4NZR5eJBwLjMef9dOU9Z75sKobXyfJlJpklJvPOcJrbEhAG73cMD30Z43owzkESeU9xvnpXmYkxuS/TyBOEvtGBTnjrHK982fn5X1ipwrBvbcIsexdTLP+bUvT4m6Xb7fvS7PEaOhvEbX4c8GwMW3+Zl4Gj60Uz6W88/SmO9qbyszKWp1+/StH10hIqLpquTZln1uWz/HbMhrWxui3iDiWCidZi77sQU5f9i+w/PHBNoscmXe60MstIFD/2//7f8u6n35cx/Pyv/0K1/i41n50YFu4VtrvGlYo3WRdVqUOTHuwNgIx09Cee4RxMzSFHN+7250RD2DYzes1VrWPhXpOIXFFk9/UpSOGczkSG56vcFtef02zw/urzVFPdwDKBcAT9eT61k3xz+34F70+jKXnTjJ+8y4eWCyW2Pr/JDjOQ/3Ioxk4rhT4+CZKcp1f7XM67DZIrBIHYvBnMI+RwnnkYjkoPJgkznb6y3uAztNGTs4T/CBJ58k8hr3pqLGhvNPoN5pTBKyhhPkrW+s383KP/zBd0S9e3dhz5h99pwhIgph/MvB2BJaY2Eb1mfVKq9jBkN5D2o1vqf2+rcI+3Ahg/mhZTIsATod7j9DK/d0+xB3cMvzFht3ff1BVv7qV7+alW8DP5+I6Bf/+X9CRA/H1aQojiNq7u2FZN1HBxjM2O7Gek6Gudf1+DrrHTmOd3PMNZ72cK8y+b2z8EyoUGBmci6V3ztT4LGhmIe9neieqOc63PfbDbkvVwKbuvW6zIVOq3L97Je5XqPD/Wy7K58PncxxO0Up8phl38QcGQA339ic8mwO/+g54ORnJZVKpVKpVCqVSqVSqVQqlUqlUk2k9AGzSqVSqVQqlUqlUqlUKpVKpVKpDqQPFZFBaUpmbD2KLMs1ngm+ku0XpH3Y9cBygq/Fk6w3Pc0WvK1tfvW9WJHogQCOUaqwfWx2Wlr4OnW2HUchv1rfbkpL7/QSW93rgMsgIsqB1cMHm3Vi2U078Or+8ZXjtJ+2t/iV+cBju1fOl9fY74M1I+V2j63vdfzJtKcTEcVxQu3WCHGwtbklPkML5F4dIqLvv/qqqOfmOHYGEduiuu2GqPfcE5f42GBHnp2dEfUIrBitLlsgFsrSLhCAfThf5BibqVREvX6X42VYlzb3eu9HWXn37iqfQiL70W6drY3rW3B+zdOiXg4sDQnYIdoW1uX+BtvX0cLnWDYUSicPq4IyROSMvVL13QfisweABfniJ57Mype+/HlR78abP87K7ftsPfEc6aGpg524muM+tXxO3oO7bzGaZAB+X39WWhH9HNuf0B4+jGR/NQH3+wFZNkVAC+VdzhXlQH6XS2zBWpiuZuWtlsxz23WwhcVgRxvI712e43xYzfN3DbrSYlgYfzapiJVup02v/vB5IiIqTlWsT/mc5+F60R5HRBQCVqVUYvtmoSBty9gCKfQrG6XhwViYy0FeKct6BZfj516Px8LFE9KOFfh87jbKwQc71dUrHLcba7IvpbuQP8Cq7HvyGp0AUCpFbs8okrk4spAA/EWP/u9JlCFDztjCatsw0ZmIyAgbk4NoMLSaGusdAfwM7f9xJI9nevDFMPcauDK2W0OOsT70Wbcgb0Bpivt2EloIK7D5+WCNT628mfe5XikHuBbfsmaDfTrw+Dw6bfm9aHH1HT5etVAV9b7whVHcf/1PPtzp8HtVSml2XyPLRp8DrAPmB8eyTOPPDtocLUyOY/gYccz10oc6HFpS4VzfAVWD9Zp9iQkYQnxXZyRmCREcBtBMBU/azx3It8Ui51cbfREDbgZpR3Eo2yIB5IgL/TawcmPRcx861kQpNeQko7YaNOW5L53ivrB07hNZeefBVVGvs8023uWTJ7Kymy+LegGsIdIe36vAvgcuxxaG6lvX5ffuNHg+Mejx/Zix8Ap5CK6mORrzAAAgAElEQVShlWPdiO9rtQpoJhvLOMR1EsxPrKmtA/3M7fI1Fq11lwPcjpgAeWDNuXLjc3cnMoAcSsdojPVtuZ69eYfXGrUm9BVrrIcpMPk56HuejcLhigbwb65n2bIN398TxzkWW4kc4/wGjwdhG87PWro8eWElK58885j4LIkAtdPjWEystX2c4vkCrsCVMXZikREcr9/iOXWjIdd7IfxeADZ8/B4iIme8/pvEyHk37TfXt2kf7RavtX708vey8q1bMlfUd3huSzEf+9iKxLNtbKziSWTFalXOCwaQ/3tdHq+sxyZibLQRfwEgOCoVRiY0mjVRrwfYHA9YXbj2G33Gx2/gGsyRY2EAfbDV4rj9oz/6I1Fv7xnSzo5c302M0jSb+9oorhSRFDDvMBYiKcG5CsRFo14X9bplHuPySJK15qlxB9c43DfxGRwREfUBeQfn6rlyzDw1BxgVV859uvBMaANoVF0rBhfLgA7e5RhZj+VYE7c5ZhxYtyfW/E5gdR1AZFjTu3gP4bLPvE/fYFapVCqVSqVSqVQqlUqlUqlUKtWBpA+YVSqVSqVSqVQqlUqlUqlUKpVKdSB9qJ5AxxgKxrakxLFfdwfLfgJ28WD/rb0j2N4xn5P2JMQXzC/wztOOtRt2kAdLIFhsPOv85mbYTlzrsJ2lXpNWv3KVbRCOZWcsl8HqAlgH+7Xzks/2hk6dkQ+44ykREUWwS7zL7dRqyFf/h32+rnAAti1r18u93Von0X2cpAn1x7bhRrslPsNdme/dY6TDj3/yuqjnw07lXbBoGsvyeOHMmawcgp2yXJCxuHKM4+qVV9/gc0ilTSaC2J4tsUVqYUYiN2pg5Wtu3hGfrbd599dBi21bnhXPRYiDIORrvPnGj0W93S22tkfgAWwPrJ1VwSYUg13fs+xNmX1lEoOHiNLUUDwc3ZeBsbA7YM2OEr4HQV5aXqaKXG8ZMChnF2TuyQPywK+cysrPPCutWkmf+9+wD/fU8oilYJffBnTKOqB/iKQtOJdaCCKwQudDvq7GrsTNGIiZHOSh4VAerzuEXa89julaTe5a2wYcSQDWRqcgd+uemht9l+tN5t88HeNQMT8659hqWgLrVh9s+gVP2tsKAf88AJt/wbJWFUsQT8L6ZdkjXcANoJUztKyHME4YsFgWctLKevw4W0VbDWmZKwcc+zm0j7kydxrcTR1QCaGFTTA9GKMgZ+DYP6oIXjDE8FiDprH+nSTFSUytMbqp25Pn3cexuc+B5btyDEdf7yACXIZlmUWkUx8wZNFQtv8CzKseNPmc/t0fXxf1XpjmXdtNwH126bS08s0vsrX41tUr4rPaFsdS1EIrsRxPTZn7wfLFi1n5iQtPiHrPf+vvs/LWxlpWXl2Vu3O3W2x5Hxoexzxr3lMbYwOiZDIHL0NEztg+79jj7j75wUZkoOKQ28JY6JTY8D3p9DhmEmsua4//jzofImkfTiFWAwtPsLXB40az0RGfFcAmPIVoOYtdMITxqg/IPNfCMyDLwkMUi3XuUYvPI4BxqV2TdvZkjCVLHxoYJkOe69BsadSG0xU57h6b5TnsVIHHnXRKzk3jAbftJuDBWuF9US+C9UXU5jlHzroHs4u8npqe5u/6zGc+LeqtgL097fPxpiw0xx7GgYhodyBjc6vJv+dPL2XlvJV/BhBOHbj3ibU+CMGmfg9s6rMWzvAMIPDub3E+n59dFPUqweh8X/QnD9ETRhHd3xxd4y1AYhAR9UNuh0KJkZKp9d4arqVzecg3juwvBuYzM/McH45FJkQrOuJKco6cb01DiNQiPvbCgrxPKydPZuWK1T/6Xb5vtW2esw09OefHzFGAfjSM5HwmAnzL2WWO2e1deby3H3CO7occmFEsc5Q34WhCIh4T7PkrIp0MjFeetYh8+9a1rHznHs9PahZmwjHQfxK+V5W8/N7pCgfG7Xu8zp6ZlYgMfC7QhblEaVqi5SpVzo02qrUFzyq6gFaYBZQekXhcRbs1XtfZtxcfS7kwXg2tdXsEcRcAYsxYaMu/+Ou/IiKiRlOi6SZFcRxRvT6aP9pzC7wWEVrWs7sAkWCAK32wK/NZF9qwmPD9WZm10GtwHvgsMLTi26vwWOPB/D3nyDibLjH7ohjI/HO7zfPv9pBz0dqaXGefWOS1WyHP8RhacbEBcVEtcqwGBflsUQx5cF35vPUMctxX95tvTuZqXqVSqVQqlUqlUqlUKpVKpVKpVBMvfcCsUqlUKpVKpVKpVCqVSqVSqVSqA0kfMKtUKpVKpVKpVCqVSqVSqVQqlepA+lChT8ZxyR+zs1zrm/t9Zl6FwKLt9ST/ynGYm5XAR72uZMnlp5iFvHycGSeDnmTNdPvtrFwGvkhe4pyotdPkHxAFGcsLaewwc2fYlfylZsSfFYBB5zmSBdZtc1s0+sxdmbGYvTngjtWB27OzK9lExRL/Xg6+tx/Ktp1YgC6NziwcczfbFk9yu8HX+9YV5j+ubUnGztwSs8+Qwbxj1btxZzUrl4BfdAz42kREv/LLv5CV760ziy4eyPvu+nx/DfD/YuAbExFFXYgPI49RAChO3OHrdSxm6axhllexwTHbGMrv6gFTsQvs8V4o+5EfSFbintJEwqFsPtLkyVBKo2vpduS59vrc7pvbt7OyZ/GG8mVmGz13iZmj6/ffEPW2XmOu18nzzBA8vTwv6rkf42O89PwLWbnVkHwlr8hcprjH97QG/FEiom1I51WLF573+JpLRb6n9U5T1Ou1uC06EFqdoYyLqMu/FxHzqvJ5yfXt7EC/gLxenVoS9QrlMWN0Qv/kORgM6MaNG0REFBuZ8wvAxu+2eTzZePBA1CuX+T76wFscWnlgepoZXTEMckEg4xGPEUXASrfSeqk4DfWYAXjVYuXGkEuaXclBffUa94vtHc6XUV/GTxIDIxVyxENsVoDLJSKXWNA5wVrer0yTCV/eU8rXmIYyX4t7D3xFC60sOKAOXLvjyg4DWwZQFEP7x/J7l6rAW4XvfeGFVfm9zzILeeki99lWRbIGP/mlp7LyylkZgGu3geu7y+Nuuy8ZnG24ifcN76WwsSrzYbfMPyfA8WwMZcy6Oc5Zrst5bSovc+PL4/Td7U0mQ5eMIW/Mi/Usli0ybxPoYzbHHxl5PnCHU1cGGnIyZ+eYq1prS+6w+C34nYe6IXRT7PN2Lgtgwt218mEeYjyB+YnNhe73OcZrOAfzZKx6kDc9mN94s5KLGQIv1Qt4XLt7XY731B/lw17T4qZPiByHqFIc3YhSUd4h3we+InHblq25z9zj57JyMM1zmk4k5+K+w22dwh45NiO0OAX7VAAPfmlJzguqMzznfrDO86pKJPvBi1d5j5FWSc5Bnj7PuenWDs+d26lcJy0u8v1PYc+K06eOiXq5Gc6drTrz4R87d07U2wE+8+Cln2Tl0FofPP/6W6PzAUbrpKg/COntW6N5pnXaVCjzvUlgnLb3CipAvikGfI3d7rqo14e1fh7mSjjvJiJKYN06AC53z5qjVuAYM2c5ZhdWHhP1fMg9u9YeIgHknhTY/cWSZIBjfkX+bbcjx6QBrDuLwHV/4uyKqLfZYPZqF9juNvo+Ho/xk7r8StOU4nGethnMKGT6R9ZcZXeH93BIYmC8W2vamQqv700O9qzoy36VA4Y6Tp88T57fyjLnotW3b/A5WJdRANa6sd7ZLBa4j+DeWLVducfJKdj3yQM2/O3bt0W9AYyNy8sc07WG9VwL6iUJx0+a2OO9HBsnTY7rUGmvHz/EYIZrQR6zNffJE4xDsMdEa03G2YNNXrvdu83tMj0lx5oyPBssLfCzNcfiWzswG0ohJcaBbPMezIuiRH5WdnmsyYV8/O1dmVfe3uR12LkVzk2hI9dTUZH3Tplf4vFuqiD3Yqrf5D2/CNn2Rj4P2lvX7Zd+JnQ5r1KpVCqVSqVSqVQqlUqlUqlUqkmXPmBWqVQqlUqlUqlUKpVKpVKpVCrVgfShIjLIccjNj+wE7a58JdsJ+HX1fAFOK5KveAdgb4vhlfReX9pjdmtsTzJgAyvm5TP1RpPREsuL/Pr4hYvSsvKTl7let8Xn1A/ly+FhxK/Z51z5unsL0BcRXK+x/LCdLtto0HpjEnnuPqAXwiHYaCyjogu2NXCj0TCyX2yfXJ9xnCRU74za9s4DiQa4tXYvK2+32Spwb0Na1L0iv+p/7sJ5/p1taf903UdbaPK+tFR88rkLWfkLX/wEf+8dab1b32V7bqPGNpkc2KWIiGJAf0SutH8iMWN2iq9jaNnCcmCLzid8f3eb8hpb0McaA46dOJX9rQQ2M7SkxJY9NR3/nE4oZiVfyNOFyyO7d60u273XYMv/T15ji9wPN2Wb+T22Wv3P//1/m5X/xVRJ1Jue+3ZW7myzDbC0eV3Uu1jm+30DXCj37khblHvyTFYOoc8OUpkP2k2Os15H9uUyIDMcl7+sZWF8dut8/R3IKfWOtLhC+qIbt7n/nZyrino+2NEGEJueI3NjmtkKJzN+arUGff3rf0FERJ4vLfYeWB1dQOC4Vv53wfrmAaqoUJAWUOG0EhY+OVy7mJwSRE7INiwU2GYVg/1wtyHxFo7H52QCiQMaJGBhh+7Tt9BUD3k4+aysn9NHlB7+CW1x0mJprGqTO3a5rkMze3ilRPajHMxn+oCMyAeS0YWoFCynVnunDlsjDQwacSLxDy6gJZ4+AZbMdSsf7K5m5dou38PS2SdEvVmwjV+YWxaf9c/zd7mAaFnbld/1p3/NufLUWba1OwWZ59ITZ7Ny0WXv4ZW3XhH10LH+qfMcz/FAxuzt1cnMOXsyxpA7ZspFkY2QgbZB3IVrIzL4M7/I96rvy9yTRtw2+RzHpmsdDzNbgn32PXbDfEHa6E+c5Pl2aKHb0HYsEBkWpisPc6FFaJfIyg1ooXVgHIos3NgQ50IwR0ota/aVn4zwB/3e5CEOiIhc11BlenQvnZyFB4v5nM0m22ITa/65vsnXvN28yr9jIdRKJZ4LYdsGgRy7KgO28RaLHIP2fHZtjef6r770Ulb+jifz424fMC2lafFZLn48K//k6tt8fkZe4wxgfy6dZXv8UxcltiNX5vj57Oc+zv+fk/OCcpnj58o1PvatB3LcHYzHxsmcOxuKzait82XZ5uUqt3MbJgU5C69ShPlHu8FogLQor7ff5bHRwFwnyMt5FKQy6sHv9HuDfevNLJ7Oyl1r3eXBHGMYyZgo4twMcAJBTraFK2z5fE6elTcRFzLo8HksVSui3ol5/nl1k+sZK8YSdxQ7iF6cNNl5+lHC9aSxUAgBXPM04FKiBYkM3dnmZy/5IiKX5NwH19lTZY7NvIVSqsLa9xjgc2rWWqhS5FzWBkQeEZEP9//cYyey8vaOfEbwYJ3z3OwcoxSPHZN4nvV1niNhu544Lp9XNZqcY9oteO5kzR+88TW/E77kH1KGDPnjdck7YWAMIjJI3kfj8LjegzZrWG0xcPg+3rjLfW552Vrfz8DaJQUMW1AU9RIYo7owL3eMxFs0OoBGJTl2nS5zHsgDo2hgTbTuN/mYrsdreN+ReaXu8FiWXvpkVi4eXxX1muu8pjfR/qjDd5O+waxSqVQqlUqlUqlUKpVKpVKpVKoDSR8wq1QqlUqlUqlUKpVKpVKpVCqV6kDSB8wqlUqlUqlUKpVKpVKpVCqVSqU6kD5cBjMZisdcrlxRst/yJWaKFHx+7l1bk0wbCoGTBrgkC58jWF6DFvNoCq7kqUTA4+t0+LuqZck6yheAT9lkblk0kNw2x+OfS1XJZNlaZ9ZKtcxMwF5HstvCIR/DB2ZTC1gtRETFEh8/AiZLYixmIdzlwPAPUdtu2/HvvU/OyoeilCiNR+cV+JLxhUzBFjAE+xZPuLbLceAk3A5L0/OiXh54UAWX2Tn36jdEvRgYawsL3OYvvyQZa72IP8sB17A/kO2fQkAnkWTs7LaA61Virs7i8oKsB9e41WP2VG8o28Jx+Lt6wNgpWOzPqSIwmGPg/1rs8XjMfU0mMHSIiFzPpbljs0REtLgk24wSbutmg9lYW811Ua11nz+7s8585pV5yb/6+S99JSvf/fHLWXl37ceinrPAvKXleeaJvX3jLVEPUVHYz9sW89EAC3ho8fwawKfrbTCjybVyRWvQyMpekfuZKch8WAPec6fN5zHoSb7UygJzrbrA1swVJLvRHZ+7zY+fHDmUmtGYFUb2Z3zOnT63RWyx55B/NoS2SFN7nwEYa4Dj7D/EYObPkhSZxjaDmcdaF/iIQ5tb7EIeqMrxuVjknOM63A+SWH6XA6cohxErMZh35/K9k2xmHHPXJi9+wiim9c0Re7JashiKBsdt/H/ZPnHK8RIBR9tuVhf+o5AH9raRsXPnATPmOh6PE5W8ZLYZj+sFeT7BRrgt6r30xpt8Sptyj4TN23f5syLnm3BKTtraA77meA1ZnfKeRhBY+SJcl5E55dr6nazca3O9tCM7cL03+r2exf6dFKVpStGYUT+0+NEFYBk7IbfnQ/0Dfh5CXupYySwFVjpyVR9i76WP5i4/xHLch+0YhZKL2Ye8mSbyd2LImxHu/WAd2wMecA4WBBZWlXowv8Y9DWJjzWmAuTqAc0h6ss325o97nOxJU5LG1EtG43LOsfZtCHm8dmKej/olmf93YF753e+/xh+4ci5erfI8pgH7odhx8eWv/JOs/JnPfDor37gp59j9Nsx7B9y+93Z3RL1Wh2/yiUV57t9/geddA1gX9juSg3rf5et/7DjH0s7GTVHveOmxrJxzuF46lPMxJ4X9eCocP2uvXZPHG+9bsepN3vteKRmKxgtI13pcMIB+VARWqGdxuRNIEMjaxb0hiIjyAX826PN9n7H2g4iAu9ys8d5IZO1J0sMchXMsKyU1YS47VZUMVM/lYxRh3VWwGPIGcgeGerkkr9GHekECsWgtnBZh/rUGbOEJHaL2VZqmWa53rfkrxkIYcSwFFrc6H3BbJxGvY5YXZkW9bptjYafJY1fPkWNNBcLTg3sVR3JsHQKrG9c1/Y5kfQ9hbdVpyrW/C/O4lRXm39q89tW7vCdZvc77NJ04cULUm5vjfcLu3uV51fa23NPsxInjWbkMXPzNDVlvOBj3pfRw8/EPUnvTlfQdHi5g/3PscdyBOU0E/PWS7MOFgO/PnfX7XL4j4zGE+12Y4/6dVGS9GPbs6vR5XR0lu6LeYpn3LQpCmZwcGNcM7P1QnJax34759+6u8bMJRz4yJKfAv9e4wnspzBfkflPTsKcKtbjf7jev3G/V9a4jmjHmpDHmW8aYN40xbxhj/ofx/88aY75hjLk+/nfm3Y6l+uhJ40d1UGnsqA4jjR/VYaTxozqoNHZUh5HGj+qg0thRHUYaP6rDSONHtaf38ifTiIj+pzRNnySizxLRf2eMeZKIfpeIvpmm6QUi+ub4Z5XKlsaP6qDS2FEdRho/qsNI40d1UGnsqA4jjR/VQaWxozqMNH5Uh5HGj4qI3gMiI03TdSJaH5dbxpi3iOg4Ef0yEX15XO33iejviOhfv+PBDJHnj16m7rWlzcwFPEDOY/tAKS+RFg5a/RP+HceXdstKkW01fsDHy1n2i3l41bwIltIuWHSIiDpdtj95cH6edF9Qscj+i7mFqvisvsuvxqfE129c+YL5MOZrTMEa6xrpjzHEX574fE6hI4+XAA4hhZfZXc+qN/YSPmSHPISOLn5SMnsxEkoriz/kdiiClXE6L3EPnT5bjbZrbBXJW3anbg/s/2BtuLYj7XtOH2yTLsdLGElMQHOHv9ckbHOo5KSVDB1yrY6MP7RoVsC+ePrksqy3sJiVX3v9Ch+7Im1myyuMiahfvZ6VS0XZ32an4Pfid/BnGXf/zw6oo809KZEZ9bmUZPyk0K8KZe4TS8cXRb2Cw/khhNzTbkirpUm5L37q534lK19/Y0nUG4QcC8GLt+EcpMUzBVtKvcH2qSixWA1oDXoHS7MH9mRj5YrCPH/3c5/5WFZemJUYmb/7jy9k5Qdg77q/K7+33edrDCHPleakdTAZh49NbTiMjjR+HIfc8ZjiWVa/IMd5Jg8W82FfInDCAVirwJqekrTL5Sps0zQwXjmurEeA0kBERmJZ/XIwFjou5JxQWv08n+99YeaY/C4Yn5He8/D9wv9I9/l/suys+/3O+zjeB6Cjip9Go0l/8Vd/S0REMxU51kzN8kscZbDsTU+VRb08YE58GOtznhxDkLMRg/3fkKxX77FVcDPH99brypidI45tH+z0z1ySlspeg/PXW7elBXBjlcfQtMrHywUynmeO8/V3Ij6PflNazwfwWXsI1sOqPN7tPl/XtZt8jNJAtu2gMbK1dvtH5z8+ytyTJikNxnk0tsZgB5AHiMxxLBQC+ra7kIfyQ5kr8NcaLZ4HJbaF1ry3fmn2KSfW+IQ/2mghkdugnn2NKeCeUnh3JrXGyQTs2DEuJ+zvBbZGH8ax1saGqLe9OmqnflfO2Q6jo4yfOEmo1hr1mYWCjP0AJp3YfmEs23YO7OinzzIiotOXY0gAfRroEQ/dq6UFnk8YiJ+nL18W9W5cfzsrN+Z5HNvpSit6u8Xzot2ctPu6kCMjGBsb1rztuY+dzcpnVjgvP9iVx1s4eZHP3fDxug2JDYpgrl+YhXYu1kU9CsY9wzma/HOUseN6Hs3Mje6VY9mj2x0eD3BMCgI5xnWgXg7WCXlr/ZPP8/X7iIiyUs8ALOpYdi0M1KAPmMwB983KrJzbGB+QSwU593bhy+dhbRVZc6xwyMd3Ac8zXZXrrjDP19z3+Ni1prz3eY/PadjnWO8OrZw3zo127jqMjnTeTDxHDCPrYQnEUwrnn6RyLZmDNahnOM6mA3m/zy1zn+2tco7f2pH9PK1yfJbg2I26nLfMHGf04dnTvM4ubMncU4NnCZv35dhQyXOuLHj8vTs9ifjJwSV3ujzudtsNUW9lhc+p0+HnS/fuSyzZtev8rGJujnPt1IxEwPR7o7h13KNbvx/p3IcYIfiOz6Vg7Wv3BZf42hAr2UvkeB0Atra9zuvTt6/KuDXQ90sDjplp2bSUAxye7wHqyUrzSRvwlZHs37ev38vKm4DYNUX5bLEAfWs24GOsbtwR9cp5/i7f5XPf7D4Q9TzAwBSJL2wQyvPby/v73Zn3BX0yxpwhoueI6AUiWhoHEhHRAyJa2ufXVCoi0vhRHVwaO6rDSONHdRhp/KgOKo0d1WGk8aM6qDR2VIeRxo/qMNL4+WjrPT9gNsaUiej/JaL/MU1T8SecdPSnhUc+xDbG/I4x5iVjzEtD66/dqo+ODhI/GDu40Yvqo6WjyD2dVvdRVVQfAR1F/BzlGyKqny4dduyK3sn5ofpHraPIPbjpj+qjpSNZdw0ndOdl1QeqI4mdga7ZP6o6ivhpNBqPqqL6COgo4qfX1XX7T7Pe07bHxhifRoHyh2ma/sn4vzeMMctpmq4bY5aJaPNRv5um6VeJ6KtERNOz06kbjV4Vzxv5bDsCi0gfEAhRKBf2BdipOYX4tJdwAexkOzUFO6NbmImZaX4tPoBjd1syMaJFEC3Sni/td3HC19VsyFfrHYctEguLjCjwLJvr2u4rWdkP2FLqFqQFdGj4u0tgqS1ZO9cOQ+6kXXjQlstLK1O/+8E8RDlo/GDsFMtB6hVGlpr8tDzvJthkyeU28aZkeHchSjZiXrShzY2IaC3mXDifcHtdb0r0xfrN9azsDDjGHrt0XNQLX2e7yvoDQBxYdtLZch4+k3E1PcOWiFPLbPEqWjumfvFzn8rKZUC5fPcHL4h6xRzvTlsElMjS/Jyotwxx6mIf2MehftTG9aPKPSfOLKfO2Co7jOWk2c9xn+122H4dWbZgF+xtf/bnf5KVn3tM/iF2c5PjcfHSF7NyYUbWe+n5v83Kd7bZXlmsSEzJYMDnUSruHyNzS3zvbMuTC7EQwGfHj0u74InL/PP8MufGnGU/rNfZrvPXm3+flcNEfm9rwBGxeJqPvXhK7oJrgnEfPOIAOqr4yedLqV8cnbPvy3xdyHG+dQBpNGhb1n5Y6DuAiMgVKqJeeZr7ZgLtHlnTMROwnROGLor6Mk95gMhAL3pK1hhnOK+6nrSKJrDjeSKs6PKG7W9js2/sfjf6nQLgg8diPPSNRzB2+Z6XbqyPxoq4J/u2sDYK3IGcH1XBaluCXcGnrV3vS1P8GeJvcp68L48t8+994Wc5xz+4Ky2etW2Yi0UcZB+fkrlxK88xt3te2oJLK5ynegMut8hCyMB0qZXwD5EVUx7iDwDzEhp5TgZ2ai8uApKsIfNm2NxDJx2tjir3PPnUk+nenK7ZkX0b0QMGLMc2kkD8gSzmK3UttFXg8z1eAkt4u/PI03zoe200U7oP3iJn2eNxvBoM5LxZvFww5PwaW3dsMMRY5f+PQjnnj8HOPuzD3NiyIzdqPFfb2WIbdLsp61Wro3szCI/2YdxRxU+x6KW1rVFb+db6x5/n+9CBmGk0pH14dpHHpM994UJWHoSyDw+hbRGb0O/b+BC+d/UaW9g7bXm8P/1TnmfNzfD8ZmihXRBLMEysdVeffw4CrmesuTMie5KYAyiMZV5xBPsD21MerwfW55kC2/enLAyD546OYY4wAx3Zmn1mLt0bRlxrThnAnBJTr+vIehG0XwHzknW5HkxiEBcY9eT9TACTmcCkKIplTBCcRwi4m6GFWDSwLrffI/DhGnM5rtfuyBxgII+KOVAiLxLvsQvIM8eV9Vy0/IfcdwZ9O0ac8Xce7dr9qOLn8QsX0uT9YjysNpud5/X0uXOM7Wut3xT1Fma4Xy02eJzcqVtoF4iffBlwp75Eau7CGmdhnvvv8TNyb7pqh39vflHOfTAUvIBjcH5eoooKRV5DDGF8NlZfGvR5TfHgAWMNYqvNimVeU/RhYuVbeL98cdRmDyG1Dqmjip+VleNp4FX2/t/6EvF9ULbwuzCnGfIniSoAACAASURBVMZczyvI+51CX49hjnnzuvwDvx/zPblwide0kTX/9PFZm4fPTuRzvATmDfWOHP+2VxljYRKOrUpZIjKW5yD2IRbu9iTWtR3zc4arD/j8Cn3ZZmcD/q4y5L3YfmQ8Xu+n+7At3zWqzOjO/R9E9Faapv8rfPTnRPRb4/JvEdG/f7djqT560vhRHVQaO6rDSONHdRhp/KgOKo0d1WGk8aM6qDR2VIeRxo/qMNL4Ue3pvbzB/Hki+i+I6HVjzKvj//tfiOj3iOjrxph/RUS3iehffjCnqPopl8aP6qDS2FEdRho/qsNI40d1UGnsqA4jjR/VQaWxozqMNH5Uh5HGj4qI3sMD5jRNv0v7e1O/crSno/rHJo0f1UGlsaM6jDR+VIeRxo/qoNLYUR1GGj+qg0pjR3UYafyoDiONH9We3hOD+ciUxJT2RowRJ5RcpRQ4TZ0eM0ncwOJd5pk1EgN3qDmQvEsPuCvI/kksTtNui3m708BjdozsH7OzzN3BTTOGAl1O1AaWSdOVTDbk7NSbzHWJLbaMW+BrdoC7PLCYqygv4c/SSNZD1li5zO1X27G5aB8+4/K9ygs8mluZJyKiXV+26wtbb2flCPBm8VnJSnKAq3Y3Yr5S4MvrNiGw9268kZWv398W9W6+zbzKGY/b8kuf+iei3grw677+x/+Bz9XiKyHB51Mf/5j47Oyp01l5CbjI1JNMxvNL81m5+KnnsvIPnn/eOndg80D8LS8siHrzM8zqdIEf5jtWrCSjn42ZzBiKk5ja3dE97/blxgGIoWx3II+kMj3GwFv/q298Kyuvv7Ui6m0Cezd5g9vZZiYPBsxxC2Y5cIcPaqJet83srl7Kx1iwOMb/2a/+fFY2eXkfHBeO3+JjHJuXfaTnckLrAV+xWJBc9wuXzmXl7337xaw8aEm+lAP5+uLlx7Py4qw89144ujc2E3RS5DgeFUqjvuUF1jmGnEvu3r6WlZvNXVEthvyD3cS3uFsJcNLml8/zObjyHhCw0/PAhR4YOWYmwFNOIH4ckrkjBS60YzG3YxhDHJg2eHZ/RxwrMO+NPbakB2G+4Ti5z/dOYPrxPY+OzY362eUnHhOf1YHn2o/45K++fVvUu3XralbG/SWCgrzXxWmOEeS0nVyRzLYy8Rg6vMv56r/+lY+Lel/7w+9m5bUHPHeazsn526bDx9tN5Tl14Z4kME+JhpKBVxpyLipDfAxjmTedmDnTBYzFSE7GYpgT4n4dYSz5mZ101P+Sd5hf/UMqTVMahqNzGwzl3CeEeTRyOHPWvLnVhLaB8d61xvHA59yGrH6bD4s8xBSYf0kkGb94vxPg9PUtznK3i+Ou+EjURX5qbMUFMuqLBeSbyu8axJCvoV81duW4G/d4TteGdYLjy9yYOHs8zQlMPkQUJQltjOOmtnVffFYjbpvpCq9/Youp2N5czcpnT3G9pfl5UW97m1nVFy/yeL+2Jr/3wQNmzy/MMVv5/t17ol4hxzmihvfH4liihlYfMbD+c1zYZ8C1rrHL42EOGKbFWAakD0NXH9aTni/nBXmPz30azvfiCTm3H44TpO9KpuwkKIojqu2O1j2louTGBnB9Luw9ZDPPsfXCkPtsvyfr1WLubwb3IHAk23QK5qIB3M9WV85nEoe/uQmbzc2ePifqBXm8LmtuB3muC/mg35cxFsFmiH3g5A+7cm43gJ/7MD615OMLcuD6feCLuxZf9qdh6+m9NaHN8JZrRYwSWS8FkuvZizw/WbVy1K0bb2blEuyrc+KYXNNuw15KPdjfxrG+dwjPpPqbnP/zRTl3NfB7fl4ymGPIHRvbfO/LFTmXX1ziOXoIv9OwNqff2OD86kP/8wLZFh6M/9juofXcbTCO20ndxDxJ04ypb58jXjHuN2KldRrCvgMdmJ9UZhdFPb/KOT+FjZWrjtw35c6bvPfWrSuvZeWLj8vjnQYe9wLsjVIuyj3EkgHHU9iVY00A3OUg4PPLl2WcFYAnvXvjblYe7FprS9hHqt/hnFWsyHH82AnOkbOQHx/CYI/7sOc9ejw+WrK3SqVSqVQqlUqlUqlUKpVKpVKpPjLSB8wqlUqlUqlUKpVKpVKpVCqVSqU6kD5cREaaEkWj17Jti32pyPbIGD4apBJp0e2xl8QP+LXsUkm+xu6ALQDtkYVAvp6+MMWvmucL/NmuZZdDO1WxyK+Zn5iqiHpXVtnami9KC2g44NfVe0O+DsuBRQRtkxi0M8pqiQH0RxrvWw+9BNguubx8rb0ztvan9nvwE6B8Lk+PX7hIRETX6nfEZy2X2yEAm8PitLThOwNuo26P48q1rI0mZFvK6g227A0a0l5SHbK1r5BwW7o9iR45McP2g2NzbKO4v7kh6i1M8fk+deaE+GxuCqzPLt8fr1QQ9ajFcbuQ53v9lc9+UlT7Dz9grEFrwG1RKcjjDbvcFgOwqiVkWWGdUdChTXeSZIzJsDlpV55jEmM9sKblZUcqQNtceOpiVn5s9rio5zQ3s3Ld4bZdmpM2lOLc2awcdjlmamstUa+1y3adCOzIjYa0v7T6bP1ypUOahsDyMTHH6kbDshkHaFPk/691pIcv9vg8imD3amxKmyK4zKi2zdeRhrLN3Hj8ZZOXeoiIqFwq0Oc/8zQREaWRtEf+8PlvZ+VowP0lsGxDMYQTugNtykS/wfEzLHPbTq88IeqlYF3y0CIWyTFuALiBiPicjIXcKANuYWlWjmvDiOM4rfGYmbalVStJOEfGCeRB+74mj7ZH2tXkWGQeWXzU702SXNeh6eqonaozElVhPE4+gyGXn3rigqj39zXOCQOw+aWWVddtcqftdXay8pOPLYl68zBO3lvnexv15Rj3z77MiJY/+4srWfnBlqhGG21AbjTlGJK24HzLHIvWVIw8B3APhs8vl8h5VArW5yFYQxM5VSSvD/0POt8JV1pme+7oYlaNjQybDCVJSr3xnCJvNdpwCG0GFtJ+T+brBOpFMZQjeb/bbW6DVoPzdd+yehvAucQhfy8iLIiIYpiXpinHZr9nzevB3j60LPbNNn93B+Y3zbpEEJ2/9FRW/uzHn87K91aviXpXNxlbNWzzMUpFOWjW4ZxCSDClqoyfwtKojzi35PdMity8S1MXRv3JdeXcp5MCzguQI4G1NOzsMh7urdcZG5damBsD7yx98xt/w8dO5D3FMe9HL76UlWdmJLJreorz5XrnAX9g4eUQWeD58pw8WEMhIiq15rCI4gkKvJ5cKkk0RAw4hDAFm7GFEXMTPse764wIqXVl8ozG8+/YWutOgtI0pWiMtTAWkgBzhwPckDiW7Yq4nrDN9yJ25PwoAnRNCug/15f9sjTL8+h4io9X78r2i3AuX2TUX6Ek14UYL0ks+4cHa+xGF+bl1ho7xTU7xGbiyH40hF/Er8J1BxFRt8/9MoLk47nyeNF4fjSZcJ6R9mz09nMFRGS4cF0PXSMgPx2YF5x6QuK8IphTrgMu4/a9TVFve5fXQj7M0QMLK4Xna2BuUCnL/BLB+Fevye9CfEYO8ARTFXmN01XAUTkcCzs7ctxtNDguekP+XqtrkgsYP2y/XE7OHyrj5192/E2K0jSlwXDU9g8hMiB+sOw48lqGcP2tIZf9ohzHQ3jwWPZ5HPrMUxJr15rnsfCvv/3XWfl7370l6r1ZBUQSrJEr1nNBWEqTsfJPC3JpdJLn8PMFOU4Gfc5N9+7wWNPaqot6LuA5Kkt8vIvnL4p6J5ZP8e/0AO1o43zHfdXG3+xpMqNKpVKpVCqVSqVSqVQqlUqlUqlUEy99wKxSqVQqlUqlUqlUKpVKpVKpVKoD6UNFZKRpmu0iW5qSNsowZKsRWkwGsbS9FMC3jVYctOmNfo/tO1NFtjtVLaRFDr4rhR1uI2s3bLQW5PP8insrtHb1TtjCYAJpP58q8mvywy7/XrcpbRBT8Dq9D7YKNyd9EENom3abd8k9vnhM1Gt3+TX5YZ+tHrYlZJKVRgklu6O2PVuS1oYSxEQ+4nuT2xHVKBdxuOfAYuBZdrtowBaaqMgWmsS6n848HyMf8N9qzEDuUo9GsCeWl7NyuyntCz/zLNs6nzy5LD5zYMfhAvRa40qbWQGsasbnmP3y5z8t6v0YUC6tVcaATFekHbAH9lRDYFXyZCym3hg/kUymWT1Nk2yn57JlZfQ8btA+7HofW1ZdB+xuM3DvW72mqHfuGbaXxJDnclac1cB27BfZClpdkbvRrq1yPJ2Evr3eeCDqra9xwC/k5H1M4N5Vq3z9rsXT8WCncLQ35wLZZn6eY+vEOca53L9h2YRhd/F7d3j33d5A4h780uh4xpnMv3nOzlTp13/lF4mIqG9Zszvb3H+asIN4vydxIZRwzjeQs1xPjoUlQF987jJblz73s18Q9Zoh13PgeGHPstWBHT0GK1m7I+udOMbW0cuPPy4+GwLS6Vt/y/foe9+VxwiHfI0xjE+JzS+A2EJLm43YQXtfAuN9YkEx9n5yrLF0EpQLAjp9+iQRjXbFRs3P81jWA6zBVEXm9ekq3+vNGo8bZQsN9vQl7lce7Cyd9KQt+/hxvtcvvszWvhtXJFrhqcs8X5rPc5zevCbnDskCo1K+dPIp8dkrq69k5dtbq1n54jOXRb1qntti8xbjo5pDOZ6685x7Sh63ixnIczqeP52VHaBffOXpz4t66+WR5X/7LYlFmxSlaULxcNx/BrIf+ZC/mxA/aST7UQXwTH1AeM3PSLv4zdXVrHz/Pufrnc1tUS9XBtskGLQHFgohhP4bgoW9uSNz6NY23+/NbfnZbp3tn/0mfzYIJdIkD3MXkz6blVfm5TXWZ2Gs/dRzWdnGQL2W8BzJLHAsHTv/jKhXnlshIqJ7r36bJlEmNZQb4xrSSI6vSQy7ysNYjbZiIiI3ArQSjAUb6xLztnyc0VclWO+klr25A3OfDoyZnbbM30vHeL4ThrymK1fkfGQKUIepNc8KhxwnLqBdMKcSEQ1hLXftJmNU5p6QeSqG8+gAEqtuxY8DKLvXV1/lY6+9IeqVxvP0MJ48RIZjHAr8cd53LIQAARon5rareLL9PXjMsAth0DXyeNUF7qdpDfA0JI9nfD5eDGvxvi/t/8988rNZ+dwzXHby8hkArmSKRfld3Q6PCcOU46hvzfk9sIjnyzAvs5BG+SlYdw75Gu/el2PPJuTD/hBRAPKRjZvN6ycXkvH+kZuWDR/wIxF85BRl/338Kc7lOcg3rZ7MZV6Bx5ANGIfs/kuw3usAKnK3IecjFZiDBTkrVqGPuA73kVJBxr4L19xp47pBtkUF0Gamy3mo0Zbx2KjBOUJbpBaCYW99H4WTl3uIiMgYMmPeo2e1hY8oGph3GAtL04D83+jxPehbc5oQ1h6LMR+70eyKeluAi/JyPCf2I3nvY58/uwv5jLbkvTI4NqbW/KnA4+6Zi3zvi4HEbCTwzKoF99JdkEg+AtRvDp5NVOZlTkwAVzcF64hCTq5V99AYniIyVCqVSqVSqVQqlUqlUqlUKpVKdZTSB8wqlUqlUqlUKpVKpVKpVCqVSqU6kPQBs0qlUqlUKpVKpVKpVCqVSqVSqQ6kD5XBTMYQeSOmSOJInkqUMPMjBWqtzfYIPGbXDIE1MhzK4w1j5u74hp+jezPTol4M3GUX2FG5nGScGGCSlMr8WX2nJeqdPMMcQWRwERGVisDdAd5Lf1MyXspTzE3JwTk5nvx7QB54P1GO2yLISb5PPuHzHfT5fJFhTcQsWmMmj+fkJSnNdkfna0KrXeE6ioY/Cyx2lw9/TylXmI0VWOyusMvXnw+YmRWUZbu4Blhb8FWpJ7uVMcytecnnioHFv12a5dhcnJ4Sn7khH8MF7nJsrL8RpXyOns/1zp+ZEdUeO81MwVv3mLV49tRJUW+qzHwpEzOjymagDsaMyPfP2/rwtHdmxaLk9xlow3ab+abIzyIi8oCnVpzidpmdlrmiCLzLOnG/DC1OvOsDy33AbKi5E5LB7FeYkfrMM8zGHb5m8d+HfPz5uTnxWepy/ioGfO5hLO9X4mPuRTaurJcHHuv5S49l5TdeuCvqlYF/j+0ZpzJup6dHOc/Zh+X0Dy1jnOx+LRyTjPtf/Gc/n5XbwHtbXV8T9QbAeHSg/0yVZF9/+iJzl3/zl34hK5+6dFHUGxL/XhHuRxxK9vNmnceXYcL5oWexml2Pz+nUqcfEZ11gZm5uXMrKjYbkpfaA7+pCHkxiGasETGbcCwDZ1ESU7dlARBRBObGYnntj1vbffYsmTX7g0/LKEhER3b9/T3w2GHA/KCEb3mLZz81wP6o3ma+XWP03Agb2+XPMgt9ek/OUjU0+DxNwTGzsyDnB0zD/mKvyfWpEZ0S9oeGcV+5aDM4O554BQDg7JcmZdgocY81d5t82anIzhYslHrsC4vNdu35H1CPg6J2e4txdv/oDUW15ehSnviNjalI06PXp+ptvEhHRcCD7UQJzwibsw+FYTM7GLrdhs8G8vqK8BWRgjHMhF9e3N0W9AszB+n0+p40tWW+nwXHXAZZy06rXQoakLzl/swtLWbkHe6v41ny4DmzyrU2e01w8vSTqPfPpT2Tlm/e5XdbevC3qzZ55MivnppktHBQk19AZT/4mb9Y8km9ydMw5R0QyJxMReR7PQXB+E1j13JR/rk0xL7aQvy7qHVvmsTHwOV90e3KNk4P9ZAYD3EtG5ils1OMLzIn89OWzotrbfZ7v3O5I5mp3m+9xAPOgcwvWHhsBn+NrNzlHdFpyr5SyOZeVw4TPt9WWHNNghr/r7W3mLudKMlLC8bR6MqfOhrzxHgn222ih4Llym3e6cv4RAQ8e0fDrO5JFeukYz3uDKY6jrZqMnaLhmHWBd/ypL0r2/4UnuP92YF2YGnnfp+AY/a6MvwTqVio8Bnux5L/H0Baex0l1pizndriXU6fF7fT2fcn/3diFdTrMiew9SkwyqVnnYb3TcwXkq0dDi/8Oj6kiF3jCFq+2mON2Xzp9Pis363L+UIHl2vFZvj831+SYtNXk+3PyJK+7POse7G7z/hbVknz2cgwYuOU8X0chJ/NrH/JjHnKvacnYr7Wwb3FblEpyDYrPsnDvEnu/qb21sOvKPTomRUmcZHvFhLGMix7M/doRrLOtPnG/znlmC/YPSIeyDwfAJ96IeE5z9+qbol7a5L5pUj6n1JXxmMB6vABzqX4q733swzMbi809c4z34orgOdX6tuRHL8LzrOnjZ/jYeRn7GLvz8Jzi6ts3Rb2Fx3jfgYUKP5dyfHl+Zi+e9unb+gazSqVSqVQqlUqlUqlUKpVKpVKpDiR9wKxSqVQqlUqlUqlUKpVKpVKpVKoD6UNFZKREtPfWuONKG1wO7A1DsEzlcxJfUCiArXyHLZXGl6/+5x1+ZTvp82vxUSQthq7Pz9hDeGV+Oi9t9DV4tb6TcLmyWBb1/AG/Qp7IN/ppMGS7Q+rw6/Rzi7OiXgjXj1bZsCfP3c/zNRqw8vi+9D0OauBLSve/5XsW6QkkZFDgOHR6bOGz0R4u3Gvf4evzbbwK/hzxvXAta0OuBBYVaIvEtichAgXOwfUqop4DFqcEbLj9obTUxWABqVSlDZNiwLzkoO9YfyKKAS8TwGduYCEJqnyOpSIfb3FGfi+4RqgNGJvE8vOle963yfT5UUpE0bgJYkcGuAd2ogDy0KAjrX75Iuee2UW2ZOYt978LVpY05Ngq5GXOcyFBIArgxBmJYFg9w1aW6hKfw+VnJDKhWOLjV6akNa8LaJwh5LnYSlLG4d+LwX7f6zREPUQyFMqc81bOzot6p06ztXjt3oOsvLVtHe/YyH5ox9WkyDiG/OLovvq+7Etnz/F9+G9+k8eNjR2Jj1gHazpawk8vy/t9+SyjDZYW2DYa+yVRz0BfdzBuY3l+KcQ7olPiRMbI9vYGH2Mg7WMRICkGEcdMqysxG60WX1cScb4IB9ICioOjLxAZsm+KXI+xYdULxmNeYg+6EyDf9+nkyVE/iC2b37Vr17JyPWErtmvhkypgvQwQi2BZKN+8xla3AiC55qflfCaEvLQ0z3E1jORYWC6fyMqXnuQc0g7l/by1yxbLWk3aLX/mWT7mF6ucD771Nz8S9dabHDu/8Ets0ZvOHxf1SoBXm5rhcezmtMwdd29z//vVf8FYDerLOVBjMDq/gnSZTozSJKF4jJ7p9OSY5JX5vuJcedCVcbG9xX27XuN2eaUnLZSzy3y/Ox2waYdyrnJnlbFNO4AguH3rlqjnVWA+AXPZdkvm/xjyS6kqY7VQ4nvcgblK38pR/QH3rUaNP7uZymu8cpet0HdrPHgPHYmVKi7yuRuXz8mxbMZONi+cwIkzERULJfr45Z8hooct9kHA44bvcfwYG7ECWJ5ykccNe+0yBERPChjA2VSiCR04jwjGEzs/9gcwfzKcc0JHTrp6AZ+TRUCgyOE+k5/j+DFFiUQJynzMpsu56NauRF3lOnwtnSbPaby8nPd7EX/vIOb+6BiLS7PXFmby5j6OIQrG851waOF5REUuRoA7ICJKAYcWp9x3EEFARHR7l3/v/AlGoDz+uMz/c4DMqTU4Lk+fldiUFqyjvQr338Ba29++zziddlPiUAgQd5U8n3vYl/eq2+HY9DwOwKQs73Ud8tIaIEJeuSLRWTstyLeGxysbfURjvN9kZp6R9vq6PbfDn+OE28xe3xPMhRzAGdo4NRxDyrO8Drlw6UlR740XGS+wucZ9+8IxiZF8/DzHUxtwB52unPt409zvEVtKROTBNeYBu1ouy8nGLCAxI7j+pb7sc7Umz7c3Nvk6tnbleA9pkwZ97ld9I/tmezyuh3abT4jy+QJdfuJpIiLasdB/bwHmbbPOc85hJPtmLUFsH9+PirUej6Gt81WOhWMrp0S9BXiGlsJ41TJyjpQCPmO7xn29bj206cO8bXZZ4ryevHghK69v871fvSfzxZTh+Dk+y/lysC1jteRCDALidbsh5+xpjj9bOsnY1MBCsu7hgHANh9I3mFUqlUqlUqlUKpVKpVKpVCqVSnUg6QNmlUqlUqlUKpVKpVKpVCqVSqVSHUgfKiIjSVMajC2sjictAh7sQouICGNZpkOwUwV5wGdYtvcATCMFsIHZ1tMU7M5t2PHaj+WO4gm87n7nAVsTZlakJXzYZ6vBoCNtC8ZDGwhfF1r0iYhM8mj72DCyXsGHax4M+Lt6PWlb9gANEYEF1g/kPUjSkQUhpcmzahkyGfLCtgkJ6w3c39TaCTsBdAhaA/NFaT3H1/1dn4+R2DYA+C4fdg7O5SXWBXdjP7vBlq6TWzVRzwvYslGdlXEV9jkOXLhvCUlrSz/itkgTaYdBJWBJKlfYDpHP5/et50Cc2vfAHdu4bAvmpMg4DrnjHVq7sexHObDNlKtsNXGtfhDCDvYG8ka3JXeeLiUcJyIUQmnpdcBCujjLdtyoKPPB5U8wgsGFEHxs5qSod2eL7ZqNmowtP8e/GA7YChRZu2EXc4DIgFxRKVh4hhR3MOaLPH5uQdQ7dYERD03AbDSbss26vZGVJ0lk3p0UGceh3F7/t/yIQYEtcifOshX//NPPynrglrx1g1EGlSmJpZkpQ9BAXgkKMq8MAYXhw8EHA1mvXOI4rk7xfYwsW1wdYgbtzUREPiA4WoBqumPtvN1u8DGGgM9IIzkWpumjc1NqjfcJnEf6DrHhjnN9v9/bt84/lBzHoWJhlNsvnD8vPpsBK97t1dWs3LdQCGfLHFepw335zSsSSbDb4DZ/6dU3svJTT0r78NI8f2/R4XFnbV3ezz/4w9f4HM7wWPjbv/60qPfWKneKt9+W+INnnuB7+uSz/F2/8eUzot4w4rGnMsMx/J3v3RH1tup8j88d53q/8vPPiXqdOtjS85zz///2zi1Gsusqw2ufS92ru6enx3Nzey6xExJibCshJFHCJWApSh7gASHgJUhIvPAAEg8gJCSQggQvwBtSpCD5ASkEEnAUkUgBEhSROHEcJ/E9M4499ozHMz0zfe+u69k8VHWtf+3p9sycU+mpdv2fZPlU165z2ec/a1/mrH+/9Ky1rlndGp7f5HV7REQkKZVk7sQg1q9csPd7blZtHU6eUKudlRtByiO0XRegX/Dyi8+ZcgtgaVH1Gh/CPiFa3jTrGlPCPuV996puwSFDzm/YPmp/W9uDKLbH2m5pG+XAXsBltu2C05UfnFdLkDi1bWHPqWbiqrZP1TTwSEErDEjtj1xokZEOz20yE9XjOJFD84eG23vZe4jEEVrD2X5cG+wR0IKv5my/oFrV57uE/ejguG3og2xvg/VFz7YL/a7qJEl0f2+IvVfL8Lm3Zi1ROmDb5I+BFWPDtknbiR6rH2t/uxIHlmqi17h2VX9TD6yzZqpqxeDW4Iug3d1x/JlE9fT7fVkftun1prWQweY4wjFmN2yn9XnuwHdRZMdTP3xZ256tTO/TqeoJU+77rzw/2n79NbU5efTXbMr7Aw9oennX6/6+8uVvmHJPP6VWTWkwFq+CLcZsU/e/uWrbkG5HdRvHMBYs23PqdFRXF69qXLq2avstXYhzXZiLiKOgbie0zdrBe53DCPt2e/4m+IxWSP1tfXbKgX1qBPG3C9u1e2zf513QTej0vjnavvz6y6bcPNhdVEr6LK9csfGlDDG0EYyf+2AXc/2GamZjy2q/2dQxRKOhMbX5FnZRzYaO2+cXbFt4A/S0AjYy15etbtd2xq5+MsddjUZdPvzhD4qISDuw6foQ6GINLGy3A4senDdbXVcLnFbP2jGVYYzbaGg/qBFYGrlNPW5rW7d9xZZb62r78pM3YWwevNf7JswfzM7ZseBCTT+/ev3V0fbijLVjevCYxsgHT+t8Qfrzv2jKVeG5KIHdWBa0cQt1nQc43tTtSsleY2XY3tf28JebzNkgQgghhBBCCCGEEEIIIRMPJ5gJIYQQQgghhBBCCCGE5IITzIQQQgghhBBC0BGs2QAAGbJJREFUCCGEEEJysa8ezFEUSWXo+7G2ZT0GK9Hu3iDOWUeeHhg/lSvqT9MOfFcy8Pspg0dc6DTT2VIvsD54Y2XO7q8LPi4zzbnRtu/ZKmz31delHfjjHgJ/sjm4xo1VWxerXT2nDnifdULPmLruY/7Q/Gi71Qq86aAucH/dwCtrx6t5Er3A4iSW5vzwGgN/uBL4JFcqWidJ6NEEnnBJgr8J/MDBT8yht1jg842+3+gxFwU+xOjN15hRP5t7FqxfbQvuRzuzx+rDPczAT7EfaKznwTMa9OwC73G883V4Pmo16/mE2kE/1Cyzz6XLrHfZxOFEhlaJ0m5ZL6feFtQneM3GFftsO/A/i1O93qQ2Z8q1wEewlKoGXRL4Vvf1cxqBt2Rq6/adD4KHGPr39ez+trzGEdexz/bsjN7X61vgedixx4pg/zHEsjQOmwr9XQ3iUH3WeostHFUPqZOLGqPaEONERMrDS5lQG0uJnBt5SqZBHGg58JOEZqPbss9mDZ7pNAFvPmfjVLms3mop+C5n4T0AQ24HfqGh112SoD+znlO3Z88PuwOVio0DPYgzGN96N+1j95iYZcHaB+BpinEqtOlz2BpB3A+vcccv/DZt/vaVyEVSTgf3O4ltfZ26T2Pv4qn7Rtvtjo1RHfj88CPq7XZ68Yem3JNPqz/lpSu6VsS5V9405dJE67KSqAfcxprt95x7TY91eV21+IFX7Pmtg7Wf79p7femqxpvWtzWmbKzbm7UOfnanU/Uv/5VHf8GU86Cr8z9+YbT9F5/+d1OuCp56Z9+tfpyry8Hzlg68RXv9YI2FScFFEg+vpdKYsd/Bs4j+t9269eh7/D++qN+BT/nmqvWhffVl9bvugtfw8or11e6A52gfnu1a055fF3Tbh2e5XLbxpQP3Xm7qS0DbCDGvJ+EaG7rP1Z7+ZqZmz6lc0fjqoN3N4vB9G/gMsSdcx0VCX9QJwzk36u9ubdn7jf3gBqylEPpJo+9yFbyFk669V30Yn6EHcxiv0YO/BN7XUWQ9HjOweE5i1dKS2GcV28bE2fFULPo7D+O6XmzHSV2nsSnrQV83tve3DesJdES3q7H128X1gmLQkgtGWFEU7/r3SaDX68i1q2+IiIgXe69LNfQLxWfFXkcGHsKZ13L9oN+zvK3lnnzh0mj7W7AtYvsfCXiHPrRm29bDm6q5//zqV0bbz/zoRVOuC33lOJhvyPp6f12k/q19sWNx8Xoezul5tFo2bjqoJ1wDoy+2LnwEfSLoX4YdHLfL1iTR63blzaH/LHqti4h0Yc7m8GH192617NgA9ZOm+tyXUhsrNmFcU4Ux7YkTdq2amfvePdr+OYjl83O2zXz5nPYtynW936dPHjXlVtbVh71asXHJRdB/hz70dsf2s968ribtsWmTd+/niti5nFYw/9XtwjgO4trhhp3rWKgNzvfSNbsmwqTgxEs6fJ7Cuj16SNt1nN/wPmi7IEZksP5EOP7pwu9wjSkXjPfwV7hWQRS8r9uH9au24P50gnK45pwE/X5se375tK7f4gLP7NPg3XxPXddXqZZtnaWR6gmfPynbZymB3Xu4jqVl6z/+zf/6toiIrK1Yb+8d+AYzIYQQQgghhBBCCCGEkFxwgpkQQgghhBBCCCGEEEJILvbVIsM5J+kwJSvMZIVscdmC9Olayb7iXW9qGsN2R1/9d1n4erq+/r3V1u00eGW834V9QGpPuW5TVlJIe88gvdf1bRVuQfp9KTiWB1uBSkVfSd/s21f149jDtp5Tv21fi0eLizqkUm9t2FQUD3WTZXq9mEYhIhLvpHNMYJ56WirLydNnRUTEB+pJk3S3n4RJTNKHVAfMNGoFaUcR3KcIzCR8O0xPgjSKEqR+3XRkLbexounI20G64pUlTTN4Y2nZfFcvq86itt7fLEjp8rGmL5YdnHtk09uas5pekppUxjDdE+os2zv/PEypnDy8iB/cl9B2B1MZ2x1ILYrtNWE6aR/qthtYtnQg9WQb9t3v27qt1/VeYboKWrSIiJSbkGYFKajSs/u79+yx0XalamMPZp5W65omlVZsnNve0lSpHpx7EtVNuQiuP4p158dOHDblajXd/9l3aKra1aUlU66cRsP9TqaOvDjxw+YyDqwq4pJeYwOqcyuwMHFw/+cXtJ6SIIU7hXuH6aDtwHqgB3XlIQ2uFzymGZTremjvAssW/Hzzk67HxjTFyAWxF1Jg8TkLrSt8hrEY2tPAxMpLaMGxOxMdf5wTN4wdidj6Qr1nUOtJGtqm6H1D+5KPfuSjptx7fvaR0fa5CxdG29994lum3LWr2g5VK1r/jaZNoVw8o9YSF1+7Mtr+wz/5qim3Bema2D8SEYkysEmAvk47EGqUaIz5pV9VG4Njx20q+8aGppOehzTWJ5941ZR73/seHG3PHLtHv/D2OUqTQZ/Su33tDt8+TjOwF44smK8qZbCagWenHzxvzzyraeFpAvc7sMT6nyeeGm0fO3mvnkJi9diEdOJWG9qJNZtqu7apn2NoJ9KSfQ4wDbWT2RiQQt8lndXrX7z3rCl3+NS7Rttz88f1Ny7QI/YXI7AUC163wSqMsI0P2ueR9ceEhqB+vyfLy4P+ZBgn0R4tgnvQ7do+LNpdHDp0aM9yvR6mamNqso3jGP+xn4Fp3yIi7QT2B+1TuRtYOG1rPCtXrQbjCPpWcL+j4IZHmcY+tDlwQb+3lOj5VqtaLq0EqdSgY+xyRkHrGk9w25UmqRw/NrDyu7Jk06OPlDUGOAg4nY7VBPZZse90U+o5fLYug2E7sbsd33//75Pm8/898aPR9rXralXhEmuFgOO9m2xKvOoRbSsyZ2MUWgZ62Ecvsu0p9uec6L5d31ocRDD2cBH02SQcg8ajrUkk85m024PrDK0jy2BhuXT16mi70bT35/53qjVAjPZsgc0EfsZ+VSWxsQdj4Mzx06PtE4E9TzKrFpavXXhptL26um7KlUpoQWfnXmZm9VrQWqgRzL2sbmgfJ8N5haCt6YAGsd3d3rS2QMjCvI41DkPsFtF5o6devSaTSKvVkpdefFZERGo1a0GEtk0OdJEmduybQDnUTxLMG+H4Hu39QktW7LvgPlwwVolg0NOABqCU2nsa11QjoQsr9pd7YFm5umwtKUowZ5qApU4cxIsXntf+8je+8Y3R9pmzZ0y5B+7Xfn8b2vgrwbh9eXge/f7u47RbvsHsnKs4577rnPuhc+4559xfDf9+xjn3HefceefcvzjnJtTAjtxNqB+SF2qHFIH6IUWgfkheqB1SBOqHFIH6IXmhdkgRqB+yw+1YZLRF5GPe+4dE5GER+bhz7oMi8rci8vfe+/tFZFlEfv+nd5rkAEP9kLxQO6QI1A8pAvVD8kLtkCJQP6QI1A/JC7VDikD9EBG5DYsMP1j+dyfnKB3+50XkYyLyu8O/PyYifyki//hW+3Iikgxz/ZJgJWZMjUULBJcE1hfwxjemNFaC1+c9rBzcaoMVwXqQStDTcjOQzr2+FaxkCitM4iqnaVCFHtKBsjBPMYX0DkgL62U2pWjhyPxou97W1+nbF6+Ycph1ZtPMbJpGmmjd1CA9Po5s2uPKsr3mcTA2/TgnfphaEKbl9aH+OrAi52bbrsjZh3u4DSupb2/bFNw0hVQJSM/sbduUHA8pvmiHEq6YjdYIVy/rPbwepJxdhdT4V163KyfP1mD/fUjbClOmUk15bJTg+ahanW7Cir6ttu5vY8M+H/0aroILKX9BWt9O+kZ47UUYZ+wR76U/TN/04XMJD9I2WNxIFKTm4YqxmKoVpIdsgJ7MSq3BYZstTQNv1PS+1YO0ZUzDaUEqTDlIM+5CCg1aBImIQJadVJsaD+rBPyK3tlUneO5RkLtTKkE6KcTA+86cNOUwdaba1Os6XjlmykkcWrMUZ7xtl5NouOp5L0jtT8p6H6sV3faBU0411d9hvO4nNo2yB21jDOndQeapdPFZi7T+8HkWESlBKmIUo4XF3hYwYVxBvc/Ozun5JTaumLRguT3saQS2HfDMYWwJ48w44w7scyz68V6kO9RMmA2NbY1ZuTooGEGaXwp2BbUgLbve0NWkD9+j/Yh75m1q5NPfUSuEboarr9uY8uqF10fbLz6nbVcnSBtsO40Vra5NIY0zOHejKytodDL41y88rh+CVcHRuqgG9h6LiydMuUZDY2oHzqEc2AJt9QbPSzahbVfmvbSHbdcsrBYuYlcJ78GzF6aRf+KTnxxtry2r/dZrF14z5Y4eV1uMU2c1NfmFcy+bcpvb2k5mHa23fmCP0uvjOek9WDxtUzI3ttXWwJdtPKwdVnuTucNqfXF44agpl5S1fYljrZc4sMhwWDcQ1/qBzryx64HxSRDY02HbOM4k9bH2fcRJNKyDmVlrx4TtOPar20EbslcKbBLoDFOL0RqhF9hFlcu7v7wWHgetORzEwO5GYBe1eXm03Zy1/f60rL+bgz5T2rWxLgbbgx7ae0T2nFpbatHTjbSv5wLbhBiehT7sLwmsAjrtwT5utqfLz/j040WG46tms2G+yfBeQZ86C2yusK9TAXstH1jhGLs/aF/CNO/YYT9FWV6z9z0C27AY0uZdYBeI3Xzn956XiCIcF5piZtyJFhmlsCAcKwbLl1ZQF9h5xPT/wN1PxyRjtFkZe+wZnn/Yp8HxRb2h2ooDW4hnn312tN0AS5/j99j4Xy3jmETpdKwu8MsS2DbNH7Vjl02wC5wBWy5Xts/B8g1tTzOx5750bWW0vQX7q9ftfFUJ+oGmjY9s/7oF9qmNuvbvji7MmXIO2rJ6U2P+2qa15Tz32iButsM6KsB49eNHcXFjY2PPUqitKHi+8TtTLtAZWlO6t3r1FvqJ5tkM9I1WQQ7e5UWti1ibqnAfHuYmenCPbly3VhX1qmp/e1P73/0grry5pFYocwtqAeMCW5Er18GiFWJYuW6tMt/70MMiYu1fkNta5M85FzvnfiAiV0XkayLysoiseO1pXRSRk3v9nkw31A/JC7VDikD9kCJQPyQv1A4pAvVDikD9kLxQO6QI1A8Ruc0JZu9933v/sIjcKyIfEJGfud0DOOf+wDn3Pefc9zrt7q1/QN525NUPamflLf71irx9GVfs2Vpv3foH5G3HuPRzY/n6rX9A3naMo+1aZ9s1lYwr9mysrd36B+Rtx9j6PsFi0mQ6GEfbZTLwyNQwtraLfZ+pZFz6WV9fv/UPyMRyWxPMO3jvV0Tk6yLyIRGZc26Uq3KviFza4zef8d6/33v//lI53a0ImRLuVD+onbkgrYBMF0VjT61Z2a0ImRKK6mf+0OHdipApoUjb1WTbNdUUjT2NmZndipApoXDfp7Z7+iqZDoq0XWnKMfs0U7jtYt9nqimqn2azuU9nSn4a3NKD2Tl3RES63vsV51xVRB6VgVn310XkN0XkcyLyKRF5fO+9DIjESW1HX4GXkAOPTw8+TVlgOtRB78oM/AsD3xUPvmtRST330PNQRCSO9XMGfnErK/aNxyjV/VUr6p8TerWU0M8p8Hp1YP7TBm8VV7LnVK3q+V5fXh1t16rW/6QM/rj9vr6lEPqiidvdS04Cr6xxesiN9jkm/WQ+k62hz1XoedsCP2X0EDZ+uiLSzyL4DjyIW/ZeozeYN7Via6jf292XLi1ZPxv0B03gH1nOnj5tyr3j7KnR9sJR6ydZjsH3r6vn3s/sOfhYtdnv6nX9+Hzgobip/7K8uKiZKpcuXTTlOtfVd7PtwJcv8ApKZXBdoXdfEcYZe0S8uKGXXOLC50Ov5dryDf17bK+xCQP9GP5t7vryiim3vqn1jr62aWp1sQZaRc11e1a3M7PqydXqaP32Ap/lXgY+cBAnRURKFfAgBb/ecimImxnETfBFRh/x8Njod++DZ6TTAw878DtLgjjck+F1jTEIjVM/mfeyPdR2vWLvI64TkNS0Q9QQ+2xG4OXYXdP7WKnYCYC0Av6D4MGWRPaetjY1DkQCdRsH/pYQ9xx4xIVe9i2Il726PfdKVfffN17fdh8e2mu7HXgMOmj/3vKe7/7lfngwj0s/zjmJh21CFniiYS2XwAMuCirFmY4GXGsW+hPDvQbP74fe+15TbvHI4mj74jVtGzY27Rsj/UzHAA+8R/sblZr9B7su3N+tVuDfCu1rGqvWu117z7bg2HhVc4esf/T99z8w2j56ZGG0PR/4EzfgHCt1eI5S22nbydq8qd9UgHHGHidO4qHX32bwNur6KvjtQYy+sfSGKYfrkCTQ1z52/Lgpd9+Zd4y2v/XdJ0fbl6/aDI5aXdvCPvRzu12r76QE/RFoW26s27hxZPE9un3qAfNd7ZD6Qpcq2gdOAv/3FK4rhe+yIIbgmifoext6NScQ12eaetxTR63f5Znjg398fObfrK9mEcY67ooiqQ3XeHDhO0W3GTbRGxJj2F7ezDvH3SEcd2F4Q8/VcEKzBOOuCPowFzasfuYiHSfV6/YaV2G81oD2tJTZf7jxgmubBGv1ABvgx9pPcF2AoL2Hjzge7QTt7tawL55le9flnTIu/XjvR/6slaqNr7gURQTtb7dj+6XYJqEmstBvG8f9me4v6IYbD+YeHDcNfERR2pmHPmpmRY8f48Dz1oNBcwZ7jIJ9xBB7nPFyD9bjwfYf9n3TehgwL2GesaAbNfI3lvExztjjfTbyQA77aOiNXK3CnEq4vo9ZX0p/s71t15rCdWwwpnS6gb8wzBV1of+UxLZPc/LMu0bblRnt17967pzdn8M1TsI7offu6pKOpQMbdqnDGmLYXiXB+iwpHCuGNQ3CZ25pST16X7+s2z6YsNoc9vn72fj6z+Nuu3a0EfadzTHt8c13xtsePZhvemhg3gfHu0E5s3+zLowtl5q4B378Xds/Xl+F9Syyt5iTg/alErysi17xG2vaFoa3dXZO27zDh9XDO/T/x/VIcD2ecJ2SeGcuITSHH3LLCWYROS4ijznnYhm88fx57/2XnXPPi8jnnHOfFpGnReSzt7EvMn1QPyQv1A4pAvVDikD9kLxQO6QI1A8pAvVD8kLtkCJQP0REbmOC2Xv/IxF5ZJe//0QG3iqE7An1Q/JC7ZAiUD+kCNQPyQu1Q4pA/ZAiUD8kL9QOKQL1Q3ZwP43U0j0P5tySiGyKyLV9O+hksyCTWRenvPdH7vZJIEPtXJDJrbP9ZlLrYeK0I0L97MKk1sMk64dtl0L93CaMPTcxqfUwcdoRoX52YVLrYZL1w7ZLoX5uE8aem5jUepg47YhQP7swqfUwyfph26UcKP3s6wSziIhz7nve+/fv60EnFNbFncM6G8B6yAfrbQDr4c5hnSmsizuHdTaA9ZAP1tsA1sOdwzpTWBd3DutsAOshH6y3AayHO4d1phy0uohuXYQQQgghhBBCCCGEEEIIuRlOMBNCCCGEEEIIIYQQQgjJxd2YYP7MXTjmpMK6uHNYZwNYD/lgvQ1gPdw5rDOFdXHnsM4GsB7ywXobwHq4c1hnCuvizmGdDWA95IP1NoD1cOewzpQDVRf77sFMCCGEEEIIIYQQQggh5O0BLTIIIYQQQgghhBBCCCGE5GJfJ5idcx93zr3knDvvnPuz/Tz23cQ5t+ic+7pz7nnn3HPOuT8a/n3eOfc159y54f8P3e1znWSoH+onL9QOtVME6of6KQL1Q/3khdqhdopA/VA/eZlW7YhQP+NgWvVD7YwH6udg62ffLDKcc7GI/FhEHhWRiyLypIj8jvf++X05gbuIc+64iBz33n/fOdcUkadE5DdE5PdE5Ib3/m+GD88h7/2f3sVTnVioH+onL9QOtVME6of6KQL1Q/3khdqhdopA/VA/eZlm7YhQP0WZZv1QO8Whfg6+fvbzDeYPiMh57/1PvPcdEfmciPz6Ph7/ruG9v+y9//5we11EXhCRkzK4/seGxR6TgYDI7lA/Qv3khNoRaqcA1I9QPwWgfoT6yQm1I9ROAagfoX5yMrXaEaF+xsDU6ofaGQvUjxxs/eznBPNJEXkdPl8c/m2qcM6dFpFHROQ7InLUe395+NWbInL0Lp3WQYD6EeonJ9SOUDsFoH6E+ikA9SPUT06oHaF2CkD9CPWTE2pnCPWTC+pHqJ0CUD9ysPXDRf72EedcQ0S+ICJ/7L1fw+/8wKtkf/xKyIGE+iF5oXZIEagfUgTqh+SF2iFFoH5IEagfkhdqhxThoOtnPyeYL4nIIny+d/i3qcA5l8pAKP/svf/i8M9Xhl4rO54rV+/W+R0AqB/qJy/UDrVTBOqH+ikC9UP95IXaoXaKQP1QP3mZau2IUD8FmWr9UDuFoX4OuH72c4L5SRF5wDl3xjlXEpHfFpEv7ePx7xrOOScinxWRF7z3fwdffUlEPjXc/pSIPL7f53aAoH6on7xQO9ROEagf6qcI1A/1kxdqh9opAvVD/eRlarUjQv2MganVD7UzFqifA64fN3jLep8O5twnROQfRCQWkX/y3v/1vh38LuKc+4iIfFNEnhGRbPjnP5eBp8rnReQ+EbkgIr/lvb9xV07yAED9UD95oXaonSJQP9RPEagf6icv1A61UwTqh/rJy7RqR4T6GQfTqh9qZzxQPwdbP/s6wUwIIYQQQgghhBBCCCHk7QMX+SOEEEIIIYQQQgghhBCSC04wE0IIIYQQQgghhBBCCMkFJ5gJIYQQQgghhBBCCCGE5IITzIQQQgghhBBCCCGEEEJywQlmQgghhBBCCCGEEEIIIbngBDMhhBBCCCGEEEIIIYSQXHCCmRBCCCGEEEIIIYQQQkguOMFMCCGEEEIIIYQQQgghJBf/D1ruileMSR+xAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 1440x720 with 20 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "labels_map={\n",
        "    0: 'Airplane', 1: 'Automobile', 2: 'Bird', 3: 'Cat', 4: 'Deer',\n",
        "    5: 'Dog', 6: 'Frog', 7: 'Horse', 8: 'Ship', 9: 'Truck'} # https://www.tensorflow.org/api_docs/python/tf/keras/datasets/cifar10/load_data\n",
        "row = 2\n",
        "col = 10\n",
        "num= row*col\n",
        "# get images\n",
        "images = X_train[0:num]\n",
        "labels = y_train[0:num]\n",
        "# plot images\n",
        "fig, axes = plt.subplots(row, col, figsize=(20,10))\n",
        "for i in range(num):\n",
        "     ax = axes[i//col, i%col]\n",
        "     ax.imshow(images[i], cmap='gray_r')\n",
        "     ax.set_title('Label: {}'.format(labels_map[labels[i][0]]))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28Ve5mrcljVm"
      },
      "source": [
        "<h2>Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7VaF5h1ljVm"
      },
      "source": [
        "scale from [0,255] to [-1,1], best practice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fQSUxh53ljVm"
      },
      "outputs": [],
      "source": [
        "X_train=X_train.reshape((50000,32,32,3))\n",
        "X_train_normal=X_train.astype('float32')/127.5 #using tanh in generator so it will provide values from -1 to 1\n",
        "# X_test=X_test.reshape((10000,32,32,3))\n",
        "# X_test_normal=X_test.astype('float32')/127.5"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HMyXrZh_ljVn"
      },
      "source": [
        "<h2>Defining Discriminator Model\n",
        "<h4> Inputs: Image (32,32,3)\n",
        "<h4>Outputs: Binary classification, 0=Fake,1=Real.\n",
        "<h5>Used a basic GAN Model Architecture from https://www.researchgate.net/figure/The-architecture-of-the-first-GAN-network-a-the-generator-and-b-the-discriminator_fig4_339100419"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-hzOUMkljVn"
      },
      "source": [
        "in GANs, fully-connected layers are not used, in the discriminator and the convolutional layers are flattened and passed directly to the output layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suKeAMfUljVn",
        "outputId": "2b84227b-0a23-4c20-cb2f-8316932e99a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 16, 16, 32)        896       \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 8, 8, 64)          18496     \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 4, 4, 128)         73856     \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 2, 2, 256)         295168    \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 1025      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 389,441\n",
            "Trainable params: 389,441\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "#use the LeakyReLU with a default slope of 0.2, reported as a best practice when training GAN models.\n",
        "def define_discriminator(in_shape=(32,32,3)):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3,3),strides=(2,2),padding='same',input_shape=in_shape)) \n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    #input-layer is padded in a way so that the output layer has a shape of the input divided by the stride.\n",
        "    #downsampling, reduces dimensionality and storage size\n",
        "    # we do not use pooling layers and use the large stride to achieve downsampling\n",
        "    model.add(Conv2D(64, (3,3),strides=(2,2),padding='same')) \n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Conv2D(128, (3,3),strides=(2,2), padding='same')) \n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Conv2D(256, (3,3),strides=(2,2), padding='same')) \n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "    #using a larger stride can make the generator faster to train, but it may produce lower-quality images. \n",
        "    # On the other hand, using a smaller stride can produce higher-quality images, but it may be slower to train.\n",
        "    optimizer=Adam(lr=0.0001)\n",
        "    model.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
        "    return model\n",
        "discriminator=define_discriminator()\n",
        "discriminator.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlEqt90dljVo"
      },
      "source": [
        "<h2>Defining Generator Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGSdCoBzljVo"
      },
      "source": [
        "<h3>Baseline Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlVAHRPAljVo"
      },
      "source": [
        "Developing a generator model requires that we transform a vector from the latent space \n",
        "to a 2D array with 32 x 32 x 3, or 3,072 values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DMFfuHLljVo"
      },
      "source": [
        "The first is a Dense layer as the first hidden layer that has enough nodes to represent a low-resolution version of the output image. It needs enough nodes for multiple versions of our output image, such as 256."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yORAnl4VljVo"
      },
      "outputs": [],
      "source": [
        "def define_generator(latent_dim):\n",
        "    #drawing points from latent_dim randomly\n",
        "    #generator will assign meaning to the latent points and, in turn, the latent space\n",
        "\n",
        "    #At the end, the latent vector space represents a compressed representation of CIFAR-10 images, \n",
        "    #that only the generator knows how to turn into CIFAR-10 images.\n",
        "    model=Sequential()\n",
        "    #Inputs: Point in latent space\n",
        "    model.add(Dense((256*4*4),activation='leaky_relu',input_dim=latent_dim))#latent dim is 1d vector, 4,4 \n",
        "    model.add(Reshape((4,4,256)))#Reshaped into 4,4,256 dimensions to apply convolutional operations\n",
        "\n",
        "    #upsample from 4,4 to 32,32 gradually upsampling layer\n",
        "    model.add(Conv2DTranspose(128,(4,4),strides=(2,2),padding='same')) # plots image features on map 128 images due to 128 filters\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    #output shape is forced to become the input shape multiplied by the stride\n",
        "    #strides increase spatial resolution of feat map,generates higher resolution images4*2=8, used kernel size 4 to prevent checkboarding of \n",
        "    model.add(Conv2DTranspose(128,(4,4),strides=(2,2),padding='same')) #\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Conv2DTranspose(128,(4,4),strides=(2,2),padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Conv2D(3, (3,3), activation='tanh', padding='same'))\n",
        "    # Outputs: Two-dimensional square color image (3 channels) of 32 x 32 pixels with pixel values in [-1,1]\n",
        "    return model\n",
        "    #three filters for the three required channels\n",
        "    #not compiled because it is not directly trained like discriminator\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGjsWE3RljVp"
      },
      "source": [
        "<h5>Latent Spaces, where the generator network learns to generate synthetic data\n",
        "\n",
        "<h5>Compact representation:easier to learn patterns and features in the data and to generate new samples that are similar to the real data.\n",
        "\n",
        "<h5>Interpolation: smoothly interpolate between points in the latent space. This can be useful for generating new samples that are \"in between\" two existing samples, Smooth transition of styles and colors of data\n",
        "<h5>Controlled generation: possible to control the properties of the generated samples by manipulating the latent space. Syle/Class etc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "For0VjN9ljVp",
        "outputId": "d0f1579d-f85a-4ffa-c757-20f4c2132a03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 4096)              413696    \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 8, 8, 128)        524416    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 16, 16, 128)      262272    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 32, 32, 128)      262272    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 3)         3459      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,466,115\n",
            "Trainable params: 1,466,115\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#size of space\n",
        "latent_dim= 100\n",
        "\n",
        "#Pass random point sample into generator to get synthetic data point\n",
        "generator = define_generator(latent_dim)\n",
        "\n",
        "generator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NrSXBl5QljVp"
      },
      "outputs": [],
      "source": [
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    # generate points in the latent space\n",
        "    #array of random numbers reshaped into samples, n rows with 100 elements per row\n",
        "    x_input =  randn(latent_dim * n_samples)\n",
        "    # reshape into batch of inputs for network\n",
        "    x_input = x_input.reshape(n_samples, latent_dim)\n",
        "    # print(x_input)\n",
        "    return x_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35KNVr9ZljVp"
      },
      "source": [
        "<h4>Batch of fake and real images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tjU7TeonljVp"
      },
      "outputs": [],
      "source": [
        "def real_samples(df,samples):\n",
        "    #random images\n",
        "    img=randint(0,df.shape[0],samples)\n",
        "    X_train=df[img]\n",
        "    y_train=np.ones((samples,1)) #labels =1 = real images\n",
        "    return X_train,y_train\n",
        "    \n",
        "#use generator to produce fake samples with class label, fetch fake img\n",
        "#Use generate_latent_points to generate latent points hence need input latent dim and batch\n",
        "def fake_samples(generator,latent_dim,samples):\n",
        "    #generate the required number of points in latent space as input to the model.\n",
        "    X_input=generate_latent_points(latent_dim,samples)\n",
        "    #predict to generate fake samples\n",
        "    X=generator.predict(X_input)\n",
        "    y=np.zeros((samples,1)) #labels =0 = fake images\n",
        "    return X,y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRHeD9IQljVq"
      },
      "source": [
        "<h3>Combined GAN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDLhPUP7ljVq"
      },
      "source": [
        "<h3>Inputs: Point in latent space, e.g. a 100-element vector of Gaussian random numbers.\n",
        "<h3>Outputs: Binary classification, likelihood the sample is real (or fake)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fft-agaeljVq"
      },
      "source": [
        "Combining generator and discriminator model, discriminator not trainable and to only train the generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6IlbjNcljVq"
      },
      "source": [
        "We do this so that backpropagation process will update generator weights when discriminator gives generated samples a low 0.3-0.5 probability</p>\n",
        "So it will update the weights accordingly to correct the error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "R-uXWMcvljVq"
      },
      "outputs": [],
      "source": [
        "def define_gan(generator,discriminator):\n",
        "    discriminator.trainable=False #discriminator trained separately, hence weights are freezed\n",
        "    model=Sequential()\n",
        "    model.add(generator)\n",
        "    model.add(discriminator)\n",
        "    optimizer=Adam(lr=0.0002, beta_1=0.5)\n",
        "    model.compile(loss='binary_crossentropy',optimizer=optimizer)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gOOGyAKljVq"
      },
      "source": [
        "<h3>Training"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YAiW-hU0ljVq"
      },
      "source": [
        "50/50 real/fake image into discriminator"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Noise vector input for generator output fake images for discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "wO0DCLejljVq"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train(g_model,d_model,gan_model,df,latent_dim,epochs=100,batchsize=128):\n",
        "    batch_per_epoch=int(df.shape[0]/batchsize)\n",
        "    half_batch=int(batchsize/2)\n",
        "    g_array=[]\n",
        "    d_array=[]\n",
        "    #discriminator is updated for half batch of real and fake samples as one batch\n",
        "    for ep in range(epochs): #in every epoch\n",
        "        for batch in range(batch_per_epoch): #in every batch\n",
        "            X_real,y_real=real_samples(df,half_batch)\n",
        "            d_loss_real,_ =d_model.train_on_batch(X_real,y_real) #update weights on real img\n",
        "\n",
        "            X_fake,y_fake=fake_samples(g_model,latent_dim,half_batch)\n",
        "            d_loss_fake,_=d_model.train_on_batch(X_fake,y_fake)#update weights on fake img\n",
        "            #averaged\n",
        "            d_loss=(d_loss_fake+d_loss_real)/2\n",
        "            #training generator using gan \n",
        "            X_gan=generate_latent_points(latent_dim,batchsize) #input for generator\n",
        "            y_gan= np.ones((batchsize,1))#label generated as real label =1\n",
        "            g_loss=gan_model.train_on_batch(X_gan,y_gan) #training gan model\n",
        "            \n",
        "            print(f\"Epoch {ep+1} Batch {batch+1}/{batch_per_epoch} d_loss_real= {d_loss_real:.3f}, d_loss_fake= {d_loss_fake:.3f}, g_loss {g_loss:.3f}, d_loss {d_loss:.3f}\")\n",
        "            if batch+1==batch_per_epoch:\n",
        "                g_array.append(g_loss)\n",
        "                d_array.append(d_loss)\n",
        "        if ep%50==0:\n",
        "            g_model.save(f'{ep}base50.h5')\n",
        "        else:\n",
        "            g_model.save(f'{ep}base50.h5')\n",
        "    return g_array,d_array\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcoLbFNY1l_w",
        "outputId": "6f0e017a-4426-4ef7-d5de-7c4fd44e2a1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 1/390 d_loss_real= 1.412, d_loss_fake= 0.231, g_loss 1.633, d_loss 0.822\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 2/390 d_loss_real= 1.404, d_loss_fake= 0.218, g_loss 1.640, d_loss 0.811\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 3/390 d_loss_real= 1.316, d_loss_fake= 0.223, g_loss 1.595, d_loss 0.770\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 4/390 d_loss_real= 1.128, d_loss_fake= 0.239, g_loss 1.515, d_loss 0.683\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 5/390 d_loss_real= 0.797, d_loss_fake= 0.266, g_loss 1.418, d_loss 0.532\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 6/390 d_loss_real= 0.550, d_loss_fake= 0.304, g_loss 1.302, d_loss 0.427\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 7/390 d_loss_real= 0.398, d_loss_fake= 0.377, g_loss 1.123, d_loss 0.388\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 8/390 d_loss_real= 0.213, d_loss_fake= 0.454, g_loss 0.986, d_loss 0.334\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 9/390 d_loss_real= 0.147, d_loss_fake= 0.627, g_loss 0.797, d_loss 0.387\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 10/390 d_loss_real= 0.097, d_loss_fake= 0.594, g_loss 0.897, d_loss 0.346\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 11/390 d_loss_real= 0.084, d_loss_fake= 0.479, g_loss 1.085, d_loss 0.282\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 12/390 d_loss_real= 0.078, d_loss_fake= 0.369, g_loss 1.294, d_loss 0.223\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 13/390 d_loss_real= 0.092, d_loss_fake= 0.290, g_loss 1.484, d_loss 0.191\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 14/390 d_loss_real= 0.100, d_loss_fake= 0.235, g_loss 1.657, d_loss 0.167\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 15/390 d_loss_real= 0.091, d_loss_fake= 0.196, g_loss 1.807, d_loss 0.144\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 16/390 d_loss_real= 0.091, d_loss_fake= 0.178, g_loss 1.893, d_loss 0.134\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 17/390 d_loss_real= 0.089, d_loss_fake= 0.676, g_loss 0.859, d_loss 0.383\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 18/390 d_loss_real= 0.091, d_loss_fake= 1.093, g_loss 0.602, d_loss 0.592\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 19/390 d_loss_real= 0.159, d_loss_fake= 0.640, g_loss 1.043, d_loss 0.399\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 20/390 d_loss_real= 0.286, d_loss_fake= 0.341, g_loss 1.442, d_loss 0.314\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 21/390 d_loss_real= 0.525, d_loss_fake= 0.240, g_loss 1.663, d_loss 0.382\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 22/390 d_loss_real= 0.688, d_loss_fake= 0.200, g_loss 1.766, d_loss 0.444\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 23/390 d_loss_real= 0.805, d_loss_fake= 0.190, g_loss 1.763, d_loss 0.497\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 24/390 d_loss_real= 0.645, d_loss_fake= 0.201, g_loss 1.671, d_loss 0.423\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 1 Batch 25/390 d_loss_real= 0.625, d_loss_fake= 0.232, g_loss 1.504, d_loss 0.429\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 1 Batch 26/390 d_loss_real= 0.464, d_loss_fake= 0.299, g_loss 1.240, d_loss 0.381\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 27/390 d_loss_real= 0.249, d_loss_fake= 0.429, g_loss 1.005, d_loss 0.339\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 28/390 d_loss_real= 0.215, d_loss_fake= 0.530, g_loss 0.968, d_loss 0.372\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 29/390 d_loss_real= 0.219, d_loss_fake= 0.472, g_loss 1.154, d_loss 0.346\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 30/390 d_loss_real= 0.241, d_loss_fake= 0.344, g_loss 1.377, d_loss 0.292\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 31/390 d_loss_real= 0.402, d_loss_fake= 0.277, g_loss 1.502, d_loss 0.340\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 1 Batch 32/390 d_loss_real= 0.357, d_loss_fake= 0.251, g_loss 1.547, d_loss 0.304\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 33/390 d_loss_real= 0.335, d_loss_fake= 0.246, g_loss 1.539, d_loss 0.291\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 34/390 d_loss_real= 0.277, d_loss_fake= 0.255, g_loss 1.499, d_loss 0.266\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 35/390 d_loss_real= 0.213, d_loss_fake= 0.274, g_loss 1.456, d_loss 0.243\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 36/390 d_loss_real= 0.283, d_loss_fake= 0.287, g_loss 1.467, d_loss 0.285\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 37/390 d_loss_real= 0.204, d_loss_fake= 0.269, g_loss 1.551, d_loss 0.237\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 1 Batch 38/390 d_loss_real= 0.217, d_loss_fake= 0.234, g_loss 1.645, d_loss 0.226\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 39/390 d_loss_real= 0.267, d_loss_fake= 0.214, g_loss 1.698, d_loss 0.240\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 40/390 d_loss_real= 0.184, d_loss_fake= 0.203, g_loss 1.729, d_loss 0.194\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 41/390 d_loss_real= 0.230, d_loss_fake= 0.202, g_loss 1.725, d_loss 0.216\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 42/390 d_loss_real= 0.296, d_loss_fake= 0.218, g_loss 1.663, d_loss 0.257\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 43/390 d_loss_real= 0.203, d_loss_fake= 0.230, g_loss 1.664, d_loss 0.217\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 1 Batch 44/390 d_loss_real= 0.162, d_loss_fake= 0.215, g_loss 1.772, d_loss 0.188\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 45/390 d_loss_real= 0.199, d_loss_fake= 0.185, g_loss 1.859, d_loss 0.192\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 46/390 d_loss_real= 0.164, d_loss_fake= 0.169, g_loss 1.909, d_loss 0.167\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 47/390 d_loss_real= 0.217, d_loss_fake= 0.163, g_loss 1.922, d_loss 0.190\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 48/390 d_loss_real= 0.273, d_loss_fake= 0.170, g_loss 1.868, d_loss 0.222\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 49/390 d_loss_real= 0.151, d_loss_fake= 0.186, g_loss 1.846, d_loss 0.168\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 1 Batch 50/390 d_loss_real= 0.166, d_loss_fake= 0.178, g_loss 1.914, d_loss 0.172\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 51/390 d_loss_real= 0.223, d_loss_fake= 0.160, g_loss 1.990, d_loss 0.192\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 52/390 d_loss_real= 0.162, d_loss_fake= 0.148, g_loss 2.031, d_loss 0.155\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 53/390 d_loss_real= 0.170, d_loss_fake= 0.145, g_loss 2.040, d_loss 0.158\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 54/390 d_loss_real= 0.175, d_loss_fake= 0.147, g_loss 2.047, d_loss 0.161\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 55/390 d_loss_real= 0.161, d_loss_fake= 0.147, g_loss 2.064, d_loss 0.154\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 1 Batch 56/390 d_loss_real= 0.168, d_loss_fake= 0.143, g_loss 2.092, d_loss 0.155\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 57/390 d_loss_real= 0.199, d_loss_fake= 0.137, g_loss 2.114, d_loss 0.168\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 58/390 d_loss_real= 0.195, d_loss_fake= 0.136, g_loss 2.129, d_loss 0.166\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 59/390 d_loss_real= 0.152, d_loss_fake= 0.133, g_loss 2.151, d_loss 0.142\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 60/390 d_loss_real= 0.146, d_loss_fake= 0.126, g_loss 2.176, d_loss 0.136\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 61/390 d_loss_real= 0.196, d_loss_fake= 0.133, g_loss 2.140, d_loss 0.165\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 62/390 d_loss_real= 0.129, d_loss_fake= 0.135, g_loss 2.171, d_loss 0.132\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 63/390 d_loss_real= 0.132, d_loss_fake= 0.123, g_loss 2.213, d_loss 0.128\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 64/390 d_loss_real= 0.173, d_loss_fake= 0.118, g_loss 2.232, d_loss 0.145\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 65/390 d_loss_real= 0.161, d_loss_fake= 0.119, g_loss 2.217, d_loss 0.140\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 66/390 d_loss_real= 0.060, d_loss_fake= 0.123, g_loss 2.254, d_loss 0.092\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 67/390 d_loss_real= 0.183, d_loss_fake= 0.125, g_loss 2.208, d_loss 0.154\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 68/390 d_loss_real= 0.134, d_loss_fake= 0.121, g_loss 2.223, d_loss 0.128\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 69/390 d_loss_real= 0.120, d_loss_fake= 0.124, g_loss 2.205, d_loss 0.122\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 1 Batch 70/390 d_loss_real= 0.197, d_loss_fake= 0.124, g_loss 2.224, d_loss 0.161\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 1 Batch 71/390 d_loss_real= 0.167, d_loss_fake= 0.122, g_loss 2.246, d_loss 0.144\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 72/390 d_loss_real= 0.155, d_loss_fake= 0.120, g_loss 2.254, d_loss 0.137\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 73/390 d_loss_real= 0.078, d_loss_fake= 0.112, g_loss 2.307, d_loss 0.095\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 74/390 d_loss_real= 0.104, d_loss_fake= 0.107, g_loss 2.349, d_loss 0.105\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 75/390 d_loss_real= 0.116, d_loss_fake= 0.107, g_loss 2.364, d_loss 0.111\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 76/390 d_loss_real= 0.167, d_loss_fake= 0.442, g_loss 1.374, d_loss 0.304\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 1 Batch 77/390 d_loss_real= 0.115, d_loss_fake= 14.519, g_loss 0.000, d_loss 7.317\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 78/390 d_loss_real= 0.386, d_loss_fake= 10.189, g_loss 0.000, d_loss 5.288\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 79/390 d_loss_real= 0.842, d_loss_fake= 6.600, g_loss 0.011, d_loss 3.721\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 80/390 d_loss_real= 1.602, d_loss_fake= 3.006, g_loss 0.286, d_loss 2.304\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 81/390 d_loss_real= 1.748, d_loss_fake= 0.600, g_loss 1.480, d_loss 1.174\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 82/390 d_loss_real= 2.451, d_loss_fake= 0.168, g_loss 2.115, d_loss 1.309\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 83/390 d_loss_real= 1.761, d_loss_fake= 0.113, g_loss 2.322, d_loss 0.937\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 84/390 d_loss_real= 2.114, d_loss_fake= 0.103, g_loss 2.337, d_loss 1.109\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 85/390 d_loss_real= 1.779, d_loss_fake= 0.105, g_loss 2.283, d_loss 0.942\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 86/390 d_loss_real= 1.475, d_loss_fake= 0.114, g_loss 2.191, d_loss 0.794\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 87/390 d_loss_real= 1.518, d_loss_fake= 0.127, g_loss 2.077, d_loss 0.823\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 88/390 d_loss_real= 1.007, d_loss_fake= 0.143, g_loss 1.969, d_loss 0.575\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 89/390 d_loss_real= 0.702, d_loss_fake= 0.159, g_loss 1.875, d_loss 0.431\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 1 Batch 90/390 d_loss_real= 0.656, d_loss_fake= 0.176, g_loss 1.788, d_loss 0.416\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 91/390 d_loss_real= 0.370, d_loss_fake= 0.191, g_loss 1.719, d_loss 0.281\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 92/390 d_loss_real= 0.248, d_loss_fake= 0.205, g_loss 1.667, d_loss 0.226\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 93/390 d_loss_real= 0.139, d_loss_fake= 0.214, g_loss 1.633, d_loss 0.177\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 94/390 d_loss_real= 0.110, d_loss_fake= 0.221, g_loss 1.615, d_loss 0.165\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 95/390 d_loss_real= 0.081, d_loss_fake= 0.223, g_loss 1.611, d_loss 0.152\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 96/390 d_loss_real= 0.046, d_loss_fake= 0.223, g_loss 1.620, d_loss 0.135\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 97/390 d_loss_real= 0.037, d_loss_fake= 0.219, g_loss 1.642, d_loss 0.128\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 1 Batch 98/390 d_loss_real= 0.031, d_loss_fake= 0.212, g_loss 1.673, d_loss 0.122\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 99/390 d_loss_real= 0.018, d_loss_fake= 0.204, g_loss 1.713, d_loss 0.111\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 100/390 d_loss_real= 0.027, d_loss_fake= 0.194, g_loss 1.761, d_loss 0.111\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 101/390 d_loss_real= 0.015, d_loss_fake= 0.184, g_loss 1.814, d_loss 0.099\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 102/390 d_loss_real= 0.013, d_loss_fake= 0.173, g_loss 1.874, d_loss 0.093\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 103/390 d_loss_real= 0.011, d_loss_fake= 0.161, g_loss 1.940, d_loss 0.086\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 1 Batch 104/390 d_loss_real= 0.010, d_loss_fake= 0.150, g_loss 2.010, d_loss 0.080\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 105/390 d_loss_real= 0.008, d_loss_fake= 0.139, g_loss 2.084, d_loss 0.073\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 106/390 d_loss_real= 0.007, d_loss_fake= 0.128, g_loss 2.162, d_loss 0.067\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 107/390 d_loss_real= 0.011, d_loss_fake= 0.118, g_loss 2.239, d_loss 0.064\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 108/390 d_loss_real= 0.007, d_loss_fake= 0.108, g_loss 2.318, d_loss 0.058\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 109/390 d_loss_real= 0.008, d_loss_fake= 0.100, g_loss 2.399, d_loss 0.054\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 110/390 d_loss_real= 0.005, d_loss_fake= 0.091, g_loss 2.481, d_loss 0.048\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 1 Batch 111/390 d_loss_real= 0.007, d_loss_fake= 0.084, g_loss 2.564, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 112/390 d_loss_real= 0.007, d_loss_fake= 0.077, g_loss 2.649, d_loss 0.042\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 113/390 d_loss_real= 0.006, d_loss_fake= 0.070, g_loss 2.735, d_loss 0.038\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 114/390 d_loss_real= 0.008, d_loss_fake= 0.064, g_loss 2.821, d_loss 0.036\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 115/390 d_loss_real= 0.008, d_loss_fake= 0.059, g_loss 2.906, d_loss 0.033\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 116/390 d_loss_real= 0.006, d_loss_fake= 0.054, g_loss 2.991, d_loss 0.030\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 117/390 d_loss_real= 0.007, d_loss_fake= 0.050, g_loss 3.073, d_loss 0.028\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 118/390 d_loss_real= 0.005, d_loss_fake= 0.046, g_loss 3.148, d_loss 0.025\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 1 Batch 119/390 d_loss_real= 0.010, d_loss_fake= 0.043, g_loss 3.210, d_loss 0.027\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 120/390 d_loss_real= 0.006, d_loss_fake= 0.086, g_loss 2.533, d_loss 0.046\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 121/390 d_loss_real= 0.009, d_loss_fake= 0.838, g_loss 0.777, d_loss 0.424\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 122/390 d_loss_real= 0.008, d_loss_fake= 1.437, g_loss 0.492, d_loss 0.722\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 123/390 d_loss_real= 0.018, d_loss_fake= 0.677, g_loss 1.185, d_loss 0.347\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 124/390 d_loss_real= 0.047, d_loss_fake= 0.254, g_loss 1.925, d_loss 0.150\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 125/390 d_loss_real= 0.072, d_loss_fake= 0.130, g_loss 2.402, d_loss 0.101\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 126/390 d_loss_real= 0.205, d_loss_fake= 0.171, g_loss 2.139, d_loss 0.188\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 127/390 d_loss_real= 0.344, d_loss_fake= 0.396, g_loss 1.366, d_loss 0.370\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 128/390 d_loss_real= 0.409, d_loss_fake= 0.273, g_loss 1.629, d_loss 0.341\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 129/390 d_loss_real= 0.652, d_loss_fake= 0.212, g_loss 1.752, d_loss 0.432\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 130/390 d_loss_real= 0.650, d_loss_fake= 0.199, g_loss 1.734, d_loss 0.424\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 131/390 d_loss_real= 0.615, d_loss_fake= 0.220, g_loss 1.586, d_loss 0.417\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 132/390 d_loss_real= 0.497, d_loss_fake= 0.278, g_loss 1.361, d_loss 0.388\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 133/390 d_loss_real= 0.442, d_loss_fake= 0.367, g_loss 1.179, d_loss 0.405\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 134/390 d_loss_real= 0.307, d_loss_fake= 0.417, g_loss 1.185, d_loss 0.362\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 135/390 d_loss_real= 0.301, d_loss_fake= 0.369, g_loss 1.345, d_loss 0.335\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 136/390 d_loss_real= 0.413, d_loss_fake= 0.292, g_loss 1.510, d_loss 0.352\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 1 Batch 137/390 d_loss_real= 0.405, d_loss_fake= 0.245, g_loss 1.626, d_loss 0.325\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 1 Batch 138/390 d_loss_real= 0.451, d_loss_fake= 0.229, g_loss 1.643, d_loss 0.340\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 139/390 d_loss_real= 0.440, d_loss_fake= 0.238, g_loss 1.579, d_loss 0.339\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 1 Batch 140/390 d_loss_real= 0.344, d_loss_fake= 0.257, g_loss 1.526, d_loss 0.300\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 141/390 d_loss_real= 0.374, d_loss_fake= 0.267, g_loss 1.528, d_loss 0.320\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 1 Batch 142/390 d_loss_real= 0.322, d_loss_fake= 0.255, g_loss 1.598, d_loss 0.289\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 143/390 d_loss_real= 0.521, d_loss_fake= 0.244, g_loss 1.588, d_loss 0.383\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 144/390 d_loss_real= 0.347, d_loss_fake= 0.247, g_loss 1.593, d_loss 0.297\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 145/390 d_loss_real= 0.352, d_loss_fake= 0.243, g_loss 1.620, d_loss 0.297\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 146/390 d_loss_real= 0.277, d_loss_fake= 0.231, g_loss 1.664, d_loss 0.254\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 147/390 d_loss_real= 0.305, d_loss_fake= 0.221, g_loss 1.697, d_loss 0.263\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 148/390 d_loss_real= 0.300, d_loss_fake= 0.215, g_loss 1.708, d_loss 0.257\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 1 Batch 149/390 d_loss_real= 0.302, d_loss_fake= 0.217, g_loss 1.725, d_loss 0.259\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 150/390 d_loss_real= 0.340, d_loss_fake= 0.207, g_loss 1.770, d_loss 0.273\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 1 Batch 151/390 d_loss_real= 0.253, d_loss_fake= 0.189, g_loss 1.837, d_loss 0.221\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 152/390 d_loss_real= 0.221, d_loss_fake= 0.175, g_loss 1.895, d_loss 0.198\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 153/390 d_loss_real= 0.325, d_loss_fake= 0.169, g_loss 1.898, d_loss 0.247\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 154/390 d_loss_real= 0.259, d_loss_fake= 0.178, g_loss 1.860, d_loss 0.218\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 1 Batch 155/390 d_loss_real= 0.297, d_loss_fake= 0.194, g_loss 1.834, d_loss 0.245\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 156/390 d_loss_real= 0.218, d_loss_fake= 0.186, g_loss 1.897, d_loss 0.202\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 157/390 d_loss_real= 0.280, d_loss_fake= 0.169, g_loss 1.950, d_loss 0.224\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 158/390 d_loss_real= 0.330, d_loss_fake= 0.164, g_loss 1.945, d_loss 0.247\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 159/390 d_loss_real= 0.317, d_loss_fake= 0.167, g_loss 1.939, d_loss 0.242\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 160/390 d_loss_real= 0.233, d_loss_fake= 0.162, g_loss 1.992, d_loss 0.197\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 161/390 d_loss_real= 0.254, d_loss_fake= 0.150, g_loss 2.019, d_loss 0.202\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 162/390 d_loss_real= 0.203, d_loss_fake= 0.148, g_loss 2.023, d_loss 0.175\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 163/390 d_loss_real= 0.246, d_loss_fake= 0.151, g_loss 2.016, d_loss 0.198\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 164/390 d_loss_real= 0.157, d_loss_fake= 0.148, g_loss 2.047, d_loss 0.152\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 165/390 d_loss_real= 0.200, d_loss_fake= 0.142, g_loss 2.083, d_loss 0.171\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 166/390 d_loss_real= 0.153, d_loss_fake= 0.135, g_loss 2.121, d_loss 0.144\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 167/390 d_loss_real= 0.142, d_loss_fake= 0.128, g_loss 2.158, d_loss 0.135\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 168/390 d_loss_real= 0.161, d_loss_fake= 0.126, g_loss 2.176, d_loss 0.144\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 169/390 d_loss_real= 0.173, d_loss_fake= 0.128, g_loss 2.187, d_loss 0.151\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 170/390 d_loss_real= 0.240, d_loss_fake= 0.130, g_loss 2.183, d_loss 0.185\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 1 Batch 171/390 d_loss_real= 0.140, d_loss_fake= 0.127, g_loss 2.223, d_loss 0.134\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 172/390 d_loss_real= 0.165, d_loss_fake= 0.116, g_loss 2.271, d_loss 0.140\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 173/390 d_loss_real= 0.152, d_loss_fake= 0.113, g_loss 2.275, d_loss 0.132\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 174/390 d_loss_real= 0.230, d_loss_fake= 0.120, g_loss 2.242, d_loss 0.175\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 175/390 d_loss_real= 0.108, d_loss_fake= 0.118, g_loss 2.290, d_loss 0.113\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 176/390 d_loss_real= 0.194, d_loss_fake= 0.113, g_loss 2.292, d_loss 0.154\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 177/390 d_loss_real= 0.170, d_loss_fake= 0.111, g_loss 2.310, d_loss 0.140\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 178/390 d_loss_real= 0.088, d_loss_fake= 0.105, g_loss 2.359, d_loss 0.097\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 179/390 d_loss_real= 0.139, d_loss_fake= 0.102, g_loss 2.372, d_loss 0.121\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 180/390 d_loss_real= 0.128, d_loss_fake= 0.105, g_loss 2.382, d_loss 0.117\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 1 Batch 181/390 d_loss_real= 0.070, d_loss_fake= 0.096, g_loss 2.467, d_loss 0.083\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 182/390 d_loss_real= 0.185, d_loss_fake= 0.093, g_loss 2.449, d_loss 0.139\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 183/390 d_loss_real= 0.186, d_loss_fake= 0.101, g_loss 2.427, d_loss 0.144\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 184/390 d_loss_real= 0.188, d_loss_fake= 0.104, g_loss 2.410, d_loss 0.146\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 185/390 d_loss_real= 0.182, d_loss_fake= 0.102, g_loss 2.398, d_loss 0.142\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 186/390 d_loss_real= 0.237, d_loss_fake= 0.105, g_loss 2.362, d_loss 0.171\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 1 Batch 187/390 d_loss_real= 0.093, d_loss_fake= 0.103, g_loss 2.404, d_loss 0.098\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 1 Batch 188/390 d_loss_real= 0.255, d_loss_fake= 0.105, g_loss 2.356, d_loss 0.180\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 189/390 d_loss_real= 0.056, d_loss_fake= 0.126, g_loss 2.239, d_loss 0.091\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 190/390 d_loss_real= 0.126, d_loss_fake= 3.226, g_loss 0.137, d_loss 1.676\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 191/390 d_loss_real= 0.234, d_loss_fake= 11.636, g_loss 0.000, d_loss 5.935\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 1 Batch 192/390 d_loss_real= 0.821, d_loss_fake= 9.158, g_loss 0.001, d_loss 4.990\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 193/390 d_loss_real= 1.513, d_loss_fake= 5.256, g_loss 0.039, d_loss 3.385\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 194/390 d_loss_real= 2.687, d_loss_fake= 1.888, g_loss 0.927, d_loss 2.288\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 195/390 d_loss_real= 3.090, d_loss_fake= 0.141, g_loss 2.618, d_loss 1.616\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 196/390 d_loss_real= 3.437, d_loss_fake= 0.061, g_loss 2.982, d_loss 1.749\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 197/390 d_loss_real= 3.484, d_loss_fake= 0.052, g_loss 2.963, d_loss 1.768\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 198/390 d_loss_real= 3.567, d_loss_fake= 0.059, g_loss 2.781, d_loss 1.813\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 199/390 d_loss_real= 3.185, d_loss_fake= 0.074, g_loss 2.517, d_loss 1.629\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 200/390 d_loss_real= 2.570, d_loss_fake= 0.099, g_loss 2.231, d_loss 1.335\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 1 Batch 201/390 d_loss_real= 2.384, d_loss_fake= 0.134, g_loss 1.954, d_loss 1.259\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 202/390 d_loss_real= 1.995, d_loss_fake= 0.178, g_loss 1.701, d_loss 1.087\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 1 Batch 203/390 d_loss_real= 1.621, d_loss_fake= 0.231, g_loss 1.487, d_loss 0.926\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 204/390 d_loss_real= 1.475, d_loss_fake= 0.288, g_loss 1.306, d_loss 0.882\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 1 Batch 205/390 d_loss_real= 1.218, d_loss_fake= 0.350, g_loss 1.157, d_loss 0.784\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 206/390 d_loss_real= 0.978, d_loss_fake= 0.410, g_loss 1.043, d_loss 0.694\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 1 Batch 207/390 d_loss_real= 0.853, d_loss_fake= 0.466, g_loss 0.950, d_loss 0.659\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 1 Batch 208/390 d_loss_real= 0.739, d_loss_fake= 0.518, g_loss 0.879, d_loss 0.629\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 209/390 d_loss_real= 0.684, d_loss_fake= 0.561, g_loss 0.827, d_loss 0.622\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 210/390 d_loss_real= 0.665, d_loss_fake= 0.595, g_loss 0.792, d_loss 0.630\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 211/390 d_loss_real= 0.656, d_loss_fake= 0.618, g_loss 0.770, d_loss 0.637\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 212/390 d_loss_real= 0.532, d_loss_fake= 0.632, g_loss 0.760, d_loss 0.582\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 213/390 d_loss_real= 0.533, d_loss_fake= 0.636, g_loss 0.760, d_loss 0.584\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 214/390 d_loss_real= 0.471, d_loss_fake= 0.632, g_loss 0.769, d_loss 0.551\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 215/390 d_loss_real= 0.502, d_loss_fake= 0.621, g_loss 0.785, d_loss 0.561\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 216/390 d_loss_real= 0.471, d_loss_fake= 0.605, g_loss 0.805, d_loss 0.538\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 217/390 d_loss_real= 0.468, d_loss_fake= 0.588, g_loss 0.827, d_loss 0.528\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 218/390 d_loss_real= 0.433, d_loss_fake= 0.570, g_loss 0.849, d_loss 0.502\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 219/390 d_loss_real= 0.471, d_loss_fake= 0.554, g_loss 0.869, d_loss 0.513\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 220/390 d_loss_real= 0.443, d_loss_fake= 0.539, g_loss 0.889, d_loss 0.491\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 1 Batch 221/390 d_loss_real= 0.437, d_loss_fake= 0.525, g_loss 0.909, d_loss 0.481\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 222/390 d_loss_real= 0.395, d_loss_fake= 0.512, g_loss 0.929, d_loss 0.454\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 223/390 d_loss_real= 0.394, d_loss_fake= 0.499, g_loss 0.949, d_loss 0.447\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 224/390 d_loss_real= 0.356, d_loss_fake= 0.485, g_loss 0.971, d_loss 0.421\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 225/390 d_loss_real= 0.364, d_loss_fake= 0.473, g_loss 0.992, d_loss 0.419\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 1 Batch 226/390 d_loss_real= 0.340, d_loss_fake= 0.460, g_loss 1.013, d_loss 0.400\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 227/390 d_loss_real= 0.290, d_loss_fake= 0.448, g_loss 1.036, d_loss 0.369\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 228/390 d_loss_real= 0.268, d_loss_fake= 0.434, g_loss 1.062, d_loss 0.351\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 1 Batch 229/390 d_loss_real= 0.253, d_loss_fake= 0.420, g_loss 1.089, d_loss 0.336\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 230/390 d_loss_real= 0.241, d_loss_fake= 0.406, g_loss 1.115, d_loss 0.324\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 231/390 d_loss_real= 0.239, d_loss_fake= 0.393, g_loss 1.143, d_loss 0.316\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 232/390 d_loss_real= 0.196, d_loss_fake= 0.380, g_loss 1.173, d_loss 0.288\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 1 Batch 233/390 d_loss_real= 0.170, d_loss_fake= 0.365, g_loss 1.206, d_loss 0.268\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 234/390 d_loss_real= 0.178, d_loss_fake= 0.350, g_loss 1.242, d_loss 0.264\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 235/390 d_loss_real= 0.175, d_loss_fake= 0.335, g_loss 1.278, d_loss 0.255\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 236/390 d_loss_real= 0.132, d_loss_fake= 0.321, g_loss 1.315, d_loss 0.227\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 1 Batch 237/390 d_loss_real= 0.138, d_loss_fake= 0.308, g_loss 1.353, d_loss 0.223\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 238/390 d_loss_real= 0.138, d_loss_fake= 0.294, g_loss 1.394, d_loss 0.216\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 1 Batch 239/390 d_loss_real= 0.107, d_loss_fake= 0.280, g_loss 1.436, d_loss 0.193\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 1 Batch 240/390 d_loss_real= 0.103, d_loss_fake= 0.266, g_loss 1.480, d_loss 0.185\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 1 Batch 241/390 d_loss_real= 0.102, d_loss_fake= 0.253, g_loss 1.527, d_loss 0.177\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 242/390 d_loss_real= 0.093, d_loss_fake= 0.239, g_loss 1.575, d_loss 0.166\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 1 Batch 243/390 d_loss_real= 0.092, d_loss_fake= 0.227, g_loss 1.624, d_loss 0.159\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 244/390 d_loss_real= 0.070, d_loss_fake= 0.214, g_loss 1.673, d_loss 0.142\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 245/390 d_loss_real= 0.065, d_loss_fake= 0.203, g_loss 1.723, d_loss 0.134\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 246/390 d_loss_real= 0.081, d_loss_fake= 0.192, g_loss 1.773, d_loss 0.137\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 247/390 d_loss_real= 0.060, d_loss_fake= 0.182, g_loss 1.824, d_loss 0.121\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 248/390 d_loss_real= 0.060, d_loss_fake= 0.172, g_loss 1.876, d_loss 0.116\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 1 Batch 249/390 d_loss_real= 0.064, d_loss_fake= 0.162, g_loss 1.926, d_loss 0.113\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 250/390 d_loss_real= 0.057, d_loss_fake= 0.154, g_loss 1.976, d_loss 0.105\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 251/390 d_loss_real= 0.048, d_loss_fake= 0.146, g_loss 2.024, d_loss 0.097\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 252/390 d_loss_real= 0.036, d_loss_fake= 0.138, g_loss 2.072, d_loss 0.087\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 253/390 d_loss_real= 0.044, d_loss_fake= 0.132, g_loss 2.120, d_loss 0.088\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 254/390 d_loss_real= 0.043, d_loss_fake= 0.125, g_loss 2.170, d_loss 0.084\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 255/390 d_loss_real= 0.031, d_loss_fake= 0.118, g_loss 2.221, d_loss 0.075\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 256/390 d_loss_real= 0.030, d_loss_fake= 0.112, g_loss 2.272, d_loss 0.071\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 257/390 d_loss_real= 0.036, d_loss_fake= 0.106, g_loss 2.323, d_loss 0.071\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 258/390 d_loss_real= 0.031, d_loss_fake= 0.101, g_loss 2.372, d_loss 0.066\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 259/390 d_loss_real= 0.036, d_loss_fake= 0.096, g_loss 2.421, d_loss 0.066\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 260/390 d_loss_real= 0.046, d_loss_fake= 0.091, g_loss 2.468, d_loss 0.068\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 1 Batch 261/390 d_loss_real= 0.019, d_loss_fake= 0.086, g_loss 2.520, d_loss 0.053\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 262/390 d_loss_real= 0.029, d_loss_fake= 0.082, g_loss 2.571, d_loss 0.055\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 263/390 d_loss_real= 0.023, d_loss_fake= 0.078, g_loss 2.623, d_loss 0.050\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 264/390 d_loss_real= 0.023, d_loss_fake= 0.074, g_loss 2.673, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 265/390 d_loss_real= 0.016, d_loss_fake= 0.070, g_loss 2.723, d_loss 0.043\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 266/390 d_loss_real= 0.024, d_loss_fake= 0.067, g_loss 2.768, d_loss 0.045\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 1 Batch 267/390 d_loss_real= 0.025, d_loss_fake= 0.064, g_loss 2.803, d_loss 0.045\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 268/390 d_loss_real= 0.019, d_loss_fake= 0.073, g_loss 2.686, d_loss 0.046\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 269/390 d_loss_real= 0.020, d_loss_fake= 1.173, g_loss 0.548, d_loss 0.597\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 1 Batch 270/390 d_loss_real= 0.023, d_loss_fake= 1.718, g_loss 0.425, d_loss 0.871\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 271/390 d_loss_real= 0.092, d_loss_fake= 1.171, g_loss 0.793, d_loss 0.632\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 272/390 d_loss_real= 0.223, d_loss_fake= 0.339, g_loss 1.788, d_loss 0.281\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 1 Batch 273/390 d_loss_real= 0.767, d_loss_fake= 0.125, g_loss 2.445, d_loss 0.446\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 1 Batch 274/390 d_loss_real= 1.335, d_loss_fake= 0.081, g_loss 2.657, d_loss 0.708\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 275/390 d_loss_real= 1.520, d_loss_fake= 0.076, g_loss 2.589, d_loss 0.798\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 1 Batch 276/390 d_loss_real= 1.462, d_loss_fake= 0.091, g_loss 2.331, d_loss 0.776\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 1 Batch 277/390 d_loss_real= 1.009, d_loss_fake= 0.128, g_loss 1.943, d_loss 0.569\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 1 Batch 278/390 d_loss_real= 0.794, d_loss_fake= 0.206, g_loss 1.487, d_loss 0.500\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 279/390 d_loss_real= 0.529, d_loss_fake= 0.344, g_loss 1.079, d_loss 0.437\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 1 Batch 280/390 d_loss_real= 0.306, d_loss_fake= 0.525, g_loss 0.831, d_loss 0.415\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 281/390 d_loss_real= 0.276, d_loss_fake= 0.655, g_loss 0.750, d_loss 0.466\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 1 Batch 282/390 d_loss_real= 0.213, d_loss_fake= 0.659, g_loss 0.807, d_loss 0.436\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 283/390 d_loss_real= 0.186, d_loss_fake= 0.558, g_loss 0.981, d_loss 0.372\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 1 Batch 284/390 d_loss_real= 0.250, d_loss_fake= 0.427, g_loss 1.196, d_loss 0.338\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 285/390 d_loss_real= 0.209, d_loss_fake= 0.324, g_loss 1.420, d_loss 0.266\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 1 Batch 286/390 d_loss_real= 0.365, d_loss_fake= 0.257, g_loss 1.584, d_loss 0.311\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 1 Batch 287/390 d_loss_real= 0.383, d_loss_fake= 0.220, g_loss 1.686, d_loss 0.302\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 288/390 d_loss_real= 0.488, d_loss_fake= 0.206, g_loss 1.708, d_loss 0.347\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 1 Batch 289/390 d_loss_real= 0.386, d_loss_fake= 0.205, g_loss 1.691, d_loss 0.296\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 290/390 d_loss_real= 0.460, d_loss_fake= 0.218, g_loss 1.606, d_loss 0.339\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 291/390 d_loss_real= 0.328, d_loss_fake= 0.249, g_loss 1.481, d_loss 0.289\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 1 Batch 292/390 d_loss_real= 0.338, d_loss_fake= 0.295, g_loss 1.356, d_loss 0.316\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 293/390 d_loss_real= 0.283, d_loss_fake= 0.327, g_loss 1.320, d_loss 0.305\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 294/390 d_loss_real= 0.304, d_loss_fake= 0.325, g_loss 1.365, d_loss 0.314\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 1 Batch 295/390 d_loss_real= 0.255, d_loss_fake= 0.294, g_loss 1.468, d_loss 0.274\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 296/390 d_loss_real= 0.311, d_loss_fake= 0.256, g_loss 1.582, d_loss 0.284\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 1 Batch 297/390 d_loss_real= 0.387, d_loss_fake= 0.230, g_loss 1.646, d_loss 0.309\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 298/390 d_loss_real= 0.223, d_loss_fake= 0.215, g_loss 1.697, d_loss 0.219\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 299/390 d_loss_real= 0.358, d_loss_fake= 0.210, g_loss 1.703, d_loss 0.284\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 300/390 d_loss_real= 0.320, d_loss_fake= 0.212, g_loss 1.685, d_loss 0.266\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 301/390 d_loss_real= 0.399, d_loss_fake= 0.222, g_loss 1.644, d_loss 0.311\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 302/390 d_loss_real= 0.296, d_loss_fake= 0.234, g_loss 1.619, d_loss 0.265\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 1 Batch 303/390 d_loss_real= 0.231, d_loss_fake= 0.229, g_loss 1.658, d_loss 0.230\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 304/390 d_loss_real= 0.262, d_loss_fake= 0.214, g_loss 1.722, d_loss 0.238\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 1 Batch 305/390 d_loss_real= 0.285, d_loss_fake= 0.199, g_loss 1.773, d_loss 0.242\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 1 Batch 306/390 d_loss_real= 0.286, d_loss_fake= 0.189, g_loss 1.805, d_loss 0.237\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 307/390 d_loss_real= 0.159, d_loss_fake= 0.181, g_loss 1.840, d_loss 0.170\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 1 Batch 308/390 d_loss_real= 0.306, d_loss_fake= 0.180, g_loss 1.823, d_loss 0.243\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 1 Batch 309/390 d_loss_real= 0.175, d_loss_fake= 0.184, g_loss 1.819, d_loss 0.180\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 1 Batch 310/390 d_loss_real= 0.228, d_loss_fake= 0.188, g_loss 1.812, d_loss 0.208\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 311/390 d_loss_real= 0.251, d_loss_fake= 0.186, g_loss 1.838, d_loss 0.219\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 1 Batch 312/390 d_loss_real= 0.241, d_loss_fake= 0.181, g_loss 1.855, d_loss 0.211\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 313/390 d_loss_real= 0.245, d_loss_fake= 0.176, g_loss 1.862, d_loss 0.210\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 1 Batch 314/390 d_loss_real= 0.187, d_loss_fake= 0.175, g_loss 1.875, d_loss 0.181\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 1 Batch 315/390 d_loss_real= 0.182, d_loss_fake= 0.169, g_loss 1.913, d_loss 0.175\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 316/390 d_loss_real= 0.220, d_loss_fake= 0.160, g_loss 1.952, d_loss 0.190\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 317/390 d_loss_real= 0.198, d_loss_fake= 0.159, g_loss 1.940, d_loss 0.179\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 1 Batch 318/390 d_loss_real= 0.097, d_loss_fake= 0.159, g_loss 1.981, d_loss 0.128\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 319/390 d_loss_real= 0.174, d_loss_fake= 0.149, g_loss 2.035, d_loss 0.161\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 1 Batch 320/390 d_loss_real= 0.324, d_loss_fake= 0.147, g_loss 2.018, d_loss 0.236\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 321/390 d_loss_real= 0.306, d_loss_fake= 0.159, g_loss 1.964, d_loss 0.232\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 1 Batch 322/390 d_loss_real= 0.113, d_loss_fake= 0.154, g_loss 2.025, d_loss 0.134\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 323/390 d_loss_real= 0.206, d_loss_fake= 0.142, g_loss 2.067, d_loss 0.174\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 1 Batch 324/390 d_loss_real= 0.147, d_loss_fake= 0.136, g_loss 2.103, d_loss 0.141\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 1 Batch 325/390 d_loss_real= 0.126, d_loss_fake= 0.131, g_loss 2.131, d_loss 0.128\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 1 Batch 326/390 d_loss_real= 0.241, d_loss_fake= 0.131, g_loss 2.121, d_loss 0.186\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 327/390 d_loss_real= 0.118, d_loss_fake= 0.134, g_loss 2.142, d_loss 0.126\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 1 Batch 328/390 d_loss_real= 0.222, d_loss_fake= 0.132, g_loss 2.163, d_loss 0.177\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 1 Batch 329/390 d_loss_real= 0.150, d_loss_fake= 0.125, g_loss 2.196, d_loss 0.137\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 330/390 d_loss_real= 0.168, d_loss_fake= 0.120, g_loss 2.210, d_loss 0.144\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 331/390 d_loss_real= 0.150, d_loss_fake= 0.118, g_loss 2.226, d_loss 0.134\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 332/390 d_loss_real= 0.255, d_loss_fake= 0.122, g_loss 2.211, d_loss 0.189\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 1 Batch 333/390 d_loss_real= 0.155, d_loss_fake= 0.121, g_loss 2.228, d_loss 0.138\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 334/390 d_loss_real= 0.083, d_loss_fake= 0.113, g_loss 2.280, d_loss 0.098\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 335/390 d_loss_real= 0.128, d_loss_fake= 0.109, g_loss 2.299, d_loss 0.118\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 1 Batch 336/390 d_loss_real= 0.146, d_loss_fake= 0.108, g_loss 2.301, d_loss 0.127\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 1 Batch 337/390 d_loss_real= 0.221, d_loss_fake= 0.115, g_loss 2.253, d_loss 0.168\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 1 Batch 338/390 d_loss_real= 0.132, d_loss_fake= 0.122, g_loss 2.257, d_loss 0.127\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 339/390 d_loss_real= 0.188, d_loss_fake= 0.114, g_loss 2.310, d_loss 0.151\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 340/390 d_loss_real= 0.172, d_loss_fake= 0.105, g_loss 2.350, d_loss 0.138\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 1 Batch 341/390 d_loss_real= 0.339, d_loss_fake= 0.104, g_loss 2.331, d_loss 0.221\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 342/390 d_loss_real= 0.154, d_loss_fake= 0.108, g_loss 2.315, d_loss 0.131\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 343/390 d_loss_real= 0.092, d_loss_fake= 0.107, g_loss 2.341, d_loss 0.099\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 344/390 d_loss_real= 0.324, d_loss_fake= 0.107, g_loss 2.316, d_loss 0.215\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 1 Batch 345/390 d_loss_real= 0.145, d_loss_fake= 0.112, g_loss 2.296, d_loss 0.128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 346/390 d_loss_real= 0.083, d_loss_fake= 0.107, g_loss 2.356, d_loss 0.095\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 347/390 d_loss_real= 0.083, d_loss_fake= 0.098, g_loss 2.409, d_loss 0.091\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 348/390 d_loss_real= 0.173, d_loss_fake= 0.095, g_loss 2.419, d_loss 0.134\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 349/390 d_loss_real= 0.090, d_loss_fake= 0.096, g_loss 2.404, d_loss 0.093\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 350/390 d_loss_real= 0.101, d_loss_fake= 0.097, g_loss 2.433, d_loss 0.099\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 1 Batch 351/390 d_loss_real= 0.126, d_loss_fake= 0.092, g_loss 2.469, d_loss 0.109\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 1 Batch 352/390 d_loss_real= 0.276, d_loss_fake= 0.098, g_loss 2.389, d_loss 0.187\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 353/390 d_loss_real= 0.215, d_loss_fake= 0.109, g_loss 2.337, d_loss 0.162\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 354/390 d_loss_real= 0.177, d_loss_fake= 0.112, g_loss 2.321, d_loss 0.145\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 355/390 d_loss_real= 0.120, d_loss_fake= 0.105, g_loss 2.394, d_loss 0.113\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 1 Batch 356/390 d_loss_real= 0.116, d_loss_fake= 0.096, g_loss 2.443, d_loss 0.106\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 1 Batch 357/390 d_loss_real= 0.052, d_loss_fake= 0.090, g_loss 2.496, d_loss 0.071\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 1 Batch 358/390 d_loss_real= 0.114, d_loss_fake= 0.086, g_loss 2.523, d_loss 0.100\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 359/390 d_loss_real= 0.236, d_loss_fake= 0.086, g_loss 2.497, d_loss 0.161\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 1 Batch 360/390 d_loss_real= 0.054, d_loss_fake= 0.091, g_loss 2.484, d_loss 0.073\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 361/390 d_loss_real= 0.157, d_loss_fake= 0.091, g_loss 2.519, d_loss 0.124\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 362/390 d_loss_real= 0.087, d_loss_fake= 0.084, g_loss 2.558, d_loss 0.085\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 363/390 d_loss_real= 0.176, d_loss_fake= 0.084, g_loss 2.534, d_loss 0.130\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 364/390 d_loss_real= 0.124, d_loss_fake= 0.090, g_loss 2.493, d_loss 0.107\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 365/390 d_loss_real= 0.171, d_loss_fake= 0.097, g_loss 2.461, d_loss 0.134\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 1 Batch 366/390 d_loss_real= 0.157, d_loss_fake= 0.092, g_loss 2.518, d_loss 0.124\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 1 Batch 367/390 d_loss_real= 0.125, d_loss_fake= 0.086, g_loss 2.542, d_loss 0.106\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 1 Batch 368/390 d_loss_real= 0.097, d_loss_fake= 0.082, g_loss 2.578, d_loss 0.089\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 1 Batch 369/390 d_loss_real= 0.099, d_loss_fake= 0.080, g_loss 2.583, d_loss 0.089\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 370/390 d_loss_real= 0.149, d_loss_fake= 0.084, g_loss 2.539, d_loss 0.117\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 371/390 d_loss_real= 0.146, d_loss_fake= 0.093, g_loss 2.501, d_loss 0.120\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 372/390 d_loss_real= 0.063, d_loss_fake= 0.086, g_loss 2.578, d_loss 0.074\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 373/390 d_loss_real= 0.071, d_loss_fake= 0.078, g_loss 2.627, d_loss 0.074\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 374/390 d_loss_real= 0.191, d_loss_fake= 0.076, g_loss 2.614, d_loss 0.134\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 1 Batch 375/390 d_loss_real= 0.064, d_loss_fake= 0.080, g_loss 2.588, d_loss 0.072\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 376/390 d_loss_real= 0.090, d_loss_fake= 0.084, g_loss 2.589, d_loss 0.087\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 377/390 d_loss_real= 0.129, d_loss_fake= 0.080, g_loss 2.646, d_loss 0.105\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 1 Batch 378/390 d_loss_real= 0.135, d_loss_fake= 0.075, g_loss 2.651, d_loss 0.105\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 379/390 d_loss_real= 0.146, d_loss_fake= 0.076, g_loss 2.651, d_loss 0.111\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 1 Batch 380/390 d_loss_real= 0.112, d_loss_fake= 0.076, g_loss 2.657, d_loss 0.094\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1 Batch 381/390 d_loss_real= 0.054, d_loss_fake= 0.072, g_loss 2.692, d_loss 0.063\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 382/390 d_loss_real= 0.079, d_loss_fake= 0.071, g_loss 2.686, d_loss 0.075\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 383/390 d_loss_real= 0.111, d_loss_fake= 0.076, g_loss 2.668, d_loss 0.093\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 1 Batch 384/390 d_loss_real= 0.048, d_loss_fake= 0.074, g_loss 2.728, d_loss 0.061\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1 Batch 385/390 d_loss_real= 0.146, d_loss_fake= 0.070, g_loss 2.717, d_loss 0.108\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 386/390 d_loss_real= 0.102, d_loss_fake= 0.072, g_loss 2.734, d_loss 0.087\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 1 Batch 387/390 d_loss_real= 0.040, d_loss_fake= 0.067, g_loss 2.768, d_loss 0.054\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 1 Batch 388/390 d_loss_real= 0.026, d_loss_fake= 0.064, g_loss 2.808, d_loss 0.045\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1 Batch 389/390 d_loss_real= 0.034, d_loss_fake= 0.062, g_loss 2.843, d_loss 0.048\n",
            "2/2 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 390/390 d_loss_real= 0.060, d_loss_fake= 0.060, g_loss 2.862, d_loss 0.060\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 1/390 d_loss_real= 0.077, d_loss_fake= 0.060, g_loss 2.859, d_loss 0.068\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 2/390 d_loss_real= 0.224, d_loss_fake= 0.069, g_loss 2.734, d_loss 0.146\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 3/390 d_loss_real= 0.098, d_loss_fake= 0.074, g_loss 2.764, d_loss 0.086\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 2 Batch 4/390 d_loss_real= 0.080, d_loss_fake= 0.063, g_loss 2.886, d_loss 0.071\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 5/390 d_loss_real= 0.102, d_loss_fake= 0.056, g_loss 2.940, d_loss 0.079\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 6/390 d_loss_real= 0.170, d_loss_fake= 0.056, g_loss 2.910, d_loss 0.113\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 7/390 d_loss_real= 0.061, d_loss_fake= 0.059, g_loss 2.856, d_loss 0.060\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 8/390 d_loss_real= 0.059, d_loss_fake= 0.062, g_loss 2.854, d_loss 0.061\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 9/390 d_loss_real= 0.170, d_loss_fake= 0.066, g_loss 2.808, d_loss 0.118\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 10/390 d_loss_real= 0.106, d_loss_fake= 0.066, g_loss 2.871, d_loss 0.086\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 11/390 d_loss_real= 0.079, d_loss_fake= 0.059, g_loss 2.911, d_loss 0.069\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 12/390 d_loss_real= 0.102, d_loss_fake= 0.056, g_loss 2.935, d_loss 0.079\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 13/390 d_loss_real= 0.051, d_loss_fake= 0.055, g_loss 2.958, d_loss 0.053\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 2 Batch 14/390 d_loss_real= 0.053, d_loss_fake= 0.054, g_loss 2.971, d_loss 0.053\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 15/390 d_loss_real= 0.046, d_loss_fake= 0.053, g_loss 2.988, d_loss 0.050\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 16/390 d_loss_real= 0.186, d_loss_fake= 0.056, g_loss 2.939, d_loss 0.121\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 17/390 d_loss_real= 0.084, d_loss_fake= 0.060, g_loss 2.924, d_loss 0.072\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 18/390 d_loss_real= 0.084, d_loss_fake= 0.055, g_loss 2.981, d_loss 0.070\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 19/390 d_loss_real= 0.082, d_loss_fake= 0.053, g_loss 2.990, d_loss 0.068\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 20/390 d_loss_real= 0.058, d_loss_fake= 0.053, g_loss 2.984, d_loss 0.056\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 21/390 d_loss_real= 0.190, d_loss_fake= 0.060, g_loss 2.819, d_loss 0.125\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 2 Batch 22/390 d_loss_real= 0.136, d_loss_fake= 0.071, g_loss 2.752, d_loss 0.103\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 23/390 d_loss_real= 0.095, d_loss_fake= 0.071, g_loss 2.792, d_loss 0.083\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 24/390 d_loss_real= 0.126, d_loss_fake= 0.063, g_loss 2.894, d_loss 0.094\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 25/390 d_loss_real= 0.035, d_loss_fake= 0.055, g_loss 2.984, d_loss 0.045\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 2 Batch 26/390 d_loss_real= 0.096, d_loss_fake= 0.052, g_loss 2.990, d_loss 0.074\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 27/390 d_loss_real= 0.028, d_loss_fake= 0.052, g_loss 3.002, d_loss 0.040\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 28/390 d_loss_real= 0.062, d_loss_fake= 0.052, g_loss 2.996, d_loss 0.057\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 29/390 d_loss_real= 0.123, d_loss_fake= 0.054, g_loss 2.974, d_loss 0.088\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 30/390 d_loss_real= 0.089, d_loss_fake= 0.055, g_loss 3.005, d_loss 0.072\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 31/390 d_loss_real= 0.084, d_loss_fake= 0.051, g_loss 3.055, d_loss 0.067\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 32/390 d_loss_real= 0.048, d_loss_fake= 0.048, g_loss 3.072, d_loss 0.048\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 33/390 d_loss_real= 0.030, d_loss_fake= 0.048, g_loss 3.091, d_loss 0.039\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 2 Batch 34/390 d_loss_real= 0.105, d_loss_fake= 0.052, g_loss 3.005, d_loss 0.078\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 2 Batch 35/390 d_loss_real= 0.014, d_loss_fake= 0.052, g_loss 3.087, d_loss 0.033\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 36/390 d_loss_real= 0.100, d_loss_fake= 0.047, g_loss 3.119, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 37/390 d_loss_real= 0.103, d_loss_fake= 0.046, g_loss 3.111, d_loss 0.075\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 38/390 d_loss_real= 0.066, d_loss_fake= 0.049, g_loss 3.065, d_loss 0.057\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 39/390 d_loss_real= 0.024, d_loss_fake= 0.050, g_loss 3.105, d_loss 0.037\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 40/390 d_loss_real= 0.022, d_loss_fake= 0.045, g_loss 3.163, d_loss 0.033\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 41/390 d_loss_real= 0.014, d_loss_fake= 0.042, g_loss 3.215, d_loss 0.028\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 42/390 d_loss_real= 0.194, d_loss_fake= 0.043, g_loss 3.112, d_loss 0.119\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 43/390 d_loss_real= 0.067, d_loss_fake= 0.054, g_loss 2.975, d_loss 0.061\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 44/390 d_loss_real= 0.106, d_loss_fake= 0.058, g_loss 3.003, d_loss 0.082\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 45/390 d_loss_real= 0.030, d_loss_fake= 0.049, g_loss 3.140, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 46/390 d_loss_real= 0.075, d_loss_fake= 0.044, g_loss 3.189, d_loss 0.059\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 2 Batch 47/390 d_loss_real= 0.069, d_loss_fake= 0.043, g_loss 3.190, d_loss 0.056\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 48/390 d_loss_real= 0.060, d_loss_fake= 0.044, g_loss 3.146, d_loss 0.052\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 49/390 d_loss_real= 0.055, d_loss_fake= 0.047, g_loss 3.135, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 50/390 d_loss_real= 0.029, d_loss_fake= 0.045, g_loss 3.200, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 51/390 d_loss_real= 0.025, d_loss_fake= 0.041, g_loss 3.262, d_loss 0.033\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 52/390 d_loss_real= 0.057, d_loss_fake= 0.039, g_loss 3.272, d_loss 0.048\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 53/390 d_loss_real= 0.096, d_loss_fake= 0.041, g_loss 3.208, d_loss 0.069\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 54/390 d_loss_real= 0.049, d_loss_fake= 0.045, g_loss 3.194, d_loss 0.047\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 55/390 d_loss_real= 0.080, d_loss_fake= 0.042, g_loss 3.269, d_loss 0.061\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 56/390 d_loss_real= 0.032, d_loss_fake= 0.038, g_loss 3.306, d_loss 0.035\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 57/390 d_loss_real= 0.083, d_loss_fake= 0.037, g_loss 3.319, d_loss 0.060\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 58/390 d_loss_real= 0.151, d_loss_fake= 0.039, g_loss 3.256, d_loss 0.095\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 59/390 d_loss_real= 0.028, d_loss_fake= 0.043, g_loss 3.216, d_loss 0.035\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 60/390 d_loss_real= 0.109, d_loss_fake= 0.043, g_loss 3.245, d_loss 0.076\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 61/390 d_loss_real= 0.206, d_loss_fake= 0.045, g_loss 3.122, d_loss 0.126\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 62/390 d_loss_real= 0.024, d_loss_fake= 0.048, g_loss 3.141, d_loss 0.036\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 2 Batch 63/390 d_loss_real= 0.056, d_loss_fake= 0.045, g_loss 3.174, d_loss 0.051\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 64/390 d_loss_real= 0.034, d_loss_fake= 0.043, g_loss 3.218, d_loss 0.038\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 65/390 d_loss_real= 0.047, d_loss_fake= 0.041, g_loss 3.244, d_loss 0.044\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 66/390 d_loss_real= 0.017, d_loss_fake= 0.040, g_loss 3.282, d_loss 0.028\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 2 Batch 67/390 d_loss_real= 0.132, d_loss_fake= 0.039, g_loss 3.288, d_loss 0.086\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 68/390 d_loss_real= 0.093, d_loss_fake= 0.042, g_loss 3.185, d_loss 0.067\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 69/390 d_loss_real= 0.064, d_loss_fake= 0.050, g_loss 3.128, d_loss 0.057\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 70/390 d_loss_real= 0.089, d_loss_fake= 0.049, g_loss 3.146, d_loss 0.069\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 71/390 d_loss_real= 0.027, d_loss_fake= 0.044, g_loss 3.237, d_loss 0.035\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 2 Batch 72/390 d_loss_real= 0.048, d_loss_fake= 0.039, g_loss 3.303, d_loss 0.044\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 73/390 d_loss_real= 0.028, d_loss_fake= 0.037, g_loss 3.348, d_loss 0.032\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 74/390 d_loss_real= 0.026, d_loss_fake= 0.036, g_loss 3.374, d_loss 0.031\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 75/390 d_loss_real= 0.033, d_loss_fake= 0.035, g_loss 3.376, d_loss 0.034\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 76/390 d_loss_real= 0.034, d_loss_fake= 0.036, g_loss 3.368, d_loss 0.035\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 77/390 d_loss_real= 0.132, d_loss_fake= 0.047, g_loss 3.033, d_loss 0.089\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 78/390 d_loss_real= 0.045, d_loss_fake= 0.062, g_loss 2.962, d_loss 0.054\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 79/390 d_loss_real= 0.062, d_loss_fake= 0.052, g_loss 3.192, d_loss 0.057\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 80/390 d_loss_real= 0.030, d_loss_fake= 0.039, g_loss 3.378, d_loss 0.035\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 81/390 d_loss_real= 0.059, d_loss_fake= 0.034, g_loss 3.426, d_loss 0.047\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 82/390 d_loss_real= 0.077, d_loss_fake= 0.034, g_loss 3.413, d_loss 0.055\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 83/390 d_loss_real= 0.073, d_loss_fake= 0.035, g_loss 3.377, d_loss 0.054\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 84/390 d_loss_real= 0.075, d_loss_fake= 0.038, g_loss 3.261, d_loss 0.056\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 2 Batch 85/390 d_loss_real= 0.010, d_loss_fake= 0.041, g_loss 3.294, d_loss 0.026\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 2 Batch 86/390 d_loss_real= 0.098, d_loss_fake= 0.038, g_loss 3.356, d_loss 0.068\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 87/390 d_loss_real= 0.044, d_loss_fake= 0.035, g_loss 3.404, d_loss 0.040\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 88/390 d_loss_real= 0.034, d_loss_fake= 0.034, g_loss 3.423, d_loss 0.034\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 89/390 d_loss_real= 0.031, d_loss_fake= 0.034, g_loss 3.424, d_loss 0.033\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 90/390 d_loss_real= 0.115, d_loss_fake= 0.038, g_loss 3.330, d_loss 0.076\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 91/390 d_loss_real= 0.008, d_loss_fake= 0.037, g_loss 3.448, d_loss 0.022\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 92/390 d_loss_real= 0.064, d_loss_fake= 0.032, g_loss 3.482, d_loss 0.048\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 93/390 d_loss_real= 0.046, d_loss_fake= 0.032, g_loss 3.474, d_loss 0.039\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 94/390 d_loss_real= 0.085, d_loss_fake= 0.033, g_loss 3.462, d_loss 0.059\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 95/390 d_loss_real= 0.008, d_loss_fake= 0.032, g_loss 3.506, d_loss 0.020\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 96/390 d_loss_real= 0.021, d_loss_fake= 0.030, g_loss 3.539, d_loss 0.026\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 97/390 d_loss_real= 0.056, d_loss_fake= 0.030, g_loss 3.511, d_loss 0.043\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 98/390 d_loss_real= 0.016, d_loss_fake= 0.032, g_loss 3.520, d_loss 0.024\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 99/390 d_loss_real= 0.004, d_loss_fake= 0.029, g_loss 3.592, d_loss 0.016\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 100/390 d_loss_real= 0.026, d_loss_fake= 0.028, g_loss 3.621, d_loss 0.027\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 101/390 d_loss_real= 0.085, d_loss_fake= 0.028, g_loss 3.535, d_loss 0.057\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 102/390 d_loss_real= 0.024, d_loss_fake= 0.034, g_loss 3.456, d_loss 0.029\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 103/390 d_loss_real= 0.043, d_loss_fake= 0.032, g_loss 3.566, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 104/390 d_loss_real= 0.040, d_loss_fake= 0.028, g_loss 3.628, d_loss 0.034\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 105/390 d_loss_real= 0.048, d_loss_fake= 0.027, g_loss 3.648, d_loss 0.037\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 106/390 d_loss_real= 0.030, d_loss_fake= 0.026, g_loss 3.664, d_loss 0.028\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 107/390 d_loss_real= 0.024, d_loss_fake= 0.026, g_loss 3.663, d_loss 0.025\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 108/390 d_loss_real= 0.097, d_loss_fake= 0.028, g_loss 3.610, d_loss 0.062\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 2 Batch 109/390 d_loss_real= 0.022, d_loss_fake= 0.029, g_loss 3.584, d_loss 0.025\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 110/390 d_loss_real= 0.091, d_loss_fake= 0.035, g_loss 3.362, d_loss 0.063\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 111/390 d_loss_real= 0.062, d_loss_fake= 0.041, g_loss 3.343, d_loss 0.051\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 112/390 d_loss_real= 0.015, d_loss_fake= 0.034, g_loss 3.529, d_loss 0.025\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 113/390 d_loss_real= 0.071, d_loss_fake= 0.030, g_loss 3.564, d_loss 0.051\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 114/390 d_loss_real= 0.052, d_loss_fake= 0.030, g_loss 3.519, d_loss 0.041\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 2 Batch 115/390 d_loss_real= 0.091, d_loss_fake= 0.034, g_loss 3.401, d_loss 0.063\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 116/390 d_loss_real= 0.106, d_loss_fake= 0.043, g_loss 3.146, d_loss 0.075\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 117/390 d_loss_real= 0.078, d_loss_fake= 0.058, g_loss 3.032, d_loss 0.068\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 118/390 d_loss_real= 0.022, d_loss_fake= 0.049, g_loss 3.245, d_loss 0.035\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 119/390 d_loss_real= 0.082, d_loss_fake= 0.041, g_loss 3.302, d_loss 0.062\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 120/390 d_loss_real= 0.019, d_loss_fake= 0.037, g_loss 3.386, d_loss 0.028\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 121/390 d_loss_real= 0.062, d_loss_fake= 0.035, g_loss 3.405, d_loss 0.049\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 122/390 d_loss_real= 0.030, d_loss_fake= 0.034, g_loss 3.411, d_loss 0.032\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 123/390 d_loss_real= 0.031, d_loss_fake= 0.035, g_loss 3.384, d_loss 0.033\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 124/390 d_loss_real= 0.064, d_loss_fake= 0.038, g_loss 3.340, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 125/390 d_loss_real= 0.010, d_loss_fake= 0.035, g_loss 3.478, d_loss 0.022\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 2 Batch 126/390 d_loss_real= 0.027, d_loss_fake= 0.030, g_loss 3.560, d_loss 0.029\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 127/390 d_loss_real= 0.054, d_loss_fake= 0.029, g_loss 3.595, d_loss 0.041\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 2 Batch 128/390 d_loss_real= 0.075, d_loss_fake= 0.030, g_loss 3.510, d_loss 0.052\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 129/390 d_loss_real= 0.023, d_loss_fake= 0.034, g_loss 3.467, d_loss 0.028\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 130/390 d_loss_real= 0.018, d_loss_fake= 0.032, g_loss 3.572, d_loss 0.025\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 131/390 d_loss_real= 0.061, d_loss_fake= 0.028, g_loss 3.626, d_loss 0.045\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 132/390 d_loss_real= 0.058, d_loss_fake= 0.029, g_loss 3.574, d_loss 0.044\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 133/390 d_loss_real= 0.017, d_loss_fake= 0.029, g_loss 3.607, d_loss 0.023\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 134/390 d_loss_real= 0.049, d_loss_fake= 0.028, g_loss 3.642, d_loss 0.038\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 2 Batch 135/390 d_loss_real= 0.009, d_loss_fake= 0.026, g_loss 3.711, d_loss 0.017\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 136/390 d_loss_real= 0.030, d_loss_fake= 0.025, g_loss 3.734, d_loss 0.027\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 137/390 d_loss_real= 0.127, d_loss_fake= 0.028, g_loss 3.566, d_loss 0.078\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 138/390 d_loss_real= 0.004, d_loss_fake= 0.032, g_loss 3.547, d_loss 0.018\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 2 Batch 139/390 d_loss_real= 0.036, d_loss_fake= 0.033, g_loss 3.509, d_loss 0.034\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 140/390 d_loss_real= 0.037, d_loss_fake= 0.052, g_loss 3.109, d_loss 0.044\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 141/390 d_loss_real= 0.013, d_loss_fake= 3.366, g_loss 0.614, d_loss 1.689\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 142/390 d_loss_real= 0.040, d_loss_fake= 0.123, g_loss 3.806, d_loss 0.082\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 2 Batch 143/390 d_loss_real= 0.606, d_loss_fake= 0.011, g_loss 4.932, d_loss 0.309\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 144/390 d_loss_real= 1.185, d_loss_fake= 0.007, g_loss 5.084, d_loss 0.596\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 2 Batch 145/390 d_loss_real= 1.226, d_loss_fake= 0.007, g_loss 4.845, d_loss 0.617\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 146/390 d_loss_real= 1.218, d_loss_fake= 0.011, g_loss 4.261, d_loss 0.614\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 147/390 d_loss_real= 0.708, d_loss_fake= 0.024, g_loss 3.187, d_loss 0.366\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 148/390 d_loss_real= 0.284, d_loss_fake= 0.110, g_loss 1.521, d_loss 0.197\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 149/390 d_loss_real= 0.032, d_loss_fake= 0.539, g_loss 1.092, d_loss 0.286\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 150/390 d_loss_real= 0.017, d_loss_fake= 0.342, g_loss 1.935, d_loss 0.180\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 151/390 d_loss_real= 0.026, d_loss_fake= 0.089, g_loss 2.968, d_loss 0.057\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 2 Batch 152/390 d_loss_real= 0.075, d_loss_fake= 0.040, g_loss 3.457, d_loss 0.057\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 153/390 d_loss_real= 0.145, d_loss_fake= 0.028, g_loss 3.689, d_loss 0.086\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 2 Batch 154/390 d_loss_real= 0.235, d_loss_fake= 0.025, g_loss 3.740, d_loss 0.130\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 2 Batch 155/390 d_loss_real= 0.160, d_loss_fake= 0.025, g_loss 3.676, d_loss 0.092\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 156/390 d_loss_real= 0.375, d_loss_fake= 0.029, g_loss 3.458, d_loss 0.202\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 157/390 d_loss_real= 0.171, d_loss_fake= 0.038, g_loss 3.124, d_loss 0.105\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 2 Batch 158/390 d_loss_real= 0.045, d_loss_fake= 0.060, g_loss 2.721, d_loss 0.052\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 159/390 d_loss_real= 0.115, d_loss_fake= 0.120, g_loss 2.115, d_loss 0.117\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 160/390 d_loss_real= 0.013, d_loss_fake= 0.426, g_loss 1.646, d_loss 0.220\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 161/390 d_loss_real= 0.033, d_loss_fake= 0.138, g_loss 2.593, d_loss 0.085\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 162/390 d_loss_real= 0.028, d_loss_fake= 0.057, g_loss 3.215, d_loss 0.042\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 163/390 d_loss_real= 0.090, d_loss_fake= 0.034, g_loss 3.590, d_loss 0.062\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 2 Batch 164/390 d_loss_real= 0.081, d_loss_fake= 0.025, g_loss 3.813, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 165/390 d_loss_real= 0.515, d_loss_fake= 0.022, g_loss 3.823, d_loss 0.269\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 166/390 d_loss_real= 0.219, d_loss_fake= 0.024, g_loss 3.705, d_loss 0.122\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 167/390 d_loss_real= 0.201, d_loss_fake= 0.028, g_loss 3.491, d_loss 0.115\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 168/390 d_loss_real= 0.167, d_loss_fake= 0.037, g_loss 3.198, d_loss 0.102\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 2 Batch 169/390 d_loss_real= 0.142, d_loss_fake= 0.052, g_loss 2.830, d_loss 0.097\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 170/390 d_loss_real= 0.145, d_loss_fake= 0.078, g_loss 2.442, d_loss 0.112\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 2 Batch 171/390 d_loss_real= 0.101, d_loss_fake= 0.114, g_loss 2.164, d_loss 0.107\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 2 Batch 172/390 d_loss_real= 0.041, d_loss_fake= 0.139, g_loss 2.118, d_loss 0.090\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 173/390 d_loss_real= 0.025, d_loss_fake= 0.124, g_loss 2.348, d_loss 0.074\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 2 Batch 174/390 d_loss_real= 0.043, d_loss_fake= 0.090, g_loss 2.634, d_loss 0.066\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 175/390 d_loss_real= 0.083, d_loss_fake= 0.068, g_loss 2.854, d_loss 0.075\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 2 Batch 176/390 d_loss_real= 0.016, d_loss_fake= 0.054, g_loss 3.063, d_loss 0.035\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 177/390 d_loss_real= 0.086, d_loss_fake= 0.045, g_loss 3.186, d_loss 0.066\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 178/390 d_loss_real= 0.180, d_loss_fake= 0.042, g_loss 3.221, d_loss 0.111\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 179/390 d_loss_real= 0.075, d_loss_fake= 0.041, g_loss 3.225, d_loss 0.058\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 180/390 d_loss_real= 0.048, d_loss_fake= 0.042, g_loss 3.197, d_loss 0.045\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 181/390 d_loss_real= 0.077, d_loss_fake= 0.044, g_loss 3.111, d_loss 0.061\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 182/390 d_loss_real= 0.092, d_loss_fake= 0.050, g_loss 2.971, d_loss 0.071\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 183/390 d_loss_real= 0.025, d_loss_fake= 0.057, g_loss 2.897, d_loss 0.041\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 184/390 d_loss_real= 0.062, d_loss_fake= 0.061, g_loss 2.858, d_loss 0.061\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 185/390 d_loss_real= 0.127, d_loss_fake= 0.061, g_loss 2.908, d_loss 0.094\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 186/390 d_loss_real= 0.011, d_loss_fake= 0.053, g_loss 3.085, d_loss 0.032\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 187/390 d_loss_real= 0.037, d_loss_fake= 0.044, g_loss 3.224, d_loss 0.040\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 2 Batch 188/390 d_loss_real= 0.051, d_loss_fake= 0.040, g_loss 3.298, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 189/390 d_loss_real= 0.011, d_loss_fake= 0.037, g_loss 3.360, d_loss 0.024\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 2 Batch 190/390 d_loss_real= 0.031, d_loss_fake= 0.035, g_loss 3.386, d_loss 0.033\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 191/390 d_loss_real= 0.033, d_loss_fake= 0.035, g_loss 3.394, d_loss 0.034\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 2 Batch 192/390 d_loss_real= 0.032, d_loss_fake= 0.035, g_loss 3.367, d_loss 0.034\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 193/390 d_loss_real= 0.093, d_loss_fake= 0.038, g_loss 3.271, d_loss 0.066\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 194/390 d_loss_real= 0.014, d_loss_fake= 0.040, g_loss 3.276, d_loss 0.027\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 195/390 d_loss_real= 0.089, d_loss_fake= 0.043, g_loss 3.181, d_loss 0.066\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 2 Batch 196/390 d_loss_real= 0.078, d_loss_fake= 0.049, g_loss 3.060, d_loss 0.063\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 2 Batch 197/390 d_loss_real= 0.010, d_loss_fake= 0.049, g_loss 3.174, d_loss 0.029\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 198/390 d_loss_real= 0.025, d_loss_fake= 0.040, g_loss 3.351, d_loss 0.033\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 2 Batch 199/390 d_loss_real= 0.024, d_loss_fake= 0.034, g_loss 3.475, d_loss 0.029\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 200/390 d_loss_real= 0.078, d_loss_fake= 0.031, g_loss 3.511, d_loss 0.055\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 201/390 d_loss_real= 0.029, d_loss_fake= 0.030, g_loss 3.522, d_loss 0.030\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 202/390 d_loss_real= 0.035, d_loss_fake= 0.031, g_loss 3.503, d_loss 0.033\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 203/390 d_loss_real= 0.114, d_loss_fake= 0.034, g_loss 3.366, d_loss 0.074\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 204/390 d_loss_real= 0.023, d_loss_fake= 0.039, g_loss 3.310, d_loss 0.031\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 205/390 d_loss_real= 0.098, d_loss_fake= 0.042, g_loss 3.235, d_loss 0.070\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 206/390 d_loss_real= 0.058, d_loss_fake= 0.046, g_loss 3.183, d_loss 0.052\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 207/390 d_loss_real= 0.107, d_loss_fake= 0.049, g_loss 3.104, d_loss 0.078\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 208/390 d_loss_real= 0.030, d_loss_fake= 0.047, g_loss 3.201, d_loss 0.039\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 2 Batch 209/390 d_loss_real= 0.016, d_loss_fake= 0.039, g_loss 3.368, d_loss 0.027\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 210/390 d_loss_real= 0.014, d_loss_fake= 0.033, g_loss 3.509, d_loss 0.023\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 211/390 d_loss_real= 0.044, d_loss_fake= 0.029, g_loss 3.583, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 212/390 d_loss_real= 0.182, d_loss_fake= 0.030, g_loss 3.471, d_loss 0.106\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 213/390 d_loss_real= 0.009, d_loss_fake= 0.034, g_loss 3.389, d_loss 0.021\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 214/390 d_loss_real= 0.013, d_loss_fake= 0.036, g_loss 3.371, d_loss 0.024\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 215/390 d_loss_real= 0.067, d_loss_fake= 0.038, g_loss 3.321, d_loss 0.053\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 2 Batch 216/390 d_loss_real= 0.014, d_loss_fake= 0.037, g_loss 3.431, d_loss 0.026\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 2 Batch 217/390 d_loss_real= 0.025, d_loss_fake= 0.032, g_loss 3.531, d_loss 0.028\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 2 Batch 218/390 d_loss_real= 0.011, d_loss_fake= 0.029, g_loss 3.613, d_loss 0.020\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 219/390 d_loss_real= 0.007, d_loss_fake= 0.026, g_loss 3.691, d_loss 0.017\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 220/390 d_loss_real= 0.002, d_loss_fake= 0.024, g_loss 3.771, d_loss 0.013\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 221/390 d_loss_real= 0.011, d_loss_fake= 0.023, g_loss 3.829, d_loss 0.017\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 222/390 d_loss_real= 0.094, d_loss_fake= 0.022, g_loss 3.801, d_loss 0.058\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 223/390 d_loss_real= 0.006, d_loss_fake= 0.023, g_loss 3.776, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 224/390 d_loss_real= 0.163, d_loss_fake= 0.030, g_loss 3.294, d_loss 0.096\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 225/390 d_loss_real= 0.002, d_loss_fake= 0.047, g_loss 3.171, d_loss 0.025\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 226/390 d_loss_real= 0.007, d_loss_fake= 0.041, g_loss 3.504, d_loss 0.024\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 227/390 d_loss_real= 0.014, d_loss_fake= 0.026, g_loss 3.766, d_loss 0.020\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 228/390 d_loss_real= 0.004, d_loss_fake= 0.022, g_loss 3.874, d_loss 0.013\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 229/390 d_loss_real= 0.033, d_loss_fake= 0.022, g_loss 3.868, d_loss 0.028\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 230/390 d_loss_real= 0.003, d_loss_fake= 0.128, g_loss 2.563, d_loss 0.065\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 2 Batch 231/390 d_loss_real= 0.041, d_loss_fake= 0.909, g_loss 1.921, d_loss 0.475\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 232/390 d_loss_real= 0.034, d_loss_fake= 0.045, g_loss 3.904, d_loss 0.039\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 233/390 d_loss_real= 0.584, d_loss_fake= 0.019, g_loss 4.278, d_loss 0.301\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 234/390 d_loss_real= 0.795, d_loss_fake= 0.183, g_loss 2.285, d_loss 0.489\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 235/390 d_loss_real= 0.859, d_loss_fake= 4.398, g_loss 0.091, d_loss 2.628\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 236/390 d_loss_real= 0.618, d_loss_fake= 1.019, g_loss 1.816, d_loss 0.818\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 237/390 d_loss_real= 0.940, d_loss_fake= 0.070, g_loss 3.256, d_loss 0.505\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 238/390 d_loss_real= 0.733, d_loss_fake= 0.027, g_loss 3.903, d_loss 0.380\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 2 Batch 239/390 d_loss_real= 0.806, d_loss_fake= 0.017, g_loss 4.225, d_loss 0.412\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 240/390 d_loss_real= 0.290, d_loss_fake= 0.014, g_loss 4.374, d_loss 0.152\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 241/390 d_loss_real= 0.072, d_loss_fake= 0.012, g_loss 4.469, d_loss 0.042\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 242/390 d_loss_real= 0.024, d_loss_fake= 0.011, g_loss 4.534, d_loss 0.018\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 2 Batch 243/390 d_loss_real= 0.025, d_loss_fake= 0.011, g_loss 4.578, d_loss 0.018\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 244/390 d_loss_real= 0.001, d_loss_fake= 0.010, g_loss 4.616, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 245/390 d_loss_real= 0.001, d_loss_fake= 0.010, g_loss 4.649, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 246/390 d_loss_real= 0.000, d_loss_fake= 0.009, g_loss 4.679, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 247/390 d_loss_real= 0.000, d_loss_fake= 0.009, g_loss 4.707, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 248/390 d_loss_real= 0.000, d_loss_fake= 0.009, g_loss 4.733, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 249/390 d_loss_real= 0.000, d_loss_fake= 0.009, g_loss 4.758, d_loss 0.004\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 2 Batch 250/390 d_loss_real= 0.000, d_loss_fake= 0.009, g_loss 4.782, d_loss 0.004\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 251/390 d_loss_real= 0.000, d_loss_fake= 0.008, g_loss 4.805, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 252/390 d_loss_real= 0.000, d_loss_fake= 0.008, g_loss 4.827, d_loss 0.004\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 2 Batch 253/390 d_loss_real= 0.000, d_loss_fake= 0.008, g_loss 4.848, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 254/390 d_loss_real= 0.000, d_loss_fake= 0.008, g_loss 4.869, d_loss 0.004\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 255/390 d_loss_real= 0.000, d_loss_fake= 0.008, g_loss 4.889, d_loss 0.004\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 2 Batch 256/390 d_loss_real= 0.000, d_loss_fake= 0.007, g_loss 4.908, d_loss 0.004\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 257/390 d_loss_real= 0.000, d_loss_fake= 0.007, g_loss 4.927, d_loss 0.004\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 2 Batch 258/390 d_loss_real= 0.000, d_loss_fake= 0.007, g_loss 4.943, d_loss 0.004\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 2 Batch 259/390 d_loss_real= 0.000, d_loss_fake= 0.007, g_loss 4.952, d_loss 0.004\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 260/390 d_loss_real= 0.000, d_loss_fake= 0.007, g_loss 4.940, d_loss 0.004\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 261/390 d_loss_real= 0.000, d_loss_fake= 0.007, g_loss 4.930, d_loss 0.004\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 262/390 d_loss_real= 0.000, d_loss_fake= 0.007, g_loss 4.926, d_loss 0.004\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 263/390 d_loss_real= 0.000, d_loss_fake= 0.007, g_loss 4.929, d_loss 0.004\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 2 Batch 264/390 d_loss_real= 0.000, d_loss_fake= 0.036, g_loss 3.455, d_loss 0.018\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 265/390 d_loss_real= 0.000, d_loss_fake= 22.152, g_loss 0.000, d_loss 11.076\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 2 Batch 266/390 d_loss_real= 0.000, d_loss_fake= 27.498, g_loss 0.000, d_loss 13.749\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 267/390 d_loss_real= 0.000, d_loss_fake= 25.874, g_loss 0.000, d_loss 12.937\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 268/390 d_loss_real= 0.001, d_loss_fake= 16.455, g_loss 0.000, d_loss 8.228\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 269/390 d_loss_real= 0.018, d_loss_fake= 8.149, g_loss 0.010, d_loss 4.084\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 270/390 d_loss_real= 0.106, d_loss_fake= 2.069, g_loss 0.768, d_loss 1.088\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 271/390 d_loss_real= 0.324, d_loss_fake= 0.229, g_loss 2.500, d_loss 0.277\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 2 Batch 272/390 d_loss_real= 0.383, d_loss_fake= 0.036, g_loss 4.044, d_loss 0.209\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 273/390 d_loss_real= 0.629, d_loss_fake= 0.011, g_loss 4.975, d_loss 0.320\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 2 Batch 274/390 d_loss_real= 0.490, d_loss_fake= 0.005, g_loss 5.522, d_loss 0.247\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 275/390 d_loss_real= 0.476, d_loss_fake= 0.003, g_loss 5.859, d_loss 0.240\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 2 Batch 276/390 d_loss_real= 0.249, d_loss_fake= 0.003, g_loss 6.016, d_loss 0.126\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 277/390 d_loss_real= 0.277, d_loss_fake= 0.003, g_loss 6.032, d_loss 0.140\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 278/390 d_loss_real= 0.173, d_loss_fake= 0.002, g_loss 6.077, d_loss 0.088\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 2 Batch 279/390 d_loss_real= 0.116, d_loss_fake= 0.002, g_loss 6.132, d_loss 0.059\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 280/390 d_loss_real= 0.044, d_loss_fake= 0.002, g_loss 6.182, d_loss 0.023\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 281/390 d_loss_real= 0.058, d_loss_fake= 0.002, g_loss 6.209, d_loss 0.030\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 2 Batch 282/390 d_loss_real= 0.044, d_loss_fake= 0.002, g_loss 6.263, d_loss 0.023\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 283/390 d_loss_real= 0.032, d_loss_fake= 0.002, g_loss 6.276, d_loss 0.017\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 284/390 d_loss_real= 0.039, d_loss_fake= 0.002, g_loss 6.290, d_loss 0.020\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 2 Batch 285/390 d_loss_real= 0.046, d_loss_fake= 0.002, g_loss 6.275, d_loss 0.024\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 286/390 d_loss_real= 0.035, d_loss_fake= 0.002, g_loss 6.258, d_loss 0.018\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 2 Batch 287/390 d_loss_real= 0.034, d_loss_fake= 0.002, g_loss 6.261, d_loss 0.018\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 288/390 d_loss_real= 0.015, d_loss_fake= 0.002, g_loss 6.281, d_loss 0.008\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 289/390 d_loss_real= 0.018, d_loss_fake= 0.002, g_loss 6.282, d_loss 0.010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 2 Batch 290/390 d_loss_real= 0.012, d_loss_fake= 0.002, g_loss 6.264, d_loss 0.007\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 2 Batch 291/390 d_loss_real= 0.009, d_loss_fake= 0.002, g_loss 6.268, d_loss 0.006\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 2 Batch 292/390 d_loss_real= 0.023, d_loss_fake= 0.002, g_loss 6.292, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 293/390 d_loss_real= 0.014, d_loss_fake= 0.002, g_loss 6.338, d_loss 0.008\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 2 Batch 294/390 d_loss_real= 0.042, d_loss_fake= 0.002, g_loss 6.356, d_loss 0.022\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 2 Batch 295/390 d_loss_real= 0.014, d_loss_fake= 0.002, g_loss 6.352, d_loss 0.008\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 296/390 d_loss_real= 0.006, d_loss_fake= 0.002, g_loss 6.349, d_loss 0.004\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 2 Batch 297/390 d_loss_real= 0.029, d_loss_fake= 0.002, g_loss 6.348, d_loss 0.015\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 298/390 d_loss_real= 0.015, d_loss_fake= 0.002, g_loss 6.349, d_loss 0.008\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 299/390 d_loss_real= 0.008, d_loss_fake= 0.002, g_loss 6.352, d_loss 0.005\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 300/390 d_loss_real= 0.007, d_loss_fake= 0.002, g_loss 6.355, d_loss 0.004\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 301/390 d_loss_real= 0.010, d_loss_fake= 0.002, g_loss 6.354, d_loss 0.006\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 302/390 d_loss_real= 0.012, d_loss_fake= 0.002, g_loss 6.340, d_loss 0.007\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 2 Batch 303/390 d_loss_real= 0.005, d_loss_fake= 0.002, g_loss 6.354, d_loss 0.004\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 2 Batch 304/390 d_loss_real= 0.026, d_loss_fake= 0.002, g_loss 6.336, d_loss 0.014\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 2 Batch 305/390 d_loss_real= 0.007, d_loss_fake= 0.002, g_loss 6.329, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 306/390 d_loss_real= 0.009, d_loss_fake= 0.002, g_loss 6.328, d_loss 0.005\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 2 Batch 307/390 d_loss_real= 0.005, d_loss_fake= 0.002, g_loss 6.338, d_loss 0.003\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 308/390 d_loss_real= 0.009, d_loss_fake= 0.002, g_loss 6.335, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 309/390 d_loss_real= 0.014, d_loss_fake= 0.002, g_loss 6.336, d_loss 0.008\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 2 Batch 310/390 d_loss_real= 0.008, d_loss_fake= 0.002, g_loss 6.341, d_loss 0.005\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 311/390 d_loss_real= 0.017, d_loss_fake= 0.002, g_loss 6.346, d_loss 0.009\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 312/390 d_loss_real= 0.015, d_loss_fake= 0.002, g_loss 6.352, d_loss 0.008\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 2 Batch 313/390 d_loss_real= 0.020, d_loss_fake= 0.002, g_loss 6.361, d_loss 0.011\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 2 Batch 314/390 d_loss_real= 0.007, d_loss_fake= 0.002, g_loss 6.369, d_loss 0.004\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 315/390 d_loss_real= 0.011, d_loss_fake= 0.002, g_loss 6.396, d_loss 0.006\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 2 Batch 316/390 d_loss_real= 0.007, d_loss_fake= 0.002, g_loss 6.376, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 317/390 d_loss_real= 0.006, d_loss_fake= 0.002, g_loss 6.437, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 318/390 d_loss_real= 0.006, d_loss_fake= 0.002, g_loss 6.455, d_loss 0.004\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 2 Batch 319/390 d_loss_real= 0.009, d_loss_fake= 0.002, g_loss 6.478, d_loss 0.005\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 320/390 d_loss_real= 0.015, d_loss_fake= 0.002, g_loss 6.490, d_loss 0.008\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 321/390 d_loss_real= 0.006, d_loss_fake= 0.002, g_loss 6.492, d_loss 0.004\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 2 Batch 322/390 d_loss_real= 0.009, d_loss_fake= 0.002, g_loss 6.493, d_loss 0.005\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 323/390 d_loss_real= 0.011, d_loss_fake= 0.002, g_loss 6.494, d_loss 0.006\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 2 Batch 324/390 d_loss_real= 0.009, d_loss_fake= 0.002, g_loss 6.497, d_loss 0.005\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 325/390 d_loss_real= 0.006, d_loss_fake= 0.002, g_loss 6.502, d_loss 0.004\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 2 Batch 326/390 d_loss_real= 0.005, d_loss_fake= 0.001, g_loss 6.507, d_loss 0.003\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 327/390 d_loss_real= 0.006, d_loss_fake= 0.001, g_loss 6.512, d_loss 0.004\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 2 Batch 328/390 d_loss_real= 0.007, d_loss_fake= 0.001, g_loss 6.512, d_loss 0.004\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 2 Batch 329/390 d_loss_real= 0.005, d_loss_fake= 0.002, g_loss 6.492, d_loss 0.003\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 2 Batch 330/390 d_loss_real= 0.007, d_loss_fake= 0.002, g_loss 6.485, d_loss 0.004\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 2 Batch 331/390 d_loss_real= 0.003, d_loss_fake= 0.002, g_loss 6.471, d_loss 0.002\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 2 Batch 332/390 d_loss_real= 0.010, d_loss_fake= 0.002, g_loss 6.480, d_loss 0.006\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 333/390 d_loss_real= 0.004, d_loss_fake= 0.002, g_loss 6.490, d_loss 0.003\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 334/390 d_loss_real= 0.005, d_loss_fake= 0.002, g_loss 6.503, d_loss 0.003\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 2 Batch 335/390 d_loss_real= 0.008, d_loss_fake= 0.002, g_loss 6.503, d_loss 0.005\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 2 Batch 336/390 d_loss_real= 0.007, d_loss_fake= 0.001, g_loss 6.510, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 337/390 d_loss_real= 0.006, d_loss_fake= 0.001, g_loss 6.514, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 338/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 6.526, d_loss 0.002\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 339/390 d_loss_real= 0.021, d_loss_fake= 0.001, g_loss 6.530, d_loss 0.011\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 340/390 d_loss_real= 0.006, d_loss_fake= 0.001, g_loss 6.543, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 341/390 d_loss_real= 0.005, d_loss_fake= 0.001, g_loss 6.539, d_loss 0.003\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 2 Batch 342/390 d_loss_real= 0.007, d_loss_fake= 0.001, g_loss 6.547, d_loss 0.004\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 2 Batch 343/390 d_loss_real= 0.003, d_loss_fake= 0.001, g_loss 6.551, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 344/390 d_loss_real= 0.004, d_loss_fake= 0.001, g_loss 6.558, d_loss 0.003\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 2 Batch 345/390 d_loss_real= 0.006, d_loss_fake= 0.001, g_loss 6.566, d_loss 0.004\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 346/390 d_loss_real= 0.007, d_loss_fake= 0.001, g_loss 6.573, d_loss 0.004\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 2 Batch 347/390 d_loss_real= 0.007, d_loss_fake= 0.001, g_loss 6.579, d_loss 0.004\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 2 Batch 348/390 d_loss_real= 0.007, d_loss_fake= 0.001, g_loss 6.586, d_loss 0.004\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 2 Batch 349/390 d_loss_real= 0.009, d_loss_fake= 0.001, g_loss 6.594, d_loss 0.005\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 2 Batch 350/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 6.600, d_loss 0.001\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 2 Batch 351/390 d_loss_real= 0.013, d_loss_fake= 0.001, g_loss 6.606, d_loss 0.007\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 2 Batch 352/390 d_loss_real= 0.009, d_loss_fake= 0.001, g_loss 6.612, d_loss 0.005\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 2 Batch 353/390 d_loss_real= 0.006, d_loss_fake= 0.001, g_loss 6.619, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 354/390 d_loss_real= 0.004, d_loss_fake= 0.001, g_loss 6.625, d_loss 0.003\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 2 Batch 355/390 d_loss_real= 0.003, d_loss_fake= 0.001, g_loss 6.631, d_loss 0.002\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 2 Batch 356/390 d_loss_real= 0.008, d_loss_fake= 0.001, g_loss 6.640, d_loss 0.004\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 2 Batch 357/390 d_loss_real= 0.003, d_loss_fake= 0.001, g_loss 6.647, d_loss 0.002\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 2 Batch 358/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 6.655, d_loss 0.001\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 2 Batch 359/390 d_loss_real= 0.004, d_loss_fake= 0.001, g_loss 6.662, d_loss 0.003\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 2 Batch 360/390 d_loss_real= 0.006, d_loss_fake= 0.001, g_loss 6.669, d_loss 0.004\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 2 Batch 361/390 d_loss_real= 0.005, d_loss_fake= 0.001, g_loss 6.675, d_loss 0.003\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 362/390 d_loss_real= 0.004, d_loss_fake= 0.001, g_loss 6.682, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 363/390 d_loss_real= 0.004, d_loss_fake= 0.001, g_loss 6.688, d_loss 0.003\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 2 Batch 364/390 d_loss_real= 0.004, d_loss_fake= 0.001, g_loss 6.696, d_loss 0.003\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 365/390 d_loss_real= 0.018, d_loss_fake= 0.001, g_loss 6.702, d_loss 0.010\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 366/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 6.708, d_loss 0.002\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 2 Batch 367/390 d_loss_real= 0.004, d_loss_fake= 0.001, g_loss 6.712, d_loss 0.003\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 368/390 d_loss_real= 0.011, d_loss_fake= 0.001, g_loss 6.718, d_loss 0.006\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 369/390 d_loss_real= 0.003, d_loss_fake= 0.001, g_loss 6.724, d_loss 0.002\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 2 Batch 370/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 6.731, d_loss 0.002\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 2 Batch 371/390 d_loss_real= 0.032, d_loss_fake= 0.001, g_loss 6.734, d_loss 0.017\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 372/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 6.739, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 373/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 6.744, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 374/390 d_loss_real= 0.006, d_loss_fake= 0.001, g_loss 6.748, d_loss 0.004\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 2 Batch 375/390 d_loss_real= 0.007, d_loss_fake= 0.001, g_loss 6.753, d_loss 0.004\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 376/390 d_loss_real= 0.005, d_loss_fake= 0.001, g_loss 6.757, d_loss 0.003\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 377/390 d_loss_real= 0.003, d_loss_fake= 0.001, g_loss 6.762, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2 Batch 378/390 d_loss_real= 0.003, d_loss_fake= 0.001, g_loss 6.768, d_loss 0.002\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 2 Batch 379/390 d_loss_real= 0.004, d_loss_fake= 0.001, g_loss 6.776, d_loss 0.003\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 2 Batch 380/390 d_loss_real= 0.005, d_loss_fake= 0.001, g_loss 6.780, d_loss 0.003\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 381/390 d_loss_real= 0.005, d_loss_fake= 0.001, g_loss 6.785, d_loss 0.003\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 382/390 d_loss_real= 0.010, d_loss_fake= 0.001, g_loss 6.792, d_loss 0.005\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 383/390 d_loss_real= 0.003, d_loss_fake= 0.001, g_loss 6.796, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2 Batch 384/390 d_loss_real= 0.017, d_loss_fake= 0.001, g_loss 6.802, d_loss 0.009\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 385/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 6.805, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 386/390 d_loss_real= 0.008, d_loss_fake= 0.001, g_loss 6.813, d_loss 0.005\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 2 Batch 387/390 d_loss_real= 0.021, d_loss_fake= 0.001, g_loss 6.815, d_loss 0.011\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 388/390 d_loss_real= 0.007, d_loss_fake= 0.001, g_loss 6.820, d_loss 0.004\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2 Batch 389/390 d_loss_real= 0.006, d_loss_fake= 0.001, g_loss 6.823, d_loss 0.004\n",
            "2/2 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 Batch 390/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 6.825, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 1/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 6.827, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 2/390 d_loss_real= 0.003, d_loss_fake= 0.001, g_loss 6.831, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 3/390 d_loss_real= 0.004, d_loss_fake= 0.001, g_loss 6.837, d_loss 0.003\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 4/390 d_loss_real= 0.005, d_loss_fake= 0.001, g_loss 6.842, d_loss 0.003\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 5/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 6.848, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 6/390 d_loss_real= 0.003, d_loss_fake= 0.001, g_loss 6.852, d_loss 0.002\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 7/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 6.860, d_loss 0.002\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 3 Batch 8/390 d_loss_real= 0.006, d_loss_fake= 0.001, g_loss 6.865, d_loss 0.004\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 9/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 6.881, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 3 Batch 10/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 6.877, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 11/390 d_loss_real= 0.005, d_loss_fake= 0.001, g_loss 6.888, d_loss 0.003\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 12/390 d_loss_real= 0.003, d_loss_fake= 0.001, g_loss 6.888, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 13/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 6.899, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 14/390 d_loss_real= 0.006, d_loss_fake= 0.001, g_loss 6.901, d_loss 0.003\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 15/390 d_loss_real= 0.004, d_loss_fake= 0.001, g_loss 6.917, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 16/390 d_loss_real= 0.005, d_loss_fake= 0.001, g_loss 6.911, d_loss 0.003\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 17/390 d_loss_real= 0.003, d_loss_fake= 0.001, g_loss 6.918, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 18/390 d_loss_real= 0.003, d_loss_fake= 0.001, g_loss 6.921, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 19/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 6.931, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 20/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 6.936, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 21/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 6.960, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 3 Batch 22/390 d_loss_real= 0.017, d_loss_fake= 0.001, g_loss 6.948, d_loss 0.009\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 23/390 d_loss_real= 0.003, d_loss_fake= 0.001, g_loss 6.966, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 24/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 6.956, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 25/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 6.960, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 3 Batch 26/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 6.965, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 27/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 6.970, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 28/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 6.978, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 29/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 6.989, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 3 Batch 30/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.000, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 31/390 d_loss_real= 0.004, d_loss_fake= 0.001, g_loss 7.053, d_loss 0.003\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 3 Batch 32/390 d_loss_real= 0.005, d_loss_fake= 0.001, g_loss 7.020, d_loss 0.003\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 33/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.092, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 34/390 d_loss_real= 0.013, d_loss_fake= 0.001, g_loss 7.087, d_loss 0.007\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 35/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.064, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 36/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.097, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 37/390 d_loss_real= 0.004, d_loss_fake= 0.001, g_loss 7.068, d_loss 0.003\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 3 Batch 38/390 d_loss_real= 0.008, d_loss_fake= 0.001, g_loss 7.047, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 39/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.049, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 40/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.061, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 41/390 d_loss_real= 0.009, d_loss_fake= 0.001, g_loss 7.040, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 42/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.056, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 43/390 d_loss_real= 0.003, d_loss_fake= 0.001, g_loss 7.065, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 44/390 d_loss_real= 0.004, d_loss_fake= 0.001, g_loss 7.051, d_loss 0.002\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 3 Batch 45/390 d_loss_real= 0.007, d_loss_fake= 0.001, g_loss 7.067, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 46/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.071, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 47/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.069, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 48/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.074, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 49/390 d_loss_real= 0.010, d_loss_fake= 0.001, g_loss 7.075, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 50/390 d_loss_real= 0.006, d_loss_fake= 0.001, g_loss 7.078, d_loss 0.004\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 51/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.082, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 52/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.085, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 3 Batch 53/390 d_loss_real= 0.003, d_loss_fake= 0.001, g_loss 7.090, d_loss 0.002\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 3 Batch 54/390 d_loss_real= 0.003, d_loss_fake= 0.001, g_loss 7.094, d_loss 0.002\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 3 Batch 55/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.098, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 56/390 d_loss_real= 0.003, d_loss_fake= 0.001, g_loss 7.103, d_loss 0.002\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 57/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.109, d_loss 0.002\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 58/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.114, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 3 Batch 59/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.119, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 60/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.124, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 61/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.130, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 62/390 d_loss_real= 0.003, d_loss_fake= 0.001, g_loss 7.135, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 63/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.140, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 64/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.144, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 65/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.147, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 66/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.150, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 3 Batch 67/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 7.154, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 3 Batch 68/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.158, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 69/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.162, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 70/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.167, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 71/390 d_loss_real= 0.005, d_loss_fake= 0.001, g_loss 7.171, d_loss 0.003\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 72/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.176, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 73/390 d_loss_real= 0.005, d_loss_fake= 0.001, g_loss 7.180, d_loss 0.003\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 74/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.185, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 75/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.191, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 3 Batch 76/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.196, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 3 Batch 77/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.201, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 78/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.207, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 79/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.212, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 80/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.218, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 81/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.223, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 82/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.229, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 83/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.235, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 84/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.241, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 85/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.247, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 86/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.252, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 87/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.258, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 88/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.264, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 89/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.269, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 3 Batch 90/390 d_loss_real= 0.007, d_loss_fake= 0.001, g_loss 7.274, d_loss 0.004\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 91/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.278, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 92/390 d_loss_real= 0.004, d_loss_fake= 0.001, g_loss 7.283, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 93/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.287, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 94/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.291, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 95/390 d_loss_real= 0.006, d_loss_fake= 0.001, g_loss 7.294, d_loss 0.003\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 96/390 d_loss_real= 0.004, d_loss_fake= 0.001, g_loss 7.296, d_loss 0.003\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 97/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.296, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 98/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.294, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 99/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 7.291, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 100/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.290, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 101/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.292, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 102/390 d_loss_real= 0.004, d_loss_fake= 0.001, g_loss 7.295, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 103/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.300, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 3 Batch 104/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.305, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 105/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 7.310, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 3 Batch 106/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.316, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 107/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.320, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 108/390 d_loss_real= 0.004, d_loss_fake= 0.001, g_loss 7.324, d_loss 0.003\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 109/390 d_loss_real= 0.004, d_loss_fake= 0.001, g_loss 7.328, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 110/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 7.332, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 111/390 d_loss_real= 0.007, d_loss_fake= 0.001, g_loss 7.334, d_loss 0.004\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 112/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.336, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 113/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.334, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 114/390 d_loss_real= 0.003, d_loss_fake= 0.001, g_loss 7.330, d_loss 0.002\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 3 Batch 115/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.327, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 116/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.331, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 117/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.335, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 118/390 d_loss_real= 0.007, d_loss_fake= 0.001, g_loss 7.339, d_loss 0.004\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 119/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 7.344, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 120/390 d_loss_real= 0.005, d_loss_fake= 0.001, g_loss 7.348, d_loss 0.003\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 121/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.353, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 122/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.358, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 123/390 d_loss_real= 0.004, d_loss_fake= 0.001, g_loss 7.362, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 124/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 7.367, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 125/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.373, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 126/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.378, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 127/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.383, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 3 Batch 128/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.388, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 129/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.394, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 130/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.399, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 131/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.405, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 132/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.410, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 133/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.415, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 134/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.421, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 135/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.426, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 136/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 7.431, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 137/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 7.437, d_loss 0.000\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 138/390 d_loss_real= 0.006, d_loss_fake= 0.001, g_loss 7.442, d_loss 0.003\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 3 Batch 139/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 7.447, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 140/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 7.452, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 141/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.458, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 142/390 d_loss_real= 0.003, d_loss_fake= 0.001, g_loss 7.463, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 143/390 d_loss_real= 0.008, d_loss_fake= 0.001, g_loss 7.466, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 144/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.470, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 145/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 7.473, d_loss 0.000\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 3 Batch 146/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.477, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 147/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.482, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 148/390 d_loss_real= 0.007, d_loss_fake= 0.001, g_loss 7.484, d_loss 0.004\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 3 Batch 149/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.487, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 150/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.490, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 151/390 d_loss_real= 0.006, d_loss_fake= 0.001, g_loss 7.492, d_loss 0.003\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 152/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.495, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 153/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.499, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 154/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.503, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 155/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.507, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 156/390 d_loss_real= 0.003, d_loss_fake= 0.001, g_loss 7.511, d_loss 0.002\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 157/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.516, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 3 Batch 158/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.521, d_loss 0.001\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 3 Batch 159/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.525, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 160/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 7.530, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 161/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.534, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 162/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.539, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 163/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.544, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 164/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.549, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 165/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.553, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 166/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 7.558, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 167/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 7.561, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 168/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.564, d_loss 0.001\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 3 Batch 169/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 7.561, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 170/390 d_loss_real= 0.007, d_loss_fake= 0.001, g_loss 7.560, d_loss 0.004\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 3 Batch 171/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.562, d_loss 0.001\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 3 Batch 172/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.566, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 173/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.571, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 174/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.575, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 175/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.580, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 176/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.585, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 177/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.589, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 178/390 d_loss_real= 0.005, d_loss_fake= 0.001, g_loss 7.593, d_loss 0.003\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 179/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.597, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 180/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 7.601, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 181/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.605, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 182/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.610, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 183/390 d_loss_real= 0.007, d_loss_fake= 0.000, g_loss 7.612, d_loss 0.004\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 184/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.616, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 185/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.619, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 186/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.623, d_loss 0.000\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 187/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.627, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 188/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.631, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 189/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.637, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 190/390 d_loss_real= 0.002, d_loss_fake= 0.000, g_loss 7.642, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 191/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.644, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 192/390 d_loss_real= 0.002, d_loss_fake= 0.000, g_loss 7.649, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 193/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.655, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 194/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.657, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 195/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.662, d_loss 0.000\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 196/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.667, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 197/390 d_loss_real= 0.002, d_loss_fake= 0.000, g_loss 7.671, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 198/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.676, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 199/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.680, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 200/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.685, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 201/390 d_loss_real= 0.002, d_loss_fake= 0.000, g_loss 7.689, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 202/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.694, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 203/390 d_loss_real= 0.003, d_loss_fake= 0.000, g_loss 7.698, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 204/390 d_loss_real= 0.003, d_loss_fake= 0.000, g_loss 7.702, d_loss 0.002\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 3 Batch 205/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.706, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 3 Batch 206/390 d_loss_real= 0.002, d_loss_fake= 0.000, g_loss 7.711, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 207/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.716, d_loss 0.001\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 3 Batch 208/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.719, d_loss 0.000\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 209/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.723, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 210/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.728, d_loss 0.000\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 211/390 d_loss_real= 0.004, d_loss_fake= 0.000, g_loss 7.732, d_loss 0.002\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 212/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.737, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 213/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.741, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 214/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.746, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 215/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.751, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 3 Batch 216/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.756, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 217/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.761, d_loss 0.000\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 218/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.764, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 219/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.768, d_loss 0.001\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 3 Batch 220/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.773, d_loss 0.000\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 3 Batch 221/390 d_loss_real= 0.008, d_loss_fake= 0.000, g_loss 7.777, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 222/390 d_loss_real= 0.004, d_loss_fake= 0.000, g_loss 7.780, d_loss 0.002\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 3 Batch 223/390 d_loss_real= 0.002, d_loss_fake= 0.000, g_loss 7.784, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 224/390 d_loss_real= 0.003, d_loss_fake= 0.000, g_loss 7.787, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 225/390 d_loss_real= 0.002, d_loss_fake= 0.000, g_loss 7.791, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 226/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.796, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 227/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.799, d_loss 0.000\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 228/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.802, d_loss 0.001\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 3 Batch 229/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.806, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 230/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.810, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 231/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.814, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 232/390 d_loss_real= 0.002, d_loss_fake= 0.000, g_loss 7.819, d_loss 0.001\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 3 Batch 233/390 d_loss_real= 0.005, d_loss_fake= 0.000, g_loss 7.823, d_loss 0.003\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 234/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.827, d_loss 0.001\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 3 Batch 235/390 d_loss_real= 0.003, d_loss_fake= 0.000, g_loss 7.829, d_loss 0.002\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 236/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.832, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 237/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.835, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 238/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.838, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 239/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.841, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 240/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.845, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 241/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.849, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 242/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.853, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 243/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.857, d_loss 0.000\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 244/390 d_loss_real= 0.006, d_loss_fake= 0.000, g_loss 7.861, d_loss 0.003\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 245/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.863, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 246/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.866, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 247/390 d_loss_real= 0.002, d_loss_fake= 0.000, g_loss 7.869, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 248/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.872, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 249/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.876, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 250/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.880, d_loss 0.000\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 251/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.884, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 252/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.888, d_loss 0.000\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 3 Batch 253/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.892, d_loss 0.000\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 3 Batch 254/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.898, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 255/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.901, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 256/390 d_loss_real= 0.002, d_loss_fake= 0.000, g_loss 7.905, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 257/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.908, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 258/390 d_loss_real= 0.004, d_loss_fake= 0.000, g_loss 7.912, d_loss 0.002\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 259/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.916, d_loss 0.000\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 260/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.920, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 261/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.924, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 262/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.929, d_loss 0.000\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 3 Batch 263/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.934, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 264/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.936, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 265/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.940, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 266/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.944, d_loss 0.000\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 267/390 d_loss_real= 0.003, d_loss_fake= 0.000, g_loss 7.947, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 268/390 d_loss_real= 0.002, d_loss_fake= 0.000, g_loss 7.951, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 269/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.954, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 270/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.957, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 271/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.961, d_loss 0.000\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 3 Batch 272/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.967, d_loss 0.000\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 3 Batch 273/390 d_loss_real= 0.003, d_loss_fake= 0.000, g_loss 7.969, d_loss 0.002\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 3 Batch 274/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.971, d_loss 0.000\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 275/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.974, d_loss 0.000\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 3 Batch 276/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.977, d_loss 0.000\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 3 Batch 277/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.981, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 278/390 d_loss_real= 0.007, d_loss_fake= 0.000, g_loss 7.983, d_loss 0.004\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 279/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.986, d_loss 0.000\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 3 Batch 280/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.989, d_loss 0.000\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 281/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 7.991, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 282/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 7.996, d_loss 0.001\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 3 Batch 283/390 d_loss_real= 0.002, d_loss_fake= 0.000, g_loss 7.999, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 284/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.001, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 285/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.003, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 286/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.005, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 287/390 d_loss_real= 0.002, d_loss_fake= 0.000, g_loss 8.008, d_loss 0.001\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 3 Batch 288/390 d_loss_real= 0.003, d_loss_fake= 0.000, g_loss 8.008, d_loss 0.002\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 3 Batch 289/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.007, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 290/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.007, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 291/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.009, d_loss 0.000\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 292/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.016, d_loss 0.000\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 3 Batch 293/390 d_loss_real= 0.003, d_loss_fake= 0.000, g_loss 8.023, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 294/390 d_loss_real= 0.005, d_loss_fake= 0.000, g_loss 8.015, d_loss 0.003\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 3 Batch 295/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.024, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 296/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.029, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 297/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.024, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 298/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.040, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 299/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.030, d_loss 0.000\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 300/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.032, d_loss 0.000\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 3 Batch 301/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.037, d_loss 0.001\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 3 Batch 302/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.038, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 303/390 d_loss_real= 0.002, d_loss_fake= 0.000, g_loss 8.041, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 304/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.044, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 305/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.048, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 306/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.051, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 307/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.055, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 308/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.058, d_loss 0.000\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 3 Batch 309/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.062, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 310/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.066, d_loss 0.000\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 3 Batch 311/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.070, d_loss 0.000\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 3 Batch 312/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.074, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 313/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.079, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 314/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.081, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 315/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.085, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 316/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.088, d_loss 0.001\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 3 Batch 317/390 d_loss_real= 0.005, d_loss_fake= 0.000, g_loss 8.091, d_loss 0.003\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 3 Batch 318/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.094, d_loss 0.000\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 3 Batch 319/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.098, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 320/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.102, d_loss 0.001\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 3 Batch 321/390 d_loss_real= 0.002, d_loss_fake= 0.000, g_loss 8.104, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 3 Batch 322/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.107, d_loss 0.000\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 323/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.110, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 324/390 d_loss_real= 0.002, d_loss_fake= 0.000, g_loss 8.112, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 325/390 d_loss_real= 0.002, d_loss_fake= 0.000, g_loss 8.112, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 326/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.109, d_loss 0.001\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 3 Batch 327/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.107, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 328/390 d_loss_real= 0.004, d_loss_fake= 0.000, g_loss 8.105, d_loss 0.002\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 3 Batch 329/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.102, d_loss 0.000\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 3 Batch 330/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.103, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 331/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.106, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 332/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.109, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 333/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.113, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 334/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.116, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 335/390 d_loss_real= 0.008, d_loss_fake= 0.000, g_loss 8.118, d_loss 0.004\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 336/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.120, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 337/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.123, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 338/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.126, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 339/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.130, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 340/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.133, d_loss 0.000\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 3 Batch 341/390 d_loss_real= 0.002, d_loss_fake= 0.000, g_loss 8.136, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 342/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.140, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 343/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.143, d_loss 0.000\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 344/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.147, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 345/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.153, d_loss 0.000\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 3 Batch 346/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.154, d_loss 0.000\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 347/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.159, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 348/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.169, d_loss 0.000\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 3 Batch 349/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.167, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 350/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.172, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 351/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.180, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 352/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.180, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 353/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.187, d_loss 0.000\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 3 Batch 354/390 d_loss_real= 0.005, d_loss_fake= 0.000, g_loss 8.184, d_loss 0.003\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 3 Batch 355/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.186, d_loss 0.000\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 3 Batch 356/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.187, d_loss 0.000\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 3 Batch 357/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.191, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 358/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.197, d_loss 0.000\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 3 Batch 359/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.196, d_loss 0.000\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3 Batch 360/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.199, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 361/390 d_loss_real= 0.002, d_loss_fake= 0.000, g_loss 8.203, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 362/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.206, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 363/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.208, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 364/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.214, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 365/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.221, d_loss 0.000\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 366/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.220, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 367/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.225, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 368/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.229, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 369/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.230, d_loss 0.001\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 3 Batch 370/390 d_loss_real= 0.002, d_loss_fake= 0.000, g_loss 8.234, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 3 Batch 371/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.237, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 372/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.239, d_loss 0.001\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 3 Batch 373/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.241, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 3 Batch 374/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.244, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 375/390 d_loss_real= 0.003, d_loss_fake= 0.000, g_loss 8.245, d_loss 0.002\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 3 Batch 376/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.248, d_loss 0.001\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 3 Batch 377/390 d_loss_real= 0.002, d_loss_fake= 0.000, g_loss 8.252, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 378/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.253, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 379/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.259, d_loss 0.000\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 3 Batch 380/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.266, d_loss 0.000\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 3 Batch 381/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.263, d_loss 0.000\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 382/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.274, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 383/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.280, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3 Batch 384/390 d_loss_real= 0.003, d_loss_fake= 0.000, g_loss 8.279, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3 Batch 385/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.277, d_loss 0.000\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 3 Batch 386/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.276, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3 Batch 387/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.279, d_loss 0.000\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 3 Batch 388/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.282, d_loss 0.000\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 3 Batch 389/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.285, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 Batch 390/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.288, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 1/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.293, d_loss 0.000\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 2/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.301, d_loss 0.000\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 3/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.299, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 4/390 d_loss_real= 0.004, d_loss_fake= 0.000, g_loss 8.307, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 5/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.316, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 6/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.313, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 7/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.312, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 8/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.313, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 9/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.315, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 10/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.319, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 11/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.321, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 12/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.324, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 13/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.327, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 14/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.331, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 15/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.337, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 16/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.343, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 17/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.342, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 18/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.348, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 19/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.355, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 20/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.354, d_loss 0.000\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 21/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.357, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 22/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.361, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 23/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.362, d_loss 0.000\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 24/390 d_loss_real= 0.002, d_loss_fake= 0.000, g_loss 8.366, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 25/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.371, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 26/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.371, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 27/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.375, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 28/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.379, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 4 Batch 29/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.381, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 30/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.383, d_loss 0.000\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 31/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.386, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 32/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.388, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 33/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.393, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 34/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.398, d_loss 0.000\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 35/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.398, d_loss 0.000\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 36/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.403, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 37/390 d_loss_real= 0.002, d_loss_fake= 0.000, g_loss 8.405, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 38/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.405, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 39/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.410, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 40/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.412, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 41/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.413, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 42/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.417, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 43/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.420, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 44/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.423, d_loss 0.000\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 45/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.426, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 46/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.430, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 4 Batch 47/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.432, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 48/390 d_loss_real= 0.002, d_loss_fake= 0.000, g_loss 8.436, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 49/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.438, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 50/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.445, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 51/390 d_loss_real= 0.005, d_loss_fake= 0.000, g_loss 8.445, d_loss 0.003\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 52/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.445, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 53/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.450, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 54/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.449, d_loss 0.000\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 55/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.451, d_loss 0.001\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 4 Batch 56/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.454, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 57/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.457, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 58/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.460, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 59/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.463, d_loss 0.000\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 60/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.466, d_loss 0.000\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 61/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.468, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 62/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.472, d_loss 0.000\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 63/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.475, d_loss 0.000\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 4 Batch 64/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.479, d_loss 0.000\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 65/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.480, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 66/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.483, d_loss 0.000\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 4 Batch 67/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.487, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 68/390 d_loss_real= 0.002, d_loss_fake= 0.000, g_loss 8.492, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 69/390 d_loss_real= 0.003, d_loss_fake= 0.000, g_loss 8.495, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 70/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.494, d_loss 0.000\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 71/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.502, d_loss 0.000\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 72/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.499, d_loss 0.000\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 73/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.502, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 74/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.505, d_loss 0.000\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 75/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.509, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 76/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.510, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 77/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.513, d_loss 0.000\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 78/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.517, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 79/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.520, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 80/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.523, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 81/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.526, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 82/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.529, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 83/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.531, d_loss 0.000\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 84/390 d_loss_real= 0.010, d_loss_fake= 0.000, g_loss 8.534, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 85/390 d_loss_real= 0.003, d_loss_fake= 0.000, g_loss 8.536, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 86/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.539, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 87/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.538, d_loss 0.000\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 4 Batch 88/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.545, d_loss 0.000\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 89/390 d_loss_real= 0.007, d_loss_fake= 0.000, g_loss 8.541, d_loss 0.004\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 4 Batch 90/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.538, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 91/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.541, d_loss 0.000\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 92/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.542, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 93/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.541, d_loss 0.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 94/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.542, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 4 Batch 95/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.544, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 96/390 d_loss_real= 0.002, d_loss_fake= 0.000, g_loss 8.546, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 97/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.550, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 98/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.550, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 99/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.551, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 100/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.553, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 101/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.556, d_loss 0.000\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 102/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.557, d_loss 0.000\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 4 Batch 103/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.558, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 4 Batch 104/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.560, d_loss 0.000\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 105/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.562, d_loss 0.000\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 106/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.563, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 107/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.560, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 108/390 d_loss_real= 0.002, d_loss_fake= 0.000, g_loss 8.559, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 4 Batch 109/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.558, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 110/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.557, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 111/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.550, d_loss 0.000\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 112/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.553, d_loss 0.001\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 4 Batch 113/390 d_loss_real= 0.000, d_loss_fake= 0.000, g_loss 8.545, d_loss 0.000\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 114/390 d_loss_real= 0.001, d_loss_fake= 0.000, g_loss 8.498, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 115/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 7.154, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 116/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.451, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 117/390 d_loss_real= 0.000, d_loss_fake= 0.031, g_loss 3.521, d_loss 0.015\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 118/390 d_loss_real= 0.000, d_loss_fake= 0.030, g_loss 3.549, d_loss 0.015\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 119/390 d_loss_real= 0.000, d_loss_fake= 0.029, g_loss 3.618, d_loss 0.014\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 120/390 d_loss_real= 0.000, d_loss_fake= 0.026, g_loss 3.726, d_loss 0.013\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 121/390 d_loss_real= 0.001, d_loss_fake= 0.023, g_loss 3.860, d_loss 0.012\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 122/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 3.989, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 123/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 4.023, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 124/390 d_loss_real= 0.000, d_loss_fake= 0.017, g_loss 4.158, d_loss 0.009\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 4 Batch 125/390 d_loss_real= 0.000, d_loss_fake= 0.015, g_loss 4.307, d_loss 0.007\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 4 Batch 126/390 d_loss_real= 0.003, d_loss_fake= 0.013, g_loss 4.451, d_loss 0.008\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 127/390 d_loss_real= 0.001, d_loss_fake= 0.011, g_loss 4.557, d_loss 0.006\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 128/390 d_loss_real= 0.002, d_loss_fake= 0.010, g_loss 4.690, d_loss 0.006\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 129/390 d_loss_real= 0.000, d_loss_fake= 0.009, g_loss 4.824, d_loss 0.004\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 130/390 d_loss_real= 0.000, d_loss_fake= 0.008, g_loss 4.948, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 131/390 d_loss_real= 0.001, d_loss_fake= 0.007, g_loss 5.067, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 132/390 d_loss_real= 0.002, d_loss_fake= 0.006, g_loss 5.176, d_loss 0.004\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 133/390 d_loss_real= 0.001, d_loss_fake= 0.005, g_loss 5.277, d_loss 0.003\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 134/390 d_loss_real= 0.002, d_loss_fake= 0.005, g_loss 5.371, d_loss 0.003\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 135/390 d_loss_real= 0.001, d_loss_fake= 0.004, g_loss 5.457, d_loss 0.003\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 136/390 d_loss_real= 0.000, d_loss_fake= 0.004, g_loss 5.534, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 137/390 d_loss_real= 0.000, d_loss_fake= 0.004, g_loss 5.609, d_loss 0.002\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 4 Batch 138/390 d_loss_real= 0.001, d_loss_fake= 0.004, g_loss 5.680, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 139/390 d_loss_real= 0.001, d_loss_fake= 0.003, g_loss 5.746, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 140/390 d_loss_real= 0.000, d_loss_fake= 0.003, g_loss 5.807, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 141/390 d_loss_real= 0.000, d_loss_fake= 0.003, g_loss 5.865, d_loss 0.002\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 4 Batch 142/390 d_loss_real= 0.000, d_loss_fake= 0.003, g_loss 5.919, d_loss 0.002\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 4 Batch 143/390 d_loss_real= 0.001, d_loss_fake= 0.003, g_loss 5.971, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 144/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.020, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 145/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.068, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 146/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.112, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 147/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.155, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 148/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.194, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 149/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.233, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 150/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.270, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 151/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.305, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 152/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.339, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 153/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.371, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 154/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.402, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 4 Batch 155/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.430, d_loss 0.002\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 156/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.455, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 157/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.453, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 158/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.388, d_loss 0.001\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 4 Batch 159/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.175, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 160/390 d_loss_real= 0.000, d_loss_fake= 0.059, g_loss 2.966, d_loss 0.029\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 161/390 d_loss_real= 0.000, d_loss_fake= 0.048, g_loss 3.217, d_loss 0.024\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 4 Batch 162/390 d_loss_real= 0.000, d_loss_fake= 0.036, g_loss 3.529, d_loss 0.018\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 4 Batch 163/390 d_loss_real= 0.002, d_loss_fake= 0.028, g_loss 3.810, d_loss 0.015\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 164/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 4.154, d_loss 0.010\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 165/390 d_loss_real= 0.002, d_loss_fake= 0.014, g_loss 4.516, d_loss 0.008\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 166/390 d_loss_real= 0.000, d_loss_fake= 0.011, g_loss 4.699, d_loss 0.006\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 167/390 d_loss_real= 0.001, d_loss_fake= 0.011, g_loss 4.653, d_loss 0.006\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 168/390 d_loss_real= 0.002, d_loss_fake= 0.012, g_loss 4.524, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 169/390 d_loss_real= 0.001, d_loss_fake= 0.326, g_loss 1.819, d_loss 0.164\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 170/390 d_loss_real= 0.003, d_loss_fake= 14.830, g_loss 0.000, d_loss 7.416\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 171/390 d_loss_real= 0.000, d_loss_fake= 19.037, g_loss 0.000, d_loss 9.519\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 172/390 d_loss_real= 0.001, d_loss_fake= 13.653, g_loss 0.000, d_loss 6.827\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 173/390 d_loss_real= 0.002, d_loss_fake= 7.323, g_loss 0.021, d_loss 3.663\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 174/390 d_loss_real= 0.009, d_loss_fake= 2.697, g_loss 0.859, d_loss 1.353\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 175/390 d_loss_real= 0.020, d_loss_fake= 0.400, g_loss 2.717, d_loss 0.210\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 176/390 d_loss_real= 0.052, d_loss_fake= 0.912, g_loss 1.042, d_loss 0.482\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 177/390 d_loss_real= 0.191, d_loss_fake= 0.752, g_loss 1.003, d_loss 0.472\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 4 Batch 178/390 d_loss_real= 0.459, d_loss_fake= 0.456, g_loss 1.513, d_loss 0.457\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 179/390 d_loss_real= 0.843, d_loss_fake= 0.331, g_loss 1.606, d_loss 0.587\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 4 Batch 180/390 d_loss_real= 0.850, d_loss_fake= 0.268, g_loss 1.646, d_loss 0.559\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 181/390 d_loss_real= 0.796, d_loss_fake= 0.270, g_loss 1.602, d_loss 0.533\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 182/390 d_loss_real= 0.479, d_loss_fake= 0.263, g_loss 1.646, d_loss 0.371\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 4 Batch 183/390 d_loss_real= 0.353, d_loss_fake= 0.218, g_loss 1.830, d_loss 0.285\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 184/390 d_loss_real= 0.246, d_loss_fake= 0.160, g_loss 2.149, d_loss 0.203\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 4 Batch 185/390 d_loss_real= 0.218, d_loss_fake= 0.111, g_loss 2.520, d_loss 0.164\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 186/390 d_loss_real= 0.170, d_loss_fake= 0.072, g_loss 2.907, d_loss 0.121\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 187/390 d_loss_real= 0.160, d_loss_fake= 0.049, g_loss 3.253, d_loss 0.105\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 188/390 d_loss_real= 0.073, d_loss_fake= 0.035, g_loss 3.576, d_loss 0.054\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 4 Batch 189/390 d_loss_real= 0.096, d_loss_fake= 0.028, g_loss 3.742, d_loss 0.062\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 190/390 d_loss_real= 0.068, d_loss_fake= 0.029, g_loss 3.674, d_loss 0.049\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 191/390 d_loss_real= 0.069, d_loss_fake= 0.026, g_loss 3.788, d_loss 0.047\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 4 Batch 192/390 d_loss_real= 0.042, d_loss_fake= 0.027, g_loss 3.733, d_loss 0.035\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 193/390 d_loss_real= 0.034, d_loss_fake= 0.042, g_loss 3.334, d_loss 0.038\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 4 Batch 194/390 d_loss_real= 0.039, d_loss_fake= 0.962, g_loss 0.890, d_loss 0.501\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 4 Batch 195/390 d_loss_real= 0.054, d_loss_fake= 3.248, g_loss 0.094, d_loss 1.651\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 196/390 d_loss_real= 0.095, d_loss_fake= 3.900, g_loss 0.055, d_loss 1.997\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 197/390 d_loss_real= 0.293, d_loss_fake= 2.337, g_loss 0.357, d_loss 1.315\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 4 Batch 198/390 d_loss_real= 0.954, d_loss_fake= 0.761, g_loss 1.415, d_loss 0.858\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 199/390 d_loss_real= 2.040, d_loss_fake= 0.250, g_loss 1.966, d_loss 1.145\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 4 Batch 200/390 d_loss_real= 2.472, d_loss_fake= 0.186, g_loss 1.794, d_loss 1.329\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 201/390 d_loss_real= 2.025, d_loss_fake= 0.304, g_loss 1.176, d_loss 1.165\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 202/390 d_loss_real= 1.422, d_loss_fake= 0.654, g_loss 0.630, d_loss 1.038\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 203/390 d_loss_real= 0.854, d_loss_fake= 1.018, g_loss 0.420, d_loss 0.936\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 204/390 d_loss_real= 0.553, d_loss_fake= 1.230, g_loss 0.362, d_loss 0.892\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 205/390 d_loss_real= 0.498, d_loss_fake= 1.232, g_loss 0.392, d_loss 0.865\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 206/390 d_loss_real= 0.475, d_loss_fake= 1.099, g_loss 0.483, d_loss 0.787\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 207/390 d_loss_real= 0.604, d_loss_fake= 0.909, g_loss 0.616, d_loss 0.757\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 208/390 d_loss_real= 0.647, d_loss_fake= 0.730, g_loss 0.762, d_loss 0.689\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 4 Batch 209/390 d_loss_real= 0.758, d_loss_fake= 0.607, g_loss 0.887, d_loss 0.683\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 210/390 d_loss_real= 0.840, d_loss_fake= 0.529, g_loss 0.970, d_loss 0.685\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 211/390 d_loss_real= 0.914, d_loss_fake= 0.484, g_loss 1.009, d_loss 0.699\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 212/390 d_loss_real= 0.902, d_loss_fake= 0.466, g_loss 1.019, d_loss 0.684\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 213/390 d_loss_real= 0.903, d_loss_fake= 0.472, g_loss 0.994, d_loss 0.687\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 4 Batch 214/390 d_loss_real= 0.824, d_loss_fake= 0.492, g_loss 0.952, d_loss 0.658\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 215/390 d_loss_real= 0.738, d_loss_fake= 0.519, g_loss 0.910, d_loss 0.629\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 216/390 d_loss_real= 0.738, d_loss_fake= 0.548, g_loss 0.874, d_loss 0.643\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 217/390 d_loss_real= 0.721, d_loss_fake= 0.575, g_loss 0.842, d_loss 0.648\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 218/390 d_loss_real= 0.608, d_loss_fake= 0.590, g_loss 0.837, d_loss 0.599\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 4 Batch 219/390 d_loss_real= 0.614, d_loss_fake= 0.583, g_loss 0.856, d_loss 0.598\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 220/390 d_loss_real= 0.638, d_loss_fake= 0.562, g_loss 0.889, d_loss 0.600\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 221/390 d_loss_real= 0.600, d_loss_fake= 0.534, g_loss 0.929, d_loss 0.567\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 222/390 d_loss_real= 0.652, d_loss_fake= 0.509, g_loss 0.961, d_loss 0.581\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 223/390 d_loss_real= 0.667, d_loss_fake= 0.494, g_loss 0.974, d_loss 0.580\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 224/390 d_loss_real= 0.617, d_loss_fake= 0.488, g_loss 0.983, d_loss 0.553\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 225/390 d_loss_real= 0.576, d_loss_fake= 0.485, g_loss 0.988, d_loss 0.530\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 226/390 d_loss_real= 0.640, d_loss_fake= 0.486, g_loss 0.987, d_loss 0.563\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 4 Batch 227/390 d_loss_real= 0.550, d_loss_fake= 0.485, g_loss 0.990, d_loss 0.518\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 228/390 d_loss_real= 0.529, d_loss_fake= 0.482, g_loss 1.001, d_loss 0.506\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 229/390 d_loss_real= 0.546, d_loss_fake= 0.481, g_loss 1.013, d_loss 0.513\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 230/390 d_loss_real= 0.537, d_loss_fake= 0.490, g_loss 1.004, d_loss 0.513\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 231/390 d_loss_real= 0.543, d_loss_fake= 0.534, g_loss 0.942, d_loss 0.539\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 232/390 d_loss_real= 0.580, d_loss_fake= 0.514, g_loss 0.970, d_loss 0.547\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 233/390 d_loss_real= 0.582, d_loss_fake= 0.479, g_loss 1.023, d_loss 0.531\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 234/390 d_loss_real= 0.590, d_loss_fake= 0.455, g_loss 1.061, d_loss 0.523\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 235/390 d_loss_real= 0.573, d_loss_fake= 0.434, g_loss 1.094, d_loss 0.503\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 4 Batch 236/390 d_loss_real= 0.544, d_loss_fake= 0.415, g_loss 1.124, d_loss 0.480\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 237/390 d_loss_real= 0.536, d_loss_fake= 0.401, g_loss 1.150, d_loss 0.469\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 238/390 d_loss_real= 0.485, d_loss_fake= 0.392, g_loss 1.166, d_loss 0.438\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 4 Batch 239/390 d_loss_real= 0.505, d_loss_fake= 0.384, g_loss 1.183, d_loss 0.445\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 4 Batch 240/390 d_loss_real= 0.453, d_loss_fake= 0.379, g_loss 1.197, d_loss 0.416\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 241/390 d_loss_real= 0.433, d_loss_fake= 0.373, g_loss 1.213, d_loss 0.403\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 242/390 d_loss_real= 0.390, d_loss_fake= 0.363, g_loss 1.244, d_loss 0.376\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 4 Batch 243/390 d_loss_real= 0.393, d_loss_fake= 0.361, g_loss 1.256, d_loss 0.377\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 244/390 d_loss_real= 0.378, d_loss_fake= 0.397, g_loss 1.190, d_loss 0.387\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 245/390 d_loss_real= 0.375, d_loss_fake= 0.422, g_loss 1.174, d_loss 0.399\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 246/390 d_loss_real= 0.388, d_loss_fake= 0.384, g_loss 1.263, d_loss 0.386\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 247/390 d_loss_real= 0.430, d_loss_fake= 0.328, g_loss 1.383, d_loss 0.379\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 248/390 d_loss_real= 0.493, d_loss_fake= 0.290, g_loss 1.454, d_loss 0.392\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 249/390 d_loss_real= 0.523, d_loss_fake= 0.278, g_loss 1.463, d_loss 0.400\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 4 Batch 250/390 d_loss_real= 0.531, d_loss_fake= 0.287, g_loss 1.415, d_loss 0.409\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 4 Batch 251/390 d_loss_real= 0.454, d_loss_fake= 0.310, g_loss 1.347, d_loss 0.382\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 252/390 d_loss_real= 0.459, d_loss_fake= 0.340, g_loss 1.280, d_loss 0.399\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 253/390 d_loss_real= 0.421, d_loss_fake= 0.358, g_loss 1.264, d_loss 0.389\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 254/390 d_loss_real= 0.415, d_loss_fake= 0.350, g_loss 1.305, d_loss 0.382\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 255/390 d_loss_real= 0.417, d_loss_fake= 0.329, g_loss 1.361, d_loss 0.373\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 4 Batch 256/390 d_loss_real= 0.407, d_loss_fake= 0.300, g_loss 1.442, d_loss 0.354\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 4 Batch 257/390 d_loss_real= 0.426, d_loss_fake= 0.277, g_loss 1.487, d_loss 0.352\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 258/390 d_loss_real= 0.386, d_loss_fake= 0.263, g_loss 1.528, d_loss 0.324\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 259/390 d_loss_real= 0.444, d_loss_fake= 0.260, g_loss 1.513, d_loss 0.352\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 260/390 d_loss_real= 0.452, d_loss_fake= 0.272, g_loss 1.475, d_loss 0.362\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 261/390 d_loss_real= 0.378, d_loss_fake= 0.284, g_loss 1.461, d_loss 0.331\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 4 Batch 262/390 d_loss_real= 0.366, d_loss_fake= 0.284, g_loss 1.482, d_loss 0.325\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 263/390 d_loss_real= 0.394, d_loss_fake= 0.273, g_loss 1.514, d_loss 0.333\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 264/390 d_loss_real= 0.322, d_loss_fake= 0.253, g_loss 1.591, d_loss 0.288\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 4 Batch 265/390 d_loss_real= 0.335, d_loss_fake= 0.232, g_loss 1.650, d_loss 0.284\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 266/390 d_loss_real= 0.347, d_loss_fake= 0.220, g_loss 1.682, d_loss 0.283\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 4 Batch 267/390 d_loss_real= 0.373, d_loss_fake= 0.221, g_loss 1.669, d_loss 0.297\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 268/390 d_loss_real= 0.385, d_loss_fake= 0.236, g_loss 1.625, d_loss 0.310\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 269/390 d_loss_real= 0.314, d_loss_fake= 0.268, g_loss 1.549, d_loss 0.291\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 4 Batch 270/390 d_loss_real= 0.356, d_loss_fake= 0.774, g_loss 0.793, d_loss 0.565\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 271/390 d_loss_real= 0.442, d_loss_fake= 2.477, g_loss 0.109, d_loss 1.460\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 272/390 d_loss_real= 0.579, d_loss_fake= 2.334, g_loss 0.138, d_loss 1.457\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 4 Batch 273/390 d_loss_real= 0.641, d_loss_fake= 1.833, g_loss 0.256, d_loss 1.237\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 4 Batch 274/390 d_loss_real= 0.659, d_loss_fake= 1.248, g_loss 0.507, d_loss 0.954\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 4 Batch 275/390 d_loss_real= 0.636, d_loss_fake= 0.708, g_loss 0.983, d_loss 0.672\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 4 Batch 276/390 d_loss_real= 0.521, d_loss_fake= 0.344, g_loss 1.649, d_loss 0.432\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 277/390 d_loss_real= 0.530, d_loss_fake= 0.426, g_loss 1.318, d_loss 0.478\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 4 Batch 278/390 d_loss_real= 0.439, d_loss_fake= 0.379, g_loss 1.382, d_loss 0.409\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 4 Batch 279/390 d_loss_real= 0.435, d_loss_fake= 0.623, g_loss 0.859, d_loss 0.529\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 4 Batch 280/390 d_loss_real= 0.501, d_loss_fake= 0.674, g_loss 0.777, d_loss 0.587\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 281/390 d_loss_real= 0.624, d_loss_fake= 0.658, g_loss 0.797, d_loss 0.641\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 282/390 d_loss_real= 0.729, d_loss_fake= 0.608, g_loss 0.851, d_loss 0.668\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 4 Batch 283/390 d_loss_real= 0.826, d_loss_fake= 0.559, g_loss 0.901, d_loss 0.693\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 284/390 d_loss_real= 0.912, d_loss_fake= 0.530, g_loss 0.925, d_loss 0.721\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 285/390 d_loss_real= 0.879, d_loss_fake= 0.518, g_loss 0.934, d_loss 0.699\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 4 Batch 286/390 d_loss_real= 0.807, d_loss_fake= 0.516, g_loss 0.932, d_loss 0.661\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 4 Batch 287/390 d_loss_real= 0.800, d_loss_fake= 0.521, g_loss 0.920, d_loss 0.660\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 4 Batch 288/390 d_loss_real= 0.651, d_loss_fake= 0.524, g_loss 0.925, d_loss 0.588\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 4 Batch 289/390 d_loss_real= 0.630, d_loss_fake= 0.515, g_loss 0.955, d_loss 0.572\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 4 Batch 290/390 d_loss_real= 0.640, d_loss_fake= 0.483, g_loss 1.039, d_loss 0.562\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 291/390 d_loss_real= 0.645, d_loss_fake= 0.420, g_loss 1.188, d_loss 0.533\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 292/390 d_loss_real= 0.616, d_loss_fake= 0.339, g_loss 1.390, d_loss 0.478\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 293/390 d_loss_real= 0.626, d_loss_fake= 0.271, g_loss 1.536, d_loss 0.448\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 294/390 d_loss_real= 0.577, d_loss_fake= 0.239, g_loss 1.618, d_loss 0.408\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 4 Batch 295/390 d_loss_real= 0.565, d_loss_fake= 0.222, g_loss 1.662, d_loss 0.393\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 296/390 d_loss_real= 0.554, d_loss_fake= 0.217, g_loss 1.658, d_loss 0.386\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 297/390 d_loss_real= 0.463, d_loss_fake= 0.222, g_loss 1.628, d_loss 0.343\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 4 Batch 298/390 d_loss_real= 0.532, d_loss_fake= 0.239, g_loss 1.543, d_loss 0.386\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 299/390 d_loss_real= 0.476, d_loss_fake= 0.266, g_loss 1.445, d_loss 0.371\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 300/390 d_loss_real= 0.316, d_loss_fake= 0.290, g_loss 1.414, d_loss 0.303\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 4 Batch 301/390 d_loss_real= 0.355, d_loss_fake= 0.292, g_loss 1.441, d_loss 0.324\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 302/390 d_loss_real= 0.296, d_loss_fake= 0.271, g_loss 1.533, d_loss 0.284\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 303/390 d_loss_real= 0.281, d_loss_fake= 0.240, g_loss 1.642, d_loss 0.260\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 304/390 d_loss_real= 0.339, d_loss_fake= 0.217, g_loss 1.716, d_loss 0.278\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 305/390 d_loss_real= 0.259, d_loss_fake= 0.199, g_loss 1.794, d_loss 0.229\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 306/390 d_loss_real= 0.303, d_loss_fake= 0.184, g_loss 1.851, d_loss 0.244\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 307/390 d_loss_real= 0.303, d_loss_fake= 0.180, g_loss 1.850, d_loss 0.242\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 4 Batch 308/390 d_loss_real= 0.285, d_loss_fake= 0.187, g_loss 1.811, d_loss 0.236\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 4 Batch 309/390 d_loss_real= 0.191, d_loss_fake= 0.186, g_loss 1.878, d_loss 0.189\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 310/390 d_loss_real= 0.282, d_loss_fake= 0.170, g_loss 1.952, d_loss 0.226\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 4 Batch 311/390 d_loss_real= 0.272, d_loss_fake= 0.159, g_loss 2.013, d_loss 0.215\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 312/390 d_loss_real= 0.179, d_loss_fake= 0.142, g_loss 2.135, d_loss 0.161\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 313/390 d_loss_real= 0.286, d_loss_fake= 0.128, g_loss 2.196, d_loss 0.207\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 314/390 d_loss_real= 0.248, d_loss_fake= 0.123, g_loss 2.203, d_loss 0.186\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 315/390 d_loss_real= 0.247, d_loss_fake= 0.125, g_loss 2.182, d_loss 0.186\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 316/390 d_loss_real= 0.190, d_loss_fake= 0.128, g_loss 2.166, d_loss 0.159\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 4 Batch 317/390 d_loss_real= 0.227, d_loss_fake= 0.135, g_loss 2.130, d_loss 0.181\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 4 Batch 318/390 d_loss_real= 0.202, d_loss_fake= 0.134, g_loss 2.181, d_loss 0.168\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 319/390 d_loss_real= 0.258, d_loss_fake= 0.129, g_loss 2.200, d_loss 0.193\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 4 Batch 320/390 d_loss_real= 0.243, d_loss_fake= 0.128, g_loss 2.186, d_loss 0.186\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 321/390 d_loss_real= 0.297, d_loss_fake= 0.136, g_loss 2.099, d_loss 0.216\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 322/390 d_loss_real= 0.170, d_loss_fake= 0.143, g_loss 2.083, d_loss 0.156\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 323/390 d_loss_real= 0.165, d_loss_fake= 0.138, g_loss 2.137, d_loss 0.152\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 4 Batch 324/390 d_loss_real= 0.154, d_loss_fake= 0.124, g_loss 2.249, d_loss 0.139\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 325/390 d_loss_real= 0.167, d_loss_fake= 0.110, g_loss 2.352, d_loss 0.139\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 4 Batch 326/390 d_loss_real= 0.220, d_loss_fake= 0.104, g_loss 2.369, d_loss 0.162\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 327/390 d_loss_real= 0.189, d_loss_fake= 0.106, g_loss 2.350, d_loss 0.148\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 328/390 d_loss_real= 0.143, d_loss_fake= 0.108, g_loss 2.382, d_loss 0.126\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 4 Batch 329/390 d_loss_real= 0.144, d_loss_fake= 0.099, g_loss 2.459, d_loss 0.121\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 330/390 d_loss_real= 0.143, d_loss_fake= 0.090, g_loss 2.533, d_loss 0.117\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 4 Batch 331/390 d_loss_real= 0.219, d_loss_fake= 0.087, g_loss 2.521, d_loss 0.153\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 4 Batch 332/390 d_loss_real= 0.188, d_loss_fake= 0.093, g_loss 2.443, d_loss 0.140\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 333/390 d_loss_real= 0.179, d_loss_fake= 0.107, g_loss 2.324, d_loss 0.143\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 334/390 d_loss_real= 0.161, d_loss_fake= 0.119, g_loss 2.286, d_loss 0.140\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 335/390 d_loss_real= 0.103, d_loss_fake= 0.108, g_loss 2.409, d_loss 0.105\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 336/390 d_loss_real= 0.176, d_loss_fake= 0.097, g_loss 2.475, d_loss 0.136\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 337/390 d_loss_real= 0.150, d_loss_fake= 0.090, g_loss 2.516, d_loss 0.120\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 338/390 d_loss_real= 0.203, d_loss_fake= 0.092, g_loss 2.460, d_loss 0.148\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 339/390 d_loss_real= 0.133, d_loss_fake= 0.100, g_loss 2.430, d_loss 0.116\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 340/390 d_loss_real= 0.152, d_loss_fake= 0.100, g_loss 2.458, d_loss 0.126\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 341/390 d_loss_real= 0.141, d_loss_fake= 0.095, g_loss 2.485, d_loss 0.118\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 342/390 d_loss_real= 0.161, d_loss_fake= 0.093, g_loss 2.495, d_loss 0.127\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 343/390 d_loss_real= 0.112, d_loss_fake= 0.088, g_loss 2.544, d_loss 0.100\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 4 Batch 344/390 d_loss_real= 0.086, d_loss_fake= 0.081, g_loss 2.625, d_loss 0.084\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 345/390 d_loss_real= 0.171, d_loss_fake= 0.078, g_loss 2.628, d_loss 0.124\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 346/390 d_loss_real= 0.190, d_loss_fake= 0.086, g_loss 2.544, d_loss 0.138\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 347/390 d_loss_real= 0.081, d_loss_fake= 0.087, g_loss 2.593, d_loss 0.084\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 348/390 d_loss_real= 0.087, d_loss_fake= 0.078, g_loss 2.685, d_loss 0.082\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 349/390 d_loss_real= 0.117, d_loss_fake= 0.071, g_loss 2.738, d_loss 0.094\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 350/390 d_loss_real= 0.111, d_loss_fake= 0.069, g_loss 2.748, d_loss 0.090\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4 Batch 351/390 d_loss_real= 0.171, d_loss_fake= 0.074, g_loss 2.645, d_loss 0.123\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 4 Batch 352/390 d_loss_real= 0.129, d_loss_fake= 0.087, g_loss 2.545, d_loss 0.108\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 4 Batch 353/390 d_loss_real= 0.124, d_loss_fake= 0.092, g_loss 2.544, d_loss 0.108\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 4 Batch 354/390 d_loss_real= 0.136, d_loss_fake= 0.087, g_loss 2.584, d_loss 0.111\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 4 Batch 355/390 d_loss_real= 0.115, d_loss_fake= 0.084, g_loss 2.592, d_loss 0.100\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 356/390 d_loss_real= 0.080, d_loss_fake= 0.080, g_loss 2.650, d_loss 0.080\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 357/390 d_loss_real= 0.178, d_loss_fake= 0.081, g_loss 2.578, d_loss 0.129\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 358/390 d_loss_real= 0.117, d_loss_fake= 0.091, g_loss 2.523, d_loss 0.104\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 4 Batch 359/390 d_loss_real= 0.072, d_loss_fake= 0.089, g_loss 2.613, d_loss 0.080\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 4 Batch 360/390 d_loss_real= 0.088, d_loss_fake= 0.161, g_loss 2.217, d_loss 0.125\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 4 Batch 361/390 d_loss_real= 0.112, d_loss_fake= 0.124, g_loss 2.462, d_loss 0.118\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 362/390 d_loss_real= 0.222, d_loss_fake= 0.243, g_loss 2.023, d_loss 0.232\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 363/390 d_loss_real= 0.245, d_loss_fake= 0.118, g_loss 2.599, d_loss 0.182\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 364/390 d_loss_real= 0.218, d_loss_fake= 0.067, g_loss 2.960, d_loss 0.142\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 365/390 d_loss_real= 0.311, d_loss_fake= 0.057, g_loss 2.913, d_loss 0.184\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 366/390 d_loss_real= 0.296, d_loss_fake= 0.074, g_loss 2.526, d_loss 0.185\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 4 Batch 367/390 d_loss_real= 0.122, d_loss_fake= 0.135, g_loss 2.091, d_loss 0.128\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 368/390 d_loss_real= 0.131, d_loss_fake= 0.180, g_loss 2.006, d_loss 0.156\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 369/390 d_loss_real= 0.055, d_loss_fake= 0.128, g_loss 2.468, d_loss 0.092\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 4 Batch 370/390 d_loss_real= 0.160, d_loss_fake= 0.077, g_loss 2.837, d_loss 0.119\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 4 Batch 371/390 d_loss_real= 0.072, d_loss_fake= 0.053, g_loss 3.134, d_loss 0.063\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 4 Batch 372/390 d_loss_real= 0.102, d_loss_fake= 0.042, g_loss 3.283, d_loss 0.072\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 373/390 d_loss_real= 0.066, d_loss_fake= 0.037, g_loss 3.383, d_loss 0.051\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 4 Batch 374/390 d_loss_real= 0.051, d_loss_fake= 0.034, g_loss 3.452, d_loss 0.042\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 375/390 d_loss_real= 0.073, d_loss_fake= 0.033, g_loss 3.448, d_loss 0.053\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 4 Batch 376/390 d_loss_real= 0.065, d_loss_fake= 0.035, g_loss 3.359, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 377/390 d_loss_real= 0.027, d_loss_fake= 0.062, g_loss 2.906, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 378/390 d_loss_real= 0.049, d_loss_fake= 1.583, g_loss 1.394, d_loss 0.816\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 379/390 d_loss_real= 0.143, d_loss_fake= 0.188, g_loss 3.664, d_loss 0.165\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 380/390 d_loss_real= 0.506, d_loss_fake= 0.011, g_loss 5.407, d_loss 0.259\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 4 Batch 381/390 d_loss_real= 1.025, d_loss_fake= 0.003, g_loss 5.887, d_loss 0.514\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 382/390 d_loss_real= 1.294, d_loss_fake= 0.004, g_loss 5.332, d_loss 0.649\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 4 Batch 383/390 d_loss_real= 0.655, d_loss_fake= 0.009, g_loss 4.153, d_loss 0.332\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 4 Batch 384/390 d_loss_real= 0.303, d_loss_fake= 0.033, g_loss 2.777, d_loss 0.168\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 4 Batch 385/390 d_loss_real= 0.096, d_loss_fake= 0.131, g_loss 1.750, d_loss 0.113\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4 Batch 386/390 d_loss_real= 0.017, d_loss_fake= 0.273, g_loss 1.661, d_loss 0.145\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 4 Batch 387/390 d_loss_real= 0.016, d_loss_fake= 0.172, g_loss 2.302, d_loss 0.094\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4 Batch 388/390 d_loss_real= 0.015, d_loss_fake= 0.070, g_loss 3.179, d_loss 0.043\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 4 Batch 389/390 d_loss_real= 0.015, d_loss_fake= 0.029, g_loss 3.957, d_loss 0.022\n",
            "2/2 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 Batch 390/390 d_loss_real= 0.024, d_loss_fake= 0.015, g_loss 4.478, d_loss 0.020\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 1/390 d_loss_real= 0.025, d_loss_fake= 0.047, g_loss 3.445, d_loss 0.036\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 2/390 d_loss_real= 0.019, d_loss_fake= 4.711, g_loss 0.015, d_loss 2.365\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 3/390 d_loss_real= 0.035, d_loss_fake= 5.020, g_loss 0.014, d_loss 2.527\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 4/390 d_loss_real= 0.105, d_loss_fake= 3.808, g_loss 0.053, d_loss 1.956\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 5/390 d_loss_real= 0.270, d_loss_fake= 2.322, g_loss 0.238, d_loss 1.296\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 6/390 d_loss_real= 0.611, d_loss_fake= 1.057, g_loss 0.842, d_loss 0.834\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 7/390 d_loss_real= 0.659, d_loss_fake= 0.295, g_loss 2.300, d_loss 0.477\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 8/390 d_loss_real= 0.576, d_loss_fake= 0.052, g_loss 3.682, d_loss 0.314\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 9/390 d_loss_real= 0.568, d_loss_fake= 0.017, g_loss 4.537, d_loss 0.292\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 10/390 d_loss_real= 0.439, d_loss_fake= 0.008, g_loss 5.137, d_loss 0.224\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 11/390 d_loss_real= 0.346, d_loss_fake= 0.005, g_loss 5.507, d_loss 0.175\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 12/390 d_loss_real= 0.219, d_loss_fake= 0.004, g_loss 5.754, d_loss 0.111\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 13/390 d_loss_real= 0.214, d_loss_fake= 0.003, g_loss 5.926, d_loss 0.109\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 14/390 d_loss_real= 0.158, d_loss_fake= 0.003, g_loss 6.047, d_loss 0.080\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 15/390 d_loss_real= 0.132, d_loss_fake= 0.002, g_loss 6.124, d_loss 0.067\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 16/390 d_loss_real= 0.110, d_loss_fake= 0.002, g_loss 6.170, d_loss 0.056\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 17/390 d_loss_real= 0.109, d_loss_fake= 0.002, g_loss 6.186, d_loss 0.056\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 18/390 d_loss_real= 0.084, d_loss_fake= 0.002, g_loss 6.178, d_loss 0.043\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 19/390 d_loss_real= 0.100, d_loss_fake= 0.002, g_loss 6.132, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 20/390 d_loss_real= 0.082, d_loss_fake= 0.002, g_loss 6.016, d_loss 0.042\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 21/390 d_loss_real= 0.066, d_loss_fake= 0.003, g_loss 5.859, d_loss 0.034\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 22/390 d_loss_real= 0.060, d_loss_fake= 0.004, g_loss 5.512, d_loss 0.032\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 23/390 d_loss_real= 0.056, d_loss_fake= 0.012, g_loss 4.436, d_loss 0.034\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 24/390 d_loss_real= 0.058, d_loss_fake= 0.055, g_loss 2.953, d_loss 0.056\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 25/390 d_loss_real= 0.058, d_loss_fake= 0.115, g_loss 2.329, d_loss 0.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 26/390 d_loss_real= 0.053, d_loss_fake= 0.311, g_loss 1.506, d_loss 0.182\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 27/390 d_loss_real= 0.043, d_loss_fake= 0.253, g_loss 1.805, d_loss 0.148\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 28/390 d_loss_real= 0.063, d_loss_fake= 0.237, g_loss 1.905, d_loss 0.150\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 29/390 d_loss_real= 0.055, d_loss_fake= 0.160, g_loss 2.289, d_loss 0.107\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 30/390 d_loss_real= 0.067, d_loss_fake= 0.084, g_loss 2.934, d_loss 0.075\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 31/390 d_loss_real= 0.082, d_loss_fake= 0.057, g_loss 3.272, d_loss 0.069\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 32/390 d_loss_real= 0.076, d_loss_fake= 0.094, g_loss 2.694, d_loss 0.085\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 33/390 d_loss_real= 0.071, d_loss_fake= 0.138, g_loss 2.333, d_loss 0.104\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 34/390 d_loss_real= 0.084, d_loss_fake= 0.240, g_loss 1.926, d_loss 0.162\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 35/390 d_loss_real= 0.092, d_loss_fake= 0.152, g_loss 2.326, d_loss 0.122\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 36/390 d_loss_real= 0.103, d_loss_fake= 0.236, g_loss 1.974, d_loss 0.170\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 37/390 d_loss_real= 0.142, d_loss_fake= 0.210, g_loss 2.167, d_loss 0.176\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 38/390 d_loss_real= 0.162, d_loss_fake= 0.101, g_loss 2.794, d_loss 0.131\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 39/390 d_loss_real= 0.163, d_loss_fake= 0.056, g_loss 3.284, d_loss 0.110\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 40/390 d_loss_real= 0.176, d_loss_fake= 0.034, g_loss 3.725, d_loss 0.105\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 5 Batch 41/390 d_loss_real= 0.232, d_loss_fake= 0.023, g_loss 4.017, d_loss 0.128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 42/390 d_loss_real= 0.157, d_loss_fake= 0.013, g_loss 4.587, d_loss 0.085\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 5 Batch 43/390 d_loss_real= 0.185, d_loss_fake= 0.014, g_loss 4.413, d_loss 0.099\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 44/390 d_loss_real= 0.170, d_loss_fake= 0.012, g_loss 4.507, d_loss 0.091\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 45/390 d_loss_real= 0.168, d_loss_fake= 0.012, g_loss 4.510, d_loss 0.090\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 46/390 d_loss_real= 0.096, d_loss_fake= 0.013, g_loss 4.397, d_loss 0.054\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 47/390 d_loss_real= 0.105, d_loss_fake= 0.019, g_loss 4.024, d_loss 0.062\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 48/390 d_loss_real= 0.087, d_loss_fake= 0.043, g_loss 3.191, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 49/390 d_loss_real= 0.055, d_loss_fake= 0.220, g_loss 1.823, d_loss 0.137\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 50/390 d_loss_real= 0.048, d_loss_fake= 0.312, g_loss 1.669, d_loss 0.180\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 51/390 d_loss_real= 0.077, d_loss_fake= 0.157, g_loss 2.374, d_loss 0.117\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 52/390 d_loss_real= 0.062, d_loss_fake= 0.068, g_loss 3.153, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 53/390 d_loss_real= 0.068, d_loss_fake= 0.033, g_loss 3.792, d_loss 0.051\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 5 Batch 54/390 d_loss_real= 0.110, d_loss_fake= 0.019, g_loss 4.271, d_loss 0.065\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 55/390 d_loss_real= 0.053, d_loss_fake= 0.013, g_loss 4.576, d_loss 0.033\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 56/390 d_loss_real= 0.086, d_loss_fake= 0.013, g_loss 4.555, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 57/390 d_loss_real= 0.088, d_loss_fake= 0.026, g_loss 3.825, d_loss 0.057\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 58/390 d_loss_real= 0.086, d_loss_fake= 0.048, g_loss 3.197, d_loss 0.067\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 59/390 d_loss_real= 0.083, d_loss_fake= 0.102, g_loss 2.504, d_loss 0.092\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 60/390 d_loss_real= 0.061, d_loss_fake= 0.365, g_loss 1.456, d_loss 0.213\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 61/390 d_loss_real= 0.071, d_loss_fake= 0.188, g_loss 2.172, d_loss 0.130\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 62/390 d_loss_real= 0.066, d_loss_fake= 0.129, g_loss 2.535, d_loss 0.097\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 63/390 d_loss_real= 0.067, d_loss_fake= 0.079, g_loss 2.983, d_loss 0.073\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 64/390 d_loss_real= 0.095, d_loss_fake= 0.040, g_loss 3.596, d_loss 0.067\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 65/390 d_loss_real= 0.049, d_loss_fake= 0.023, g_loss 4.077, d_loss 0.036\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 66/390 d_loss_real= 0.108, d_loss_fake= 0.020, g_loss 4.169, d_loss 0.064\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 67/390 d_loss_real= 0.074, d_loss_fake= 0.020, g_loss 4.103, d_loss 0.047\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 68/390 d_loss_real= 0.078, d_loss_fake= 0.017, g_loss 4.236, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 69/390 d_loss_real= 0.068, d_loss_fake= 0.012, g_loss 4.542, d_loss 0.040\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 70/390 d_loss_real= 0.050, d_loss_fake= 0.010, g_loss 4.678, d_loss 0.030\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 71/390 d_loss_real= 0.054, d_loss_fake= 0.012, g_loss 4.542, d_loss 0.033\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 72/390 d_loss_real= 0.076, d_loss_fake= 0.033, g_loss 3.502, d_loss 0.054\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 73/390 d_loss_real= 0.042, d_loss_fake= 0.039, g_loss 3.346, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 74/390 d_loss_real= 0.050, d_loss_fake= 0.037, g_loss 3.397, d_loss 0.044\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 75/390 d_loss_real= 0.030, d_loss_fake= 0.036, g_loss 3.452, d_loss 0.033\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 76/390 d_loss_real= 0.053, d_loss_fake= 0.032, g_loss 3.570, d_loss 0.043\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 77/390 d_loss_real= 0.018, d_loss_fake= 0.027, g_loss 3.757, d_loss 0.022\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 78/390 d_loss_real= 0.024, d_loss_fake= 0.022, g_loss 3.929, d_loss 0.023\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 79/390 d_loss_real= 0.034, d_loss_fake= 0.018, g_loss 4.137, d_loss 0.026\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 80/390 d_loss_real= 0.026, d_loss_fake= 0.014, g_loss 4.353, d_loss 0.020\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 81/390 d_loss_real= 0.020, d_loss_fake= 0.012, g_loss 4.511, d_loss 0.016\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 82/390 d_loss_real= 0.016, d_loss_fake= 0.011, g_loss 4.653, d_loss 0.013\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 83/390 d_loss_real= 0.031, d_loss_fake= 0.009, g_loss 4.780, d_loss 0.020\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 84/390 d_loss_real= 0.025, d_loss_fake= 0.008, g_loss 4.882, d_loss 0.017\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 85/390 d_loss_real= 0.025, d_loss_fake= 0.007, g_loss 4.997, d_loss 0.016\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 86/390 d_loss_real= 0.024, d_loss_fake= 0.006, g_loss 5.115, d_loss 0.015\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 87/390 d_loss_real= 0.022, d_loss_fake= 0.006, g_loss 5.118, d_loss 0.014\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 88/390 d_loss_real= 0.037, d_loss_fake= 0.006, g_loss 5.177, d_loss 0.021\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 89/390 d_loss_real= 0.013, d_loss_fake= 0.006, g_loss 5.104, d_loss 0.010\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 90/390 d_loss_real= 0.017, d_loss_fake= 0.007, g_loss 5.049, d_loss 0.012\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 91/390 d_loss_real= 0.040, d_loss_fake= 0.006, g_loss 5.194, d_loss 0.023\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 92/390 d_loss_real= 0.017, d_loss_fake= 0.008, g_loss 4.891, d_loss 0.012\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 93/390 d_loss_real= 0.046, d_loss_fake= 0.009, g_loss 4.772, d_loss 0.027\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 94/390 d_loss_real= 0.016, d_loss_fake= 0.009, g_loss 4.780, d_loss 0.012\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 95/390 d_loss_real= 0.028, d_loss_fake= 0.009, g_loss 4.706, d_loss 0.019\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 96/390 d_loss_real= 0.021, d_loss_fake= 0.010, g_loss 4.686, d_loss 0.015\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 97/390 d_loss_real= 0.020, d_loss_fake= 0.009, g_loss 4.704, d_loss 0.015\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 98/390 d_loss_real= 0.015, d_loss_fake= 0.009, g_loss 4.754, d_loss 0.012\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 99/390 d_loss_real= 0.071, d_loss_fake= 0.009, g_loss 4.769, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 100/390 d_loss_real= 0.030, d_loss_fake= 0.008, g_loss 4.827, d_loss 0.019\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 101/390 d_loss_real= 0.023, d_loss_fake= 0.007, g_loss 5.004, d_loss 0.015\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 102/390 d_loss_real= 0.024, d_loss_fake= 0.007, g_loss 5.013, d_loss 0.015\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 103/390 d_loss_real= 0.010, d_loss_fake= 0.005, g_loss 5.345, d_loss 0.007\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 104/390 d_loss_real= 0.015, d_loss_fake= 0.006, g_loss 5.108, d_loss 0.011\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 105/390 d_loss_real= 0.016, d_loss_fake= 0.005, g_loss 5.361, d_loss 0.010\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 106/390 d_loss_real= 0.012, d_loss_fake= 0.005, g_loss 5.389, d_loss 0.009\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 107/390 d_loss_real= 0.014, d_loss_fake= 0.004, g_loss 5.482, d_loss 0.009\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 5 Batch 108/390 d_loss_real= 0.011, d_loss_fake= 0.004, g_loss 5.463, d_loss 0.008\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 109/390 d_loss_real= 0.010, d_loss_fake= 0.004, g_loss 5.499, d_loss 0.007\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 110/390 d_loss_real= 0.013, d_loss_fake= 0.004, g_loss 5.600, d_loss 0.009\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 111/390 d_loss_real= 0.009, d_loss_fake= 0.004, g_loss 5.484, d_loss 0.006\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 112/390 d_loss_real= 0.021, d_loss_fake= 0.004, g_loss 5.501, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 113/390 d_loss_real= 0.009, d_loss_fake= 0.004, g_loss 5.559, d_loss 0.007\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 114/390 d_loss_real= 0.009, d_loss_fake= 0.004, g_loss 5.479, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 115/390 d_loss_real= 0.007, d_loss_fake= 0.004, g_loss 5.622, d_loss 0.005\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 116/390 d_loss_real= 0.020, d_loss_fake= 0.004, g_loss 5.491, d_loss 0.012\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 117/390 d_loss_real= 0.014, d_loss_fake= 0.005, g_loss 5.340, d_loss 0.009\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 118/390 d_loss_real= 0.009, d_loss_fake= 0.004, g_loss 5.512, d_loss 0.007\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 119/390 d_loss_real= 0.007, d_loss_fake= 0.004, g_loss 5.448, d_loss 0.006\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 120/390 d_loss_real= 0.008, d_loss_fake= 0.004, g_loss 5.451, d_loss 0.006\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 121/390 d_loss_real= 0.011, d_loss_fake= 0.005, g_loss 5.400, d_loss 0.008\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 122/390 d_loss_real= 0.011, d_loss_fake= 0.005, g_loss 5.405, d_loss 0.008\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 123/390 d_loss_real= 0.008, d_loss_fake= 0.004, g_loss 5.513, d_loss 0.006\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 124/390 d_loss_real= 0.005, d_loss_fake= 0.004, g_loss 5.512, d_loss 0.005\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 125/390 d_loss_real= 0.008, d_loss_fake= 0.004, g_loss 5.544, d_loss 0.006\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 5 Batch 126/390 d_loss_real= 0.006, d_loss_fake= 0.004, g_loss 5.667, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 127/390 d_loss_real= 0.008, d_loss_fake= 0.004, g_loss 5.634, d_loss 0.006\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 5 Batch 128/390 d_loss_real= 0.010, d_loss_fake= 0.004, g_loss 5.666, d_loss 0.007\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 129/390 d_loss_real= 0.010, d_loss_fake= 0.004, g_loss 5.546, d_loss 0.007\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 130/390 d_loss_real= 0.022, d_loss_fake= 0.005, g_loss 5.231, d_loss 0.014\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 131/390 d_loss_real= 0.013, d_loss_fake= 0.009, g_loss 4.709, d_loss 0.011\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 132/390 d_loss_real= 0.006, d_loss_fake= 0.013, g_loss 4.409, d_loss 0.009\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 133/390 d_loss_real= 0.005, d_loss_fake= 0.016, g_loss 4.213, d_loss 0.010\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 134/390 d_loss_real= 0.008, d_loss_fake= 0.017, g_loss 4.198, d_loss 0.012\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 135/390 d_loss_real= 0.013, d_loss_fake= 0.020, g_loss 4.019, d_loss 0.017\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 136/390 d_loss_real= 0.011, d_loss_fake= 0.032, g_loss 3.614, d_loss 0.021\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 137/390 d_loss_real= 0.011, d_loss_fake= 0.042, g_loss 3.414, d_loss 0.026\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 138/390 d_loss_real= 0.006, d_loss_fake= 0.059, g_loss 3.198, d_loss 0.033\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 139/390 d_loss_real= 0.019, d_loss_fake= 0.026, g_loss 3.982, d_loss 0.023\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 5 Batch 140/390 d_loss_real= 0.026, d_loss_fake= 0.018, g_loss 4.370, d_loss 0.022\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 5 Batch 141/390 d_loss_real= 0.020, d_loss_fake= 0.010, g_loss 4.873, d_loss 0.015\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 142/390 d_loss_real= 0.021, d_loss_fake= 0.006, g_loss 5.287, d_loss 0.014\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 143/390 d_loss_real= 0.018, d_loss_fake= 0.004, g_loss 5.673, d_loss 0.011\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 144/390 d_loss_real= 0.029, d_loss_fake= 0.003, g_loss 5.920, d_loss 0.016\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 145/390 d_loss_real= 0.034, d_loss_fake= 0.003, g_loss 5.882, d_loss 0.019\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 146/390 d_loss_real= 0.034, d_loss_fake= 0.007, g_loss 5.070, d_loss 0.020\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 147/390 d_loss_real= 0.012, d_loss_fake= 0.011, g_loss 4.601, d_loss 0.012\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 5 Batch 148/390 d_loss_real= 0.025, d_loss_fake= 0.011, g_loss 4.633, d_loss 0.018\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 149/390 d_loss_real= 0.026, d_loss_fake= 0.014, g_loss 4.374, d_loss 0.020\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 150/390 d_loss_real= 0.012, d_loss_fake= 0.024, g_loss 3.838, d_loss 0.018\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 5 Batch 151/390 d_loss_real= 0.021, d_loss_fake= 0.133, g_loss 2.408, d_loss 0.077\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 5 Batch 152/390 d_loss_real= 0.011, d_loss_fake= 0.325, g_loss 1.865, d_loss 0.168\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 5 Batch 153/390 d_loss_real= 0.031, d_loss_fake= 2.088, g_loss 0.348, d_loss 1.059\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 154/390 d_loss_real= 0.028, d_loss_fake= 2.179, g_loss 0.434, d_loss 1.104\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 5 Batch 155/390 d_loss_real= 0.170, d_loss_fake= 1.707, g_loss 0.942, d_loss 0.938\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 5 Batch 156/390 d_loss_real= 0.878, d_loss_fake= 0.607, g_loss 2.052, d_loss 0.743\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 157/390 d_loss_real= 2.495, d_loss_fake= 0.687, g_loss 1.141, d_loss 1.591\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 158/390 d_loss_real= 2.454, d_loss_fake= 1.042, g_loss 0.532, d_loss 1.748\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 159/390 d_loss_real= 1.386, d_loss_fake= 1.583, g_loss 0.315, d_loss 1.485\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 160/390 d_loss_real= 1.031, d_loss_fake= 1.650, g_loss 0.356, d_loss 1.340\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 161/390 d_loss_real= 0.809, d_loss_fake= 1.232, g_loss 0.612, d_loss 1.020\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 162/390 d_loss_real= 1.169, d_loss_fake= 0.755, g_loss 0.965, d_loss 0.962\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 163/390 d_loss_real= 1.030, d_loss_fake= 0.502, g_loss 1.153, d_loss 0.766\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 164/390 d_loss_real= 1.108, d_loss_fake= 0.467, g_loss 1.076, d_loss 0.787\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 165/390 d_loss_real= 0.893, d_loss_fake= 0.541, g_loss 0.928, d_loss 0.717\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 166/390 d_loss_real= 0.683, d_loss_fake= 0.615, g_loss 0.866, d_loss 0.649\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 167/390 d_loss_real= 0.671, d_loss_fake= 0.628, g_loss 0.883, d_loss 0.650\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 168/390 d_loss_real= 0.603, d_loss_fake= 0.570, g_loss 0.987, d_loss 0.586\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 169/390 d_loss_real= 0.649, d_loss_fake= 0.484, g_loss 1.134, d_loss 0.566\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 170/390 d_loss_real= 0.655, d_loss_fake= 0.422, g_loss 1.231, d_loss 0.539\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 171/390 d_loss_real= 0.606, d_loss_fake= 0.391, g_loss 1.278, d_loss 0.499\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 172/390 d_loss_real= 0.672, d_loss_fake= 0.359, g_loss 1.322, d_loss 0.516\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 173/390 d_loss_real= 0.490, d_loss_fake= 0.336, g_loss 1.382, d_loss 0.413\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 174/390 d_loss_real= 0.496, d_loss_fake= 0.319, g_loss 1.415, d_loss 0.408\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 175/390 d_loss_real= 0.556, d_loss_fake= 0.341, g_loss 1.335, d_loss 0.449\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 176/390 d_loss_real= 0.467, d_loss_fake= 0.444, g_loss 1.178, d_loss 0.456\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 177/390 d_loss_real= 0.472, d_loss_fake= 0.404, g_loss 1.314, d_loss 0.438\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 178/390 d_loss_real= 0.490, d_loss_fake= 0.323, g_loss 1.510, d_loss 0.406\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 179/390 d_loss_real= 0.521, d_loss_fake= 0.355, g_loss 1.414, d_loss 0.438\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 180/390 d_loss_real= 0.484, d_loss_fake= 0.299, g_loss 1.562, d_loss 0.391\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 181/390 d_loss_real= 0.619, d_loss_fake= 0.258, g_loss 1.635, d_loss 0.438\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 182/390 d_loss_real= 0.523, d_loss_fake= 0.245, g_loss 1.669, d_loss 0.384\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 183/390 d_loss_real= 0.305, d_loss_fake= 0.312, g_loss 1.567, d_loss 0.309\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 184/390 d_loss_real= 0.445, d_loss_fake= 0.184, g_loss 2.072, d_loss 0.314\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 185/390 d_loss_real= 0.353, d_loss_fake= 0.206, g_loss 1.969, d_loss 0.279\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 186/390 d_loss_real= 0.335, d_loss_fake= 0.154, g_loss 2.204, d_loss 0.245\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 187/390 d_loss_real= 0.306, d_loss_fake= 0.136, g_loss 2.290, d_loss 0.221\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 188/390 d_loss_real= 0.207, d_loss_fake= 0.222, g_loss 1.849, d_loss 0.215\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 189/390 d_loss_real= 0.249, d_loss_fake= 0.258, g_loss 1.620, d_loss 0.254\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 190/390 d_loss_real= 0.200, d_loss_fake= 0.315, g_loss 1.532, d_loss 0.258\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 191/390 d_loss_real= 0.307, d_loss_fake= 0.631, g_loss 1.024, d_loss 0.469\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 192/390 d_loss_real= 0.314, d_loss_fake= 0.383, g_loss 1.513, d_loss 0.348\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 193/390 d_loss_real= 0.513, d_loss_fake= 0.214, g_loss 1.938, d_loss 0.364\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 194/390 d_loss_real= 0.695, d_loss_fake= 0.162, g_loss 1.996, d_loss 0.428\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 195/390 d_loss_real= 0.662, d_loss_fake= 0.179, g_loss 1.766, d_loss 0.421\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 196/390 d_loss_real= 0.556, d_loss_fake= 0.252, g_loss 1.446, d_loss 0.404\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 5 Batch 197/390 d_loss_real= 0.305, d_loss_fake= 0.341, g_loss 1.298, d_loss 0.323\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 198/390 d_loss_real= 0.305, d_loss_fake= 0.361, g_loss 1.381, d_loss 0.333\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 5 Batch 199/390 d_loss_real= 0.214, d_loss_fake= 0.273, g_loss 1.713, d_loss 0.243\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 200/390 d_loss_real= 0.300, d_loss_fake= 0.185, g_loss 1.991, d_loss 0.242\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 201/390 d_loss_real= 0.376, d_loss_fake= 0.151, g_loss 2.084, d_loss 0.263\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 202/390 d_loss_real= 0.377, d_loss_fake= 0.167, g_loss 1.925, d_loss 0.272\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 203/390 d_loss_real= 0.275, d_loss_fake= 0.523, g_loss 1.215, d_loss 0.399\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 204/390 d_loss_real= 0.364, d_loss_fake= 1.610, g_loss 0.677, d_loss 0.987\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 205/390 d_loss_real= 0.706, d_loss_fake= 0.731, g_loss 1.611, d_loss 0.719\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 5 Batch 206/390 d_loss_real= 1.415, d_loss_fake= 0.166, g_loss 2.602, d_loss 0.790\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 207/390 d_loss_real= 1.790, d_loss_fake= 0.077, g_loss 2.831, d_loss 0.933\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 208/390 d_loss_real= 1.571, d_loss_fake= 0.093, g_loss 2.373, d_loss 0.832\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 209/390 d_loss_real= 0.880, d_loss_fake= 0.205, g_loss 1.670, d_loss 0.543\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 210/390 d_loss_real= 0.367, d_loss_fake= 0.322, g_loss 1.475, d_loss 0.345\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 211/390 d_loss_real= 0.165, d_loss_fake= 0.610, g_loss 1.161, d_loss 0.388\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 212/390 d_loss_real= 0.086, d_loss_fake= 0.997, g_loss 0.961, d_loss 0.542\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 213/390 d_loss_real= 0.096, d_loss_fake= 0.605, g_loss 1.636, d_loss 0.350\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 214/390 d_loss_real= 0.169, d_loss_fake= 0.467, g_loss 1.877, d_loss 0.318\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 215/390 d_loss_real= 0.265, d_loss_fake= 0.236, g_loss 2.442, d_loss 0.250\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 216/390 d_loss_real= 0.517, d_loss_fake= 0.081, g_loss 3.188, d_loss 0.299\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 217/390 d_loss_real= 0.968, d_loss_fake= 0.039, g_loss 3.425, d_loss 0.503\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 218/390 d_loss_real= 0.742, d_loss_fake= 0.059, g_loss 2.785, d_loss 0.400\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 219/390 d_loss_real= 0.580, d_loss_fake= 0.167, g_loss 1.647, d_loss 0.373\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 5 Batch 220/390 d_loss_real= 0.329, d_loss_fake= 0.361, g_loss 1.141, d_loss 0.345\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 5 Batch 221/390 d_loss_real= 0.240, d_loss_fake= 0.529, g_loss 0.998, d_loss 0.385\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 222/390 d_loss_real= 0.269, d_loss_fake= 0.457, g_loss 1.266, d_loss 0.363\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 223/390 d_loss_real= 0.244, d_loss_fake= 0.289, g_loss 1.730, d_loss 0.266\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 224/390 d_loss_real= 0.295, d_loss_fake= 0.182, g_loss 2.131, d_loss 0.239\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 225/390 d_loss_real= 0.347, d_loss_fake= 0.140, g_loss 2.302, d_loss 0.243\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 226/390 d_loss_real= 0.357, d_loss_fake= 0.154, g_loss 2.100, d_loss 0.255\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 227/390 d_loss_real= 0.385, d_loss_fake= 0.817, g_loss 0.742, d_loss 0.601\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 228/390 d_loss_real= 0.351, d_loss_fake= 0.779, g_loss 0.858, d_loss 0.565\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 229/390 d_loss_real= 0.499, d_loss_fake= 0.467, g_loss 1.280, d_loss 0.483\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 230/390 d_loss_real= 0.670, d_loss_fake= 0.291, g_loss 1.598, d_loss 0.481\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 231/390 d_loss_real= 0.754, d_loss_fake= 0.230, g_loss 1.676, d_loss 0.492\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 232/390 d_loss_real= 0.647, d_loss_fake= 0.232, g_loss 1.598, d_loss 0.440\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 233/390 d_loss_real= 0.389, d_loss_fake= 0.259, g_loss 1.495, d_loss 0.324\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 234/390 d_loss_real= 0.269, d_loss_fake= 0.278, g_loss 1.469, d_loss 0.273\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 235/390 d_loss_real= 0.254, d_loss_fake= 0.278, g_loss 1.517, d_loss 0.266\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 236/390 d_loss_real= 0.198, d_loss_fake= 0.267, g_loss 1.582, d_loss 0.233\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 237/390 d_loss_real= 0.211, d_loss_fake= 0.265, g_loss 1.619, d_loss 0.238\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 238/390 d_loss_real= 0.180, d_loss_fake= 0.271, g_loss 1.643, d_loss 0.226\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 239/390 d_loss_real= 0.285, d_loss_fake= 0.216, g_loss 1.831, d_loss 0.250\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 240/390 d_loss_real= 0.366, d_loss_fake= 0.176, g_loss 1.966, d_loss 0.271\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 241/390 d_loss_real= 0.517, d_loss_fake= 0.163, g_loss 1.978, d_loss 0.340\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 242/390 d_loss_real= 0.343, d_loss_fake= 0.162, g_loss 1.962, d_loss 0.252\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 243/390 d_loss_real= 0.197, d_loss_fake= 0.158, g_loss 2.006, d_loss 0.178\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 244/390 d_loss_real= 0.295, d_loss_fake= 0.152, g_loss 2.033, d_loss 0.224\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 245/390 d_loss_real= 0.197, d_loss_fake= 0.147, g_loss 2.076, d_loss 0.172\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 246/390 d_loss_real= 0.211, d_loss_fake= 0.142, g_loss 2.110, d_loss 0.176\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 247/390 d_loss_real= 0.196, d_loss_fake= 0.133, g_loss 2.193, d_loss 0.164\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 248/390 d_loss_real= 0.218, d_loss_fake= 0.120, g_loss 2.295, d_loss 0.169\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 249/390 d_loss_real= 0.344, d_loss_fake= 0.114, g_loss 2.283, d_loss 0.229\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 250/390 d_loss_real= 0.177, d_loss_fake= 0.115, g_loss 2.293, d_loss 0.146\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 251/390 d_loss_real= 0.225, d_loss_fake= 0.111, g_loss 2.337, d_loss 0.168\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 252/390 d_loss_real= 0.178, d_loss_fake= 0.104, g_loss 2.407, d_loss 0.141\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 253/390 d_loss_real= 0.141, d_loss_fake= 0.095, g_loss 2.497, d_loss 0.118\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 5 Batch 254/390 d_loss_real= 0.198, d_loss_fake= 0.088, g_loss 2.563, d_loss 0.143\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 5 Batch 255/390 d_loss_real= 0.149, d_loss_fake= 0.082, g_loss 2.618, d_loss 0.116\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 256/390 d_loss_real= 0.192, d_loss_fake= 0.082, g_loss 2.561, d_loss 0.137\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 257/390 d_loss_real= 0.098, d_loss_fake= 0.085, g_loss 2.581, d_loss 0.091\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 5 Batch 258/390 d_loss_real= 0.125, d_loss_fake= 0.082, g_loss 2.621, d_loss 0.103\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 259/390 d_loss_real= 0.071, d_loss_fake= 0.074, g_loss 2.734, d_loss 0.073\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 5 Batch 260/390 d_loss_real= 0.124, d_loss_fake= 0.068, g_loss 2.789, d_loss 0.096\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 261/390 d_loss_real= 0.108, d_loss_fake= 0.065, g_loss 2.805, d_loss 0.087\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 262/390 d_loss_real= 0.123, d_loss_fake= 0.066, g_loss 2.776, d_loss 0.095\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 263/390 d_loss_real= 0.109, d_loss_fake= 0.070, g_loss 2.729, d_loss 0.089\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 264/390 d_loss_real= 0.131, d_loss_fake= 0.075, g_loss 2.666, d_loss 0.103\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 265/390 d_loss_real= 0.119, d_loss_fake= 0.079, g_loss 2.640, d_loss 0.099\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 266/390 d_loss_real= 0.116, d_loss_fake= 0.080, g_loss 2.648, d_loss 0.098\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 5 Batch 267/390 d_loss_real= 0.069, d_loss_fake= 0.074, g_loss 2.749, d_loss 0.071\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 5 Batch 268/390 d_loss_real= 0.118, d_loss_fake= 0.066, g_loss 2.838, d_loss 0.092\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 269/390 d_loss_real= 0.097, d_loss_fake= 0.061, g_loss 2.883, d_loss 0.079\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 270/390 d_loss_real= 0.096, d_loss_fake= 0.059, g_loss 2.916, d_loss 0.078\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 271/390 d_loss_real= 0.073, d_loss_fake= 0.056, g_loss 2.968, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 272/390 d_loss_real= 0.118, d_loss_fake= 0.056, g_loss 2.939, d_loss 0.087\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 273/390 d_loss_real= 0.089, d_loss_fake= 0.057, g_loss 2.960, d_loss 0.073\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 274/390 d_loss_real= 0.063, d_loss_fake= 0.053, g_loss 3.034, d_loss 0.058\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 275/390 d_loss_real= 0.143, d_loss_fake= 0.053, g_loss 2.967, d_loss 0.098\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 276/390 d_loss_real= 0.056, d_loss_fake= 0.056, g_loss 2.981, d_loss 0.056\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 5 Batch 277/390 d_loss_real= 0.102, d_loss_fake= 0.056, g_loss 2.972, d_loss 0.079\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 278/390 d_loss_real= 0.090, d_loss_fake= 0.058, g_loss 2.949, d_loss 0.074\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 279/390 d_loss_real= 0.082, d_loss_fake= 0.057, g_loss 2.975, d_loss 0.069\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 280/390 d_loss_real= 0.182, d_loss_fake= 0.059, g_loss 2.892, d_loss 0.121\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 281/390 d_loss_real= 0.101, d_loss_fake= 0.061, g_loss 2.915, d_loss 0.081\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 282/390 d_loss_real= 0.123, d_loss_fake= 0.057, g_loss 2.940, d_loss 0.090\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 283/390 d_loss_real= 0.025, d_loss_fake= 0.053, g_loss 3.027, d_loss 0.039\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 284/390 d_loss_real= 0.083, d_loss_fake= 0.050, g_loss 3.067, d_loss 0.066\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 285/390 d_loss_real= 0.167, d_loss_fake= 0.049, g_loss 3.066, d_loss 0.108\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 286/390 d_loss_real= 0.072, d_loss_fake= 0.049, g_loss 3.079, d_loss 0.060\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 287/390 d_loss_real= 0.057, d_loss_fake= 0.049, g_loss 3.097, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 288/390 d_loss_real= 0.114, d_loss_fake= 0.050, g_loss 3.082, d_loss 0.082\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 289/390 d_loss_real= 0.056, d_loss_fake= 0.048, g_loss 3.158, d_loss 0.052\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 290/390 d_loss_real= 0.042, d_loss_fake= 0.042, g_loss 3.257, d_loss 0.042\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 291/390 d_loss_real= 0.109, d_loss_fake= 0.040, g_loss 3.265, d_loss 0.074\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 292/390 d_loss_real= 0.113, d_loss_fake= 0.042, g_loss 3.181, d_loss 0.078\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 293/390 d_loss_real= 0.097, d_loss_fake= 0.051, g_loss 2.980, d_loss 0.074\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 294/390 d_loss_real= 0.043, d_loss_fake= 0.056, g_loss 3.001, d_loss 0.049\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 5 Batch 295/390 d_loss_real= 0.032, d_loss_fake= 0.050, g_loss 3.144, d_loss 0.041\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 296/390 d_loss_real= 0.080, d_loss_fake= 0.043, g_loss 3.233, d_loss 0.062\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 297/390 d_loss_real= 0.057, d_loss_fake= 0.040, g_loss 3.293, d_loss 0.049\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 298/390 d_loss_real= 0.079, d_loss_fake= 0.038, g_loss 3.350, d_loss 0.058\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 299/390 d_loss_real= 0.054, d_loss_fake= 0.036, g_loss 3.389, d_loss 0.045\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 300/390 d_loss_real= 0.080, d_loss_fake= 0.036, g_loss 3.366, d_loss 0.058\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 5 Batch 301/390 d_loss_real= 0.033, d_loss_fake= 0.036, g_loss 3.378, d_loss 0.034\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 302/390 d_loss_real= 0.116, d_loss_fake= 0.038, g_loss 3.303, d_loss 0.077\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 303/390 d_loss_real= 0.078, d_loss_fake= 0.040, g_loss 3.322, d_loss 0.059\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 5 Batch 304/390 d_loss_real= 0.056, d_loss_fake= 0.037, g_loss 3.398, d_loss 0.046\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 305/390 d_loss_real= 0.080, d_loss_fake= 0.035, g_loss 3.401, d_loss 0.058\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 306/390 d_loss_real= 0.050, d_loss_fake= 0.035, g_loss 3.409, d_loss 0.042\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 307/390 d_loss_real= 0.133, d_loss_fake= 0.036, g_loss 3.372, d_loss 0.085\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 308/390 d_loss_real= 0.085, d_loss_fake= 0.038, g_loss 3.307, d_loss 0.061\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 5 Batch 309/390 d_loss_real= 0.054, d_loss_fake= 0.041, g_loss 3.254, d_loss 0.048\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 310/390 d_loss_real= 0.050, d_loss_fake= 0.043, g_loss 3.234, d_loss 0.046\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 311/390 d_loss_real= 0.059, d_loss_fake= 0.045, g_loss 3.166, d_loss 0.052\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 312/390 d_loss_real= 0.057, d_loss_fake= 0.048, g_loss 3.120, d_loss 0.052\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 313/390 d_loss_real= 0.064, d_loss_fake= 0.049, g_loss 3.107, d_loss 0.056\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 314/390 d_loss_real= 0.057, d_loss_fake= 0.048, g_loss 3.127, d_loss 0.052\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 315/390 d_loss_real= 0.049, d_loss_fake= 0.046, g_loss 3.180, d_loss 0.047\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 316/390 d_loss_real= 0.033, d_loss_fake= 0.043, g_loss 3.241, d_loss 0.038\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 317/390 d_loss_real= 0.143, d_loss_fake= 0.053, g_loss 3.071, d_loss 0.098\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 318/390 d_loss_real= 0.162, d_loss_fake= 0.175, g_loss 2.171, d_loss 0.169\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 319/390 d_loss_real= 0.161, d_loss_fake= 0.450, g_loss 1.788, d_loss 0.306\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 5 Batch 320/390 d_loss_real= 0.136, d_loss_fake= 1.071, g_loss 1.785, d_loss 0.603\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 321/390 d_loss_real= 0.262, d_loss_fake= 0.392, g_loss 2.800, d_loss 0.327\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 322/390 d_loss_real= 1.251, d_loss_fake= 1.116, g_loss 1.586, d_loss 1.183\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 323/390 d_loss_real= 2.425, d_loss_fake= 0.263, g_loss 2.444, d_loss 1.344\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 324/390 d_loss_real= 3.625, d_loss_fake= 0.077, g_loss 2.912, d_loss 1.851\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 325/390 d_loss_real= 3.756, d_loss_fake= 0.081, g_loss 2.376, d_loss 1.918\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 326/390 d_loss_real= 2.506, d_loss_fake= 0.197, g_loss 1.428, d_loss 1.351\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 327/390 d_loss_real= 1.473, d_loss_fake= 0.604, g_loss 0.749, d_loss 1.039\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 5 Batch 328/390 d_loss_real= 0.309, d_loss_fake= 1.074, g_loss 0.640, d_loss 0.691\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 5 Batch 329/390 d_loss_real= 0.122, d_loss_fake= 0.800, g_loss 1.131, d_loss 0.461\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 5 Batch 330/390 d_loss_real= 0.135, d_loss_fake= 0.306, g_loss 2.066, d_loss 0.220\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 331/390 d_loss_real= 0.200, d_loss_fake= 0.095, g_loss 3.031, d_loss 0.148\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 332/390 d_loss_real= 0.218, d_loss_fake= 0.036, g_loss 3.820, d_loss 0.127\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 333/390 d_loss_real= 0.188, d_loss_fake= 0.021, g_loss 4.189, d_loss 0.105\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 334/390 d_loss_real= 0.171, d_loss_fake= 0.013, g_loss 4.561, d_loss 0.092\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 335/390 d_loss_real= 0.219, d_loss_fake= 0.011, g_loss 4.674, d_loss 0.115\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 336/390 d_loss_real= 0.123, d_loss_fake= 0.018, g_loss 4.071, d_loss 0.071\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 337/390 d_loss_real= 0.096, d_loss_fake= 0.043, g_loss 3.205, d_loss 0.069\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 338/390 d_loss_real= 0.069, d_loss_fake= 0.045, g_loss 3.163, d_loss 0.057\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 339/390 d_loss_real= 0.057, d_loss_fake= 0.050, g_loss 3.077, d_loss 0.053\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 5 Batch 340/390 d_loss_real= 0.140, d_loss_fake= 0.059, g_loss 2.933, d_loss 0.099\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 341/390 d_loss_real= 0.047, d_loss_fake= 0.055, g_loss 3.007, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 342/390 d_loss_real= 0.056, d_loss_fake= 0.051, g_loss 3.094, d_loss 0.054\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 343/390 d_loss_real= 0.050, d_loss_fake= 0.046, g_loss 3.200, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 344/390 d_loss_real= 0.038, d_loss_fake= 0.042, g_loss 3.293, d_loss 0.040\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 345/390 d_loss_real= 0.037, d_loss_fake= 0.039, g_loss 3.369, d_loss 0.038\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 346/390 d_loss_real= 0.050, d_loss_fake= 0.035, g_loss 3.487, d_loss 0.042\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 347/390 d_loss_real= 0.045, d_loss_fake= 0.029, g_loss 3.637, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 348/390 d_loss_real= 0.047, d_loss_fake= 0.025, g_loss 3.781, d_loss 0.036\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 349/390 d_loss_real= 0.060, d_loss_fake= 0.022, g_loss 3.895, d_loss 0.041\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 350/390 d_loss_real= 0.038, d_loss_fake= 0.020, g_loss 3.986, d_loss 0.029\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5 Batch 351/390 d_loss_real= 0.034, d_loss_fake= 0.018, g_loss 4.066, d_loss 0.026\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 5 Batch 352/390 d_loss_real= 0.063, d_loss_fake= 0.018, g_loss 4.091, d_loss 0.040\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 353/390 d_loss_real= 0.038, d_loss_fake= 0.017, g_loss 4.090, d_loss 0.028\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 354/390 d_loss_real= 0.038, d_loss_fake= 0.017, g_loss 4.111, d_loss 0.027\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 355/390 d_loss_real= 0.047, d_loss_fake= 0.017, g_loss 4.096, d_loss 0.032\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 356/390 d_loss_real= 0.042, d_loss_fake= 0.019, g_loss 3.977, d_loss 0.031\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5 Batch 357/390 d_loss_real= 0.037, d_loss_fake= 0.034, g_loss 3.422, d_loss 0.036\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 358/390 d_loss_real= 0.066, d_loss_fake= 0.048, g_loss 3.112, d_loss 0.057\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 359/390 d_loss_real= 0.043, d_loss_fake= 0.058, g_loss 2.973, d_loss 0.051\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 360/390 d_loss_real= 0.035, d_loss_fake= 0.057, g_loss 3.037, d_loss 0.046\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 5 Batch 361/390 d_loss_real= 0.042, d_loss_fake= 0.046, g_loss 3.249, d_loss 0.044\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 362/390 d_loss_real= 0.061, d_loss_fake= 0.036, g_loss 3.467, d_loss 0.049\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 5 Batch 363/390 d_loss_real= 0.027, d_loss_fake= 0.029, g_loss 3.688, d_loss 0.028\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 5 Batch 364/390 d_loss_real= 0.035, d_loss_fake= 0.024, g_loss 3.877, d_loss 0.029\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 5 Batch 365/390 d_loss_real= 0.049, d_loss_fake= 0.021, g_loss 3.992, d_loss 0.035\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 366/390 d_loss_real= 0.062, d_loss_fake= 0.020, g_loss 4.022, d_loss 0.041\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 367/390 d_loss_real= 0.049, d_loss_fake= 0.020, g_loss 3.968, d_loss 0.035\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 368/390 d_loss_real= 0.023, d_loss_fake= 0.023, g_loss 3.836, d_loss 0.023\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 369/390 d_loss_real= 0.145, d_loss_fake= 0.034, g_loss 3.475, d_loss 0.089\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 370/390 d_loss_real= 0.039, d_loss_fake= 0.053, g_loss 3.099, d_loss 0.046\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 5 Batch 371/390 d_loss_real= 0.031, d_loss_fake= 0.092, g_loss 2.664, d_loss 0.061\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 372/390 d_loss_real= 0.051, d_loss_fake= 0.065, g_loss 3.046, d_loss 0.058\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 5 Batch 373/390 d_loss_real= 0.050, d_loss_fake= 0.041, g_loss 3.502, d_loss 0.045\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 374/390 d_loss_real= 0.057, d_loss_fake= 0.026, g_loss 3.893, d_loss 0.042\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 5 Batch 375/390 d_loss_real= 0.055, d_loss_fake= 0.018, g_loss 4.219, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 376/390 d_loss_real= 0.054, d_loss_fake= 0.013, g_loss 4.486, d_loss 0.034\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 377/390 d_loss_real= 0.050, d_loss_fake= 0.011, g_loss 4.655, d_loss 0.030\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 378/390 d_loss_real= 0.063, d_loss_fake= 0.010, g_loss 4.676, d_loss 0.036\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5 Batch 379/390 d_loss_real= 0.091, d_loss_fake= 0.013, g_loss 4.380, d_loss 0.052\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 380/390 d_loss_real= 0.046, d_loss_fake= 0.014, g_loss 4.306, d_loss 0.030\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 381/390 d_loss_real= 0.050, d_loss_fake= 0.015, g_loss 4.219, d_loss 0.033\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 382/390 d_loss_real= 0.033, d_loss_fake= 0.019, g_loss 4.026, d_loss 0.026\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 383/390 d_loss_real= 0.038, d_loss_fake= 0.026, g_loss 3.760, d_loss 0.032\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 384/390 d_loss_real= 0.040, d_loss_fake= 0.103, g_loss 2.579, d_loss 0.072\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 5 Batch 385/390 d_loss_real= 0.034, d_loss_fake= 0.292, g_loss 1.885, d_loss 0.163\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 5 Batch 386/390 d_loss_real= 0.063, d_loss_fake= 0.352, g_loss 1.922, d_loss 0.207\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 5 Batch 387/390 d_loss_real= 0.051, d_loss_fake= 0.425, g_loss 1.993, d_loss 0.238\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5 Batch 388/390 d_loss_real= 0.106, d_loss_fake= 0.082, g_loss 3.590, d_loss 0.094\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5 Batch 389/390 d_loss_real= 0.205, d_loss_fake= 0.022, g_loss 4.617, d_loss 0.113\n",
            "2/2 [==============================] - 0s 13ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 Batch 390/390 d_loss_real= 0.408, d_loss_fake= 0.011, g_loss 4.942, d_loss 0.209\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 6 Batch 1/390 d_loss_real= 0.252, d_loss_fake= 0.008, g_loss 5.022, d_loss 0.130\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 2/390 d_loss_real= 0.219, d_loss_fake= 0.007, g_loss 4.987, d_loss 0.113\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 3/390 d_loss_real= 0.154, d_loss_fake= 0.008, g_loss 4.866, d_loss 0.081\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 6 Batch 4/390 d_loss_real= 0.101, d_loss_fake= 0.010, g_loss 4.571, d_loss 0.055\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 5/390 d_loss_real= 0.042, d_loss_fake= 0.016, g_loss 4.103, d_loss 0.029\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 6/390 d_loss_real= 0.025, d_loss_fake= 0.020, g_loss 3.921, d_loss 0.022\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 7/390 d_loss_real= 0.041, d_loss_fake= 0.021, g_loss 3.884, d_loss 0.031\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 8/390 d_loss_real= 0.020, d_loss_fake= 0.022, g_loss 3.872, d_loss 0.021\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 9/390 d_loss_real= 0.024, d_loss_fake= 0.023, g_loss 3.851, d_loss 0.023\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 6 Batch 10/390 d_loss_real= 0.025, d_loss_fake= 0.020, g_loss 3.972, d_loss 0.023\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 11/390 d_loss_real= 0.020, d_loss_fake= 0.019, g_loss 4.027, d_loss 0.020\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 12/390 d_loss_real= 0.014, d_loss_fake= 0.019, g_loss 4.024, d_loss 0.017\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 13/390 d_loss_real= 0.014, d_loss_fake= 0.023, g_loss 3.886, d_loss 0.018\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 14/390 d_loss_real= 0.013, d_loss_fake= 0.023, g_loss 3.897, d_loss 0.018\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 15/390 d_loss_real= 0.012, d_loss_fake= 0.027, g_loss 3.746, d_loss 0.019\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 16/390 d_loss_real= 0.014, d_loss_fake= 0.027, g_loss 3.753, d_loss 0.020\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 17/390 d_loss_real= 0.017, d_loss_fake= 0.031, g_loss 3.624, d_loss 0.024\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 18/390 d_loss_real= 0.018, d_loss_fake= 0.117, g_loss 2.493, d_loss 0.067\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 19/390 d_loss_real= 0.013, d_loss_fake= 0.106, g_loss 2.701, d_loss 0.060\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 20/390 d_loss_real= 0.011, d_loss_fake= 0.069, g_loss 3.158, d_loss 0.040\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 21/390 d_loss_real= 0.014, d_loss_fake= 0.043, g_loss 3.613, d_loss 0.029\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 22/390 d_loss_real= 0.054, d_loss_fake= 0.022, g_loss 4.225, d_loss 0.038\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 23/390 d_loss_real= 0.055, d_loss_fake= 0.025, g_loss 4.007, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 24/390 d_loss_real= 0.049, d_loss_fake= 0.038, g_loss 3.571, d_loss 0.043\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 25/390 d_loss_real= 0.053, d_loss_fake= 0.055, g_loss 3.177, d_loss 0.054\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 6 Batch 26/390 d_loss_real= 0.079, d_loss_fake= 0.118, g_loss 2.514, d_loss 0.099\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 27/390 d_loss_real= 0.061, d_loss_fake= 0.766, g_loss 1.006, d_loss 0.414\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 6 Batch 28/390 d_loss_real= 0.090, d_loss_fake= 0.493, g_loss 1.567, d_loss 0.291\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 29/390 d_loss_real= 0.275, d_loss_fake= 0.183, g_loss 2.476, d_loss 0.229\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 30/390 d_loss_real= 0.455, d_loss_fake= 0.130, g_loss 2.540, d_loss 0.293\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 31/390 d_loss_real= 0.638, d_loss_fake= 0.378, g_loss 1.475, d_loss 0.508\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 32/390 d_loss_real= 0.630, d_loss_fake= 0.693, g_loss 1.070, d_loss 0.662\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 6 Batch 33/390 d_loss_real= 0.600, d_loss_fake= 0.386, g_loss 1.547, d_loss 0.493\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 34/390 d_loss_real= 0.827, d_loss_fake= 0.260, g_loss 1.655, d_loss 0.544\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 35/390 d_loss_real= 0.654, d_loss_fake= 0.286, g_loss 1.433, d_loss 0.470\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 36/390 d_loss_real= 0.467, d_loss_fake= 0.374, g_loss 1.232, d_loss 0.420\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 37/390 d_loss_real= 0.204, d_loss_fake= 0.387, g_loss 1.350, d_loss 0.296\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 38/390 d_loss_real= 0.240, d_loss_fake= 0.287, g_loss 1.681, d_loss 0.264\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 39/390 d_loss_real= 0.278, d_loss_fake= 0.194, g_loss 1.957, d_loss 0.236\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 40/390 d_loss_real= 0.391, d_loss_fake= 0.157, g_loss 2.047, d_loss 0.274\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 6 Batch 41/390 d_loss_real= 0.293, d_loss_fake= 0.159, g_loss 1.966, d_loss 0.226\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 42/390 d_loss_real= 0.233, d_loss_fake= 0.178, g_loss 1.866, d_loss 0.206\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 43/390 d_loss_real= 0.214, d_loss_fake= 0.194, g_loss 1.857, d_loss 0.204\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 44/390 d_loss_real= 0.162, d_loss_fake= 0.172, g_loss 2.046, d_loss 0.167\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 45/390 d_loss_real= 0.215, d_loss_fake= 0.137, g_loss 2.238, d_loss 0.176\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 46/390 d_loss_real= 0.170, d_loss_fake= 0.110, g_loss 2.408, d_loss 0.140\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 47/390 d_loss_real= 0.253, d_loss_fake= 0.100, g_loss 2.437, d_loss 0.176\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 48/390 d_loss_real= 0.172, d_loss_fake= 0.099, g_loss 2.435, d_loss 0.135\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 49/390 d_loss_real= 0.217, d_loss_fake= 0.105, g_loss 2.344, d_loss 0.161\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 50/390 d_loss_real= 0.147, d_loss_fake= 0.112, g_loss 2.330, d_loss 0.129\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 6 Batch 51/390 d_loss_real= 0.100, d_loss_fake= 0.106, g_loss 2.454, d_loss 0.103\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 52/390 d_loss_real= 0.101, d_loss_fake= 0.088, g_loss 2.626, d_loss 0.095\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 53/390 d_loss_real= 0.257, d_loss_fake= 0.076, g_loss 2.703, d_loss 0.167\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 54/390 d_loss_real= 0.137, d_loss_fake= 0.073, g_loss 2.690, d_loss 0.105\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 55/390 d_loss_real= 0.111, d_loss_fake= 0.076, g_loss 2.647, d_loss 0.093\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 56/390 d_loss_real= 0.209, d_loss_fake= 0.086, g_loss 2.496, d_loss 0.147\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 6 Batch 57/390 d_loss_real= 0.153, d_loss_fake= 0.101, g_loss 2.380, d_loss 0.127\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 58/390 d_loss_real= 0.133, d_loss_fake= 0.115, g_loss 2.315, d_loss 0.124\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 59/390 d_loss_real= 0.082, d_loss_fake= 0.105, g_loss 2.487, d_loss 0.094\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 60/390 d_loss_real= 0.040, d_loss_fake= 0.077, g_loss 2.779, d_loss 0.059\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 61/390 d_loss_real= 0.125, d_loss_fake= 0.061, g_loss 2.936, d_loss 0.093\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 62/390 d_loss_real= 0.121, d_loss_fake= 0.055, g_loss 2.982, d_loss 0.088\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 63/390 d_loss_real= 0.197, d_loss_fake= 0.057, g_loss 2.863, d_loss 0.127\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 64/390 d_loss_real= 0.155, d_loss_fake= 0.069, g_loss 2.667, d_loss 0.112\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 65/390 d_loss_real= 0.058, d_loss_fake= 0.083, g_loss 2.602, d_loss 0.071\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 6 Batch 66/390 d_loss_real= 0.034, d_loss_fake= 0.076, g_loss 2.791, d_loss 0.055\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 67/390 d_loss_real= 0.097, d_loss_fake= 0.061, g_loss 2.944, d_loss 0.079\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 68/390 d_loss_real= 0.132, d_loss_fake= 0.054, g_loss 2.998, d_loss 0.093\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 69/390 d_loss_real= 0.161, d_loss_fake= 0.054, g_loss 2.962, d_loss 0.108\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 70/390 d_loss_real= 0.081, d_loss_fake= 0.059, g_loss 2.882, d_loss 0.070\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 71/390 d_loss_real= 0.095, d_loss_fake= 0.066, g_loss 2.783, d_loss 0.080\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 72/390 d_loss_real= 0.101, d_loss_fake= 0.073, g_loss 2.709, d_loss 0.087\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 73/390 d_loss_real= 0.082, d_loss_fake= 0.073, g_loss 2.788, d_loss 0.078\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 74/390 d_loss_real= 0.052, d_loss_fake= 0.061, g_loss 2.978, d_loss 0.056\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 75/390 d_loss_real= 0.109, d_loss_fake= 0.052, g_loss 3.059, d_loss 0.080\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 76/390 d_loss_real= 0.128, d_loss_fake= 0.050, g_loss 3.039, d_loss 0.089\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 77/390 d_loss_real= 0.085, d_loss_fake= 0.054, g_loss 2.931, d_loss 0.069\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 78/390 d_loss_real= 0.026, d_loss_fake= 0.058, g_loss 2.962, d_loss 0.042\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 79/390 d_loss_real= 0.048, d_loss_fake= 0.053, g_loss 3.058, d_loss 0.050\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 6 Batch 80/390 d_loss_real= 0.061, d_loss_fake= 0.047, g_loss 3.144, d_loss 0.054\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 81/390 d_loss_real= 0.095, d_loss_fake= 0.046, g_loss 3.137, d_loss 0.070\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 82/390 d_loss_real= 0.032, d_loss_fake= 0.045, g_loss 3.171, d_loss 0.038\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 83/390 d_loss_real= 0.115, d_loss_fake= 0.047, g_loss 3.096, d_loss 0.081\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 84/390 d_loss_real= 0.061, d_loss_fake= 0.050, g_loss 3.083, d_loss 0.056\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 85/390 d_loss_real= 0.071, d_loss_fake= 0.050, g_loss 3.109, d_loss 0.060\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 86/390 d_loss_real= 0.068, d_loss_fake= 0.047, g_loss 3.152, d_loss 0.057\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 6 Batch 87/390 d_loss_real= 0.074, d_loss_fake= 0.046, g_loss 3.176, d_loss 0.060\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 88/390 d_loss_real= 0.066, d_loss_fake= 0.045, g_loss 3.188, d_loss 0.055\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 89/390 d_loss_real= 0.137, d_loss_fake= 0.048, g_loss 3.084, d_loss 0.092\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 90/390 d_loss_real= 0.059, d_loss_fake= 0.052, g_loss 3.051, d_loss 0.055\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 6 Batch 91/390 d_loss_real= 0.058, d_loss_fake= 0.050, g_loss 3.108, d_loss 0.054\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 6 Batch 92/390 d_loss_real= 0.086, d_loss_fake= 0.049, g_loss 3.080, d_loss 0.068\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 93/390 d_loss_real= 0.044, d_loss_fake= 0.047, g_loss 3.155, d_loss 0.045\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 94/390 d_loss_real= 0.025, d_loss_fake= 0.042, g_loss 3.261, d_loss 0.034\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 95/390 d_loss_real= 0.041, d_loss_fake= 0.039, g_loss 3.334, d_loss 0.040\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 96/390 d_loss_real= 0.048, d_loss_fake= 0.036, g_loss 3.379, d_loss 0.042\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 97/390 d_loss_real= 0.092, d_loss_fake= 0.037, g_loss 3.328, d_loss 0.064\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 98/390 d_loss_real= 0.062, d_loss_fake= 0.041, g_loss 3.209, d_loss 0.052\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 99/390 d_loss_real= 0.052, d_loss_fake= 0.047, g_loss 3.137, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 100/390 d_loss_real= 0.026, d_loss_fake= 0.045, g_loss 3.260, d_loss 0.035\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 101/390 d_loss_real= 0.039, d_loss_fake= 0.038, g_loss 3.403, d_loss 0.038\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 102/390 d_loss_real= 0.026, d_loss_fake= 0.032, g_loss 3.533, d_loss 0.029\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 103/390 d_loss_real= 0.074, d_loss_fake= 0.029, g_loss 3.582, d_loss 0.052\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 104/390 d_loss_real= 0.029, d_loss_fake= 0.028, g_loss 3.634, d_loss 0.028\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 105/390 d_loss_real= 0.055, d_loss_fake= 0.027, g_loss 3.621, d_loss 0.041\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 106/390 d_loss_real= 0.039, d_loss_fake= 0.029, g_loss 3.576, d_loss 0.034\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 107/390 d_loss_real= 0.041, d_loss_fake= 0.030, g_loss 3.539, d_loss 0.036\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 108/390 d_loss_real= 0.097, d_loss_fake= 0.036, g_loss 3.312, d_loss 0.066\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 109/390 d_loss_real= 0.057, d_loss_fake= 0.044, g_loss 3.193, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 110/390 d_loss_real= 0.025, d_loss_fake= 0.043, g_loss 3.341, d_loss 0.034\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 111/390 d_loss_real= 0.022, d_loss_fake= 0.033, g_loss 3.582, d_loss 0.028\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 112/390 d_loss_real= 0.066, d_loss_fake= 0.028, g_loss 3.686, d_loss 0.047\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 113/390 d_loss_real= 0.069, d_loss_fake= 0.026, g_loss 3.665, d_loss 0.048\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 114/390 d_loss_real= 0.050, d_loss_fake= 0.028, g_loss 3.601, d_loss 0.039\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 115/390 d_loss_real= 0.031, d_loss_fake= 0.029, g_loss 3.577, d_loss 0.030\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 116/390 d_loss_real= 0.032, d_loss_fake= 0.029, g_loss 3.604, d_loss 0.031\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 117/390 d_loss_real= 0.040, d_loss_fake= 0.029, g_loss 3.608, d_loss 0.034\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 118/390 d_loss_real= 0.168, d_loss_fake= 0.034, g_loss 3.349, d_loss 0.101\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 119/390 d_loss_real= 0.092, d_loss_fake= 0.046, g_loss 3.095, d_loss 0.069\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 120/390 d_loss_real= 0.017, d_loss_fake= 0.049, g_loss 3.207, d_loss 0.033\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 121/390 d_loss_real= 0.023, d_loss_fake= 0.038, g_loss 3.483, d_loss 0.030\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 122/390 d_loss_real= 0.126, d_loss_fake= 0.032, g_loss 3.488, d_loss 0.079\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 6 Batch 123/390 d_loss_real= 0.047, d_loss_fake= 0.032, g_loss 3.472, d_loss 0.040\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 124/390 d_loss_real= 0.052, d_loss_fake= 0.033, g_loss 3.445, d_loss 0.042\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 125/390 d_loss_real= 0.071, d_loss_fake= 0.037, g_loss 3.276, d_loss 0.054\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 126/390 d_loss_real= 0.015, d_loss_fake= 0.041, g_loss 3.285, d_loss 0.028\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 127/390 d_loss_real= 0.040, d_loss_fake= 0.039, g_loss 3.358, d_loss 0.039\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 128/390 d_loss_real= 0.039, d_loss_fake= 0.036, g_loss 3.420, d_loss 0.037\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 129/390 d_loss_real= 0.056, d_loss_fake= 0.034, g_loss 3.466, d_loss 0.045\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 130/390 d_loss_real= 0.018, d_loss_fake= 0.031, g_loss 3.565, d_loss 0.024\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 131/390 d_loss_real= 0.023, d_loss_fake= 0.028, g_loss 3.659, d_loss 0.026\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 132/390 d_loss_real= 0.024, d_loss_fake= 0.025, g_loss 3.738, d_loss 0.025\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 133/390 d_loss_real= 0.079, d_loss_fake= 0.025, g_loss 3.658, d_loss 0.052\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 134/390 d_loss_real= 0.027, d_loss_fake= 0.029, g_loss 3.557, d_loss 0.028\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 6 Batch 135/390 d_loss_real= 0.049, d_loss_fake= 0.031, g_loss 3.563, d_loss 0.040\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 6 Batch 136/390 d_loss_real= 0.014, d_loss_fake= 0.028, g_loss 3.711, d_loss 0.021\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 6 Batch 137/390 d_loss_real= 0.024, d_loss_fake= 0.024, g_loss 3.857, d_loss 0.024\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 138/390 d_loss_real= 0.029, d_loss_fake= 0.021, g_loss 3.919, d_loss 0.025\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 139/390 d_loss_real= 0.021, d_loss_fake= 0.020, g_loss 3.962, d_loss 0.020\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 140/390 d_loss_real= 0.080, d_loss_fake= 0.021, g_loss 3.861, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 141/390 d_loss_real= 0.040, d_loss_fake= 0.023, g_loss 3.756, d_loss 0.032\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 142/390 d_loss_real= 0.033, d_loss_fake= 0.026, g_loss 3.663, d_loss 0.030\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 6 Batch 143/390 d_loss_real= 0.027, d_loss_fake= 0.028, g_loss 3.652, d_loss 0.028\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 144/390 d_loss_real= 0.023, d_loss_fake= 0.026, g_loss 3.748, d_loss 0.025\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 6 Batch 145/390 d_loss_real= 0.030, d_loss_fake= 0.024, g_loss 3.834, d_loss 0.027\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 146/390 d_loss_real= 0.015, d_loss_fake= 0.021, g_loss 3.946, d_loss 0.018\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 147/390 d_loss_real= 0.041, d_loss_fake= 0.020, g_loss 3.966, d_loss 0.030\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 148/390 d_loss_real= 0.077, d_loss_fake= 0.021, g_loss 3.812, d_loss 0.049\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 149/390 d_loss_real= 0.020, d_loss_fake= 0.025, g_loss 3.723, d_loss 0.023\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 150/390 d_loss_real= 0.057, d_loss_fake= 0.029, g_loss 3.557, d_loss 0.043\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 151/390 d_loss_real= 0.047, d_loss_fake= 0.031, g_loss 3.565, d_loss 0.039\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 152/390 d_loss_real= 0.016, d_loss_fake= 0.028, g_loss 3.713, d_loss 0.022\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 153/390 d_loss_real= 0.110, d_loss_fake= 0.024, g_loss 3.833, d_loss 0.067\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 154/390 d_loss_real= 0.019, d_loss_fake= 0.021, g_loss 3.949, d_loss 0.020\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 155/390 d_loss_real= 0.070, d_loss_fake= 0.021, g_loss 3.884, d_loss 0.045\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 156/390 d_loss_real= 0.038, d_loss_fake= 0.022, g_loss 3.802, d_loss 0.030\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 157/390 d_loss_real= 0.033, d_loss_fake= 0.024, g_loss 3.742, d_loss 0.029\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 6 Batch 158/390 d_loss_real= 0.007, d_loss_fake= 0.024, g_loss 3.808, d_loss 0.016\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 159/390 d_loss_real= 0.013, d_loss_fake= 0.022, g_loss 3.905, d_loss 0.017\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 160/390 d_loss_real= 0.087, d_loss_fake= 0.022, g_loss 3.801, d_loss 0.055\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 161/390 d_loss_real= 0.030, d_loss_fake= 0.026, g_loss 3.663, d_loss 0.028\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 162/390 d_loss_real= 0.010, d_loss_fake= 0.027, g_loss 3.730, d_loss 0.018\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 163/390 d_loss_real= 0.042, d_loss_fake= 0.025, g_loss 3.767, d_loss 0.034\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 164/390 d_loss_real= 0.006, d_loss_fake= 0.022, g_loss 3.897, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 165/390 d_loss_real= 0.013, d_loss_fake= 0.019, g_loss 4.029, d_loss 0.016\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 166/390 d_loss_real= 0.032, d_loss_fake= 0.018, g_loss 4.105, d_loss 0.025\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 167/390 d_loss_real= 0.021, d_loss_fake= 0.017, g_loss 4.143, d_loss 0.019\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 168/390 d_loss_real= 0.024, d_loss_fake= 0.016, g_loss 4.150, d_loss 0.020\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 169/390 d_loss_real= 0.026, d_loss_fake= 0.017, g_loss 4.099, d_loss 0.021\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 6 Batch 170/390 d_loss_real= 0.033, d_loss_fake= 0.018, g_loss 3.987, d_loss 0.026\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 171/390 d_loss_real= 0.032, d_loss_fake= 0.020, g_loss 3.923, d_loss 0.026\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 172/390 d_loss_real= 0.021, d_loss_fake= 0.021, g_loss 3.945, d_loss 0.021\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 173/390 d_loss_real= 0.023, d_loss_fake= 0.020, g_loss 4.008, d_loss 0.021\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 174/390 d_loss_real= 0.026, d_loss_fake= 0.019, g_loss 4.032, d_loss 0.022\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 175/390 d_loss_real= 0.085, d_loss_fake= 0.020, g_loss 3.914, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 176/390 d_loss_real= 0.022, d_loss_fake= 0.022, g_loss 3.879, d_loss 0.022\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 177/390 d_loss_real= 0.016, d_loss_fake= 0.021, g_loss 3.928, d_loss 0.019\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 178/390 d_loss_real= 0.020, d_loss_fake= 0.020, g_loss 3.994, d_loss 0.020\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 179/390 d_loss_real= 0.013, d_loss_fake= 0.018, g_loss 4.105, d_loss 0.015\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 180/390 d_loss_real= 0.010, d_loss_fake= 0.016, g_loss 4.233, d_loss 0.013\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 181/390 d_loss_real= 0.047, d_loss_fake= 0.015, g_loss 4.245, d_loss 0.031\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 182/390 d_loss_real= 0.023, d_loss_fake= 0.015, g_loss 4.206, d_loss 0.019\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 6 Batch 183/390 d_loss_real= 0.014, d_loss_fake= 0.016, g_loss 4.175, d_loss 0.015\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 184/390 d_loss_real= 0.024, d_loss_fake= 0.016, g_loss 4.144, d_loss 0.020\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 185/390 d_loss_real= 0.020, d_loss_fake= 0.017, g_loss 4.160, d_loss 0.018\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 186/390 d_loss_real= 0.028, d_loss_fake= 0.017, g_loss 4.122, d_loss 0.022\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 187/390 d_loss_real= 0.035, d_loss_fake= 0.019, g_loss 3.976, d_loss 0.027\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 188/390 d_loss_real= 0.006, d_loss_fake= 0.020, g_loss 4.009, d_loss 0.013\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 6 Batch 189/390 d_loss_real= 0.016, d_loss_fake= 0.018, g_loss 4.087, d_loss 0.017\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 190/390 d_loss_real= 0.012, d_loss_fake= 0.017, g_loss 4.187, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 191/390 d_loss_real= 0.113, d_loss_fake= 0.017, g_loss 4.093, d_loss 0.065\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 6 Batch 192/390 d_loss_real= 0.038, d_loss_fake= 0.020, g_loss 3.911, d_loss 0.029\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 193/390 d_loss_real= 0.028, d_loss_fake= 0.023, g_loss 3.834, d_loss 0.025\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 194/390 d_loss_real= 0.011, d_loss_fake= 0.022, g_loss 3.956, d_loss 0.016\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 195/390 d_loss_real= 0.013, d_loss_fake= 0.018, g_loss 4.110, d_loss 0.016\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 196/390 d_loss_real= 0.020, d_loss_fake= 0.016, g_loss 4.201, d_loss 0.018\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 197/390 d_loss_real= 0.011, d_loss_fake= 0.015, g_loss 4.297, d_loss 0.013\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 198/390 d_loss_real= 0.016, d_loss_fake= 0.013, g_loss 4.357, d_loss 0.015\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 199/390 d_loss_real= 0.011, d_loss_fake= 0.013, g_loss 4.414, d_loss 0.012\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 200/390 d_loss_real= 0.022, d_loss_fake= 0.012, g_loss 4.461, d_loss 0.017\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 201/390 d_loss_real= 0.015, d_loss_fake= 0.012, g_loss 4.488, d_loss 0.013\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 6 Batch 202/390 d_loss_real= 0.037, d_loss_fake= 0.012, g_loss 4.394, d_loss 0.025\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 203/390 d_loss_real= 0.049, d_loss_fake= 0.015, g_loss 4.136, d_loss 0.032\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 204/390 d_loss_real= 0.010, d_loss_fake= 0.019, g_loss 3.993, d_loss 0.014\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 205/390 d_loss_real= 0.027, d_loss_fake= 0.021, g_loss 3.895, d_loss 0.024\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 206/390 d_loss_real= 0.012, d_loss_fake= 0.021, g_loss 3.999, d_loss 0.016\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 207/390 d_loss_real= 0.011, d_loss_fake= 0.018, g_loss 4.195, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 208/390 d_loss_real= 0.023, d_loss_fake= 0.015, g_loss 4.277, d_loss 0.019\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 209/390 d_loss_real= 0.014, d_loss_fake= 0.013, g_loss 4.381, d_loss 0.013\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 210/390 d_loss_real= 0.018, d_loss_fake= 0.012, g_loss 4.440, d_loss 0.015\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 211/390 d_loss_real= 0.049, d_loss_fake= 0.013, g_loss 4.328, d_loss 0.031\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 212/390 d_loss_real= 0.007, d_loss_fake= 0.014, g_loss 4.271, d_loss 0.011\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 213/390 d_loss_real= 0.033, d_loss_fake= 0.016, g_loss 4.112, d_loss 0.025\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 6 Batch 214/390 d_loss_real= 0.011, d_loss_fake= 0.018, g_loss 4.061, d_loss 0.015\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 215/390 d_loss_real= 0.020, d_loss_fake= 0.018, g_loss 4.160, d_loss 0.019\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 216/390 d_loss_real= 0.012, d_loss_fake= 0.015, g_loss 4.348, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 217/390 d_loss_real= 0.008, d_loss_fake= 0.012, g_loss 4.477, d_loss 0.010\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 218/390 d_loss_real= 0.007, d_loss_fake= 0.011, g_loss 4.583, d_loss 0.009\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 6 Batch 219/390 d_loss_real= 0.037, d_loss_fake= 0.010, g_loss 4.601, d_loss 0.024\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 6 Batch 220/390 d_loss_real= 0.013, d_loss_fake= 0.010, g_loss 4.601, d_loss 0.012\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 6 Batch 221/390 d_loss_real= 0.036, d_loss_fake= 0.010, g_loss 4.548, d_loss 0.023\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 6 Batch 222/390 d_loss_real= 0.008, d_loss_fake= 0.011, g_loss 4.507, d_loss 0.009\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 6 Batch 223/390 d_loss_real= 0.015, d_loss_fake= 0.012, g_loss 4.397, d_loss 0.013\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 224/390 d_loss_real= 0.011, d_loss_fake= 0.013, g_loss 4.334, d_loss 0.012\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 6 Batch 225/390 d_loss_real= 0.024, d_loss_fake= 0.014, g_loss 4.308, d_loss 0.019\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 226/390 d_loss_real= 0.017, d_loss_fake= 0.014, g_loss 4.364, d_loss 0.016\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 227/390 d_loss_real= 0.009, d_loss_fake= 0.012, g_loss 4.477, d_loss 0.011\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 228/390 d_loss_real= 0.011, d_loss_fake= 0.011, g_loss 4.594, d_loss 0.011\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 229/390 d_loss_real= 0.004, d_loss_fake= 0.010, g_loss 4.704, d_loss 0.007\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 230/390 d_loss_real= 0.009, d_loss_fake= 0.009, g_loss 4.795, d_loss 0.009\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 231/390 d_loss_real= 0.062, d_loss_fake= 0.009, g_loss 4.696, d_loss 0.035\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 232/390 d_loss_real= 0.023, d_loss_fake= 0.010, g_loss 4.539, d_loss 0.016\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 233/390 d_loss_real= 0.014, d_loss_fake= 0.013, g_loss 4.321, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 234/390 d_loss_real= 0.006, d_loss_fake= 0.015, g_loss 4.266, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 235/390 d_loss_real= 0.005, d_loss_fake= 0.014, g_loss 4.388, d_loss 0.010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 236/390 d_loss_real= 0.012, d_loss_fake= 0.012, g_loss 4.539, d_loss 0.012\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 237/390 d_loss_real= 0.034, d_loss_fake= 0.011, g_loss 4.577, d_loss 0.023\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 238/390 d_loss_real= 0.020, d_loss_fake= 0.011, g_loss 4.572, d_loss 0.015\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 6 Batch 239/390 d_loss_real= 0.013, d_loss_fake= 0.010, g_loss 4.604, d_loss 0.012\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 240/390 d_loss_real= 0.012, d_loss_fake= 0.010, g_loss 4.630, d_loss 0.011\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 241/390 d_loss_real= 0.006, d_loss_fake= 0.010, g_loss 4.686, d_loss 0.008\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 242/390 d_loss_real= 0.028, d_loss_fake= 0.010, g_loss 4.628, d_loss 0.019\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 243/390 d_loss_real= 0.010, d_loss_fake= 0.010, g_loss 4.585, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 244/390 d_loss_real= 0.025, d_loss_fake= 0.011, g_loss 4.487, d_loss 0.018\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 245/390 d_loss_real= 0.012, d_loss_fake= 0.012, g_loss 4.423, d_loss 0.012\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 6 Batch 246/390 d_loss_real= 0.010, d_loss_fake= 0.012, g_loss 4.476, d_loss 0.011\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 247/390 d_loss_real= 0.042, d_loss_fake= 0.013, g_loss 4.331, d_loss 0.028\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 248/390 d_loss_real= 0.005, d_loss_fake= 0.014, g_loss 4.348, d_loss 0.010\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 6 Batch 249/390 d_loss_real= 0.010, d_loss_fake= 0.013, g_loss 4.429, d_loss 0.011\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 250/390 d_loss_real= 0.009, d_loss_fake= 0.012, g_loss 4.552, d_loss 0.010\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 6 Batch 251/390 d_loss_real= 0.016, d_loss_fake= 0.010, g_loss 4.626, d_loss 0.013\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 252/390 d_loss_real= 0.012, d_loss_fake= 0.010, g_loss 4.682, d_loss 0.011\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 253/390 d_loss_real= 0.021, d_loss_fake= 0.010, g_loss 4.652, d_loss 0.015\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 254/390 d_loss_real= 0.018, d_loss_fake= 0.010, g_loss 4.594, d_loss 0.014\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 255/390 d_loss_real= 0.020, d_loss_fake= 0.011, g_loss 4.469, d_loss 0.016\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 6 Batch 256/390 d_loss_real= 0.008, d_loss_fake= 0.012, g_loss 4.475, d_loss 0.010\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 257/390 d_loss_real= 0.055, d_loss_fake= 0.013, g_loss 4.301, d_loss 0.034\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 258/390 d_loss_real= 0.006, d_loss_fake= 0.014, g_loss 4.337, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 259/390 d_loss_real= 0.007, d_loss_fake= 0.013, g_loss 4.457, d_loss 0.010\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 260/390 d_loss_real= 0.014, d_loss_fake= 0.011, g_loss 4.539, d_loss 0.013\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 261/390 d_loss_real= 0.003, d_loss_fake= 0.010, g_loss 4.650, d_loss 0.007\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 262/390 d_loss_real= 0.022, d_loss_fake= 0.010, g_loss 4.696, d_loss 0.016\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 263/390 d_loss_real= 0.005, d_loss_fake= 0.009, g_loss 4.750, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 264/390 d_loss_real= 0.035, d_loss_fake= 0.009, g_loss 4.711, d_loss 0.022\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 265/390 d_loss_real= 0.005, d_loss_fake= 0.009, g_loss 4.696, d_loss 0.007\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 266/390 d_loss_real= 0.015, d_loss_fake= 0.010, g_loss 4.649, d_loss 0.012\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 267/390 d_loss_real= 0.011, d_loss_fake= 0.010, g_loss 4.634, d_loss 0.011\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 268/390 d_loss_real= 0.006, d_loss_fake= 0.010, g_loss 4.681, d_loss 0.008\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 269/390 d_loss_real= 0.009, d_loss_fake= 0.009, g_loss 4.750, d_loss 0.009\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 6 Batch 270/390 d_loss_real= 0.014, d_loss_fake= 0.009, g_loss 4.782, d_loss 0.011\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 271/390 d_loss_real= 0.019, d_loss_fake= 0.009, g_loss 4.733, d_loss 0.014\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 6 Batch 272/390 d_loss_real= 0.008, d_loss_fake= 0.009, g_loss 4.742, d_loss 0.009\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 6 Batch 273/390 d_loss_real= 0.009, d_loss_fake= 0.009, g_loss 4.773, d_loss 0.009\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 274/390 d_loss_real= 0.006, d_loss_fake= 0.008, g_loss 4.827, d_loss 0.007\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 6 Batch 275/390 d_loss_real= 0.016, d_loss_fake= 0.008, g_loss 4.843, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 276/390 d_loss_real= 0.004, d_loss_fake= 0.008, g_loss 4.884, d_loss 0.006\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 277/390 d_loss_real= 0.033, d_loss_fake= 0.008, g_loss 4.769, d_loss 0.021\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 278/390 d_loss_real= 0.009, d_loss_fake= 0.009, g_loss 4.679, d_loss 0.009\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 279/390 d_loss_real= 0.014, d_loss_fake= 0.010, g_loss 4.606, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 280/390 d_loss_real= 0.010, d_loss_fake= 0.010, g_loss 4.622, d_loss 0.010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 281/390 d_loss_real= 0.005, d_loss_fake= 0.010, g_loss 4.726, d_loss 0.007\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 282/390 d_loss_real= 0.007, d_loss_fake= 0.009, g_loss 4.823, d_loss 0.008\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 283/390 d_loss_real= 0.023, d_loss_fake= 0.008, g_loss 4.849, d_loss 0.016\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 284/390 d_loss_real= 0.020, d_loss_fake= 0.008, g_loss 4.811, d_loss 0.014\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 6 Batch 285/390 d_loss_real= 0.012, d_loss_fake= 0.009, g_loss 4.763, d_loss 0.010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 286/390 d_loss_real= 0.011, d_loss_fake= 0.009, g_loss 4.736, d_loss 0.010\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 287/390 d_loss_real= 0.026, d_loss_fake= 0.010, g_loss 4.595, d_loss 0.018\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 288/390 d_loss_real= 0.010, d_loss_fake= 0.011, g_loss 4.541, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 289/390 d_loss_real= 0.011, d_loss_fake= 0.011, g_loss 4.582, d_loss 0.011\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 290/390 d_loss_real= 0.005, d_loss_fake= 0.010, g_loss 4.726, d_loss 0.007\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 291/390 d_loss_real= 0.010, d_loss_fake= 0.009, g_loss 4.828, d_loss 0.009\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 292/390 d_loss_real= 0.007, d_loss_fake= 0.008, g_loss 4.912, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 293/390 d_loss_real= 0.019, d_loss_fake= 0.007, g_loss 4.934, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 294/390 d_loss_real= 0.090, d_loss_fake= 0.008, g_loss 4.850, d_loss 0.049\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 6 Batch 295/390 d_loss_real= 0.013, d_loss_fake= 0.008, g_loss 4.747, d_loss 0.011\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 6 Batch 296/390 d_loss_real= 0.013, d_loss_fake= 0.009, g_loss 4.691, d_loss 0.011\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 6 Batch 297/390 d_loss_real= 0.012, d_loss_fake= 0.010, g_loss 4.686, d_loss 0.011\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 6 Batch 298/390 d_loss_real= 0.016, d_loss_fake= 0.010, g_loss 4.657, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 299/390 d_loss_real= 0.005, d_loss_fake= 0.009, g_loss 4.752, d_loss 0.007\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 6 Batch 300/390 d_loss_real= 0.007, d_loss_fake= 0.008, g_loss 4.856, d_loss 0.007\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 301/390 d_loss_real= 0.008, d_loss_fake= 0.008, g_loss 4.926, d_loss 0.008\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 302/390 d_loss_real= 0.013, d_loss_fake= 0.007, g_loss 4.926, d_loss 0.010\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 6 Batch 303/390 d_loss_real= 0.005, d_loss_fake= 0.007, g_loss 4.944, d_loss 0.006\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 304/390 d_loss_real= 0.011, d_loss_fake= 0.007, g_loss 4.935, d_loss 0.009\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 305/390 d_loss_real= 0.012, d_loss_fake= 0.008, g_loss 4.882, d_loss 0.010\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 306/390 d_loss_real= 0.011, d_loss_fake= 0.008, g_loss 4.845, d_loss 0.009\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 307/390 d_loss_real= 0.020, d_loss_fake= 0.008, g_loss 4.806, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 308/390 d_loss_real= 0.026, d_loss_fake= 0.009, g_loss 4.666, d_loss 0.018\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 309/390 d_loss_real= 0.003, d_loss_fake= 0.010, g_loss 4.715, d_loss 0.006\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 310/390 d_loss_real= 0.014, d_loss_fake= 0.009, g_loss 4.713, d_loss 0.012\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 6 Batch 311/390 d_loss_real= 0.045, d_loss_fake= 0.010, g_loss 4.519, d_loss 0.028\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 312/390 d_loss_real= 0.002, d_loss_fake= 0.012, g_loss 4.529, d_loss 0.007\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 6 Batch 313/390 d_loss_real= 0.003, d_loss_fake= 0.010, g_loss 4.664, d_loss 0.007\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 6 Batch 314/390 d_loss_real= 0.005, d_loss_fake= 0.009, g_loss 4.832, d_loss 0.007\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 315/390 d_loss_real= 0.018, d_loss_fake= 0.008, g_loss 4.926, d_loss 0.013\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 316/390 d_loss_real= 0.008, d_loss_fake= 0.007, g_loss 4.986, d_loss 0.007\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 317/390 d_loss_real= 0.015, d_loss_fake= 0.007, g_loss 4.987, d_loss 0.011\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 318/390 d_loss_real= 0.003, d_loss_fake= 0.007, g_loss 5.006, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 319/390 d_loss_real= 0.008, d_loss_fake= 0.007, g_loss 5.012, d_loss 0.008\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 6 Batch 320/390 d_loss_real= 0.008, d_loss_fake= 0.007, g_loss 5.013, d_loss 0.008\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 6 Batch 321/390 d_loss_real= 0.002, d_loss_fake= 0.007, g_loss 5.052, d_loss 0.004\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 6 Batch 322/390 d_loss_real= 0.017, d_loss_fake= 0.007, g_loss 5.018, d_loss 0.012\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 6 Batch 323/390 d_loss_real= 0.008, d_loss_fake= 0.007, g_loss 4.969, d_loss 0.007\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 324/390 d_loss_real= 0.018, d_loss_fake= 0.008, g_loss 4.845, d_loss 0.013\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 6 Batch 325/390 d_loss_real= 0.005, d_loss_fake= 0.008, g_loss 4.835, d_loss 0.007\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 6 Batch 326/390 d_loss_real= 0.003, d_loss_fake= 0.008, g_loss 4.929, d_loss 0.005\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 327/390 d_loss_real= 0.009, d_loss_fake= 0.007, g_loss 5.009, d_loss 0.008\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 328/390 d_loss_real= 0.007, d_loss_fake= 0.007, g_loss 5.084, d_loss 0.007\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 329/390 d_loss_real= 0.013, d_loss_fake= 0.006, g_loss 5.060, d_loss 0.010\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 330/390 d_loss_real= 0.016, d_loss_fake= 0.007, g_loss 5.016, d_loss 0.011\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 331/390 d_loss_real= 0.003, d_loss_fake= 0.007, g_loss 5.030, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 332/390 d_loss_real= 0.006, d_loss_fake= 0.007, g_loss 5.072, d_loss 0.006\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 333/390 d_loss_real= 0.003, d_loss_fake= 0.006, g_loss 5.130, d_loss 0.005\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 334/390 d_loss_real= 0.007, d_loss_fake= 0.006, g_loss 5.178, d_loss 0.006\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 335/390 d_loss_real= 0.003, d_loss_fake= 0.006, g_loss 5.235, d_loss 0.004\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 336/390 d_loss_real= 0.008, d_loss_fake= 0.005, g_loss 5.261, d_loss 0.007\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 337/390 d_loss_real= 0.023, d_loss_fake= 0.006, g_loss 5.127, d_loss 0.015\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 338/390 d_loss_real= 0.018, d_loss_fake= 0.007, g_loss 4.875, d_loss 0.013\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 339/390 d_loss_real= 0.003, d_loss_fake= 0.008, g_loss 4.780, d_loss 0.006\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 340/390 d_loss_real= 0.011, d_loss_fake= 0.009, g_loss 4.761, d_loss 0.010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 341/390 d_loss_real= 0.011, d_loss_fake= 0.009, g_loss 4.786, d_loss 0.010\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 6 Batch 342/390 d_loss_real= 0.003, d_loss_fake= 0.008, g_loss 4.914, d_loss 0.006\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 343/390 d_loss_real= 0.002, d_loss_fake= 0.007, g_loss 5.087, d_loss 0.004\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 6 Batch 344/390 d_loss_real= 0.003, d_loss_fake= 0.006, g_loss 5.233, d_loss 0.004\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 6 Batch 345/390 d_loss_real= 0.004, d_loss_fake= 0.005, g_loss 5.346, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 346/390 d_loss_real= 0.023, d_loss_fake= 0.005, g_loss 5.321, d_loss 0.014\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 347/390 d_loss_real= 0.019, d_loss_fake= 0.005, g_loss 5.273, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 348/390 d_loss_real= 0.013, d_loss_fake= 0.005, g_loss 5.178, d_loss 0.009\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 349/390 d_loss_real= 0.004, d_loss_fake= 0.006, g_loss 5.105, d_loss 0.005\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 6 Batch 350/390 d_loss_real= 0.006, d_loss_fake= 0.006, g_loss 5.068, d_loss 0.006\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 6 Batch 351/390 d_loss_real= 0.003, d_loss_fake= 0.006, g_loss 5.109, d_loss 0.005\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 352/390 d_loss_real= 0.004, d_loss_fake= 0.006, g_loss 5.196, d_loss 0.005\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 6 Batch 353/390 d_loss_real= 0.013, d_loss_fake= 0.006, g_loss 5.170, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 354/390 d_loss_real= 0.020, d_loss_fake= 0.006, g_loss 4.997, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 355/390 d_loss_real= 0.005, d_loss_fake= 0.007, g_loss 4.918, d_loss 0.006\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 356/390 d_loss_real= 0.007, d_loss_fake= 0.008, g_loss 4.916, d_loss 0.007\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 6 Batch 357/390 d_loss_real= 0.007, d_loss_fake= 0.007, g_loss 4.964, d_loss 0.007\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 358/390 d_loss_real= 0.019, d_loss_fake= 0.008, g_loss 4.871, d_loss 0.013\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 6 Batch 359/390 d_loss_real= 0.012, d_loss_fake= 0.009, g_loss 4.769, d_loss 0.010\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 360/390 d_loss_real= 0.004, d_loss_fake= 0.009, g_loss 4.821, d_loss 0.006\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 361/390 d_loss_real= 0.022, d_loss_fake= 0.009, g_loss 4.704, d_loss 0.015\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 362/390 d_loss_real= 0.024, d_loss_fake= 0.012, g_loss 4.405, d_loss 0.018\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 6 Batch 363/390 d_loss_real= 0.024, d_loss_fake= 0.016, g_loss 4.119, d_loss 0.020\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 6 Batch 364/390 d_loss_real= 0.001, d_loss_fake= 0.017, g_loss 4.260, d_loss 0.009\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 365/390 d_loss_real= 0.002, d_loss_fake= 0.013, g_loss 4.526, d_loss 0.007\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 366/390 d_loss_real= 0.003, d_loss_fake= 0.010, g_loss 4.808, d_loss 0.006\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 367/390 d_loss_real= 0.003, d_loss_fake= 0.007, g_loss 5.062, d_loss 0.005\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 6 Batch 368/390 d_loss_real= 0.006, d_loss_fake= 0.006, g_loss 5.257, d_loss 0.006\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 369/390 d_loss_real= 0.002, d_loss_fake= 0.005, g_loss 5.411, d_loss 0.004\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6 Batch 370/390 d_loss_real= 0.007, d_loss_fake= 0.004, g_loss 5.503, d_loss 0.006\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 371/390 d_loss_real= 0.012, d_loss_fake= 0.004, g_loss 5.538, d_loss 0.008\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 372/390 d_loss_real= 0.024, d_loss_fake= 0.004, g_loss 5.461, d_loss 0.014\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 6 Batch 373/390 d_loss_real= 0.008, d_loss_fake= 0.004, g_loss 5.369, d_loss 0.006\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 6 Batch 374/390 d_loss_real= 0.034, d_loss_fake= 0.005, g_loss 5.113, d_loss 0.020\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 375/390 d_loss_real= 0.009, d_loss_fake= 0.007, g_loss 4.790, d_loss 0.008\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 6 Batch 376/390 d_loss_real= 0.003, d_loss_fake= 0.010, g_loss 4.581, d_loss 0.006\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 377/390 d_loss_real= 0.008, d_loss_fake= 0.011, g_loss 4.573, d_loss 0.009\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 378/390 d_loss_real= 0.004, d_loss_fake= 0.010, g_loss 4.703, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 379/390 d_loss_real= 0.005, d_loss_fake= 0.008, g_loss 4.916, d_loss 0.007\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 380/390 d_loss_real= 0.002, d_loss_fake= 0.007, g_loss 5.114, d_loss 0.004\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6 Batch 381/390 d_loss_real= 0.003, d_loss_fake= 0.006, g_loss 5.286, d_loss 0.004\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 382/390 d_loss_real= 0.009, d_loss_fake= 0.005, g_loss 5.343, d_loss 0.007\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 383/390 d_loss_real= 0.022, d_loss_fake= 0.005, g_loss 5.249, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 384/390 d_loss_real= 0.021, d_loss_fake= 0.006, g_loss 5.029, d_loss 0.014\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6 Batch 385/390 d_loss_real= 0.015, d_loss_fake= 0.008, g_loss 4.722, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 386/390 d_loss_real= 0.002, d_loss_fake= 0.010, g_loss 4.661, d_loss 0.006\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 387/390 d_loss_real= 0.003, d_loss_fake= 0.009, g_loss 4.824, d_loss 0.006\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6 Batch 388/390 d_loss_real= 0.036, d_loss_fake= 0.009, g_loss 4.719, d_loss 0.023\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6 Batch 389/390 d_loss_real= 0.012, d_loss_fake= 0.010, g_loss 4.657, d_loss 0.011\n",
            "2/2 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 Batch 390/390 d_loss_real= 0.011, d_loss_fake= 0.010, g_loss 4.689, d_loss 0.010\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 1/390 d_loss_real= 0.007, d_loss_fake= 0.009, g_loss 4.839, d_loss 0.008\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 2/390 d_loss_real= 0.004, d_loss_fake= 0.007, g_loss 4.987, d_loss 0.006\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 3/390 d_loss_real= 0.012, d_loss_fake= 0.007, g_loss 5.077, d_loss 0.009\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 4/390 d_loss_real= 0.011, d_loss_fake= 0.006, g_loss 5.099, d_loss 0.009\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 5/390 d_loss_real= 0.026, d_loss_fake= 0.007, g_loss 4.976, d_loss 0.016\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7 Batch 6/390 d_loss_real= 0.009, d_loss_fake= 0.008, g_loss 4.837, d_loss 0.008\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 7/390 d_loss_real= 0.003, d_loss_fake= 0.008, g_loss 4.814, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 8/390 d_loss_real= 0.003, d_loss_fake= 0.008, g_loss 4.899, d_loss 0.006\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 9/390 d_loss_real= 0.004, d_loss_fake= 0.007, g_loss 5.040, d_loss 0.006\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 10/390 d_loss_real= 0.012, d_loss_fake= 0.006, g_loss 5.091, d_loss 0.009\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7 Batch 11/390 d_loss_real= 0.016, d_loss_fake= 0.006, g_loss 5.075, d_loss 0.011\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 12/390 d_loss_real= 0.022, d_loss_fake= 0.006, g_loss 5.114, d_loss 0.014\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7 Batch 13/390 d_loss_real= 0.003, d_loss_fake= 0.006, g_loss 5.180, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 14/390 d_loss_real= 0.047, d_loss_fake= 0.008, g_loss 4.538, d_loss 0.028\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 15/390 d_loss_real= 0.004, d_loss_fake= 0.015, g_loss 4.178, d_loss 0.010\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 16/390 d_loss_real= 0.004, d_loss_fake= 0.017, g_loss 4.292, d_loss 0.010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 17/390 d_loss_real= 0.004, d_loss_fake= 0.012, g_loss 4.706, d_loss 0.008\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 18/390 d_loss_real= 0.002, d_loss_fake= 0.008, g_loss 5.039, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 19/390 d_loss_real= 0.007, d_loss_fake= 0.006, g_loss 5.256, d_loss 0.006\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 20/390 d_loss_real= 0.012, d_loss_fake= 0.005, g_loss 5.403, d_loss 0.008\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7 Batch 21/390 d_loss_real= 0.007, d_loss_fake= 0.004, g_loss 5.517, d_loss 0.006\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 22/390 d_loss_real= 0.025, d_loss_fake= 0.004, g_loss 5.474, d_loss 0.015\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 23/390 d_loss_real= 0.012, d_loss_fake= 0.004, g_loss 5.415, d_loss 0.008\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7 Batch 24/390 d_loss_real= 0.004, d_loss_fake= 0.005, g_loss 5.376, d_loss 0.004\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 25/390 d_loss_real= 0.031, d_loss_fake= 0.005, g_loss 5.217, d_loss 0.018\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 26/390 d_loss_real= 0.018, d_loss_fake= 0.006, g_loss 4.977, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 27/390 d_loss_real= 0.002, d_loss_fake= 0.008, g_loss 4.812, d_loss 0.005\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7 Batch 28/390 d_loss_real= 0.002, d_loss_fake= 0.009, g_loss 4.785, d_loss 0.006\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 29/390 d_loss_real= 0.005, d_loss_fake= 0.009, g_loss 4.840, d_loss 0.007\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 30/390 d_loss_real= 0.005, d_loss_fake= 0.008, g_loss 4.958, d_loss 0.006\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 31/390 d_loss_real= 0.003, d_loss_fake= 0.007, g_loss 5.121, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 32/390 d_loss_real= 0.007, d_loss_fake= 0.006, g_loss 5.224, d_loss 0.006\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 33/390 d_loss_real= 0.012, d_loss_fake= 0.005, g_loss 5.233, d_loss 0.009\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7 Batch 34/390 d_loss_real= 0.007, d_loss_fake= 0.005, g_loss 5.228, d_loss 0.006\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 35/390 d_loss_real= 0.007, d_loss_fake= 0.006, g_loss 5.217, d_loss 0.006\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7 Batch 36/390 d_loss_real= 0.007, d_loss_fake= 0.006, g_loss 5.215, d_loss 0.006\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7 Batch 37/390 d_loss_real= 0.004, d_loss_fake= 0.006, g_loss 5.250, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 38/390 d_loss_real= 0.002, d_loss_fake= 0.005, g_loss 5.337, d_loss 0.004\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 39/390 d_loss_real= 0.007, d_loss_fake= 0.005, g_loss 5.395, d_loss 0.006\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7 Batch 40/390 d_loss_real= 0.006, d_loss_fake= 0.004, g_loss 5.443, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 41/390 d_loss_real= 0.004, d_loss_fake= 0.004, g_loss 5.487, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 42/390 d_loss_real= 0.003, d_loss_fake= 0.004, g_loss 5.531, d_loss 0.004\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 43/390 d_loss_real= 0.003, d_loss_fake= 0.004, g_loss 5.579, d_loss 0.003\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 44/390 d_loss_real= 0.002, d_loss_fake= 0.004, g_loss 5.636, d_loss 0.003\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 45/390 d_loss_real= 0.004, d_loss_fake= 0.004, g_loss 5.682, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 46/390 d_loss_real= 0.002, d_loss_fake= 0.003, g_loss 5.728, d_loss 0.003\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 47/390 d_loss_real= 0.004, d_loss_fake= 0.003, g_loss 5.767, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 48/390 d_loss_real= 0.023, d_loss_fake= 0.003, g_loss 5.558, d_loss 0.013\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 49/390 d_loss_real= 0.002, d_loss_fake= 0.004, g_loss 5.342, d_loss 0.003\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7 Batch 50/390 d_loss_real= 0.017, d_loss_fake= 0.006, g_loss 4.917, d_loss 0.012\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 51/390 d_loss_real= 0.004, d_loss_fake= 0.009, g_loss 4.722, d_loss 0.006\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7 Batch 52/390 d_loss_real= 0.002, d_loss_fake= 0.009, g_loss 4.813, d_loss 0.006\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 53/390 d_loss_real= 0.011, d_loss_fake= 0.008, g_loss 4.983, d_loss 0.009\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 54/390 d_loss_real= 0.002, d_loss_fake= 0.006, g_loss 5.281, d_loss 0.004\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 55/390 d_loss_real= 0.005, d_loss_fake= 0.005, g_loss 5.507, d_loss 0.005\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 56/390 d_loss_real= 0.011, d_loss_fake= 0.004, g_loss 5.585, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 57/390 d_loss_real= 0.009, d_loss_fake= 0.004, g_loss 5.582, d_loss 0.006\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 58/390 d_loss_real= 0.011, d_loss_fake= 0.004, g_loss 5.515, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 59/390 d_loss_real= 0.013, d_loss_fake= 0.004, g_loss 5.369, d_loss 0.009\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 60/390 d_loss_real= 0.007, d_loss_fake= 0.005, g_loss 5.251, d_loss 0.006\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 61/390 d_loss_real= 0.002, d_loss_fake= 0.006, g_loss 5.230, d_loss 0.004\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 62/390 d_loss_real= 0.003, d_loss_fake= 0.005, g_loss 5.286, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 63/390 d_loss_real= 0.004, d_loss_fake= 0.005, g_loss 5.366, d_loss 0.004\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7 Batch 64/390 d_loss_real= 0.007, d_loss_fake= 0.005, g_loss 5.429, d_loss 0.006\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 65/390 d_loss_real= 0.003, d_loss_fake= 0.004, g_loss 5.497, d_loss 0.004\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 66/390 d_loss_real= 0.002, d_loss_fake= 0.004, g_loss 5.585, d_loss 0.003\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 67/390 d_loss_real= 0.010, d_loss_fake= 0.004, g_loss 5.641, d_loss 0.007\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 68/390 d_loss_real= 0.015, d_loss_fake= 0.004, g_loss 5.527, d_loss 0.010\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7 Batch 69/390 d_loss_real= 0.015, d_loss_fake= 0.005, g_loss 5.071, d_loss 0.010\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7 Batch 70/390 d_loss_real= 0.001, d_loss_fake= 0.008, g_loss 4.861, d_loss 0.004\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 71/390 d_loss_real= 0.008, d_loss_fake= 0.009, g_loss 4.830, d_loss 0.008\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 72/390 d_loss_real= 0.003, d_loss_fake= 0.008, g_loss 5.032, d_loss 0.005\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7 Batch 73/390 d_loss_real= 0.002, d_loss_fake= 0.006, g_loss 5.313, d_loss 0.004\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 74/390 d_loss_real= 0.002, d_loss_fake= 0.004, g_loss 5.586, d_loss 0.003\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 75/390 d_loss_real= 0.003, d_loss_fake= 0.003, g_loss 5.732, d_loss 0.003\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 76/390 d_loss_real= 0.015, d_loss_fake= 0.003, g_loss 5.775, d_loss 0.009\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 77/390 d_loss_real= 0.005, d_loss_fake= 0.003, g_loss 5.791, d_loss 0.004\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7 Batch 78/390 d_loss_real= 0.010, d_loss_fake= 0.003, g_loss 5.755, d_loss 0.007\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 79/390 d_loss_real= 0.015, d_loss_fake= 0.003, g_loss 5.630, d_loss 0.009\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 80/390 d_loss_real= 0.002, d_loss_fake= 0.004, g_loss 5.506, d_loss 0.003\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 81/390 d_loss_real= 0.002, d_loss_fake= 0.004, g_loss 5.442, d_loss 0.003\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 82/390 d_loss_real= 0.011, d_loss_fake= 0.005, g_loss 5.337, d_loss 0.008\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 83/390 d_loss_real= 0.003, d_loss_fake= 0.005, g_loss 5.308, d_loss 0.004\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 84/390 d_loss_real= 0.002, d_loss_fake= 0.005, g_loss 5.379, d_loss 0.003\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7 Batch 85/390 d_loss_real= 0.002, d_loss_fake= 0.004, g_loss 5.495, d_loss 0.003\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 86/390 d_loss_real= 0.006, d_loss_fake= 0.004, g_loss 5.577, d_loss 0.005\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 87/390 d_loss_real= 0.028, d_loss_fake= 0.004, g_loss 5.309, d_loss 0.016\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 88/390 d_loss_real= 0.004, d_loss_fake= 0.006, g_loss 5.073, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 89/390 d_loss_real= 0.006, d_loss_fake= 0.007, g_loss 5.043, d_loss 0.006\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 90/390 d_loss_real= 0.001, d_loss_fake= 0.006, g_loss 5.201, d_loss 0.004\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 91/390 d_loss_real= 0.008, d_loss_fake= 0.005, g_loss 5.371, d_loss 0.006\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 92/390 d_loss_real= 0.002, d_loss_fake= 0.004, g_loss 5.512, d_loss 0.003\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 93/390 d_loss_real= 0.010, d_loss_fake= 0.004, g_loss 5.520, d_loss 0.007\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7 Batch 94/390 d_loss_real= 0.003, d_loss_fake= 0.004, g_loss 5.550, d_loss 0.003\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 95/390 d_loss_real= 0.005, d_loss_fake= 0.004, g_loss 5.587, d_loss 0.005\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 96/390 d_loss_real= 0.009, d_loss_fake= 0.004, g_loss 5.571, d_loss 0.007\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 97/390 d_loss_real= 0.004, d_loss_fake= 0.004, g_loss 5.566, d_loss 0.004\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 98/390 d_loss_real= 0.022, d_loss_fake= 0.005, g_loss 5.283, d_loss 0.013\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 99/390 d_loss_real= 0.017, d_loss_fake= 0.007, g_loss 4.725, d_loss 0.012\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 100/390 d_loss_real= 0.004, d_loss_fake= 0.011, g_loss 4.545, d_loss 0.007\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 101/390 d_loss_real= 0.006, d_loss_fake= 0.011, g_loss 4.639, d_loss 0.009\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 102/390 d_loss_real= 0.002, d_loss_fake= 0.009, g_loss 4.946, d_loss 0.005\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 103/390 d_loss_real= 0.002, d_loss_fake= 0.006, g_loss 5.249, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 104/390 d_loss_real= 0.003, d_loss_fake= 0.005, g_loss 5.496, d_loss 0.004\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7 Batch 105/390 d_loss_real= 0.004, d_loss_fake= 0.004, g_loss 5.659, d_loss 0.004\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7 Batch 106/390 d_loss_real= 0.003, d_loss_fake= 0.003, g_loss 5.780, d_loss 0.003\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7 Batch 107/390 d_loss_real= 0.002, d_loss_fake= 0.003, g_loss 5.878, d_loss 0.002\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7 Batch 108/390 d_loss_real= 0.010, d_loss_fake= 0.003, g_loss 5.919, d_loss 0.006\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 109/390 d_loss_real= 0.018, d_loss_fake= 0.003, g_loss 5.784, d_loss 0.011\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7 Batch 110/390 d_loss_real= 0.009, d_loss_fake= 0.003, g_loss 5.625, d_loss 0.006\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 111/390 d_loss_real= 0.006, d_loss_fake= 0.004, g_loss 5.434, d_loss 0.005\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 112/390 d_loss_real= 0.001, d_loss_fake= 0.005, g_loss 5.305, d_loss 0.003\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 113/390 d_loss_real= 0.002, d_loss_fake= 0.005, g_loss 5.253, d_loss 0.003\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 114/390 d_loss_real= 0.007, d_loss_fake= 0.006, g_loss 5.235, d_loss 0.006\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 115/390 d_loss_real= 0.002, d_loss_fake= 0.005, g_loss 5.345, d_loss 0.004\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7 Batch 116/390 d_loss_real= 0.002, d_loss_fake= 0.004, g_loss 5.502, d_loss 0.003\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 117/390 d_loss_real= 0.013, d_loss_fake= 0.004, g_loss 5.518, d_loss 0.009\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 118/390 d_loss_real= 0.003, d_loss_fake= 0.004, g_loss 5.579, d_loss 0.004\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 119/390 d_loss_real= 0.004, d_loss_fake= 0.004, g_loss 5.643, d_loss 0.004\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 120/390 d_loss_real= 0.001, d_loss_fake= 0.003, g_loss 5.718, d_loss 0.002\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 121/390 d_loss_real= 0.019, d_loss_fake= 0.003, g_loss 5.610, d_loss 0.011\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 122/390 d_loss_real= 0.010, d_loss_fake= 0.004, g_loss 5.330, d_loss 0.007\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 123/390 d_loss_real= 0.002, d_loss_fake= 0.005, g_loss 5.212, d_loss 0.003\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 124/390 d_loss_real= 0.008, d_loss_fake= 0.006, g_loss 5.218, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 125/390 d_loss_real= 0.005, d_loss_fake= 0.006, g_loss 5.289, d_loss 0.005\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 126/390 d_loss_real= 0.003, d_loss_fake= 0.005, g_loss 5.475, d_loss 0.004\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 127/390 d_loss_real= 0.006, d_loss_fake= 0.004, g_loss 5.597, d_loss 0.005\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 128/390 d_loss_real= 0.004, d_loss_fake= 0.004, g_loss 5.665, d_loss 0.004\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 129/390 d_loss_real= 0.003, d_loss_fake= 0.003, g_loss 5.716, d_loss 0.003\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 130/390 d_loss_real= 0.011, d_loss_fake= 0.003, g_loss 5.688, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 131/390 d_loss_real= 0.005, d_loss_fake= 0.003, g_loss 5.654, d_loss 0.004\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 132/390 d_loss_real= 0.009, d_loss_fake= 0.004, g_loss 5.536, d_loss 0.006\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7 Batch 133/390 d_loss_real= 0.004, d_loss_fake= 0.004, g_loss 5.459, d_loss 0.004\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7 Batch 134/390 d_loss_real= 0.001, d_loss_fake= 0.004, g_loss 5.485, d_loss 0.003\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 135/390 d_loss_real= 0.001, d_loss_fake= 0.004, g_loss 5.596, d_loss 0.002\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 136/390 d_loss_real= 0.006, d_loss_fake= 0.004, g_loss 5.674, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 137/390 d_loss_real= 0.010, d_loss_fake= 0.004, g_loss 5.638, d_loss 0.007\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 138/390 d_loss_real= 0.001, d_loss_fake= 0.004, g_loss 5.653, d_loss 0.003\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 139/390 d_loss_real= 0.010, d_loss_fake= 0.004, g_loss 5.639, d_loss 0.007\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7 Batch 140/390 d_loss_real= 0.007, d_loss_fake= 0.004, g_loss 5.568, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 141/390 d_loss_real= 0.016, d_loss_fake= 0.004, g_loss 5.432, d_loss 0.010\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 142/390 d_loss_real= 0.006, d_loss_fake= 0.005, g_loss 5.333, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 143/390 d_loss_real= 0.015, d_loss_fake= 0.006, g_loss 5.151, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 144/390 d_loss_real= 0.012, d_loss_fake= 0.007, g_loss 4.952, d_loss 0.009\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 145/390 d_loss_real= 0.002, d_loss_fake= 0.007, g_loss 4.989, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 146/390 d_loss_real= 0.005, d_loss_fake= 0.007, g_loss 5.097, d_loss 0.006\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 147/390 d_loss_real= 0.003, d_loss_fake= 0.006, g_loss 5.263, d_loss 0.005\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 148/390 d_loss_real= 0.002, d_loss_fake= 0.005, g_loss 5.455, d_loss 0.003\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 149/390 d_loss_real= 0.001, d_loss_fake= 0.004, g_loss 5.640, d_loss 0.002\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 150/390 d_loss_real= 0.032, d_loss_fake= 0.004, g_loss 5.460, d_loss 0.018\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 151/390 d_loss_real= 0.002, d_loss_fake= 0.005, g_loss 5.297, d_loss 0.003\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 152/390 d_loss_real= 0.002, d_loss_fake= 0.006, g_loss 5.203, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 153/390 d_loss_real= 0.001, d_loss_fake= 0.006, g_loss 5.266, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 154/390 d_loss_real= 0.002, d_loss_fake= 0.005, g_loss 5.441, d_loss 0.004\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7 Batch 155/390 d_loss_real= 0.016, d_loss_fake= 0.005, g_loss 5.254, d_loss 0.010\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7 Batch 156/390 d_loss_real= 0.019, d_loss_fake= 0.007, g_loss 4.725, d_loss 0.013\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 157/390 d_loss_real= 0.002, d_loss_fake= 0.011, g_loss 4.582, d_loss 0.006\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 158/390 d_loss_real= 0.005, d_loss_fake= 0.010, g_loss 4.768, d_loss 0.008\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7 Batch 159/390 d_loss_real= 0.041, d_loss_fake= 0.010, g_loss 4.647, d_loss 0.025\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 160/390 d_loss_real= 0.000, d_loss_fake= 0.009, g_loss 4.860, d_loss 0.005\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 161/390 d_loss_real= 0.001, d_loss_fake= 0.007, g_loss 5.191, d_loss 0.004\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 162/390 d_loss_real= 0.002, d_loss_fake= 0.005, g_loss 5.457, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 163/390 d_loss_real= 0.003, d_loss_fake= 0.004, g_loss 5.660, d_loss 0.003\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 164/390 d_loss_real= 0.002, d_loss_fake= 0.003, g_loss 5.822, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 165/390 d_loss_real= 0.007, d_loss_fake= 0.003, g_loss 5.919, d_loss 0.005\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7 Batch 166/390 d_loss_real= 0.005, d_loss_fake= 0.003, g_loss 5.972, d_loss 0.004\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 167/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.027, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 168/390 d_loss_real= 0.007, d_loss_fake= 0.002, g_loss 6.038, d_loss 0.005\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 169/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.051, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 170/390 d_loss_real= 0.010, d_loss_fake= 0.002, g_loss 5.995, d_loss 0.006\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 171/390 d_loss_real= 0.021, d_loss_fake= 0.003, g_loss 5.819, d_loss 0.012\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 172/390 d_loss_real= 0.012, d_loss_fake= 0.004, g_loss 5.483, d_loss 0.008\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 173/390 d_loss_real= 0.002, d_loss_fake= 0.005, g_loss 5.176, d_loss 0.004\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 174/390 d_loss_real= 0.007, d_loss_fake= 0.007, g_loss 4.912, d_loss 0.007\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 175/390 d_loss_real= 0.001, d_loss_fake= 0.008, g_loss 4.916, d_loss 0.005\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 176/390 d_loss_real= 0.006, d_loss_fake= 0.008, g_loss 5.023, d_loss 0.007\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7 Batch 177/390 d_loss_real= 0.006, d_loss_fake= 0.006, g_loss 5.257, d_loss 0.006\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 178/390 d_loss_real= 0.003, d_loss_fake= 0.005, g_loss 5.491, d_loss 0.004\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 179/390 d_loss_real= 0.003, d_loss_fake= 0.004, g_loss 5.677, d_loss 0.003\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 180/390 d_loss_real= 0.002, d_loss_fake= 0.003, g_loss 5.826, d_loss 0.002\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 181/390 d_loss_real= 0.005, d_loss_fake= 0.003, g_loss 5.917, d_loss 0.004\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 182/390 d_loss_real= 0.005, d_loss_fake= 0.003, g_loss 5.970, d_loss 0.004\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 183/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.031, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 184/390 d_loss_real= 0.009, d_loss_fake= 0.002, g_loss 6.015, d_loss 0.006\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 185/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.003, d_loss 0.002\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 186/390 d_loss_real= 0.037, d_loss_fake= 0.003, g_loss 5.592, d_loss 0.020\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7 Batch 187/390 d_loss_real= 0.001, d_loss_fake= 0.005, g_loss 5.165, d_loss 0.003\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 188/390 d_loss_real= 0.011, d_loss_fake= 0.009, g_loss 4.581, d_loss 0.010\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 189/390 d_loss_real= 0.002, d_loss_fake= 0.013, g_loss 4.490, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 190/390 d_loss_real= 0.002, d_loss_fake= 0.010, g_loss 4.883, d_loss 0.006\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 191/390 d_loss_real= 0.001, d_loss_fake= 0.006, g_loss 5.383, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 192/390 d_loss_real= 0.007, d_loss_fake= 0.004, g_loss 5.696, d_loss 0.006\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 193/390 d_loss_real= 0.004, d_loss_fake= 0.003, g_loss 5.866, d_loss 0.004\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 194/390 d_loss_real= 0.002, d_loss_fake= 0.003, g_loss 6.004, d_loss 0.002\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 195/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.104, d_loss 0.002\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 196/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.171, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 197/390 d_loss_real= 0.013, d_loss_fake= 0.002, g_loss 6.153, d_loss 0.008\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 198/390 d_loss_real= 0.006, d_loss_fake= 0.002, g_loss 6.109, d_loss 0.004\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 199/390 d_loss_real= 0.003, d_loss_fake= 0.002, g_loss 6.073, d_loss 0.002\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 200/390 d_loss_real= 0.006, d_loss_fake= 0.002, g_loss 5.961, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 201/390 d_loss_real= 0.003, d_loss_fake= 0.003, g_loss 5.824, d_loss 0.003\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 202/390 d_loss_real= 0.002, d_loss_fake= 0.003, g_loss 5.722, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 203/390 d_loss_real= 0.024, d_loss_fake= 0.004, g_loss 5.378, d_loss 0.014\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 7 Batch 204/390 d_loss_real= 0.020, d_loss_fake= 0.007, g_loss 4.645, d_loss 0.014\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 205/390 d_loss_real= 0.001, d_loss_fake= 0.013, g_loss 4.374, d_loss 0.007\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 206/390 d_loss_real= 0.001, d_loss_fake= 0.012, g_loss 4.702, d_loss 0.007\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 207/390 d_loss_real= 0.001, d_loss_fake= 0.007, g_loss 5.187, d_loss 0.004\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 208/390 d_loss_real= 0.002, d_loss_fake= 0.005, g_loss 5.604, d_loss 0.003\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7 Batch 209/390 d_loss_real= 0.004, d_loss_fake= 0.003, g_loss 5.890, d_loss 0.003\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 210/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.090, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 211/390 d_loss_real= 0.022, d_loss_fake= 0.002, g_loss 6.029, d_loss 0.012\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 212/390 d_loss_real= 0.010, d_loss_fake= 0.003, g_loss 5.907, d_loss 0.006\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 213/390 d_loss_real= 0.007, d_loss_fake= 0.003, g_loss 5.716, d_loss 0.005\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 214/390 d_loss_real= 0.002, d_loss_fake= 0.004, g_loss 5.588, d_loss 0.003\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 215/390 d_loss_real= 0.001, d_loss_fake= 0.004, g_loss 5.542, d_loss 0.002\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 216/390 d_loss_real= 0.006, d_loss_fake= 0.004, g_loss 5.452, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 217/390 d_loss_real= 0.001, d_loss_fake= 0.004, g_loss 5.455, d_loss 0.003\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 218/390 d_loss_real= 0.002, d_loss_fake= 0.004, g_loss 5.498, d_loss 0.003\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7 Batch 219/390 d_loss_real= 0.001, d_loss_fake= 0.004, g_loss 5.615, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 220/390 d_loss_real= 0.001, d_loss_fake= 0.003, g_loss 5.763, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 221/390 d_loss_real= 0.028, d_loss_fake= 0.004, g_loss 5.579, d_loss 0.016\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 222/390 d_loss_real= 0.003, d_loss_fake= 0.004, g_loss 5.418, d_loss 0.004\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 223/390 d_loss_real= 0.003, d_loss_fake= 0.005, g_loss 5.389, d_loss 0.004\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 224/390 d_loss_real= 0.001, d_loss_fake= 0.004, g_loss 5.516, d_loss 0.003\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7 Batch 225/390 d_loss_real= 0.002, d_loss_fake= 0.004, g_loss 5.695, d_loss 0.003\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 226/390 d_loss_real= 0.003, d_loss_fake= 0.003, g_loss 5.838, d_loss 0.003\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7 Batch 227/390 d_loss_real= 0.004, d_loss_fake= 0.003, g_loss 5.937, d_loss 0.003\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 7 Batch 228/390 d_loss_real= 0.004, d_loss_fake= 0.003, g_loss 5.989, d_loss 0.003\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 229/390 d_loss_real= 0.007, d_loss_fake= 0.003, g_loss 5.921, d_loss 0.005\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7 Batch 230/390 d_loss_real= 0.001, d_loss_fake= 0.003, g_loss 5.879, d_loss 0.002\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 231/390 d_loss_real= 0.002, d_loss_fake= 0.003, g_loss 5.853, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7 Batch 232/390 d_loss_real= 0.001, d_loss_fake= 0.003, g_loss 5.874, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7 Batch 233/390 d_loss_real= 0.002, d_loss_fake= 0.003, g_loss 5.929, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 234/390 d_loss_real= 0.024, d_loss_fake= 0.004, g_loss 5.369, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 235/390 d_loss_real= 0.006, d_loss_fake= 0.006, g_loss 5.005, d_loss 0.006\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 236/390 d_loss_real= 0.004, d_loss_fake= 0.008, g_loss 4.966, d_loss 0.006\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7 Batch 237/390 d_loss_real= 0.002, d_loss_fake= 0.007, g_loss 5.157, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 238/390 d_loss_real= 0.004, d_loss_fake= 0.005, g_loss 5.413, d_loss 0.005\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 239/390 d_loss_real= 0.037, d_loss_fake= 0.005, g_loss 5.356, d_loss 0.021\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 240/390 d_loss_real= 0.001, d_loss_fake= 0.005, g_loss 5.421, d_loss 0.003\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 241/390 d_loss_real= 0.002, d_loss_fake= 0.004, g_loss 5.559, d_loss 0.003\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 242/390 d_loss_real= 0.001, d_loss_fake= 0.004, g_loss 5.731, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 243/390 d_loss_real= 0.001, d_loss_fake= 0.003, g_loss 5.881, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 244/390 d_loss_real= 0.001, d_loss_fake= 0.003, g_loss 6.016, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7 Batch 245/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.131, d_loss 0.002\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 246/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.224, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7 Batch 247/390 d_loss_real= 0.009, d_loss_fake= 0.002, g_loss 6.255, d_loss 0.005\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7 Batch 248/390 d_loss_real= 0.011, d_loss_fake= 0.002, g_loss 6.199, d_loss 0.006\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7 Batch 249/390 d_loss_real= 0.003, d_loss_fake= 0.002, g_loss 6.149, d_loss 0.002\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 250/390 d_loss_real= 0.003, d_loss_fake= 0.002, g_loss 6.099, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 251/390 d_loss_real= 0.011, d_loss_fake= 0.002, g_loss 5.947, d_loss 0.007\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 252/390 d_loss_real= 0.001, d_loss_fake= 0.003, g_loss 5.839, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 253/390 d_loss_real= 0.003, d_loss_fake= 0.003, g_loss 5.793, d_loss 0.003\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 254/390 d_loss_real= 0.012, d_loss_fake= 0.004, g_loss 5.460, d_loss 0.008\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7 Batch 255/390 d_loss_real= 0.018, d_loss_fake= 0.007, g_loss 4.792, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 256/390 d_loss_real= 0.003, d_loss_fake= 0.011, g_loss 4.579, d_loss 0.007\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 257/390 d_loss_real= 0.003, d_loss_fake= 0.010, g_loss 4.812, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 258/390 d_loss_real= 0.002, d_loss_fake= 0.007, g_loss 5.303, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 259/390 d_loss_real= 0.003, d_loss_fake= 0.004, g_loss 5.705, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 260/390 d_loss_real= 0.002, d_loss_fake= 0.003, g_loss 6.000, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 261/390 d_loss_real= 0.006, d_loss_fake= 0.002, g_loss 6.126, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 262/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.206, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 263/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.260, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 264/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.307, d_loss 0.002\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 265/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.347, d_loss 0.002\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 266/390 d_loss_real= 0.006, d_loss_fake= 0.002, g_loss 6.329, d_loss 0.004\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 267/390 d_loss_real= 0.003, d_loss_fake= 0.002, g_loss 6.305, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 268/390 d_loss_real= 0.024, d_loss_fake= 0.002, g_loss 5.948, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 269/390 d_loss_real= 0.001, d_loss_fake= 0.003, g_loss 5.573, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 270/390 d_loss_real= 0.005, d_loss_fake= 0.005, g_loss 5.195, d_loss 0.005\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7 Batch 271/390 d_loss_real= 0.000, d_loss_fake= 0.006, g_loss 5.035, d_loss 0.003\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 272/390 d_loss_real= 0.001, d_loss_fake= 0.007, g_loss 5.103, d_loss 0.004\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7 Batch 273/390 d_loss_real= 0.007, d_loss_fake= 0.007, g_loss 5.114, d_loss 0.007\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 274/390 d_loss_real= 0.003, d_loss_fake= 0.006, g_loss 5.274, d_loss 0.005\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7 Batch 275/390 d_loss_real= 0.003, d_loss_fake= 0.005, g_loss 5.485, d_loss 0.004\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7 Batch 276/390 d_loss_real= 0.003, d_loss_fake= 0.004, g_loss 5.700, d_loss 0.003\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 277/390 d_loss_real= 0.009, d_loss_fake= 0.003, g_loss 5.800, d_loss 0.006\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 278/390 d_loss_real= 0.003, d_loss_fake= 0.003, g_loss 5.904, d_loss 0.003\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 279/390 d_loss_real= 0.008, d_loss_fake= 0.003, g_loss 5.878, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 280/390 d_loss_real= 0.003, d_loss_fake= 0.003, g_loss 5.864, d_loss 0.003\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7 Batch 281/390 d_loss_real= 0.004, d_loss_fake= 0.003, g_loss 5.835, d_loss 0.003\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 282/390 d_loss_real= 0.002, d_loss_fake= 0.003, g_loss 5.840, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 283/390 d_loss_real= 0.001, d_loss_fake= 0.003, g_loss 5.925, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 284/390 d_loss_real= 0.005, d_loss_fake= 0.003, g_loss 5.948, d_loss 0.004\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 285/390 d_loss_real= 0.008, d_loss_fake= 0.003, g_loss 5.877, d_loss 0.005\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7 Batch 286/390 d_loss_real= 0.000, d_loss_fake= 0.003, g_loss 5.891, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 287/390 d_loss_real= 0.001, d_loss_fake= 0.003, g_loss 5.952, d_loss 0.002\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 288/390 d_loss_real= 0.001, d_loss_fake= 0.003, g_loss 6.019, d_loss 0.002\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 289/390 d_loss_real= 0.041, d_loss_fake= 0.003, g_loss 5.319, d_loss 0.022\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 290/390 d_loss_real= 0.001, d_loss_fake= 0.007, g_loss 4.861, d_loss 0.004\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 291/390 d_loss_real= 0.001, d_loss_fake= 0.009, g_loss 4.832, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 292/390 d_loss_real= 0.003, d_loss_fake= 0.008, g_loss 4.988, d_loss 0.006\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 293/390 d_loss_real= 0.004, d_loss_fake= 0.006, g_loss 5.285, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 294/390 d_loss_real= 0.001, d_loss_fake= 0.004, g_loss 5.648, d_loss 0.002\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 295/390 d_loss_real= 0.001, d_loss_fake= 0.003, g_loss 5.974, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 296/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.197, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 297/390 d_loss_real= 0.005, d_loss_fake= 0.002, g_loss 6.322, d_loss 0.003\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 298/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.412, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 299/390 d_loss_real= 0.014, d_loss_fake= 0.002, g_loss 6.355, d_loss 0.008\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 300/390 d_loss_real= 0.006, d_loss_fake= 0.002, g_loss 6.241, d_loss 0.004\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7 Batch 301/390 d_loss_real= 0.004, d_loss_fake= 0.002, g_loss 6.092, d_loss 0.003\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7 Batch 302/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 5.964, d_loss 0.002\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 303/390 d_loss_real= 0.007, d_loss_fake= 0.003, g_loss 5.851, d_loss 0.005\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 304/390 d_loss_real= 0.001, d_loss_fake= 0.003, g_loss 5.798, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 305/390 d_loss_real= 0.002, d_loss_fake= 0.003, g_loss 5.800, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 306/390 d_loss_real= 0.004, d_loss_fake= 0.003, g_loss 5.836, d_loss 0.003\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7 Batch 307/390 d_loss_real= 0.001, d_loss_fake= 0.003, g_loss 5.937, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 308/390 d_loss_real= 0.002, d_loss_fake= 0.003, g_loss 6.038, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 309/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.123, d_loss 0.002\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 310/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.207, d_loss 0.002\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7 Batch 311/390 d_loss_real= 0.005, d_loss_fake= 0.002, g_loss 6.238, d_loss 0.004\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 312/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.268, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 313/390 d_loss_real= 0.009, d_loss_fake= 0.002, g_loss 6.179, d_loss 0.005\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 314/390 d_loss_real= 0.012, d_loss_fake= 0.003, g_loss 5.648, d_loss 0.008\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7 Batch 315/390 d_loss_real= 0.001, d_loss_fake= 0.005, g_loss 5.306, d_loss 0.003\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 316/390 d_loss_real= 0.002, d_loss_fake= 0.006, g_loss 5.257, d_loss 0.004\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 317/390 d_loss_real= 0.001, d_loss_fake= 0.005, g_loss 5.470, d_loss 0.003\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 318/390 d_loss_real= 0.021, d_loss_fake= 0.005, g_loss 5.192, d_loss 0.013\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 319/390 d_loss_real= 0.002, d_loss_fake= 0.006, g_loss 5.212, d_loss 0.004\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 320/390 d_loss_real= 0.002, d_loss_fake= 0.005, g_loss 5.446, d_loss 0.004\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 321/390 d_loss_real= 0.000, d_loss_fake= 0.004, g_loss 5.728, d_loss 0.002\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 322/390 d_loss_real= 0.002, d_loss_fake= 0.003, g_loss 6.024, d_loss 0.002\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 323/390 d_loss_real= 0.011, d_loss_fake= 0.002, g_loss 6.101, d_loss 0.007\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 324/390 d_loss_real= 0.003, d_loss_fake= 0.002, g_loss 6.160, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 325/390 d_loss_real= 0.005, d_loss_fake= 0.002, g_loss 6.127, d_loss 0.003\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7 Batch 326/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.124, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 327/390 d_loss_real= 0.004, d_loss_fake= 0.002, g_loss 6.065, d_loss 0.003\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 328/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.024, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 329/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.011, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 330/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.035, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7 Batch 331/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.092, d_loss 0.002\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7 Batch 332/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.163, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 333/390 d_loss_real= 0.004, d_loss_fake= 0.002, g_loss 6.181, d_loss 0.003\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 334/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.215, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 335/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.262, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 336/390 d_loss_real= 0.018, d_loss_fake= 0.002, g_loss 5.993, d_loss 0.010\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 337/390 d_loss_real= 0.004, d_loss_fake= 0.003, g_loss 5.664, d_loss 0.003\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 338/390 d_loss_real= 0.006, d_loss_fake= 0.004, g_loss 5.436, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 339/390 d_loss_real= 0.000, d_loss_fake= 0.005, g_loss 5.496, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 340/390 d_loss_real= 0.002, d_loss_fake= 0.004, g_loss 5.692, d_loss 0.003\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 341/390 d_loss_real= 0.000, d_loss_fake= 0.003, g_loss 5.934, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7 Batch 342/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.119, d_loss 0.002\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7 Batch 343/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.284, d_loss 0.001\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7 Batch 344/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.380, d_loss 0.002\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7 Batch 345/390 d_loss_real= 0.006, d_loss_fake= 0.002, g_loss 6.367, d_loss 0.004\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7 Batch 346/390 d_loss_real= 0.007, d_loss_fake= 0.002, g_loss 6.269, d_loss 0.005\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7 Batch 347/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.201, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 348/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.124, d_loss 0.002\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 349/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.077, d_loss 0.002\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7 Batch 350/390 d_loss_real= 0.003, d_loss_fake= 0.002, g_loss 6.044, d_loss 0.003\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 351/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.039, d_loss 0.002\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7 Batch 352/390 d_loss_real= 0.015, d_loss_fake= 0.003, g_loss 5.573, d_loss 0.009\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 353/390 d_loss_real= 0.013, d_loss_fake= 0.005, g_loss 5.063, d_loss 0.009\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 354/390 d_loss_real= 0.001, d_loss_fake= 0.007, g_loss 5.009, d_loss 0.004\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 355/390 d_loss_real= 0.001, d_loss_fake= 0.006, g_loss 5.296, d_loss 0.003\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7 Batch 356/390 d_loss_real= 0.008, d_loss_fake= 0.005, g_loss 5.382, d_loss 0.006\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 357/390 d_loss_real= 0.000, d_loss_fake= 0.004, g_loss 5.604, d_loss 0.002\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7 Batch 358/390 d_loss_real= 0.000, d_loss_fake= 0.003, g_loss 5.858, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 359/390 d_loss_real= 0.003, d_loss_fake= 0.003, g_loss 6.059, d_loss 0.003\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 7 Batch 360/390 d_loss_real= 0.006, d_loss_fake= 0.002, g_loss 6.130, d_loss 0.004\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 361/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.215, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7 Batch 362/390 d_loss_real= 0.013, d_loss_fake= 0.002, g_loss 6.104, d_loss 0.008\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 363/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.047, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 364/390 d_loss_real= 0.030, d_loss_fake= 0.003, g_loss 5.480, d_loss 0.017\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7 Batch 365/390 d_loss_real= 0.001, d_loss_fake= 0.006, g_loss 5.049, d_loss 0.003\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 7 Batch 366/390 d_loss_real= 0.001, d_loss_fake= 0.007, g_loss 5.029, d_loss 0.004\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7 Batch 367/390 d_loss_real= 0.005, d_loss_fake= 0.006, g_loss 5.286, d_loss 0.006\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 368/390 d_loss_real= 0.001, d_loss_fake= 0.004, g_loss 5.697, d_loss 0.002\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 369/390 d_loss_real= 0.002, d_loss_fake= 0.003, g_loss 6.020, d_loss 0.003\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 370/390 d_loss_real= 0.018, d_loss_fake= 0.003, g_loss 5.989, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 371/390 d_loss_real= 0.004, d_loss_fake= 0.003, g_loss 5.920, d_loss 0.003\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 372/390 d_loss_real= 0.004, d_loss_fake= 0.003, g_loss 5.854, d_loss 0.003\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 373/390 d_loss_real= 0.005, d_loss_fake= 0.003, g_loss 5.720, d_loss 0.004\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7 Batch 374/390 d_loss_real= 0.002, d_loss_fake= 0.004, g_loss 5.652, d_loss 0.003\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 375/390 d_loss_real= 0.000, d_loss_fake= 0.004, g_loss 5.726, d_loss 0.002\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 376/390 d_loss_real= 0.003, d_loss_fake= 0.003, g_loss 5.823, d_loss 0.003\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 7 Batch 377/390 d_loss_real= 0.007, d_loss_fake= 0.003, g_loss 5.797, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 378/390 d_loss_real= 0.002, d_loss_fake= 0.003, g_loss 5.812, d_loss 0.003\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 379/390 d_loss_real= 0.001, d_loss_fake= 0.003, g_loss 5.910, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 380/390 d_loss_real= 0.002, d_loss_fake= 0.003, g_loss 6.044, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 381/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.163, d_loss 0.002\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 7 Batch 382/390 d_loss_real= 0.009, d_loss_fake= 0.002, g_loss 6.190, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7 Batch 383/390 d_loss_real= 0.004, d_loss_fake= 0.002, g_loss 6.197, d_loss 0.003\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7 Batch 384/390 d_loss_real= 0.005, d_loss_fake= 0.002, g_loss 6.179, d_loss 0.004\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 385/390 d_loss_real= 0.037, d_loss_fake= 0.002, g_loss 6.075, d_loss 0.020\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7 Batch 386/390 d_loss_real= 0.009, d_loss_fake= 0.003, g_loss 5.919, d_loss 0.006\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 387/390 d_loss_real= 0.005, d_loss_fake= 0.003, g_loss 5.742, d_loss 0.004\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7 Batch 388/390 d_loss_real= 0.001, d_loss_fake= 0.003, g_loss 5.744, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7 Batch 389/390 d_loss_real= 0.000, d_loss_fake= 0.003, g_loss 5.879, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 Batch 390/390 d_loss_real= 0.001, d_loss_fake= 0.003, g_loss 6.039, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 1/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.169, d_loss 0.002\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8 Batch 2/390 d_loss_real= 0.008, d_loss_fake= 0.002, g_loss 6.169, d_loss 0.005\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 3/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.187, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 4/390 d_loss_real= 0.006, d_loss_fake= 0.002, g_loss 6.125, d_loss 0.004\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 5/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.081, d_loss 0.002\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 6/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.084, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 7/390 d_loss_real= 0.003, d_loss_fake= 0.002, g_loss 6.081, d_loss 0.003\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 8/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.079, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 9/390 d_loss_real= 0.011, d_loss_fake= 0.002, g_loss 6.130, d_loss 0.007\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 10/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.174, d_loss 0.002\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 11/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.209, d_loss 0.002\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 12/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.255, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 13/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.318, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 14/390 d_loss_real= 0.015, d_loss_fake= 0.002, g_loss 5.971, d_loss 0.008\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 15/390 d_loss_real= 0.009, d_loss_fake= 0.004, g_loss 5.430, d_loss 0.006\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 16/390 d_loss_real= 0.002, d_loss_fake= 0.006, g_loss 5.158, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 17/390 d_loss_real= 0.000, d_loss_fake= 0.006, g_loss 5.314, d_loss 0.003\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 18/390 d_loss_real= 0.001, d_loss_fake= 0.004, g_loss 5.707, d_loss 0.003\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 19/390 d_loss_real= 0.001, d_loss_fake= 0.003, g_loss 6.078, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 20/390 d_loss_real= 0.004, d_loss_fake= 0.002, g_loss 6.246, d_loss 0.003\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 21/390 d_loss_real= 0.006, d_loss_fake= 0.002, g_loss 6.254, d_loss 0.004\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 22/390 d_loss_real= 0.013, d_loss_fake= 0.002, g_loss 6.096, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 23/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 5.990, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 24/390 d_loss_real= 0.001, d_loss_fake= 0.003, g_loss 5.952, d_loss 0.002\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 25/390 d_loss_real= 0.003, d_loss_fake= 0.003, g_loss 5.962, d_loss 0.003\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 26/390 d_loss_real= 0.002, d_loss_fake= 0.003, g_loss 6.024, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 27/390 d_loss_real= 0.010, d_loss_fake= 0.003, g_loss 5.703, d_loss 0.006\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 28/390 d_loss_real= 0.003, d_loss_fake= 0.004, g_loss 5.561, d_loss 0.003\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 29/390 d_loss_real= 0.000, d_loss_fake= 0.004, g_loss 5.647, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 30/390 d_loss_real= 0.000, d_loss_fake= 0.003, g_loss 5.884, d_loss 0.002\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 31/390 d_loss_real= 0.002, d_loss_fake= 0.003, g_loss 6.081, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 32/390 d_loss_real= 0.003, d_loss_fake= 0.002, g_loss 6.206, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 33/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.308, d_loss 0.001\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 34/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.407, d_loss 0.001\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8 Batch 35/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.497, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 36/390 d_loss_real= 0.006, d_loss_fake= 0.002, g_loss 6.488, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 37/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.463, d_loss 0.002\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8 Batch 38/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.450, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 39/390 d_loss_real= 0.009, d_loss_fake= 0.002, g_loss 6.209, d_loss 0.005\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 40/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 5.900, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 41/390 d_loss_real= 0.011, d_loss_fake= 0.004, g_loss 5.241, d_loss 0.008\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8 Batch 42/390 d_loss_real= 0.000, d_loss_fake= 0.007, g_loss 5.074, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 43/390 d_loss_real= 0.001, d_loss_fake= 0.006, g_loss 5.360, d_loss 0.003\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 44/390 d_loss_real= 0.001, d_loss_fake= 0.004, g_loss 5.833, d_loss 0.002\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 45/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.171, d_loss 0.002\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 46/390 d_loss_real= 0.003, d_loss_fake= 0.002, g_loss 6.367, d_loss 0.002\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 47/390 d_loss_real= 0.003, d_loss_fake= 0.002, g_loss 6.455, d_loss 0.002\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 48/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.532, d_loss 0.001\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 49/390 d_loss_real= 0.014, d_loss_fake= 0.002, g_loss 6.359, d_loss 0.008\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 50/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.217, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 51/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.117, d_loss 0.002\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 52/390 d_loss_real= 0.003, d_loss_fake= 0.002, g_loss 6.014, d_loss 0.003\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 53/390 d_loss_real= 0.004, d_loss_fake= 0.003, g_loss 5.837, d_loss 0.003\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 54/390 d_loss_real= 0.001, d_loss_fake= 0.003, g_loss 5.731, d_loss 0.002\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 55/390 d_loss_real= 0.001, d_loss_fake= 0.003, g_loss 5.768, d_loss 0.002\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 56/390 d_loss_real= 0.006, d_loss_fake= 0.003, g_loss 5.796, d_loss 0.005\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 57/390 d_loss_real= 0.001, d_loss_fake= 0.003, g_loss 5.981, d_loss 0.002\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 58/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.202, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8 Batch 59/390 d_loss_real= 0.010, d_loss_fake= 0.002, g_loss 6.007, d_loss 0.006\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 60/390 d_loss_real= 0.001, d_loss_fake= 0.003, g_loss 5.906, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 61/390 d_loss_real= 0.005, d_loss_fake= 0.003, g_loss 5.828, d_loss 0.004\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 62/390 d_loss_real= 0.002, d_loss_fake= 0.003, g_loss 5.892, d_loss 0.002\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 63/390 d_loss_real= 0.002, d_loss_fake= 0.003, g_loss 6.002, d_loss 0.002\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8 Batch 64/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.154, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 65/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.306, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 66/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.445, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 67/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.557, d_loss 0.002\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 68/390 d_loss_real= 0.012, d_loss_fake= 0.002, g_loss 6.446, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 69/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.338, d_loss 0.001\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 70/390 d_loss_real= 0.011, d_loss_fake= 0.002, g_loss 5.957, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 71/390 d_loss_real= 0.000, d_loss_fake= 0.003, g_loss 5.748, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 72/390 d_loss_real= 0.002, d_loss_fake= 0.004, g_loss 5.687, d_loss 0.003\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 73/390 d_loss_real= 0.004, d_loss_fake= 0.003, g_loss 5.841, d_loss 0.003\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 74/390 d_loss_real= 0.000, d_loss_fake= 0.003, g_loss 6.077, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 75/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.314, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 76/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.477, d_loss 0.001\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 77/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 6.605, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 78/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 6.709, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 79/390 d_loss_real= 0.004, d_loss_fake= 0.001, g_loss 6.760, d_loss 0.003\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 80/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 6.783, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 81/390 d_loss_real= 0.012, d_loss_fake= 0.001, g_loss 6.704, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 82/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 6.631, d_loss 0.002\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 83/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 6.582, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 84/390 d_loss_real= 0.004, d_loss_fake= 0.001, g_loss 6.450, d_loss 0.003\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 85/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.330, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 86/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.268, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 87/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.295, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 88/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.382, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 89/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.475, d_loss 0.001\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 90/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 6.549, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 91/390 d_loss_real= 0.008, d_loss_fake= 0.002, g_loss 6.413, d_loss 0.005\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 92/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.267, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 93/390 d_loss_real= 0.013, d_loss_fake= 0.003, g_loss 5.511, d_loss 0.008\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 94/390 d_loss_real= 0.001, d_loss_fake= 0.005, g_loss 5.180, d_loss 0.003\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 95/390 d_loss_real= 0.007, d_loss_fake= 0.007, g_loss 5.110, d_loss 0.007\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 96/390 d_loss_real= 0.001, d_loss_fake= 0.006, g_loss 5.488, d_loss 0.003\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 97/390 d_loss_real= 0.001, d_loss_fake= 0.003, g_loss 6.003, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 98/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.327, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 99/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.559, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 100/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 6.715, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 101/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 6.816, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 102/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 6.897, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 103/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 6.958, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 104/390 d_loss_real= 0.030, d_loss_fake= 0.001, g_loss 6.508, d_loss 0.016\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 105/390 d_loss_real= 0.008, d_loss_fake= 0.002, g_loss 5.749, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 106/390 d_loss_real= 0.000, d_loss_fake= 0.005, g_loss 5.108, d_loss 0.003\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 107/390 d_loss_real= 0.002, d_loss_fake= 0.008, g_loss 4.809, d_loss 0.005\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 108/390 d_loss_real= 0.001, d_loss_fake= 0.008, g_loss 5.064, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 109/390 d_loss_real= 0.002, d_loss_fake= 0.005, g_loss 5.470, d_loss 0.004\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 110/390 d_loss_real= 0.001, d_loss_fake= 0.003, g_loss 5.894, d_loss 0.002\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 111/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.273, d_loss 0.001\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 112/390 d_loss_real= 0.006, d_loss_fake= 0.002, g_loss 6.400, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 113/390 d_loss_real= 0.017, d_loss_fake= 0.002, g_loss 6.494, d_loss 0.009\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 114/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 6.573, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 115/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 6.643, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 116/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 6.712, d_loss 0.001\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 117/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 6.764, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 118/390 d_loss_real= 0.005, d_loss_fake= 0.001, g_loss 6.729, d_loss 0.003\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 119/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 6.713, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 120/390 d_loss_real= 0.012, d_loss_fake= 0.001, g_loss 6.519, d_loss 0.007\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 121/390 d_loss_real= 0.003, d_loss_fake= 0.002, g_loss 6.270, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 122/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.061, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 123/390 d_loss_real= 0.000, d_loss_fake= 0.003, g_loss 5.957, d_loss 0.001\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 124/390 d_loss_real= 0.003, d_loss_fake= 0.003, g_loss 5.969, d_loss 0.003\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 125/390 d_loss_real= 0.002, d_loss_fake= 0.003, g_loss 6.061, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 126/390 d_loss_real= 0.003, d_loss_fake= 0.002, g_loss 6.150, d_loss 0.003\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 127/390 d_loss_real= 0.005, d_loss_fake= 0.002, g_loss 6.124, d_loss 0.003\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 128/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.202, d_loss 0.002\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 129/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.314, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 130/390 d_loss_real= 0.020, d_loss_fake= 0.002, g_loss 5.784, d_loss 0.011\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 131/390 d_loss_real= 0.021, d_loss_fake= 0.004, g_loss 5.376, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 132/390 d_loss_real= 0.001, d_loss_fake= 0.005, g_loss 5.402, d_loss 0.003\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 133/390 d_loss_real= 0.001, d_loss_fake= 0.004, g_loss 5.743, d_loss 0.003\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 134/390 d_loss_real= 0.003, d_loss_fake= 0.003, g_loss 5.968, d_loss 0.003\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 135/390 d_loss_real= 0.046, d_loss_fake= 0.004, g_loss 5.422, d_loss 0.025\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 136/390 d_loss_real= 0.001, d_loss_fake= 0.006, g_loss 5.198, d_loss 0.003\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 137/390 d_loss_real= 0.001, d_loss_fake= 0.006, g_loss 5.349, d_loss 0.003\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 138/390 d_loss_real= 0.000, d_loss_fake= 0.004, g_loss 5.688, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 139/390 d_loss_real= 0.000, d_loss_fake= 0.003, g_loss 6.003, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 140/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.281, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 141/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.528, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 142/390 d_loss_real= 0.007, d_loss_fake= 0.001, g_loss 6.514, d_loss 0.004\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 143/390 d_loss_real= 0.023, d_loss_fake= 0.002, g_loss 5.644, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 144/390 d_loss_real= 0.002, d_loss_fake= 0.006, g_loss 4.731, d_loss 0.004\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 145/390 d_loss_real= 0.000, d_loss_fake= 0.012, g_loss 4.638, d_loss 0.006\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 146/390 d_loss_real= 0.002, d_loss_fake= 0.008, g_loss 5.203, d_loss 0.005\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 147/390 d_loss_real= 0.000, d_loss_fake= 0.004, g_loss 5.785, d_loss 0.002\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 148/390 d_loss_real= 0.003, d_loss_fake= 0.003, g_loss 6.149, d_loss 0.003\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 149/390 d_loss_real= 0.005, d_loss_fake= 0.002, g_loss 6.329, d_loss 0.003\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 150/390 d_loss_real= 0.003, d_loss_fake= 0.002, g_loss 6.469, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 151/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 6.603, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 152/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 6.721, d_loss 0.001\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 153/390 d_loss_real= 0.008, d_loss_fake= 0.001, g_loss 6.722, d_loss 0.004\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 154/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 6.710, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 155/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 6.678, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 156/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 6.642, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 157/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 6.630, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 158/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 6.630, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 159/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 6.655, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 160/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 6.689, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 161/390 d_loss_real= 0.003, d_loss_fake= 0.001, g_loss 6.664, d_loss 0.002\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 162/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 6.673, d_loss 0.001\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 163/390 d_loss_real= 0.003, d_loss_fake= 0.001, g_loss 6.650, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 164/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 6.661, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 165/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 6.687, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 166/390 d_loss_real= 0.005, d_loss_fake= 0.001, g_loss 6.631, d_loss 0.003\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 167/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 6.625, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 168/390 d_loss_real= 0.006, d_loss_fake= 0.001, g_loss 6.435, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 169/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.286, d_loss 0.002\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8 Batch 170/390 d_loss_real= 0.011, d_loss_fake= 0.003, g_loss 5.465, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 171/390 d_loss_real= 0.000, d_loss_fake= 0.006, g_loss 4.980, d_loss 0.003\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8 Batch 172/390 d_loss_real= 0.026, d_loss_fake= 0.011, g_loss 4.588, d_loss 0.018\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 173/390 d_loss_real= 0.000, d_loss_fake= 0.010, g_loss 5.131, d_loss 0.005\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 174/390 d_loss_real= 0.001, d_loss_fake= 0.004, g_loss 5.852, d_loss 0.002\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 175/390 d_loss_real= 0.008, d_loss_fake= 0.003, g_loss 6.052, d_loss 0.005\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 176/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.279, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 177/390 d_loss_real= 0.020, d_loss_fake= 0.003, g_loss 5.586, d_loss 0.011\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 178/390 d_loss_real= 0.000, d_loss_fake= 0.005, g_loss 5.131, d_loss 0.003\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8 Batch 179/390 d_loss_real= 0.000, d_loss_fake= 0.007, g_loss 5.039, d_loss 0.004\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 180/390 d_loss_real= 0.002, d_loss_fake= 0.006, g_loss 5.308, d_loss 0.004\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 181/390 d_loss_real= 0.001, d_loss_fake= 0.004, g_loss 5.674, d_loss 0.003\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8 Batch 182/390 d_loss_real= 0.000, d_loss_fake= 0.003, g_loss 6.062, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 183/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.428, d_loss 0.002\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 184/390 d_loss_real= 0.004, d_loss_fake= 0.001, g_loss 6.657, d_loss 0.003\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 185/390 d_loss_real= 0.024, d_loss_fake= 0.001, g_loss 6.461, d_loss 0.013\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 186/390 d_loss_real= 0.011, d_loss_fake= 0.002, g_loss 5.806, d_loss 0.007\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8 Batch 187/390 d_loss_real= 0.000, d_loss_fake= 0.004, g_loss 5.212, d_loss 0.002\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 188/390 d_loss_real= 0.002, d_loss_fake= 0.007, g_loss 5.050, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 189/390 d_loss_real= 0.001, d_loss_fake= 0.006, g_loss 5.461, d_loss 0.003\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 190/390 d_loss_real= 0.000, d_loss_fake= 0.003, g_loss 5.957, d_loss 0.002\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 191/390 d_loss_real= 0.003, d_loss_fake= 0.002, g_loss 6.273, d_loss 0.002\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 192/390 d_loss_real= 0.005, d_loss_fake= 0.002, g_loss 6.414, d_loss 0.003\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8 Batch 193/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.528, d_loss 0.001\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 194/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 6.639, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 195/390 d_loss_real= 0.016, d_loss_fake= 0.001, g_loss 6.480, d_loss 0.009\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 196/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.331, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 197/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.236, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 198/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.193, d_loss 0.002\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 199/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.229, d_loss 0.001\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8 Batch 200/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.337, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 201/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.380, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 202/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.460, d_loss 0.001\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 203/390 d_loss_real= 0.006, d_loss_fake= 0.002, g_loss 6.442, d_loss 0.004\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8 Batch 204/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.470, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8 Batch 205/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.529, d_loss 0.001\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 206/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 6.596, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 207/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 6.684, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 208/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 6.740, d_loss 0.002\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 209/390 d_loss_real= 0.006, d_loss_fake= 0.001, g_loss 6.598, d_loss 0.004\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 210/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 6.467, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 211/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.385, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 212/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 6.365, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 213/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.465, d_loss 0.001\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 214/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 6.604, d_loss 0.001\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 215/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 6.711, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 216/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 6.803, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 217/390 d_loss_real= 0.003, d_loss_fake= 0.001, g_loss 6.792, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 218/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 6.795, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 219/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 6.762, d_loss 0.002\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 220/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 6.751, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 221/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 6.764, d_loss 0.001\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 222/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 6.806, d_loss 0.001\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 223/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 6.864, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 224/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 6.922, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 225/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 6.976, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8 Batch 226/390 d_loss_real= 0.008, d_loss_fake= 0.001, g_loss 6.712, d_loss 0.005\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 227/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 6.429, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 228/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.312, d_loss 0.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 229/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.364, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 230/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.525, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 231/390 d_loss_real= 0.029, d_loss_fake= 0.002, g_loss 5.937, d_loss 0.016\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8 Batch 232/390 d_loss_real= 0.000, d_loss_fake= 0.003, g_loss 5.681, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 233/390 d_loss_real= 0.001, d_loss_fake= 0.004, g_loss 5.768, d_loss 0.002\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 234/390 d_loss_real= 0.004, d_loss_fake= 0.003, g_loss 5.889, d_loss 0.003\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 235/390 d_loss_real= 0.005, d_loss_fake= 0.003, g_loss 5.948, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 236/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.157, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 237/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.373, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 238/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.576, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 239/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 6.691, d_loss 0.002\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8 Batch 240/390 d_loss_real= 0.006, d_loss_fake= 0.001, g_loss 6.665, d_loss 0.004\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 241/390 d_loss_real= 0.003, d_loss_fake= 0.001, g_loss 6.595, d_loss 0.002\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 242/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 6.571, d_loss 0.001\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 243/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 6.595, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 244/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 6.660, d_loss 0.001\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8 Batch 245/390 d_loss_real= 0.011, d_loss_fake= 0.001, g_loss 6.405, d_loss 0.006\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 246/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.207, d_loss 0.001\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 247/390 d_loss_real= 0.004, d_loss_fake= 0.002, g_loss 6.067, d_loss 0.003\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 248/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.080, d_loss 0.002\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 249/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.227, d_loss 0.001\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 250/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.397, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 251/390 d_loss_real= 0.023, d_loss_fake= 0.003, g_loss 5.330, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 252/390 d_loss_real= 0.033, d_loss_fake= 0.008, g_loss 4.787, d_loss 0.020\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 253/390 d_loss_real= 0.000, d_loss_fake= 0.009, g_loss 4.977, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 254/390 d_loss_real= 0.001, d_loss_fake= 0.006, g_loss 5.582, d_loss 0.003\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 255/390 d_loss_real= 0.000, d_loss_fake= 0.003, g_loss 6.219, d_loss 0.002\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 256/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.707, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 257/390 d_loss_real= 0.008, d_loss_fake= 0.001, g_loss 6.840, d_loss 0.005\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 258/390 d_loss_real= 0.004, d_loss_fake= 0.001, g_loss 6.877, d_loss 0.003\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 259/390 d_loss_real= 0.003, d_loss_fake= 0.001, g_loss 6.862, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 260/390 d_loss_real= 0.005, d_loss_fake= 0.001, g_loss 6.753, d_loss 0.003\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 261/390 d_loss_real= 0.001, d_loss_fake= 0.001, g_loss 6.680, d_loss 0.001\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 262/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 6.637, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 263/390 d_loss_real= 0.000, d_loss_fake= 0.001, g_loss 6.625, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 264/390 d_loss_real= 0.003, d_loss_fake= 0.001, g_loss 6.532, d_loss 0.002\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 265/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.378, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 266/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.270, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 267/390 d_loss_real= 0.001, d_loss_fake= 0.003, g_loss 5.871, d_loss 0.002\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8 Batch 268/390 d_loss_real= 0.001, d_loss_fake= 0.007, g_loss 5.171, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 269/390 d_loss_real= 0.001, d_loss_fake= 0.007, g_loss 5.317, d_loss 0.004\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 270/390 d_loss_real= 0.014, d_loss_fake= 0.005, g_loss 5.550, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 271/390 d_loss_real= 0.013, d_loss_fake= 0.005, g_loss 5.275, d_loss 0.009\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 272/390 d_loss_real= 0.001, d_loss_fake= 0.009, g_loss 4.888, d_loss 0.005\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 273/390 d_loss_real= 0.010, d_loss_fake= 0.055, g_loss 4.439, d_loss 0.033\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8 Batch 274/390 d_loss_real= 0.003, d_loss_fake= 0.004, g_loss 6.446, d_loss 0.004\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 275/390 d_loss_real= 0.002, d_loss_fake= 0.001, g_loss 7.636, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 276/390 d_loss_real= 0.124, d_loss_fake= 0.001, g_loss 6.632, d_loss 0.063\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 277/390 d_loss_real= 0.012, d_loss_fake= 0.007, g_loss 4.623, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 278/390 d_loss_real= 0.001, d_loss_fake= 0.954, g_loss 7.667, d_loss 0.478\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 279/390 d_loss_real= 0.670, d_loss_fake= 0.002, g_loss 10.120, d_loss 0.336\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 280/390 d_loss_real= 4.334, d_loss_fake= 1.837, g_loss 3.315, d_loss 3.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 281/390 d_loss_real= 4.540, d_loss_fake= 0.532, g_loss 3.333, d_loss 2.536\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 282/390 d_loss_real= 3.219, d_loss_fake= 0.403, g_loss 3.112, d_loss 1.811\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 283/390 d_loss_real= 0.406, d_loss_fake= 0.120, g_loss 4.081, d_loss 0.263\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 284/390 d_loss_real= 0.059, d_loss_fake= 0.025, g_loss 5.570, d_loss 0.042\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 285/390 d_loss_real= 0.002, d_loss_fake= 0.006, g_loss 6.626, d_loss 0.004\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 286/390 d_loss_real= 0.002, d_loss_fake= 0.002, g_loss 7.350, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 287/390 d_loss_real= 0.005, d_loss_fake= 0.002, g_loss 7.317, d_loss 0.003\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 288/390 d_loss_real= 0.007, d_loss_fake= 0.002, g_loss 7.296, d_loss 0.004\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8 Batch 289/390 d_loss_real= 0.012, d_loss_fake= 0.001, g_loss 7.163, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 290/390 d_loss_real= 0.009, d_loss_fake= 0.002, g_loss 6.623, d_loss 0.006\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 291/390 d_loss_real= 0.005, d_loss_fake= 0.001, g_loss 6.890, d_loss 0.003\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 292/390 d_loss_real= 0.004, d_loss_fake= 0.001, g_loss 7.295, d_loss 0.003\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 293/390 d_loss_real= 0.013, d_loss_fake= 0.001, g_loss 7.579, d_loss 0.007\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8 Batch 294/390 d_loss_real= 0.007, d_loss_fake= 0.000, g_loss 7.774, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 295/390 d_loss_real= 0.018, d_loss_fake= 0.000, g_loss 7.796, d_loss 0.009\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 296/390 d_loss_real= 0.015, d_loss_fake= 0.001, g_loss 7.108, d_loss 0.008\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 297/390 d_loss_real= 0.024, d_loss_fake= 0.004, g_loss 5.572, d_loss 0.014\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 298/390 d_loss_real= 0.005, d_loss_fake= 0.063, g_loss 3.281, d_loss 0.034\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8 Batch 299/390 d_loss_real= 0.018, d_loss_fake= 0.070, g_loss 3.589, d_loss 0.044\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 300/390 d_loss_real= 0.062, d_loss_fake= 0.582, g_loss 3.645, d_loss 0.322\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8 Batch 301/390 d_loss_real= 0.025, d_loss_fake= 0.003, g_loss 8.213, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 302/390 d_loss_real= 0.320, d_loss_fake= 0.000, g_loss 9.701, d_loss 0.160\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 303/390 d_loss_real= 0.646, d_loss_fake= 0.000, g_loss 9.245, d_loss 0.323\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 304/390 d_loss_real= 0.156, d_loss_fake= 0.000, g_loss 8.365, d_loss 0.078\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8 Batch 305/390 d_loss_real= 0.035, d_loss_fake= 0.000, g_loss 7.514, d_loss 0.018\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 306/390 d_loss_real= 0.005, d_loss_fake= 0.001, g_loss 6.742, d_loss 0.003\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 307/390 d_loss_real= 0.001, d_loss_fake= 0.002, g_loss 6.086, d_loss 0.001\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 308/390 d_loss_real= 0.000, d_loss_fake= 0.004, g_loss 5.263, d_loss 0.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 309/390 d_loss_real= 0.000, d_loss_fake= 0.012, g_loss 4.355, d_loss 0.006\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 310/390 d_loss_real= 0.001, d_loss_fake= 0.016, g_loss 4.137, d_loss 0.008\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 311/390 d_loss_real= 0.000, d_loss_fake= 0.018, g_loss 4.136, d_loss 0.009\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 312/390 d_loss_real= 0.000, d_loss_fake= 0.016, g_loss 4.305, d_loss 0.008\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 313/390 d_loss_real= 0.000, d_loss_fake= 0.013, g_loss 4.525, d_loss 0.007\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 314/390 d_loss_real= 0.000, d_loss_fake= 0.010, g_loss 4.730, d_loss 0.005\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 315/390 d_loss_real= 0.000, d_loss_fake= 0.009, g_loss 4.932, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 316/390 d_loss_real= 0.000, d_loss_fake= 0.008, g_loss 4.957, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 317/390 d_loss_real= 0.000, d_loss_fake= 0.009, g_loss 4.838, d_loss 0.005\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 318/390 d_loss_real= 0.001, d_loss_fake= 0.018, g_loss 4.366, d_loss 0.009\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 319/390 d_loss_real= 0.000, d_loss_fake= 0.285, g_loss 2.666, d_loss 0.143\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 320/390 d_loss_real= 0.000, d_loss_fake= 0.080, g_loss 4.155, d_loss 0.040\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 321/390 d_loss_real= 0.003, d_loss_fake= 0.282, g_loss 3.713, d_loss 0.143\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 322/390 d_loss_real= 0.018, d_loss_fake= 0.065, g_loss 4.986, d_loss 0.041\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 323/390 d_loss_real= 0.059, d_loss_fake= 0.022, g_loss 5.643, d_loss 0.041\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 324/390 d_loss_real= 0.214, d_loss_fake= 0.981, g_loss 3.676, d_loss 0.597\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 325/390 d_loss_real= 2.027, d_loss_fake= 0.543, g_loss 2.431, d_loss 1.285\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 326/390 d_loss_real= 3.320, d_loss_fake= 0.395, g_loss 1.046, d_loss 1.858\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 327/390 d_loss_real= 1.560, d_loss_fake= 1.588, g_loss 0.527, d_loss 1.574\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 328/390 d_loss_real= 0.708, d_loss_fake= 0.982, g_loss 1.447, d_loss 0.845\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 329/390 d_loss_real= 0.790, d_loss_fake= 0.214, g_loss 2.455, d_loss 0.502\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 330/390 d_loss_real= 1.096, d_loss_fake= 0.258, g_loss 1.576, d_loss 0.677\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 331/390 d_loss_real= 0.751, d_loss_fake= 0.822, g_loss 0.974, d_loss 0.786\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 332/390 d_loss_real= 0.577, d_loss_fake= 0.528, g_loss 1.567, d_loss 0.552\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 333/390 d_loss_real= 0.764, d_loss_fake= 0.213, g_loss 2.089, d_loss 0.488\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 334/390 d_loss_real= 0.816, d_loss_fake= 0.199, g_loss 1.712, d_loss 0.508\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 335/390 d_loss_real= 0.376, d_loss_fake= 0.305, g_loss 1.455, d_loss 0.341\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 336/390 d_loss_real= 0.307, d_loss_fake= 0.321, g_loss 1.684, d_loss 0.314\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 337/390 d_loss_real= 0.355, d_loss_fake= 0.204, g_loss 2.053, d_loss 0.280\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 338/390 d_loss_real= 0.339, d_loss_fake= 0.142, g_loss 2.261, d_loss 0.240\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 339/390 d_loss_real= 0.301, d_loss_fake= 0.125, g_loss 2.277, d_loss 0.213\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 340/390 d_loss_real= 0.275, d_loss_fake= 0.142, g_loss 2.141, d_loss 0.208\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 341/390 d_loss_real= 0.230, d_loss_fake= 0.153, g_loss 2.124, d_loss 0.191\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8 Batch 342/390 d_loss_real= 0.145, d_loss_fake= 0.146, g_loss 2.254, d_loss 0.145\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8 Batch 343/390 d_loss_real= 0.247, d_loss_fake= 0.152, g_loss 2.188, d_loss 0.199\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 344/390 d_loss_real= 0.294, d_loss_fake= 0.152, g_loss 2.227, d_loss 0.223\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8 Batch 345/390 d_loss_real= 0.359, d_loss_fake= 0.131, g_loss 2.321, d_loss 0.245\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 346/390 d_loss_real= 0.246, d_loss_fake= 0.147, g_loss 2.248, d_loss 0.196\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 347/390 d_loss_real= 0.257, d_loss_fake= 0.171, g_loss 2.168, d_loss 0.214\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8 Batch 348/390 d_loss_real= 0.132, d_loss_fake= 0.175, g_loss 2.354, d_loss 0.153\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8 Batch 349/390 d_loss_real= 0.247, d_loss_fake= 0.200, g_loss 2.351, d_loss 0.223\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 350/390 d_loss_real= 0.401, d_loss_fake= 0.352, g_loss 1.968, d_loss 0.376\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 351/390 d_loss_real= 0.364, d_loss_fake= 0.648, g_loss 1.892, d_loss 0.506\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 352/390 d_loss_real= 0.511, d_loss_fake= 0.584, g_loss 2.155, d_loss 0.548\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 353/390 d_loss_real= 1.314, d_loss_fake= 0.424, g_loss 2.375, d_loss 0.869\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 354/390 d_loss_real= 1.555, d_loss_fake= 0.474, g_loss 1.674, d_loss 1.015\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 355/390 d_loss_real= 1.733, d_loss_fake= 0.903, g_loss 1.245, d_loss 1.318\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 356/390 d_loss_real= 1.360, d_loss_fake= 1.123, g_loss 1.417, d_loss 1.242\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 357/390 d_loss_real= 0.964, d_loss_fake= 0.853, g_loss 2.264, d_loss 0.908\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 358/390 d_loss_real= 0.786, d_loss_fake= 0.299, g_loss 3.138, d_loss 0.542\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8 Batch 359/390 d_loss_real= 0.685, d_loss_fake= 0.118, g_loss 3.461, d_loss 0.401\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 360/390 d_loss_real= 0.420, d_loss_fake= 0.097, g_loss 3.443, d_loss 0.258\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 361/390 d_loss_real= 0.142, d_loss_fake= 0.067, g_loss 3.595, d_loss 0.104\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 362/390 d_loss_real= 0.118, d_loss_fake= 0.085, g_loss 3.244, d_loss 0.102\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 363/390 d_loss_real= 0.053, d_loss_fake= 0.122, g_loss 2.903, d_loss 0.087\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 364/390 d_loss_real= 0.021, d_loss_fake= 0.171, g_loss 2.692, d_loss 0.096\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 365/390 d_loss_real= 0.023, d_loss_fake= 0.211, g_loss 2.613, d_loss 0.117\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 366/390 d_loss_real= 0.025, d_loss_fake= 0.270, g_loss 2.650, d_loss 0.148\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 367/390 d_loss_real= 0.027, d_loss_fake= 0.431, g_loss 2.356, d_loss 0.229\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 368/390 d_loss_real= 0.028, d_loss_fake= 0.382, g_loss 2.422, d_loss 0.205\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8 Batch 369/390 d_loss_real= 0.194, d_loss_fake= 0.468, g_loss 2.457, d_loss 0.331\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 370/390 d_loss_real= 0.513, d_loss_fake= 0.386, g_loss 2.453, d_loss 0.449\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8 Batch 371/390 d_loss_real= 0.787, d_loss_fake= 1.092, g_loss 1.155, d_loss 0.940\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 372/390 d_loss_real= 1.069, d_loss_fake= 2.129, g_loss 0.451, d_loss 1.599\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 373/390 d_loss_real= 1.963, d_loss_fake= 1.050, g_loss 1.028, d_loss 1.506\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 374/390 d_loss_real= 1.988, d_loss_fake= 0.512, g_loss 1.481, d_loss 1.250\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 375/390 d_loss_real= 1.198, d_loss_fake= 0.274, g_loss 1.799, d_loss 0.736\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 376/390 d_loss_real= 0.776, d_loss_fake= 0.285, g_loss 1.626, d_loss 0.531\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 377/390 d_loss_real= 0.350, d_loss_fake= 0.405, g_loss 1.411, d_loss 0.377\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 8 Batch 378/390 d_loss_real= 0.332, d_loss_fake= 0.589, g_loss 1.180, d_loss 0.461\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8 Batch 379/390 d_loss_real= 0.324, d_loss_fake= 0.780, g_loss 1.115, d_loss 0.552\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8 Batch 380/390 d_loss_real= 0.247, d_loss_fake= 0.619, g_loss 1.519, d_loss 0.433\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 8 Batch 381/390 d_loss_real= 0.487, d_loss_fake= 0.186, g_loss 2.596, d_loss 0.337\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 382/390 d_loss_real= 0.851, d_loss_fake= 0.064, g_loss 3.188, d_loss 0.457\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 383/390 d_loss_real= 1.104, d_loss_fake= 0.053, g_loss 2.877, d_loss 0.578\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 8 Batch 384/390 d_loss_real= 0.790, d_loss_fake= 0.090, g_loss 2.222, d_loss 0.440\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8 Batch 385/390 d_loss_real= 0.352, d_loss_fake= 0.183, g_loss 1.605, d_loss 0.267\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 386/390 d_loss_real= 0.444, d_loss_fake= 0.325, g_loss 1.256, d_loss 0.385\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8 Batch 387/390 d_loss_real= 0.146, d_loss_fake= 0.384, g_loss 1.357, d_loss 0.265\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 388/390 d_loss_real= 0.185, d_loss_fake= 0.261, g_loss 1.802, d_loss 0.223\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8 Batch 389/390 d_loss_real= 0.111, d_loss_fake= 0.147, g_loss 2.364, d_loss 0.129\n",
            "2/2 [==============================] - 0s 9ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 Batch 390/390 d_loss_real= 0.182, d_loss_fake= 0.084, g_loss 2.809, d_loss 0.133\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 1/390 d_loss_real= 0.209, d_loss_fake= 0.062, g_loss 2.968, d_loss 0.135\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 2/390 d_loss_real= 0.303, d_loss_fake= 0.058, g_loss 2.908, d_loss 0.181\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 3/390 d_loss_real= 0.148, d_loss_fake= 0.063, g_loss 2.778, d_loss 0.106\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 4/390 d_loss_real= 0.156, d_loss_fake= 0.075, g_loss 2.586, d_loss 0.115\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 5/390 d_loss_real= 0.128, d_loss_fake= 0.092, g_loss 2.406, d_loss 0.110\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 6/390 d_loss_real= 0.137, d_loss_fake= 0.110, g_loss 2.298, d_loss 0.124\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9 Batch 7/390 d_loss_real= 0.160, d_loss_fake= 0.119, g_loss 2.263, d_loss 0.140\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 8/390 d_loss_real= 0.108, d_loss_fake= 0.112, g_loss 2.413, d_loss 0.110\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 9/390 d_loss_real= 0.068, d_loss_fake= 0.087, g_loss 2.700, d_loss 0.078\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9 Batch 10/390 d_loss_real= 0.076, d_loss_fake= 0.063, g_loss 2.999, d_loss 0.069\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9 Batch 11/390 d_loss_real= 0.157, d_loss_fake= 0.049, g_loss 3.161, d_loss 0.103\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9 Batch 12/390 d_loss_real= 0.082, d_loss_fake= 0.043, g_loss 3.251, d_loss 0.063\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 13/390 d_loss_real= 0.090, d_loss_fake= 0.040, g_loss 3.276, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 14/390 d_loss_real= 0.087, d_loss_fake= 0.041, g_loss 3.255, d_loss 0.064\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 15/390 d_loss_real= 0.100, d_loss_fake= 0.044, g_loss 3.110, d_loss 0.072\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9 Batch 16/390 d_loss_real= 0.083, d_loss_fake= 0.053, g_loss 2.958, d_loss 0.068\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9 Batch 17/390 d_loss_real= 0.086, d_loss_fake= 0.062, g_loss 2.835, d_loss 0.074\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9 Batch 18/390 d_loss_real= 0.056, d_loss_fake= 0.065, g_loss 2.813, d_loss 0.061\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 19/390 d_loss_real= 0.071, d_loss_fake= 0.067, g_loss 2.859, d_loss 0.069\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9 Batch 20/390 d_loss_real= 0.079, d_loss_fake= 0.059, g_loss 3.006, d_loss 0.069\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9 Batch 21/390 d_loss_real= 0.049, d_loss_fake= 0.050, g_loss 3.184, d_loss 0.049\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 22/390 d_loss_real= 0.055, d_loss_fake= 0.039, g_loss 3.423, d_loss 0.047\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9 Batch 23/390 d_loss_real= 0.055, d_loss_fake= 0.031, g_loss 3.616, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 24/390 d_loss_real= 0.093, d_loss_fake= 0.027, g_loss 3.693, d_loss 0.060\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 25/390 d_loss_real= 0.042, d_loss_fake= 0.025, g_loss 3.760, d_loss 0.034\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9 Batch 26/390 d_loss_real= 0.047, d_loss_fake= 0.024, g_loss 3.780, d_loss 0.036\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9 Batch 27/390 d_loss_real= 0.085, d_loss_fake= 0.025, g_loss 3.703, d_loss 0.055\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 28/390 d_loss_real= 0.123, d_loss_fake= 0.030, g_loss 3.441, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 29/390 d_loss_real= 0.063, d_loss_fake= 0.041, g_loss 3.137, d_loss 0.052\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 30/390 d_loss_real= 0.073, d_loss_fake= 0.053, g_loss 3.008, d_loss 0.063\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 31/390 d_loss_real= 0.112, d_loss_fake= 0.055, g_loss 3.079, d_loss 0.084\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 32/390 d_loss_real= 0.059, d_loss_fake= 0.050, g_loss 3.194, d_loss 0.054\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 33/390 d_loss_real= 0.037, d_loss_fake= 0.042, g_loss 3.375, d_loss 0.039\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9 Batch 34/390 d_loss_real= 0.043, d_loss_fake= 0.034, g_loss 3.553, d_loss 0.038\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 35/390 d_loss_real= 0.029, d_loss_fake= 0.027, g_loss 3.750, d_loss 0.028\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9 Batch 36/390 d_loss_real= 0.052, d_loss_fake= 0.023, g_loss 3.853, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 37/390 d_loss_real= 0.059, d_loss_fake= 0.023, g_loss 3.842, d_loss 0.041\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9 Batch 38/390 d_loss_real= 0.043, d_loss_fake= 0.023, g_loss 3.824, d_loss 0.033\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 39/390 d_loss_real= 0.045, d_loss_fake= 0.024, g_loss 3.748, d_loss 0.035\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 40/390 d_loss_real= 0.051, d_loss_fake= 0.026, g_loss 3.690, d_loss 0.038\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 41/390 d_loss_real= 0.040, d_loss_fake= 0.027, g_loss 3.663, d_loss 0.033\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9 Batch 42/390 d_loss_real= 0.103, d_loss_fake= 0.031, g_loss 3.461, d_loss 0.067\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 43/390 d_loss_real= 0.024, d_loss_fake= 0.036, g_loss 3.382, d_loss 0.030\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9 Batch 44/390 d_loss_real= 0.053, d_loss_fake= 0.039, g_loss 3.299, d_loss 0.046\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 45/390 d_loss_real= 0.021, d_loss_fake= 0.038, g_loss 3.369, d_loss 0.030\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 46/390 d_loss_real= 0.047, d_loss_fake= 0.034, g_loss 3.504, d_loss 0.041\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 47/390 d_loss_real= 0.043, d_loss_fake= 0.031, g_loss 3.569, d_loss 0.037\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9 Batch 48/390 d_loss_real= 0.015, d_loss_fake= 0.028, g_loss 3.713, d_loss 0.021\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 49/390 d_loss_real= 0.031, d_loss_fake= 0.024, g_loss 3.832, d_loss 0.027\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 50/390 d_loss_real= 0.042, d_loss_fake= 0.022, g_loss 3.905, d_loss 0.032\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 51/390 d_loss_real= 0.048, d_loss_fake= 0.022, g_loss 3.851, d_loss 0.035\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 52/390 d_loss_real= 0.021, d_loss_fake= 0.022, g_loss 3.826, d_loss 0.022\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 53/390 d_loss_real= 0.049, d_loss_fake= 0.024, g_loss 3.757, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 54/390 d_loss_real= 0.028, d_loss_fake= 0.026, g_loss 3.725, d_loss 0.027\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 55/390 d_loss_real= 0.040, d_loss_fake= 0.026, g_loss 3.690, d_loss 0.033\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 56/390 d_loss_real= 0.031, d_loss_fake= 0.027, g_loss 3.688, d_loss 0.029\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9 Batch 57/390 d_loss_real= 0.028, d_loss_fake= 0.026, g_loss 3.723, d_loss 0.027\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9 Batch 58/390 d_loss_real= 0.027, d_loss_fake= 0.024, g_loss 3.847, d_loss 0.025\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 59/390 d_loss_real= 0.023, d_loss_fake= 0.021, g_loss 3.934, d_loss 0.022\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 60/390 d_loss_real= 0.020, d_loss_fake= 0.022, g_loss 3.933, d_loss 0.021\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 61/390 d_loss_real= 0.033, d_loss_fake= 0.068, g_loss 2.956, d_loss 0.050\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9 Batch 62/390 d_loss_real= 0.018, d_loss_fake= 0.227, g_loss 2.264, d_loss 0.123\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 63/390 d_loss_real= 0.066, d_loss_fake= 0.200, g_loss 2.529, d_loss 0.133\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9 Batch 64/390 d_loss_real= 0.122, d_loss_fake= 0.080, g_loss 3.271, d_loss 0.101\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 65/390 d_loss_real= 0.305, d_loss_fake= 0.044, g_loss 3.526, d_loss 0.175\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 66/390 d_loss_real= 0.613, d_loss_fake= 0.056, g_loss 2.876, d_loss 0.334\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 67/390 d_loss_real= 0.179, d_loss_fake= 0.117, g_loss 2.210, d_loss 0.148\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 68/390 d_loss_real= 0.117, d_loss_fake= 0.184, g_loss 2.059, d_loss 0.150\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 69/390 d_loss_real= 0.079, d_loss_fake= 0.215, g_loss 2.226, d_loss 0.147\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9 Batch 70/390 d_loss_real= 0.073, d_loss_fake= 0.187, g_loss 2.453, d_loss 0.130\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 71/390 d_loss_real= 0.206, d_loss_fake= 0.114, g_loss 2.787, d_loss 0.160\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 72/390 d_loss_real= 0.142, d_loss_fake= 0.062, g_loss 3.330, d_loss 0.102\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9 Batch 73/390 d_loss_real= 0.166, d_loss_fake= 0.043, g_loss 3.521, d_loss 0.105\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 74/390 d_loss_real= 0.150, d_loss_fake= 0.045, g_loss 3.312, d_loss 0.098\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 75/390 d_loss_real= 0.152, d_loss_fake= 0.168, g_loss 2.612, d_loss 0.160\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9 Batch 76/390 d_loss_real= 0.219, d_loss_fake= 0.652, g_loss 1.864, d_loss 0.436\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 77/390 d_loss_real= 0.242, d_loss_fake= 0.122, g_loss 3.405, d_loss 0.182\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 78/390 d_loss_real= 0.233, d_loss_fake= 0.039, g_loss 4.079, d_loss 0.136\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 79/390 d_loss_real= 0.268, d_loss_fake= 0.037, g_loss 3.879, d_loss 0.152\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 80/390 d_loss_real= 0.378, d_loss_fake= 0.040, g_loss 3.523, d_loss 0.209\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9 Batch 81/390 d_loss_real= 0.364, d_loss_fake= 0.100, g_loss 2.607, d_loss 0.232\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 82/390 d_loss_real= 0.109, d_loss_fake= 0.747, g_loss 1.558, d_loss 0.428\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9 Batch 83/390 d_loss_real= 0.099, d_loss_fake= 0.606, g_loss 2.181, d_loss 0.352\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 84/390 d_loss_real= 0.198, d_loss_fake= 0.397, g_loss 2.879, d_loss 0.297\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 85/390 d_loss_real= 0.696, d_loss_fake= 0.034, g_loss 4.550, d_loss 0.365\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 86/390 d_loss_real= 0.781, d_loss_fake= 0.008, g_loss 5.267, d_loss 0.394\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 87/390 d_loss_real= 0.710, d_loss_fake= 0.007, g_loss 4.944, d_loss 0.358\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 88/390 d_loss_real= 0.283, d_loss_fake= 0.016, g_loss 4.012, d_loss 0.150\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 89/390 d_loss_real= 0.098, d_loss_fake= 0.061, g_loss 2.746, d_loss 0.080\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9 Batch 90/390 d_loss_real= 0.044, d_loss_fake= 0.150, g_loss 2.208, d_loss 0.097\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9 Batch 91/390 d_loss_real= 0.044, d_loss_fake= 0.187, g_loss 2.269, d_loss 0.115\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 92/390 d_loss_real= 0.060, d_loss_fake= 0.175, g_loss 2.663, d_loss 0.117\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 93/390 d_loss_real= 0.027, d_loss_fake= 0.091, g_loss 3.189, d_loss 0.059\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 94/390 d_loss_real= 0.039, d_loss_fake= 0.075, g_loss 3.405, d_loss 0.057\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 95/390 d_loss_real= 0.083, d_loss_fake= 0.138, g_loss 2.804, d_loss 0.111\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 96/390 d_loss_real= 0.102, d_loss_fake= 0.306, g_loss 2.354, d_loss 0.204\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 97/390 d_loss_real= 0.148, d_loss_fake= 0.239, g_loss 3.057, d_loss 0.193\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 98/390 d_loss_real= 0.559, d_loss_fake= 0.110, g_loss 3.448, d_loss 0.334\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 99/390 d_loss_real= 0.815, d_loss_fake= 0.170, g_loss 2.653, d_loss 0.493\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 100/390 d_loss_real= 0.688, d_loss_fake= 0.560, g_loss 1.870, d_loss 0.624\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 101/390 d_loss_real= 0.605, d_loss_fake= 0.332, g_loss 2.192, d_loss 0.468\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 102/390 d_loss_real= 0.755, d_loss_fake= 0.108, g_loss 2.708, d_loss 0.431\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 103/390 d_loss_real= 0.569, d_loss_fake= 0.117, g_loss 2.186, d_loss 0.343\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 104/390 d_loss_real= 0.355, d_loss_fake= 0.404, g_loss 1.465, d_loss 0.380\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 105/390 d_loss_real= 0.243, d_loss_fake= 1.064, g_loss 1.372, d_loss 0.653\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 106/390 d_loss_real= 0.581, d_loss_fake= 0.185, g_loss 2.875, d_loss 0.383\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 107/390 d_loss_real= 0.782, d_loss_fake= 0.043, g_loss 3.522, d_loss 0.412\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 108/390 d_loss_real= 0.858, d_loss_fake= 0.048, g_loss 2.754, d_loss 0.453\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9 Batch 109/390 d_loss_real= 0.431, d_loss_fake= 0.145, g_loss 1.655, d_loss 0.288\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 110/390 d_loss_real= 0.125, d_loss_fake= 0.363, g_loss 1.281, d_loss 0.244\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 111/390 d_loss_real= 0.123, d_loss_fake= 0.349, g_loss 1.653, d_loss 0.236\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 112/390 d_loss_real= 0.109, d_loss_fake= 0.153, g_loss 2.482, d_loss 0.131\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 113/390 d_loss_real= 0.142, d_loss_fake= 0.061, g_loss 3.255, d_loss 0.101\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9 Batch 114/390 d_loss_real= 0.493, d_loss_fake= 0.036, g_loss 3.479, d_loss 0.264\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 115/390 d_loss_real= 0.211, d_loss_fake= 0.035, g_loss 3.360, d_loss 0.123\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 116/390 d_loss_real= 0.115, d_loss_fake= 0.043, g_loss 3.109, d_loss 0.079\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 117/390 d_loss_real= 0.120, d_loss_fake= 0.057, g_loss 2.833, d_loss 0.089\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 118/390 d_loss_real= 0.077, d_loss_fake= 0.076, g_loss 2.620, d_loss 0.077\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9 Batch 119/390 d_loss_real= 0.110, d_loss_fake= 0.091, g_loss 2.500, d_loss 0.100\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 120/390 d_loss_real= 0.098, d_loss_fake= 0.095, g_loss 2.559, d_loss 0.096\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9 Batch 121/390 d_loss_real= 0.097, d_loss_fake= 0.083, g_loss 2.719, d_loss 0.090\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 122/390 d_loss_real= 0.038, d_loss_fake= 0.063, g_loss 3.040, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 123/390 d_loss_real= 0.088, d_loss_fake= 0.045, g_loss 3.330, d_loss 0.066\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9 Batch 124/390 d_loss_real= 0.069, d_loss_fake= 0.034, g_loss 3.568, d_loss 0.052\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9 Batch 125/390 d_loss_real= 0.080, d_loss_fake= 0.028, g_loss 3.710, d_loss 0.054\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 126/390 d_loss_real= 0.119, d_loss_fake= 0.027, g_loss 3.617, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 127/390 d_loss_real= 0.097, d_loss_fake= 0.034, g_loss 3.306, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 128/390 d_loss_real= 0.097, d_loss_fake= 0.049, g_loss 2.934, d_loss 0.073\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9 Batch 129/390 d_loss_real= 0.062, d_loss_fake= 0.069, g_loss 2.697, d_loss 0.066\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9 Batch 130/390 d_loss_real= 0.058, d_loss_fake= 0.081, g_loss 2.659, d_loss 0.070\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9 Batch 131/390 d_loss_real= 0.019, d_loss_fake= 0.071, g_loss 2.923, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 132/390 d_loss_real= 0.037, d_loss_fake= 0.049, g_loss 3.295, d_loss 0.043\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9 Batch 133/390 d_loss_real= 0.084, d_loss_fake= 0.034, g_loss 3.579, d_loss 0.059\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 134/390 d_loss_real= 0.070, d_loss_fake= 0.028, g_loss 3.694, d_loss 0.049\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9 Batch 135/390 d_loss_real= 0.045, d_loss_fake= 0.025, g_loss 3.779, d_loss 0.035\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9 Batch 136/390 d_loss_real= 0.062, d_loss_fake= 0.025, g_loss 3.702, d_loss 0.044\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9 Batch 137/390 d_loss_real= 0.046, d_loss_fake= 0.028, g_loss 3.584, d_loss 0.037\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9 Batch 138/390 d_loss_real= 0.042, d_loss_fake= 0.031, g_loss 3.497, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 139/390 d_loss_real= 0.040, d_loss_fake= 0.034, g_loss 3.449, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 140/390 d_loss_real= 0.056, d_loss_fake= 0.036, g_loss 3.392, d_loss 0.046\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9 Batch 141/390 d_loss_real= 0.053, d_loss_fake= 0.037, g_loss 3.371, d_loss 0.045\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 142/390 d_loss_real= 0.040, d_loss_fake= 0.036, g_loss 3.480, d_loss 0.038\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9 Batch 143/390 d_loss_real= 0.026, d_loss_fake= 0.030, g_loss 3.650, d_loss 0.028\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 144/390 d_loss_real= 0.027, d_loss_fake= 0.025, g_loss 3.835, d_loss 0.026\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9 Batch 145/390 d_loss_real= 0.055, d_loss_fake= 0.022, g_loss 3.874, d_loss 0.038\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9 Batch 146/390 d_loss_real= 0.038, d_loss_fake= 0.022, g_loss 3.865, d_loss 0.030\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9 Batch 147/390 d_loss_real= 0.029, d_loss_fake= 0.022, g_loss 3.863, d_loss 0.025\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9 Batch 148/390 d_loss_real= 0.018, d_loss_fake= 0.022, g_loss 3.915, d_loss 0.020\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9 Batch 149/390 d_loss_real= 0.052, d_loss_fake= 0.021, g_loss 3.951, d_loss 0.036\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 150/390 d_loss_real= 0.033, d_loss_fake= 0.020, g_loss 3.950, d_loss 0.026\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 151/390 d_loss_real= 0.084, d_loss_fake= 0.022, g_loss 3.847, d_loss 0.053\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 152/390 d_loss_real= 0.024, d_loss_fake= 0.023, g_loss 3.801, d_loss 0.023\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 153/390 d_loss_real= 0.023, d_loss_fake= 0.024, g_loss 3.791, d_loss 0.024\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 154/390 d_loss_real= 0.009, d_loss_fake= 0.022, g_loss 3.937, d_loss 0.015\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 155/390 d_loss_real= 0.008, d_loss_fake= 0.019, g_loss 4.124, d_loss 0.014\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9 Batch 156/390 d_loss_real= 0.020, d_loss_fake= 0.015, g_loss 4.266, d_loss 0.018\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9 Batch 157/390 d_loss_real= 0.027, d_loss_fake= 0.014, g_loss 4.315, d_loss 0.021\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 158/390 d_loss_real= 0.059, d_loss_fake= 0.015, g_loss 4.164, d_loss 0.037\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 159/390 d_loss_real= 0.024, d_loss_fake= 0.017, g_loss 4.028, d_loss 0.021\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 160/390 d_loss_real= 0.021, d_loss_fake= 0.020, g_loss 3.920, d_loss 0.020\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9 Batch 161/390 d_loss_real= 0.031, d_loss_fake= 0.022, g_loss 3.864, d_loss 0.026\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 162/390 d_loss_real= 0.009, d_loss_fake= 0.021, g_loss 3.924, d_loss 0.015\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9 Batch 163/390 d_loss_real= 0.160, d_loss_fake= 0.019, g_loss 4.033, d_loss 0.090\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 164/390 d_loss_real= 0.066, d_loss_fake= 0.019, g_loss 4.008, d_loss 0.043\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9 Batch 165/390 d_loss_real= 0.012, d_loss_fake= 0.019, g_loss 4.050, d_loss 0.016\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 166/390 d_loss_real= 0.080, d_loss_fake= 0.020, g_loss 3.876, d_loss 0.050\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 167/390 d_loss_real= 0.024, d_loss_fake= 0.023, g_loss 3.769, d_loss 0.023\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9 Batch 168/390 d_loss_real= 0.021, d_loss_fake= 0.026, g_loss 3.769, d_loss 0.023\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 169/390 d_loss_real= 0.011, d_loss_fake= 0.023, g_loss 3.901, d_loss 0.017\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 170/390 d_loss_real= 0.017, d_loss_fake= 0.019, g_loss 4.068, d_loss 0.018\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9 Batch 171/390 d_loss_real= 0.045, d_loss_fake= 0.018, g_loss 4.067, d_loss 0.031\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9 Batch 172/390 d_loss_real= 0.036, d_loss_fake= 0.018, g_loss 4.014, d_loss 0.027\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9 Batch 173/390 d_loss_real= 0.019, d_loss_fake= 0.020, g_loss 3.984, d_loss 0.019\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 174/390 d_loss_real= 0.026, d_loss_fake= 0.020, g_loss 4.031, d_loss 0.023\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9 Batch 175/390 d_loss_real= 0.042, d_loss_fake= 0.020, g_loss 3.981, d_loss 0.031\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 176/390 d_loss_real= 0.012, d_loss_fake= 0.024, g_loss 3.981, d_loss 0.018\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 177/390 d_loss_real= 0.036, d_loss_fake= 0.022, g_loss 3.949, d_loss 0.029\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 178/390 d_loss_real= 0.014, d_loss_fake= 0.026, g_loss 3.998, d_loss 0.020\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9 Batch 179/390 d_loss_real= 0.010, d_loss_fake= 0.018, g_loss 4.164, d_loss 0.014\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9 Batch 180/390 d_loss_real= 0.018, d_loss_fake= 0.016, g_loss 4.394, d_loss 0.017\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 181/390 d_loss_real= 0.016, d_loss_fake= 0.021, g_loss 4.347, d_loss 0.018\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 182/390 d_loss_real= 0.021, d_loss_fake= 0.023, g_loss 4.284, d_loss 0.022\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 183/390 d_loss_real= 0.016, d_loss_fake= 0.091, g_loss 4.510, d_loss 0.053\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9 Batch 184/390 d_loss_real= 0.027, d_loss_fake= 0.052, g_loss 4.669, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 185/390 d_loss_real= 0.062, d_loss_fake= 0.026, g_loss 4.402, d_loss 0.044\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 186/390 d_loss_real= 0.022, d_loss_fake= 0.365, g_loss 4.489, d_loss 0.194\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9 Batch 187/390 d_loss_real= 0.079, d_loss_fake= 0.527, g_loss 4.152, d_loss 0.303\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9 Batch 188/390 d_loss_real= 0.264, d_loss_fake= 0.349, g_loss 3.262, d_loss 0.306\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 189/390 d_loss_real= 0.106, d_loss_fake= 0.761, g_loss 2.849, d_loss 0.433\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 190/390 d_loss_real= 0.178, d_loss_fake= 1.989, g_loss 1.815, d_loss 1.084\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 191/390 d_loss_real= 0.980, d_loss_fake= 2.756, g_loss 0.866, d_loss 1.868\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9 Batch 192/390 d_loss_real= 2.001, d_loss_fake= 1.501, g_loss 1.269, d_loss 1.751\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 193/390 d_loss_real= 2.791, d_loss_fake= 0.812, g_loss 1.956, d_loss 1.802\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 194/390 d_loss_real= 2.853, d_loss_fake= 0.488, g_loss 2.027, d_loss 1.670\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 195/390 d_loss_real= 1.568, d_loss_fake= 0.498, g_loss 1.837, d_loss 1.033\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9 Batch 196/390 d_loss_real= 0.723, d_loss_fake= 0.295, g_loss 2.130, d_loss 0.509\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 197/390 d_loss_real= 0.150, d_loss_fake= 0.282, g_loss 2.439, d_loss 0.216\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 198/390 d_loss_real= 0.097, d_loss_fake= 0.395, g_loss 2.232, d_loss 0.246\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 199/390 d_loss_real= 0.163, d_loss_fake= 0.328, g_loss 2.201, d_loss 0.245\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9 Batch 200/390 d_loss_real= 0.120, d_loss_fake= 0.432, g_loss 2.282, d_loss 0.276\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9 Batch 201/390 d_loss_real= 0.357, d_loss_fake= 0.347, g_loss 2.093, d_loss 0.352\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9 Batch 202/390 d_loss_real= 0.557, d_loss_fake= 0.496, g_loss 1.704, d_loss 0.527\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 203/390 d_loss_real= 0.730, d_loss_fake= 0.632, g_loss 1.410, d_loss 0.681\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 204/390 d_loss_real= 1.158, d_loss_fake= 0.501, g_loss 1.456, d_loss 0.829\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9 Batch 205/390 d_loss_real= 1.266, d_loss_fake= 0.820, g_loss 0.989, d_loss 1.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 206/390 d_loss_real= 1.267, d_loss_fake= 0.682, g_loss 1.048, d_loss 0.974\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 207/390 d_loss_real= 1.242, d_loss_fake= 0.551, g_loss 1.114, d_loss 0.896\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 208/390 d_loss_real= 0.987, d_loss_fake= 0.542, g_loss 1.119, d_loss 0.764\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 209/390 d_loss_real= 0.692, d_loss_fake= 0.520, g_loss 1.128, d_loss 0.606\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9 Batch 210/390 d_loss_real= 0.426, d_loss_fake= 0.499, g_loss 1.201, d_loss 0.462\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 211/390 d_loss_real= 0.502, d_loss_fake= 0.416, g_loss 1.347, d_loss 0.459\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 212/390 d_loss_real= 0.497, d_loss_fake= 0.352, g_loss 1.493, d_loss 0.424\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 213/390 d_loss_real= 0.615, d_loss_fake= 0.332, g_loss 1.473, d_loss 0.474\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 214/390 d_loss_real= 0.453, d_loss_fake= 0.350, g_loss 1.447, d_loss 0.401\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 215/390 d_loss_real= 0.608, d_loss_fake= 0.352, g_loss 1.338, d_loss 0.480\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 216/390 d_loss_real= 0.433, d_loss_fake= 0.410, g_loss 1.248, d_loss 0.421\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 217/390 d_loss_real= 0.523, d_loss_fake= 0.447, g_loss 1.204, d_loss 0.485\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 218/390 d_loss_real= 0.293, d_loss_fake= 0.429, g_loss 1.321, d_loss 0.361\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9 Batch 219/390 d_loss_real= 0.473, d_loss_fake= 0.350, g_loss 1.424, d_loss 0.412\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 220/390 d_loss_real= 0.471, d_loss_fake= 0.262, g_loss 1.624, d_loss 0.366\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9 Batch 221/390 d_loss_real= 0.436, d_loss_fake= 0.235, g_loss 1.714, d_loss 0.336\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9 Batch 222/390 d_loss_real= 0.506, d_loss_fake= 0.225, g_loss 1.635, d_loss 0.365\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9 Batch 223/390 d_loss_real= 0.562, d_loss_fake= 0.267, g_loss 1.450, d_loss 0.414\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 224/390 d_loss_real= 0.486, d_loss_fake= 0.348, g_loss 1.248, d_loss 0.417\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 225/390 d_loss_real= 0.306, d_loss_fake= 0.383, g_loss 1.259, d_loss 0.344\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 226/390 d_loss_real= 0.173, d_loss_fake= 0.325, g_loss 1.482, d_loss 0.249\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9 Batch 227/390 d_loss_real= 0.246, d_loss_fake= 0.243, g_loss 1.737, d_loss 0.244\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 228/390 d_loss_real= 0.287, d_loss_fake= 0.189, g_loss 1.915, d_loss 0.238\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9 Batch 229/390 d_loss_real= 0.299, d_loss_fake= 0.163, g_loss 2.025, d_loss 0.231\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9 Batch 230/390 d_loss_real= 0.248, d_loss_fake= 0.152, g_loss 2.048, d_loss 0.200\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9 Batch 231/390 d_loss_real= 0.288, d_loss_fake= 0.156, g_loss 1.963, d_loss 0.222\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 232/390 d_loss_real= 0.339, d_loss_fake= 0.182, g_loss 1.824, d_loss 0.260\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 233/390 d_loss_real= 0.238, d_loss_fake= 0.215, g_loss 1.703, d_loss 0.226\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 234/390 d_loss_real= 0.195, d_loss_fake= 0.214, g_loss 1.774, d_loss 0.204\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 235/390 d_loss_real= 0.275, d_loss_fake= 0.191, g_loss 1.922, d_loss 0.233\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 236/390 d_loss_real= 0.112, d_loss_fake= 0.151, g_loss 2.195, d_loss 0.132\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 237/390 d_loss_real= 0.086, d_loss_fake= 0.103, g_loss 2.527, d_loss 0.095\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 238/390 d_loss_real= 0.141, d_loss_fake= 0.075, g_loss 2.779, d_loss 0.108\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 239/390 d_loss_real= 0.236, d_loss_fake= 0.066, g_loss 2.831, d_loss 0.151\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 240/390 d_loss_real= 0.191, d_loss_fake= 0.070, g_loss 2.715, d_loss 0.130\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 241/390 d_loss_real= 0.232, d_loss_fake= 0.085, g_loss 2.507, d_loss 0.159\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 242/390 d_loss_real= 0.153, d_loss_fake= 0.108, g_loss 2.306, d_loss 0.131\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 243/390 d_loss_real= 0.105, d_loss_fake= 0.121, g_loss 2.211, d_loss 0.113\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 244/390 d_loss_real= 0.032, d_loss_fake= 0.120, g_loss 2.419, d_loss 0.076\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 245/390 d_loss_real= 0.073, d_loss_fake= 0.085, g_loss 2.707, d_loss 0.079\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 246/390 d_loss_real= 0.079, d_loss_fake= 0.069, g_loss 3.019, d_loss 0.074\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 247/390 d_loss_real= 0.121, d_loss_fake= 0.051, g_loss 3.143, d_loss 0.086\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9 Batch 248/390 d_loss_real= 0.118, d_loss_fake= 0.048, g_loss 3.136, d_loss 0.083\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 249/390 d_loss_real= 0.131, d_loss_fake= 0.056, g_loss 3.020, d_loss 0.093\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 250/390 d_loss_real= 0.058, d_loss_fake= 0.066, g_loss 2.832, d_loss 0.062\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 251/390 d_loss_real= 0.086, d_loss_fake= 0.082, g_loss 2.687, d_loss 0.084\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9 Batch 252/390 d_loss_real= 0.067, d_loss_fake= 0.079, g_loss 2.828, d_loss 0.073\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 253/390 d_loss_real= 0.085, d_loss_fake= 0.067, g_loss 3.011, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 254/390 d_loss_real= 0.090, d_loss_fake= 0.057, g_loss 3.117, d_loss 0.073\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 255/390 d_loss_real= 0.118, d_loss_fake= 0.052, g_loss 3.097, d_loss 0.085\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 256/390 d_loss_real= 0.052, d_loss_fake= 0.052, g_loss 3.121, d_loss 0.052\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 257/390 d_loss_real= 0.091, d_loss_fake= 0.051, g_loss 3.126, d_loss 0.071\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9 Batch 258/390 d_loss_real= 0.114, d_loss_fake= 0.049, g_loss 3.049, d_loss 0.081\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9 Batch 259/390 d_loss_real= 0.069, d_loss_fake= 0.060, g_loss 2.966, d_loss 0.064\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 260/390 d_loss_real= 0.120, d_loss_fake= 0.070, g_loss 2.849, d_loss 0.095\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 261/390 d_loss_real= 0.073, d_loss_fake= 0.087, g_loss 2.670, d_loss 0.080\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9 Batch 262/390 d_loss_real= 0.076, d_loss_fake= 0.107, g_loss 2.629, d_loss 0.092\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9 Batch 263/390 d_loss_real= 0.139, d_loss_fake= 0.125, g_loss 2.545, d_loss 0.132\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9 Batch 264/390 d_loss_real= 0.160, d_loss_fake= 0.191, g_loss 2.365, d_loss 0.176\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 265/390 d_loss_real= 0.163, d_loss_fake= 0.241, g_loss 2.245, d_loss 0.202\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9 Batch 266/390 d_loss_real= 0.178, d_loss_fake= 0.154, g_loss 2.605, d_loss 0.166\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 267/390 d_loss_real= 0.282, d_loss_fake= 0.098, g_loss 2.919, d_loss 0.190\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 268/390 d_loss_real= 0.505, d_loss_fake= 0.075, g_loss 2.829, d_loss 0.290\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 269/390 d_loss_real= 0.499, d_loss_fake= 0.103, g_loss 2.368, d_loss 0.301\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9 Batch 270/390 d_loss_real= 0.163, d_loss_fake= 0.241, g_loss 1.915, d_loss 0.202\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9 Batch 271/390 d_loss_real= 0.189, d_loss_fake= 0.182, g_loss 2.365, d_loss 0.185\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 272/390 d_loss_real= 0.071, d_loss_fake= 0.096, g_loss 2.958, d_loss 0.084\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 273/390 d_loss_real= 0.113, d_loss_fake= 0.087, g_loss 3.031, d_loss 0.100\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 274/390 d_loss_real= 0.175, d_loss_fake= 0.194, g_loss 2.496, d_loss 0.185\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 275/390 d_loss_real= 0.170, d_loss_fake= 0.152, g_loss 2.808, d_loss 0.161\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9 Batch 276/390 d_loss_real= 0.287, d_loss_fake= 0.087, g_loss 3.063, d_loss 0.187\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 277/390 d_loss_real= 0.255, d_loss_fake= 0.081, g_loss 2.913, d_loss 0.168\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9 Batch 278/390 d_loss_real= 0.322, d_loss_fake= 0.160, g_loss 2.252, d_loss 0.241\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 279/390 d_loss_real= 0.190, d_loss_fake= 0.277, g_loss 2.171, d_loss 0.234\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 280/390 d_loss_real= 0.125, d_loss_fake= 0.338, g_loss 2.434, d_loss 0.231\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 281/390 d_loss_real= 0.196, d_loss_fake= 0.067, g_loss 3.719, d_loss 0.132\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 282/390 d_loss_real= 0.236, d_loss_fake= 0.030, g_loss 4.213, d_loss 0.133\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9 Batch 283/390 d_loss_real= 0.388, d_loss_fake= 0.043, g_loss 3.552, d_loss 0.215\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9 Batch 284/390 d_loss_real= 0.235, d_loss_fake= 0.092, g_loss 2.810, d_loss 0.164\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9 Batch 285/390 d_loss_real= 0.139, d_loss_fake= 0.366, g_loss 2.014, d_loss 0.253\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 286/390 d_loss_real= 0.124, d_loss_fake= 0.721, g_loss 2.189, d_loss 0.422\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9 Batch 287/390 d_loss_real= 0.246, d_loss_fake= 0.078, g_loss 4.005, d_loss 0.162\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 288/390 d_loss_real= 0.596, d_loss_fake= 0.018, g_loss 4.672, d_loss 0.307\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 289/390 d_loss_real= 0.696, d_loss_fake= 0.026, g_loss 3.886, d_loss 0.361\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9 Batch 290/390 d_loss_real= 0.533, d_loss_fake= 0.181, g_loss 1.870, d_loss 0.357\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 291/390 d_loss_real= 0.285, d_loss_fake= 0.850, g_loss 0.972, d_loss 0.568\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 292/390 d_loss_real= 0.215, d_loss_fake= 0.520, g_loss 1.934, d_loss 0.367\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9 Batch 293/390 d_loss_real= 0.399, d_loss_fake= 0.117, g_loss 2.981, d_loss 0.258\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 294/390 d_loss_real= 0.830, d_loss_fake= 0.050, g_loss 3.204, d_loss 0.440\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 295/390 d_loss_real= 0.601, d_loss_fake= 0.060, g_loss 2.646, d_loss 0.330\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9 Batch 296/390 d_loss_real= 0.541, d_loss_fake= 0.143, g_loss 1.716, d_loss 0.342\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9 Batch 297/390 d_loss_real= 0.131, d_loss_fake= 0.311, g_loss 1.448, d_loss 0.221\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9 Batch 298/390 d_loss_real= 0.132, d_loss_fake= 0.272, g_loss 1.838, d_loss 0.202\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 299/390 d_loss_real= 0.134, d_loss_fake= 0.134, g_loss 2.561, d_loss 0.134\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9 Batch 300/390 d_loss_real= 0.152, d_loss_fake= 0.060, g_loss 3.246, d_loss 0.106\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 301/390 d_loss_real= 0.176, d_loss_fake= 0.035, g_loss 3.625, d_loss 0.106\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 302/390 d_loss_real= 0.162, d_loss_fake= 0.030, g_loss 3.605, d_loss 0.096\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 303/390 d_loss_real= 0.195, d_loss_fake= 0.043, g_loss 3.165, d_loss 0.119\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 304/390 d_loss_real= 0.111, d_loss_fake= 0.068, g_loss 2.723, d_loss 0.090\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 305/390 d_loss_real= 0.094, d_loss_fake= 0.114, g_loss 2.389, d_loss 0.104\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 306/390 d_loss_real= 0.158, d_loss_fake= 0.131, g_loss 2.364, d_loss 0.144\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 307/390 d_loss_real= 0.103, d_loss_fake= 0.108, g_loss 2.594, d_loss 0.106\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 308/390 d_loss_real= 0.065, d_loss_fake= 0.066, g_loss 3.052, d_loss 0.066\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9 Batch 309/390 d_loss_real= 0.100, d_loss_fake= 0.041, g_loss 3.422, d_loss 0.071\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9 Batch 310/390 d_loss_real= 0.096, d_loss_fake= 0.031, g_loss 3.620, d_loss 0.063\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9 Batch 311/390 d_loss_real= 0.139, d_loss_fake= 0.029, g_loss 3.563, d_loss 0.084\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 312/390 d_loss_real= 0.203, d_loss_fake= 0.037, g_loss 3.178, d_loss 0.120\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9 Batch 313/390 d_loss_real= 0.078, d_loss_fake= 0.058, g_loss 2.741, d_loss 0.068\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9 Batch 314/390 d_loss_real= 0.032, d_loss_fake= 0.078, g_loss 2.624, d_loss 0.055\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9 Batch 315/390 d_loss_real= 0.035, d_loss_fake= 0.078, g_loss 2.730, d_loss 0.057\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9 Batch 316/390 d_loss_real= 0.042, d_loss_fake= 0.064, g_loss 2.980, d_loss 0.053\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9 Batch 317/390 d_loss_real= 0.067, d_loss_fake= 0.047, g_loss 3.243, d_loss 0.057\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 318/390 d_loss_real= 0.050, d_loss_fake= 0.037, g_loss 3.462, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 319/390 d_loss_real= 0.061, d_loss_fake= 0.031, g_loss 3.574, d_loss 0.046\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9 Batch 320/390 d_loss_real= 0.093, d_loss_fake= 0.031, g_loss 3.522, d_loss 0.062\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 321/390 d_loss_real= 0.034, d_loss_fake= 0.032, g_loss 3.479, d_loss 0.033\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9 Batch 322/390 d_loss_real= 0.027, d_loss_fake= 0.033, g_loss 3.484, d_loss 0.030\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9 Batch 323/390 d_loss_real= 0.060, d_loss_fake= 0.034, g_loss 3.427, d_loss 0.047\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 324/390 d_loss_real= 0.070, d_loss_fake= 0.036, g_loss 3.324, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 325/390 d_loss_real= 0.035, d_loss_fake= 0.040, g_loss 3.305, d_loss 0.038\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 326/390 d_loss_real= 0.036, d_loss_fake= 0.039, g_loss 3.338, d_loss 0.037\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9 Batch 327/390 d_loss_real= 0.044, d_loss_fake= 0.036, g_loss 3.433, d_loss 0.040\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 328/390 d_loss_real= 0.031, d_loss_fake= 0.032, g_loss 3.596, d_loss 0.031\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 329/390 d_loss_real= 0.024, d_loss_fake= 0.026, g_loss 3.810, d_loss 0.025\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9 Batch 330/390 d_loss_real= 0.040, d_loss_fake= 0.021, g_loss 3.966, d_loss 0.031\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9 Batch 331/390 d_loss_real= 0.057, d_loss_fake= 0.019, g_loss 3.998, d_loss 0.038\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9 Batch 332/390 d_loss_real= 0.022, d_loss_fake= 0.018, g_loss 4.067, d_loss 0.020\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9 Batch 333/390 d_loss_real= 0.063, d_loss_fake= 0.018, g_loss 4.002, d_loss 0.041\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9 Batch 334/390 d_loss_real= 0.043, d_loss_fake= 0.020, g_loss 3.936, d_loss 0.031\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 335/390 d_loss_real= 0.041, d_loss_fake= 0.021, g_loss 3.839, d_loss 0.031\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 336/390 d_loss_real= 0.023, d_loss_fake= 0.023, g_loss 3.781, d_loss 0.023\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 337/390 d_loss_real= 0.027, d_loss_fake= 0.024, g_loss 3.765, d_loss 0.025\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9 Batch 338/390 d_loss_real= 0.031, d_loss_fake= 0.024, g_loss 3.773, d_loss 0.028\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9 Batch 339/390 d_loss_real= 0.035, d_loss_fake= 0.024, g_loss 3.774, d_loss 0.030\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9 Batch 340/390 d_loss_real= 0.033, d_loss_fake= 0.025, g_loss 3.745, d_loss 0.029\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9 Batch 341/390 d_loss_real= 0.038, d_loss_fake= 0.025, g_loss 3.712, d_loss 0.032\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9 Batch 342/390 d_loss_real= 0.024, d_loss_fake= 0.026, g_loss 3.748, d_loss 0.025\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9 Batch 343/390 d_loss_real= 0.039, d_loss_fake= 0.025, g_loss 3.764, d_loss 0.032\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 344/390 d_loss_real= 0.033, d_loss_fake= 0.024, g_loss 3.805, d_loss 0.029\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 345/390 d_loss_real= 0.009, d_loss_fake= 0.022, g_loss 3.935, d_loss 0.015\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 346/390 d_loss_real= 0.019, d_loss_fake= 0.019, g_loss 4.083, d_loss 0.019\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 347/390 d_loss_real= 0.027, d_loss_fake= 0.016, g_loss 4.199, d_loss 0.022\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 348/390 d_loss_real= 0.013, d_loss_fake= 0.015, g_loss 4.302, d_loss 0.014\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9 Batch 349/390 d_loss_real= 0.050, d_loss_fake= 0.014, g_loss 4.309, d_loss 0.032\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 350/390 d_loss_real= 0.037, d_loss_fake= 0.014, g_loss 4.273, d_loss 0.026\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 351/390 d_loss_real= 0.020, d_loss_fake= 0.014, g_loss 4.252, d_loss 0.017\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9 Batch 352/390 d_loss_real= 0.042, d_loss_fake= 0.016, g_loss 4.145, d_loss 0.029\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 353/390 d_loss_real= 0.038, d_loss_fake= 0.018, g_loss 4.013, d_loss 0.028\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 354/390 d_loss_real= 0.026, d_loss_fake= 0.020, g_loss 3.916, d_loss 0.023\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 355/390 d_loss_real= 0.015, d_loss_fake= 0.021, g_loss 3.886, d_loss 0.018\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 356/390 d_loss_real= 0.011, d_loss_fake= 0.021, g_loss 3.957, d_loss 0.016\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9 Batch 357/390 d_loss_real= 0.008, d_loss_fake= 0.019, g_loss 4.085, d_loss 0.014\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 358/390 d_loss_real= 0.011, d_loss_fake= 0.016, g_loss 4.238, d_loss 0.013\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 9 Batch 359/390 d_loss_real= 0.022, d_loss_fake= 0.014, g_loss 4.352, d_loss 0.018\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 360/390 d_loss_real= 0.034, d_loss_fake= 0.013, g_loss 4.411, d_loss 0.023\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9 Batch 361/390 d_loss_real= 0.017, d_loss_fake= 0.012, g_loss 4.452, d_loss 0.015\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9 Batch 362/390 d_loss_real= 0.024, d_loss_fake= 0.012, g_loss 4.476, d_loss 0.018\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 363/390 d_loss_real= 0.042, d_loss_fake= 0.013, g_loss 4.341, d_loss 0.027\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 364/390 d_loss_real= 0.041, d_loss_fake= 0.014, g_loss 4.203, d_loss 0.028\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 365/390 d_loss_real= 0.170, d_loss_fake= 0.016, g_loss 4.089, d_loss 0.093\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 366/390 d_loss_real= 0.010, d_loss_fake= 0.018, g_loss 4.038, d_loss 0.014\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 367/390 d_loss_real= 0.028, d_loss_fake= 0.018, g_loss 4.037, d_loss 0.023\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 368/390 d_loss_real= 0.011, d_loss_fake= 0.017, g_loss 4.139, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 369/390 d_loss_real= 0.029, d_loss_fake= 0.017, g_loss 4.139, d_loss 0.023\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 370/390 d_loss_real= 0.046, d_loss_fake= 0.017, g_loss 4.107, d_loss 0.031\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 371/390 d_loss_real= 0.008, d_loss_fake= 0.017, g_loss 4.138, d_loss 0.012\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 9 Batch 372/390 d_loss_real= 0.056, d_loss_fake= 0.017, g_loss 4.098, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 373/390 d_loss_real= 0.006, d_loss_fake= 0.016, g_loss 4.176, d_loss 0.011\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 374/390 d_loss_real= 0.009, d_loss_fake= 0.016, g_loss 4.220, d_loss 0.012\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 9 Batch 375/390 d_loss_real= 0.026, d_loss_fake= 0.014, g_loss 4.339, d_loss 0.020\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 376/390 d_loss_real= 0.016, d_loss_fake= 0.013, g_loss 4.451, d_loss 0.014\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9 Batch 377/390 d_loss_real= 0.061, d_loss_fake= 0.012, g_loss 4.516, d_loss 0.037\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9 Batch 378/390 d_loss_real= 0.027, d_loss_fake= 0.011, g_loss 4.574, d_loss 0.019\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9 Batch 379/390 d_loss_real= 0.026, d_loss_fake= 0.010, g_loss 4.589, d_loss 0.018\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 380/390 d_loss_real= 0.032, d_loss_fake= 0.011, g_loss 4.503, d_loss 0.022\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9 Batch 381/390 d_loss_real= 0.012, d_loss_fake= 0.012, g_loss 4.440, d_loss 0.012\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 382/390 d_loss_real= 0.013, d_loss_fake= 0.013, g_loss 4.352, d_loss 0.013\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9 Batch 383/390 d_loss_real= 0.014, d_loss_fake= 0.013, g_loss 4.314, d_loss 0.014\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 9 Batch 384/390 d_loss_real= 0.008, d_loss_fake= 0.014, g_loss 4.347, d_loss 0.011\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9 Batch 385/390 d_loss_real= 0.036, d_loss_fake= 0.014, g_loss 4.310, d_loss 0.025\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9 Batch 386/390 d_loss_real= 0.014, d_loss_fake= 0.013, g_loss 4.362, d_loss 0.013\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 387/390 d_loss_real= 0.021, d_loss_fake= 0.014, g_loss 4.297, d_loss 0.017\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 9 Batch 388/390 d_loss_real= 0.018, d_loss_fake= 0.013, g_loss 4.354, d_loss 0.016\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9 Batch 389/390 d_loss_real= 0.008, d_loss_fake= 0.014, g_loss 4.348, d_loss 0.011\n",
            "2/2 [==============================] - 0s 12ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 Batch 390/390 d_loss_real= 0.013, d_loss_fake= 0.013, g_loss 4.446, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 1/390 d_loss_real= 0.028, d_loss_fake= 0.012, g_loss 4.453, d_loss 0.020\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 10 Batch 2/390 d_loss_real= 0.030, d_loss_fake= 0.013, g_loss 4.305, d_loss 0.021\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 3/390 d_loss_real= 0.009, d_loss_fake= 0.014, g_loss 4.259, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 4/390 d_loss_real= 0.003, d_loss_fake= 0.014, g_loss 4.329, d_loss 0.009\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 5/390 d_loss_real= 0.007, d_loss_fake= 0.012, g_loss 4.507, d_loss 0.009\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 10 Batch 6/390 d_loss_real= 0.005, d_loss_fake= 0.011, g_loss 4.603, d_loss 0.008\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 7/390 d_loss_real= 0.040, d_loss_fake= 0.010, g_loss 4.684, d_loss 0.025\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 10 Batch 8/390 d_loss_real= 0.023, d_loss_fake= 0.009, g_loss 4.786, d_loss 0.016\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 10 Batch 9/390 d_loss_real= 0.012, d_loss_fake= 0.008, g_loss 4.795, d_loss 0.010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 10/390 d_loss_real= 0.007, d_loss_fake= 0.008, g_loss 4.806, d_loss 0.008\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 11/390 d_loss_real= 0.007, d_loss_fake= 0.009, g_loss 4.758, d_loss 0.008\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 12/390 d_loss_real= 0.009, d_loss_fake= 0.008, g_loss 4.903, d_loss 0.008\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 13/390 d_loss_real= 0.004, d_loss_fake= 0.007, g_loss 4.938, d_loss 0.006\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 10 Batch 14/390 d_loss_real= 0.015, d_loss_fake= 0.008, g_loss 4.918, d_loss 0.011\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 15/390 d_loss_real= 0.008, d_loss_fake= 0.008, g_loss 4.927, d_loss 0.008\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 10 Batch 16/390 d_loss_real= 0.025, d_loss_fake= 0.007, g_loss 4.879, d_loss 0.016\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 17/390 d_loss_real= 0.009, d_loss_fake= 0.008, g_loss 4.773, d_loss 0.009\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 18/390 d_loss_real= 0.006, d_loss_fake= 0.009, g_loss 4.772, d_loss 0.007\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 19/390 d_loss_real= 0.013, d_loss_fake= 0.009, g_loss 4.709, d_loss 0.011\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 20/390 d_loss_real= 0.007, d_loss_fake= 0.009, g_loss 4.763, d_loss 0.008\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 21/390 d_loss_real= 0.005, d_loss_fake= 0.009, g_loss 4.742, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 22/390 d_loss_real= 0.015, d_loss_fake= 0.009, g_loss 4.696, d_loss 0.012\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 23/390 d_loss_real= 0.008, d_loss_fake= 0.009, g_loss 4.697, d_loss 0.009\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 24/390 d_loss_real= 0.015, d_loss_fake= 0.010, g_loss 4.681, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 25/390 d_loss_real= 0.010, d_loss_fake= 0.009, g_loss 4.733, d_loss 0.009\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 10 Batch 26/390 d_loss_real= 0.008, d_loss_fake= 0.009, g_loss 4.772, d_loss 0.008\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 27/390 d_loss_real= 0.004, d_loss_fake= 0.009, g_loss 4.804, d_loss 0.006\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 10 Batch 28/390 d_loss_real= 0.008, d_loss_fake= 0.009, g_loss 4.812, d_loss 0.008\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 10 Batch 29/390 d_loss_real= 0.007, d_loss_fake= 0.007, g_loss 4.975, d_loss 0.007\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 10 Batch 30/390 d_loss_real= 0.018, d_loss_fake= 0.007, g_loss 4.921, d_loss 0.013\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 31/390 d_loss_real= 0.012, d_loss_fake= 0.007, g_loss 4.922, d_loss 0.010\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 10 Batch 32/390 d_loss_real= 0.007, d_loss_fake= 0.007, g_loss 4.927, d_loss 0.007\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 33/390 d_loss_real= 0.011, d_loss_fake= 0.008, g_loss 4.882, d_loss 0.009\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 10 Batch 34/390 d_loss_real= 0.013, d_loss_fake= 0.008, g_loss 4.810, d_loss 0.010\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 10 Batch 35/390 d_loss_real= 0.007, d_loss_fake= 0.008, g_loss 4.794, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 36/390 d_loss_real= 0.005, d_loss_fake= 0.009, g_loss 4.805, d_loss 0.007\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 10 Batch 37/390 d_loss_real= 0.004, d_loss_fake= 0.008, g_loss 4.863, d_loss 0.006\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 38/390 d_loss_real= 0.018, d_loss_fake= 0.008, g_loss 4.877, d_loss 0.013\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 10 Batch 39/390 d_loss_real= 0.036, d_loss_fake= 0.008, g_loss 4.888, d_loss 0.022\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 40/390 d_loss_real= 0.036, d_loss_fake= 0.009, g_loss 4.651, d_loss 0.022\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 41/390 d_loss_real= 0.013, d_loss_fake= 0.010, g_loss 4.515, d_loss 0.012\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 42/390 d_loss_real= 0.009, d_loss_fake= 0.012, g_loss 4.445, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 43/390 d_loss_real= 0.004, d_loss_fake= 0.015, g_loss 4.254, d_loss 0.010\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 10 Batch 44/390 d_loss_real= 0.012, d_loss_fake= 0.019, g_loss 4.068, d_loss 0.015\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 10 Batch 45/390 d_loss_real= 0.006, d_loss_fake= 0.019, g_loss 4.089, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 46/390 d_loss_real= 0.007, d_loss_fake= 0.017, g_loss 4.276, d_loss 0.012\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 47/390 d_loss_real= 0.007, d_loss_fake= 0.013, g_loss 4.551, d_loss 0.010\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 48/390 d_loss_real= 0.035, d_loss_fake= 0.010, g_loss 4.678, d_loss 0.022\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 49/390 d_loss_real= 0.010, d_loss_fake= 0.009, g_loss 4.828, d_loss 0.010\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 10 Batch 50/390 d_loss_real= 0.009, d_loss_fake= 0.008, g_loss 4.958, d_loss 0.009\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 10 Batch 51/390 d_loss_real= 0.006, d_loss_fake= 0.007, g_loss 5.051, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 52/390 d_loss_real= 0.039, d_loss_fake= 0.007, g_loss 5.029, d_loss 0.023\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 53/390 d_loss_real= 0.029, d_loss_fake= 0.007, g_loss 4.874, d_loss 0.018\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 54/390 d_loss_real= 0.008, d_loss_fake= 0.008, g_loss 4.784, d_loss 0.008\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 55/390 d_loss_real= 0.027, d_loss_fake= 0.010, g_loss 4.561, d_loss 0.018\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 56/390 d_loss_real= 0.003, d_loss_fake= 0.012, g_loss 4.430, d_loss 0.007\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 57/390 d_loss_real= 0.018, d_loss_fake= 0.013, g_loss 4.309, d_loss 0.015\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 58/390 d_loss_real= 0.004, d_loss_fake= 0.014, g_loss 4.325, d_loss 0.009\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 59/390 d_loss_real= 0.051, d_loss_fake= 0.015, g_loss 4.182, d_loss 0.033\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 60/390 d_loss_real= 0.014, d_loss_fake= 0.017, g_loss 4.136, d_loss 0.015\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 10 Batch 61/390 d_loss_real= 0.035, d_loss_fake= 0.017, g_loss 4.101, d_loss 0.026\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 62/390 d_loss_real= 0.013, d_loss_fake= 0.017, g_loss 4.148, d_loss 0.015\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 10 Batch 63/390 d_loss_real= 0.007, d_loss_fake= 0.015, g_loss 4.291, d_loss 0.011\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 64/390 d_loss_real= 0.055, d_loss_fake= 0.016, g_loss 4.203, d_loss 0.035\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 65/390 d_loss_real= 0.009, d_loss_fake= 0.022, g_loss 3.958, d_loss 0.015\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 66/390 d_loss_real= 0.013, d_loss_fake= 0.020, g_loss 4.069, d_loss 0.016\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 67/390 d_loss_real= 0.024, d_loss_fake= 0.018, g_loss 4.165, d_loss 0.021\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 68/390 d_loss_real= 0.010, d_loss_fake= 0.015, g_loss 4.294, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 69/390 d_loss_real= 0.004, d_loss_fake= 0.012, g_loss 4.519, d_loss 0.008\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 70/390 d_loss_real= 0.005, d_loss_fake= 0.010, g_loss 4.717, d_loss 0.008\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 10 Batch 71/390 d_loss_real= 0.006, d_loss_fake= 0.008, g_loss 4.931, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 72/390 d_loss_real= 0.042, d_loss_fake= 0.008, g_loss 4.907, d_loss 0.025\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 73/390 d_loss_real= 0.027, d_loss_fake= 0.008, g_loss 4.784, d_loss 0.018\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 10 Batch 74/390 d_loss_real= 0.005, d_loss_fake= 0.009, g_loss 4.720, d_loss 0.007\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 75/390 d_loss_real= 0.058, d_loss_fake= 0.011, g_loss 4.480, d_loss 0.034\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 76/390 d_loss_real= 0.009, d_loss_fake= 0.013, g_loss 4.328, d_loss 0.011\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 10 Batch 77/390 d_loss_real= 0.018, d_loss_fake= 0.021, g_loss 4.011, d_loss 0.019\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 78/390 d_loss_real= 0.010, d_loss_fake= 0.157, g_loss 2.875, d_loss 0.084\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 79/390 d_loss_real= 0.022, d_loss_fake= 0.055, g_loss 3.952, d_loss 0.039\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 80/390 d_loss_real= 0.031, d_loss_fake= 0.013, g_loss 5.118, d_loss 0.022\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 81/390 d_loss_real= 0.117, d_loss_fake= 0.006, g_loss 5.589, d_loss 0.061\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 82/390 d_loss_real= 0.195, d_loss_fake= 0.006, g_loss 5.243, d_loss 0.100\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 10 Batch 83/390 d_loss_real= 0.203, d_loss_fake= 0.019, g_loss 3.717, d_loss 0.111\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 84/390 d_loss_real= 0.184, d_loss_fake= 0.100, g_loss 2.498, d_loss 0.142\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 85/390 d_loss_real= 0.129, d_loss_fake= 0.274, g_loss 2.371, d_loss 0.201\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 86/390 d_loss_real= 0.052, d_loss_fake= 0.073, g_loss 3.793, d_loss 0.063\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 87/390 d_loss_real= 0.107, d_loss_fake= 0.029, g_loss 4.405, d_loss 0.068\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 88/390 d_loss_real= 0.073, d_loss_fake= 0.008, g_loss 5.404, d_loss 0.040\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 89/390 d_loss_real= 0.219, d_loss_fake= 0.005, g_loss 5.275, d_loss 0.112\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 10 Batch 90/390 d_loss_real= 0.149, d_loss_fake= 0.008, g_loss 4.725, d_loss 0.078\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 91/390 d_loss_real= 0.080, d_loss_fake= 0.029, g_loss 3.554, d_loss 0.054\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 92/390 d_loss_real= 0.031, d_loss_fake= 2.787, g_loss 1.200, d_loss 1.409\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 93/390 d_loss_real= 0.159, d_loss_fake= 0.601, g_loss 3.956, d_loss 0.380\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 94/390 d_loss_real= 1.409, d_loss_fake= 0.102, g_loss 4.294, d_loss 0.755\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 10 Batch 95/390 d_loss_real= 2.839, d_loss_fake= 0.037, g_loss 3.589, d_loss 1.438\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 96/390 d_loss_real= 2.409, d_loss_fake= 0.146, g_loss 1.639, d_loss 1.277\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 97/390 d_loss_real= 0.165, d_loss_fake= 0.788, g_loss 1.153, d_loss 0.477\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 98/390 d_loss_real= 0.051, d_loss_fake= 0.363, g_loss 2.348, d_loss 0.207\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 99/390 d_loss_real= 0.035, d_loss_fake= 0.044, g_loss 4.151, d_loss 0.040\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 100/390 d_loss_real= 0.082, d_loss_fake= 0.008, g_loss 5.505, d_loss 0.045\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 101/390 d_loss_real= 0.085, d_loss_fake= 0.003, g_loss 6.315, d_loss 0.044\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 102/390 d_loss_real= 0.047, d_loss_fake= 0.001, g_loss 6.862, d_loss 0.024\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 103/390 d_loss_real= 0.069, d_loss_fake= 0.001, g_loss 7.143, d_loss 0.035\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 104/390 d_loss_real= 0.103, d_loss_fake= 0.001, g_loss 7.238, d_loss 0.052\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 10 Batch 105/390 d_loss_real= 0.019, d_loss_fake= 0.001, g_loss 7.169, d_loss 0.010\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 106/390 d_loss_real= 0.023, d_loss_fake= 0.001, g_loss 7.048, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 107/390 d_loss_real= 0.010, d_loss_fake= 0.001, g_loss 6.932, d_loss 0.006\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 108/390 d_loss_real= 0.064, d_loss_fake= 0.001, g_loss 6.771, d_loss 0.033\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 109/390 d_loss_real= 0.055, d_loss_fake= 0.001, g_loss 6.619, d_loss 0.028\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 110/390 d_loss_real= 0.059, d_loss_fake= 0.002, g_loss 6.443, d_loss 0.030\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 10 Batch 111/390 d_loss_real= 0.013, d_loss_fake= 0.002, g_loss 6.271, d_loss 0.007\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 10 Batch 112/390 d_loss_real= 0.022, d_loss_fake= 0.002, g_loss 6.111, d_loss 0.012\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 10 Batch 113/390 d_loss_real= 0.031, d_loss_fake= 0.003, g_loss 5.917, d_loss 0.017\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 10 Batch 114/390 d_loss_real= 0.003, d_loss_fake= 0.003, g_loss 5.710, d_loss 0.003\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 115/390 d_loss_real= 0.003, d_loss_fake= 0.005, g_loss 5.229, d_loss 0.004\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 116/390 d_loss_real= 0.013, d_loss_fake= 0.022, g_loss 3.894, d_loss 0.018\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 117/390 d_loss_real= 0.003, d_loss_fake= 0.055, g_loss 3.023, d_loss 0.029\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 118/390 d_loss_real= 0.007, d_loss_fake= 0.063, g_loss 2.992, d_loss 0.035\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 119/390 d_loss_real= 0.012, d_loss_fake= 0.149, g_loss 2.393, d_loss 0.080\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 120/390 d_loss_real= 0.009, d_loss_fake= 0.099, g_loss 2.899, d_loss 0.054\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 121/390 d_loss_real= 0.014, d_loss_fake= 0.038, g_loss 3.744, d_loss 0.026\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 122/390 d_loss_real= 0.050, d_loss_fake= 0.018, g_loss 4.388, d_loss 0.034\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 123/390 d_loss_real= 0.017, d_loss_fake= 0.011, g_loss 4.807, d_loss 0.014\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 124/390 d_loss_real= 0.024, d_loss_fake= 0.008, g_loss 5.064, d_loss 0.016\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 125/390 d_loss_real= 0.041, d_loss_fake= 0.006, g_loss 5.281, d_loss 0.023\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 126/390 d_loss_real= 0.038, d_loss_fake= 0.005, g_loss 5.408, d_loss 0.022\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 10 Batch 127/390 d_loss_real= 0.026, d_loss_fake= 0.005, g_loss 5.383, d_loss 0.015\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 10 Batch 128/390 d_loss_real= 0.099, d_loss_fake= 0.005, g_loss 5.379, d_loss 0.052\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 129/390 d_loss_real= 0.073, d_loss_fake= 0.006, g_loss 5.138, d_loss 0.040\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 130/390 d_loss_real= 0.087, d_loss_fake= 0.008, g_loss 4.763, d_loss 0.047\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 10 Batch 131/390 d_loss_real= 0.100, d_loss_fake= 0.021, g_loss 3.773, d_loss 0.060\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 132/390 d_loss_real= 0.023, d_loss_fake= 0.072, g_loss 2.707, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 133/390 d_loss_real= 0.173, d_loss_fake= 0.182, g_loss 2.208, d_loss 0.178\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 134/390 d_loss_real= 0.013, d_loss_fake= 0.198, g_loss 2.379, d_loss 0.106\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 135/390 d_loss_real= 0.035, d_loss_fake= 0.111, g_loss 3.112, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 136/390 d_loss_real= 0.046, d_loss_fake= 0.026, g_loss 4.272, d_loss 0.036\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 137/390 d_loss_real= 0.206, d_loss_fake= 0.013, g_loss 4.811, d_loss 0.110\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 10 Batch 138/390 d_loss_real= 0.152, d_loss_fake= 0.007, g_loss 5.224, d_loss 0.079\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 139/390 d_loss_real= 0.102, d_loss_fake= 0.006, g_loss 5.286, d_loss 0.054\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 140/390 d_loss_real= 0.096, d_loss_fake= 0.006, g_loss 5.269, d_loss 0.051\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 141/390 d_loss_real= 0.112, d_loss_fake= 0.006, g_loss 5.107, d_loss 0.059\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 142/390 d_loss_real= 0.090, d_loss_fake= 0.007, g_loss 4.852, d_loss 0.049\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 10 Batch 143/390 d_loss_real= 0.091, d_loss_fake= 0.011, g_loss 4.435, d_loss 0.051\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 144/390 d_loss_real= 0.040, d_loss_fake= 0.017, g_loss 3.959, d_loss 0.029\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 145/390 d_loss_real= 0.045, d_loss_fake= 0.027, g_loss 3.607, d_loss 0.036\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 10 Batch 146/390 d_loss_real= 0.009, d_loss_fake= 0.035, g_loss 3.436, d_loss 0.022\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 10 Batch 147/390 d_loss_real= 0.030, d_loss_fake= 0.040, g_loss 3.303, d_loss 0.035\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 148/390 d_loss_real= 0.015, d_loss_fake= 0.038, g_loss 3.410, d_loss 0.027\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 10 Batch 149/390 d_loss_real= 0.036, d_loss_fake= 0.037, g_loss 3.537, d_loss 0.036\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 10 Batch 150/390 d_loss_real= 0.025, d_loss_fake= 0.032, g_loss 3.687, d_loss 0.028\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 10 Batch 151/390 d_loss_real= 0.010, d_loss_fake= 0.092, g_loss 2.873, d_loss 0.051\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 10 Batch 152/390 d_loss_real= 0.036, d_loss_fake= 0.161, g_loss 2.601, d_loss 0.098\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 153/390 d_loss_real= 0.021, d_loss_fake= 0.088, g_loss 3.295, d_loss 0.054\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 154/390 d_loss_real= 0.067, d_loss_fake= 0.030, g_loss 4.220, d_loss 0.049\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 10 Batch 155/390 d_loss_real= 0.175, d_loss_fake= 0.011, g_loss 4.953, d_loss 0.093\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 10 Batch 156/390 d_loss_real= 0.063, d_loss_fake= 0.006, g_loss 5.412, d_loss 0.035\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 10 Batch 157/390 d_loss_real= 0.073, d_loss_fake= 0.006, g_loss 5.410, d_loss 0.039\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 158/390 d_loss_real= 0.117, d_loss_fake= 0.007, g_loss 5.042, d_loss 0.062\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 10 Batch 159/390 d_loss_real= 0.063, d_loss_fake= 0.022, g_loss 3.855, d_loss 0.042\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 10 Batch 160/390 d_loss_real= 0.484, d_loss_fake= 0.027, g_loss 3.737, d_loss 0.255\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 10 Batch 161/390 d_loss_real= 0.053, d_loss_fake= 0.053, g_loss 3.162, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 162/390 d_loss_real= 0.018, d_loss_fake= 0.130, g_loss 2.649, d_loss 0.074\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 163/390 d_loss_real= 0.116, d_loss_fake= 0.099, g_loss 3.086, d_loss 0.107\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 164/390 d_loss_real= 0.072, d_loss_fake= 0.046, g_loss 3.777, d_loss 0.059\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 165/390 d_loss_real= 0.061, d_loss_fake= 0.020, g_loss 4.458, d_loss 0.041\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 10 Batch 166/390 d_loss_real= 0.148, d_loss_fake= 0.009, g_loss 5.002, d_loss 0.079\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 167/390 d_loss_real= 0.134, d_loss_fake= 0.008, g_loss 4.848, d_loss 0.071\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 10 Batch 168/390 d_loss_real= 0.207, d_loss_fake= 0.012, g_loss 4.419, d_loss 0.109\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 10 Batch 169/390 d_loss_real= 0.052, d_loss_fake= 0.016, g_loss 4.122, d_loss 0.034\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 10 Batch 170/390 d_loss_real= 0.045, d_loss_fake= 0.023, g_loss 3.766, d_loss 0.034\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 10 Batch 171/390 d_loss_real= 0.015, d_loss_fake= 0.031, g_loss 3.633, d_loss 0.023\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 172/390 d_loss_real= 0.014, d_loss_fake= 0.030, g_loss 3.700, d_loss 0.022\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 173/390 d_loss_real= 0.010, d_loss_fake= 0.024, g_loss 3.983, d_loss 0.017\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 10 Batch 174/390 d_loss_real= 0.023, d_loss_fake= 0.024, g_loss 3.999, d_loss 0.023\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 10 Batch 175/390 d_loss_real= 0.017, d_loss_fake= 0.020, g_loss 4.150, d_loss 0.019\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 176/390 d_loss_real= 0.022, d_loss_fake= 0.016, g_loss 4.349, d_loss 0.019\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 177/390 d_loss_real= 0.017, d_loss_fake= 0.010, g_loss 4.759, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 178/390 d_loss_real= 0.028, d_loss_fake= 0.009, g_loss 4.873, d_loss 0.019\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 10 Batch 179/390 d_loss_real= 0.024, d_loss_fake= 0.007, g_loss 5.099, d_loss 0.016\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 180/390 d_loss_real= 0.039, d_loss_fake= 0.006, g_loss 5.126, d_loss 0.023\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 181/390 d_loss_real= 0.009, d_loss_fake= 0.005, g_loss 5.265, d_loss 0.007\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 182/390 d_loss_real= 0.047, d_loss_fake= 0.005, g_loss 5.296, d_loss 0.026\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 183/390 d_loss_real= 0.023, d_loss_fake= 0.006, g_loss 5.151, d_loss 0.014\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 10 Batch 184/390 d_loss_real= 0.011, d_loss_fake= 0.007, g_loss 5.024, d_loss 0.009\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 185/390 d_loss_real= 0.012, d_loss_fake= 0.008, g_loss 4.903, d_loss 0.010\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 186/390 d_loss_real= 0.012, d_loss_fake= 0.008, g_loss 4.882, d_loss 0.010\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 187/390 d_loss_real= 0.020, d_loss_fake= 0.006, g_loss 5.200, d_loss 0.013\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 188/390 d_loss_real= 0.007, d_loss_fake= 0.009, g_loss 4.768, d_loss 0.008\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 189/390 d_loss_real= 0.041, d_loss_fake= 0.009, g_loss 4.768, d_loss 0.025\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 190/390 d_loss_real= 0.005, d_loss_fake= 0.006, g_loss 5.140, d_loss 0.005\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 191/390 d_loss_real= 0.116, d_loss_fake= 0.007, g_loss 4.969, d_loss 0.062\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 192/390 d_loss_real= 0.028, d_loss_fake= 0.006, g_loss 5.072, d_loss 0.017\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 10 Batch 193/390 d_loss_real= 0.004, d_loss_fake= 0.007, g_loss 4.997, d_loss 0.006\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 194/390 d_loss_real= 0.025, d_loss_fake= 0.009, g_loss 4.718, d_loss 0.017\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 10 Batch 195/390 d_loss_real= 0.003, d_loss_fake= 0.032, g_loss 3.746, d_loss 0.017\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 196/390 d_loss_real= 0.015, d_loss_fake= 0.095, g_loss 3.020, d_loss 0.055\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 197/390 d_loss_real= 0.014, d_loss_fake= 0.034, g_loss 3.935, d_loss 0.024\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 198/390 d_loss_real= 0.006, d_loss_fake= 0.038, g_loss 3.857, d_loss 0.022\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 199/390 d_loss_real= 0.010, d_loss_fake= 0.011, g_loss 5.029, d_loss 0.011\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 10 Batch 200/390 d_loss_real= 0.021, d_loss_fake= 0.006, g_loss 5.497, d_loss 0.014\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 10 Batch 201/390 d_loss_real= 0.023, d_loss_fake= 0.004, g_loss 5.799, d_loss 0.014\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 10 Batch 202/390 d_loss_real= 0.098, d_loss_fake= 0.003, g_loss 5.836, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 203/390 d_loss_real= 0.024, d_loss_fake= 0.004, g_loss 5.642, d_loss 0.014\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 10 Batch 204/390 d_loss_real= 0.074, d_loss_fake= 0.006, g_loss 5.061, d_loss 0.040\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 205/390 d_loss_real= 0.019, d_loss_fake= 0.018, g_loss 4.107, d_loss 0.019\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 10 Batch 206/390 d_loss_real= 0.011, d_loss_fake= 0.042, g_loss 3.367, d_loss 0.026\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 207/390 d_loss_real= 0.007, d_loss_fake= 0.051, g_loss 3.403, d_loss 0.029\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 10 Batch 208/390 d_loss_real= 0.021, d_loss_fake= 0.026, g_loss 4.050, d_loss 0.023\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 209/390 d_loss_real= 0.025, d_loss_fake= 0.021, g_loss 4.213, d_loss 0.023\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 10 Batch 210/390 d_loss_real= 0.055, d_loss_fake= 0.017, g_loss 4.331, d_loss 0.036\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 211/390 d_loss_real= 0.017, d_loss_fake= 0.016, g_loss 4.442, d_loss 0.016\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 212/390 d_loss_real= 0.054, d_loss_fake= 0.016, g_loss 4.348, d_loss 0.035\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 213/390 d_loss_real= 0.046, d_loss_fake= 0.012, g_loss 4.589, d_loss 0.029\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 214/390 d_loss_real= 0.032, d_loss_fake= 0.019, g_loss 4.138, d_loss 0.025\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 215/390 d_loss_real= 0.058, d_loss_fake= 0.015, g_loss 4.249, d_loss 0.037\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 10 Batch 216/390 d_loss_real= 0.018, d_loss_fake= 0.016, g_loss 4.327, d_loss 0.017\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 217/390 d_loss_real= 0.027, d_loss_fake= 0.015, g_loss 4.341, d_loss 0.021\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 218/390 d_loss_real= 0.008, d_loss_fake= 0.014, g_loss 4.391, d_loss 0.011\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 219/390 d_loss_real= 0.012, d_loss_fake= 0.012, g_loss 4.648, d_loss 0.012\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 10 Batch 220/390 d_loss_real= 0.012, d_loss_fake= 0.009, g_loss 4.796, d_loss 0.011\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 221/390 d_loss_real= 0.007, d_loss_fake= 0.007, g_loss 5.069, d_loss 0.007\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 222/390 d_loss_real= 0.018, d_loss_fake= 0.008, g_loss 4.882, d_loss 0.013\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 223/390 d_loss_real= 0.003, d_loss_fake= 0.008, g_loss 4.969, d_loss 0.006\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 224/390 d_loss_real= 0.087, d_loss_fake= 0.008, g_loss 4.889, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 225/390 d_loss_real= 0.034, d_loss_fake= 0.012, g_loss 4.503, d_loss 0.023\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 226/390 d_loss_real= 0.007, d_loss_fake= 0.017, g_loss 4.272, d_loss 0.012\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 227/390 d_loss_real= 0.061, d_loss_fake= 0.015, g_loss 4.322, d_loss 0.038\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 228/390 d_loss_real= 0.005, d_loss_fake= 0.012, g_loss 4.555, d_loss 0.008\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 229/390 d_loss_real= 0.026, d_loss_fake= 0.011, g_loss 4.627, d_loss 0.019\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 10 Batch 230/390 d_loss_real= 0.012, d_loss_fake= 0.011, g_loss 4.638, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 231/390 d_loss_real= 0.064, d_loss_fake= 0.008, g_loss 4.912, d_loss 0.036\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 10 Batch 232/390 d_loss_real= 0.005, d_loss_fake= 0.007, g_loss 4.998, d_loss 0.006\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 233/390 d_loss_real= 0.034, d_loss_fake= 0.007, g_loss 5.002, d_loss 0.021\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 234/390 d_loss_real= 0.007, d_loss_fake= 0.007, g_loss 5.029, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 235/390 d_loss_real= 0.004, d_loss_fake= 0.007, g_loss 5.076, d_loss 0.005\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 236/390 d_loss_real= 0.052, d_loss_fake= 0.006, g_loss 5.186, d_loss 0.029\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 10 Batch 237/390 d_loss_real= 0.010, d_loss_fake= 0.007, g_loss 5.042, d_loss 0.009\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 238/390 d_loss_real= 0.003, d_loss_fake= 0.007, g_loss 5.130, d_loss 0.005\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 239/390 d_loss_real= 0.005, d_loss_fake= 0.006, g_loss 5.216, d_loss 0.005\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 240/390 d_loss_real= 0.021, d_loss_fake= 0.006, g_loss 5.165, d_loss 0.014\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 241/390 d_loss_real= 0.007, d_loss_fake= 0.005, g_loss 5.489, d_loss 0.006\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 242/390 d_loss_real= 0.004, d_loss_fake= 0.006, g_loss 5.216, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 243/390 d_loss_real= 0.064, d_loss_fake= 0.008, g_loss 4.875, d_loss 0.036\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 10 Batch 244/390 d_loss_real= 0.013, d_loss_fake= 0.006, g_loss 5.197, d_loss 0.009\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 245/390 d_loss_real= 0.010, d_loss_fake= 0.008, g_loss 4.878, d_loss 0.009\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 246/390 d_loss_real= 0.008, d_loss_fake= 0.011, g_loss 4.585, d_loss 0.009\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 247/390 d_loss_real= 0.014, d_loss_fake= 0.011, g_loss 4.599, d_loss 0.012\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 248/390 d_loss_real= 0.041, d_loss_fake= 0.010, g_loss 4.615, d_loss 0.026\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 249/390 d_loss_real= 0.013, d_loss_fake= 0.012, g_loss 4.500, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 250/390 d_loss_real= 0.004, d_loss_fake= 0.012, g_loss 4.534, d_loss 0.008\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 10 Batch 251/390 d_loss_real= 0.004, d_loss_fake= 0.013, g_loss 4.475, d_loss 0.008\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 252/390 d_loss_real= 0.003, d_loss_fake= 0.011, g_loss 4.680, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 253/390 d_loss_real= 0.006, d_loss_fake= 0.011, g_loss 4.670, d_loss 0.008\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 254/390 d_loss_real= 0.010, d_loss_fake= 0.014, g_loss 4.402, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 255/390 d_loss_real= 0.005, d_loss_fake= 0.025, g_loss 3.900, d_loss 0.015\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 256/390 d_loss_real= 0.006, d_loss_fake= 0.050, g_loss 3.325, d_loss 0.028\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 257/390 d_loss_real= 0.040, d_loss_fake= 0.022, g_loss 4.127, d_loss 0.031\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 10 Batch 258/390 d_loss_real= 0.003, d_loss_fake= 0.032, g_loss 3.851, d_loss 0.018\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 259/390 d_loss_real= 0.003, d_loss_fake= 0.029, g_loss 3.919, d_loss 0.016\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 10 Batch 260/390 d_loss_real= 0.083, d_loss_fake= 0.025, g_loss 3.934, d_loss 0.054\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 261/390 d_loss_real= 0.029, d_loss_fake= 0.022, g_loss 4.154, d_loss 0.025\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 262/390 d_loss_real= 0.021, d_loss_fake= 0.029, g_loss 3.827, d_loss 0.025\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 263/390 d_loss_real= 0.014, d_loss_fake= 0.025, g_loss 4.008, d_loss 0.019\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 264/390 d_loss_real= 0.018, d_loss_fake= 0.034, g_loss 3.744, d_loss 0.026\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 265/390 d_loss_real= 0.076, d_loss_fake= 0.146, g_loss 2.673, d_loss 0.111\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 10 Batch 266/390 d_loss_real= 0.261, d_loss_fake= 0.093, g_loss 3.053, d_loss 0.177\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 10 Batch 267/390 d_loss_real= 0.133, d_loss_fake= 0.066, g_loss 3.454, d_loss 0.099\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 268/390 d_loss_real= 0.103, d_loss_fake= 0.124, g_loss 2.932, d_loss 0.113\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 269/390 d_loss_real= 0.052, d_loss_fake= 0.109, g_loss 3.141, d_loss 0.081\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 270/390 d_loss_real= 0.085, d_loss_fake= 0.225, g_loss 2.771, d_loss 0.155\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 271/390 d_loss_real= 0.139, d_loss_fake= 0.199, g_loss 2.969, d_loss 0.169\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 272/390 d_loss_real= 0.203, d_loss_fake= 0.162, g_loss 3.112, d_loss 0.183\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 273/390 d_loss_real= 0.289, d_loss_fake= 0.040, g_loss 3.871, d_loss 0.165\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 274/390 d_loss_real= 0.114, d_loss_fake= 0.081, g_loss 3.382, d_loss 0.098\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 275/390 d_loss_real= 0.238, d_loss_fake= 0.124, g_loss 3.025, d_loss 0.181\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 10 Batch 276/390 d_loss_real= 0.016, d_loss_fake= 0.059, g_loss 3.655, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 277/390 d_loss_real= 0.034, d_loss_fake= 0.061, g_loss 3.660, d_loss 0.048\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 278/390 d_loss_real= 0.009, d_loss_fake= 0.018, g_loss 4.778, d_loss 0.014\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 279/390 d_loss_real= 0.012, d_loss_fake= 0.006, g_loss 5.833, d_loss 0.009\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 280/390 d_loss_real= 0.036, d_loss_fake= 0.007, g_loss 5.359, d_loss 0.021\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 281/390 d_loss_real= 0.009, d_loss_fake= 0.011, g_loss 4.798, d_loss 0.010\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 282/390 d_loss_real= 0.081, d_loss_fake= 0.020, g_loss 4.271, d_loss 0.050\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 283/390 d_loss_real= 0.038, d_loss_fake= 0.051, g_loss 3.390, d_loss 0.044\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 284/390 d_loss_real= 0.053, d_loss_fake= 1.045, g_loss 1.712, d_loss 0.549\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 285/390 d_loss_real= 0.059, d_loss_fake= 1.411, g_loss 2.961, d_loss 0.735\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 286/390 d_loss_real= 0.185, d_loss_fake= 0.559, g_loss 5.112, d_loss 0.372\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 287/390 d_loss_real= 2.988, d_loss_fake= 0.340, g_loss 3.003, d_loss 1.664\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 10 Batch 288/390 d_loss_real= 2.342, d_loss_fake= 2.330, g_loss 0.643, d_loss 2.336\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 10 Batch 289/390 d_loss_real= 0.531, d_loss_fake= 1.489, g_loss 2.047, d_loss 1.010\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 290/390 d_loss_real= 0.567, d_loss_fake= 0.413, g_loss 3.490, d_loss 0.490\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 10 Batch 291/390 d_loss_real= 0.423, d_loss_fake= 0.273, g_loss 3.149, d_loss 0.348\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 10 Batch 292/390 d_loss_real= 0.531, d_loss_fake= 1.201, g_loss 1.622, d_loss 0.866\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 293/390 d_loss_real= 0.979, d_loss_fake= 5.563, g_loss 0.082, d_loss 3.271\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 294/390 d_loss_real= 1.370, d_loss_fake= 4.570, g_loss 0.356, d_loss 2.970\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 295/390 d_loss_real= 2.704, d_loss_fake= 5.577, g_loss 0.171, d_loss 4.141\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 296/390 d_loss_real= 3.501, d_loss_fake= 4.965, g_loss 0.225, d_loss 4.233\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 297/390 d_loss_real= 3.910, d_loss_fake= 4.293, g_loss 0.436, d_loss 4.101\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 298/390 d_loss_real= 3.059, d_loss_fake= 4.708, g_loss 0.211, d_loss 3.883\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 299/390 d_loss_real= 1.989, d_loss_fake= 3.806, g_loss 0.377, d_loss 2.897\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 300/390 d_loss_real= 2.580, d_loss_fake= 2.729, g_loss 0.592, d_loss 2.655\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 10 Batch 301/390 d_loss_real= 2.724, d_loss_fake= 1.711, g_loss 0.808, d_loss 2.217\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 10 Batch 302/390 d_loss_real= 2.896, d_loss_fake= 1.673, g_loss 0.529, d_loss 2.284\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 303/390 d_loss_real= 3.123, d_loss_fake= 1.453, g_loss 0.509, d_loss 2.288\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 304/390 d_loss_real= 3.694, d_loss_fake= 1.315, g_loss 0.473, d_loss 2.505\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 305/390 d_loss_real= 2.751, d_loss_fake= 1.209, g_loss 0.472, d_loss 1.980\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 306/390 d_loss_real= 3.056, d_loss_fake= 1.163, g_loss 0.463, d_loss 2.109\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 307/390 d_loss_real= 2.294, d_loss_fake= 1.149, g_loss 0.446, d_loss 1.721\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 308/390 d_loss_real= 1.969, d_loss_fake= 1.133, g_loss 0.442, d_loss 1.551\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 309/390 d_loss_real= 1.364, d_loss_fake= 1.107, g_loss 0.449, d_loss 1.236\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 310/390 d_loss_real= 1.188, d_loss_fake= 1.068, g_loss 0.473, d_loss 1.128\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 311/390 d_loss_real= 1.061, d_loss_fake= 1.008, g_loss 0.513, d_loss 1.035\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 312/390 d_loss_real= 1.062, d_loss_fake= 0.923, g_loss 0.572, d_loss 0.992\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 313/390 d_loss_real= 0.817, d_loss_fake= 0.833, g_loss 0.636, d_loss 0.825\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 314/390 d_loss_real= 0.855, d_loss_fake= 0.750, g_loss 0.704, d_loss 0.802\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 315/390 d_loss_real= 0.741, d_loss_fake= 0.681, g_loss 0.768, d_loss 0.711\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 10 Batch 316/390 d_loss_real= 0.869, d_loss_fake= 0.629, g_loss 0.814, d_loss 0.749\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 10 Batch 317/390 d_loss_real= 0.700, d_loss_fake= 0.593, g_loss 0.855, d_loss 0.647\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 10 Batch 318/390 d_loss_real= 0.718, d_loss_fake= 0.567, g_loss 0.887, d_loss 0.642\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 10 Batch 319/390 d_loss_real= 0.608, d_loss_fake= 0.547, g_loss 0.911, d_loss 0.578\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 320/390 d_loss_real= 0.691, d_loss_fake= 0.530, g_loss 0.934, d_loss 0.610\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 321/390 d_loss_real= 0.577, d_loss_fake= 0.525, g_loss 0.948, d_loss 0.551\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 322/390 d_loss_real= 0.640, d_loss_fake= 0.526, g_loss 0.944, d_loss 0.583\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 323/390 d_loss_real= 0.639, d_loss_fake= 0.534, g_loss 0.927, d_loss 0.587\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 10 Batch 324/390 d_loss_real= 0.582, d_loss_fake= 0.540, g_loss 0.914, d_loss 0.561\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 325/390 d_loss_real= 0.615, d_loss_fake= 0.549, g_loss 0.915, d_loss 0.582\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 10 Batch 326/390 d_loss_real= 0.575, d_loss_fake= 0.532, g_loss 0.936, d_loss 0.554\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 327/390 d_loss_real= 0.626, d_loss_fake= 0.515, g_loss 0.961, d_loss 0.571\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 10 Batch 328/390 d_loss_real= 0.625, d_loss_fake= 0.504, g_loss 0.974, d_loss 0.565\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 10 Batch 329/390 d_loss_real= 0.656, d_loss_fake= 0.504, g_loss 0.973, d_loss 0.580\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 10 Batch 330/390 d_loss_real= 0.553, d_loss_fake= 0.505, g_loss 0.973, d_loss 0.529\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 10 Batch 331/390 d_loss_real= 0.621, d_loss_fake= 0.510, g_loss 0.970, d_loss 0.566\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 332/390 d_loss_real= 0.587, d_loss_fake= 0.511, g_loss 0.974, d_loss 0.549\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 333/390 d_loss_real= 0.653, d_loss_fake= 0.512, g_loss 0.973, d_loss 0.582\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 334/390 d_loss_real= 0.620, d_loss_fake= 0.508, g_loss 0.980, d_loss 0.564\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 10 Batch 335/390 d_loss_real= 0.608, d_loss_fake= 0.503, g_loss 0.983, d_loss 0.555\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 336/390 d_loss_real= 0.549, d_loss_fake= 0.492, g_loss 1.002, d_loss 0.521\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 10 Batch 337/390 d_loss_real= 0.593, d_loss_fake= 0.474, g_loss 1.020, d_loss 0.533\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 338/390 d_loss_real= 0.558, d_loss_fake= 0.464, g_loss 1.040, d_loss 0.511\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 339/390 d_loss_real= 0.468, d_loss_fake= 0.453, g_loss 1.050, d_loss 0.460\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 340/390 d_loss_real= 0.563, d_loss_fake= 0.456, g_loss 1.052, d_loss 0.510\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 341/390 d_loss_real= 0.450, d_loss_fake= 0.469, g_loss 1.037, d_loss 0.459\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 342/390 d_loss_real= 0.367, d_loss_fake= 0.496, g_loss 1.016, d_loss 0.432\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 343/390 d_loss_real= 0.349, d_loss_fake= 0.489, g_loss 1.047, d_loss 0.419\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 10 Batch 344/390 d_loss_real= 0.406, d_loss_fake= 0.452, g_loss 1.124, d_loss 0.429\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 345/390 d_loss_real= 0.402, d_loss_fake= 0.395, g_loss 1.245, d_loss 0.399\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 346/390 d_loss_real= 0.535, d_loss_fake= 0.338, g_loss 1.371, d_loss 0.437\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 347/390 d_loss_real= 0.524, d_loss_fake= 0.298, g_loss 1.456, d_loss 0.411\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 10 Batch 348/390 d_loss_real= 0.548, d_loss_fake= 0.274, g_loss 1.506, d_loss 0.411\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 349/390 d_loss_real= 0.550, d_loss_fake= 0.265, g_loss 1.510, d_loss 0.407\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 350/390 d_loss_real= 0.519, d_loss_fake= 0.278, g_loss 1.456, d_loss 0.399\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 10 Batch 351/390 d_loss_real= 0.509, d_loss_fake= 0.306, g_loss 1.375, d_loss 0.408\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 10 Batch 352/390 d_loss_real= 0.473, d_loss_fake= 0.327, g_loss 1.348, d_loss 0.400\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10 Batch 353/390 d_loss_real= 0.378, d_loss_fake= 0.325, g_loss 1.387, d_loss 0.352\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 10 Batch 354/390 d_loss_real= 0.369, d_loss_fake= 0.297, g_loss 1.478, d_loss 0.333\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 355/390 d_loss_real= 0.415, d_loss_fake= 0.265, g_loss 1.576, d_loss 0.340\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 356/390 d_loss_real= 0.376, d_loss_fake= 0.243, g_loss 1.629, d_loss 0.310\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 10 Batch 357/390 d_loss_real= 0.447, d_loss_fake= 0.250, g_loss 1.580, d_loss 0.349\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 10 Batch 358/390 d_loss_real= 0.422, d_loss_fake= 0.390, g_loss 1.246, d_loss 0.406\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 359/390 d_loss_real= 0.446, d_loss_fake= 0.582, g_loss 0.947, d_loss 0.514\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 360/390 d_loss_real= 0.523, d_loss_fake= 0.626, g_loss 0.931, d_loss 0.575\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 361/390 d_loss_real= 0.390, d_loss_fake= 0.719, g_loss 0.846, d_loss 0.555\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 362/390 d_loss_real= 0.590, d_loss_fake= 0.682, g_loss 0.904, d_loss 0.636\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 363/390 d_loss_real= 0.581, d_loss_fake= 0.617, g_loss 0.974, d_loss 0.599\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 10 Batch 364/390 d_loss_real= 0.639, d_loss_fake= 0.680, g_loss 0.920, d_loss 0.660\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 10 Batch 365/390 d_loss_real= 0.874, d_loss_fake= 0.511, g_loss 1.117, d_loss 0.693\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 366/390 d_loss_real= 0.687, d_loss_fake= 0.369, g_loss 1.347, d_loss 0.528\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 10 Batch 367/390 d_loss_real= 0.743, d_loss_fake= 0.295, g_loss 1.477, d_loss 0.519\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 368/390 d_loss_real= 0.496, d_loss_fake= 0.270, g_loss 1.533, d_loss 0.383\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 10 Batch 369/390 d_loss_real= 0.527, d_loss_fake= 0.291, g_loss 1.438, d_loss 0.409\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 370/390 d_loss_real= 0.345, d_loss_fake= 0.638, g_loss 0.861, d_loss 0.492\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 371/390 d_loss_real= 0.241, d_loss_fake= 0.707, g_loss 0.845, d_loss 0.474\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10 Batch 372/390 d_loss_real= 0.252, d_loss_fake= 0.498, g_loss 1.160, d_loss 0.375\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 10 Batch 373/390 d_loss_real= 0.197, d_loss_fake= 0.316, g_loss 1.558, d_loss 0.257\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 10 Batch 374/390 d_loss_real= 0.262, d_loss_fake= 0.198, g_loss 1.952, d_loss 0.230\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 375/390 d_loss_real= 0.268, d_loss_fake= 0.135, g_loss 2.248, d_loss 0.201\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 376/390 d_loss_real= 0.286, d_loss_fake= 0.108, g_loss 2.408, d_loss 0.197\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 377/390 d_loss_real= 0.322, d_loss_fake= 0.095, g_loss 2.488, d_loss 0.208\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 10 Batch 378/390 d_loss_real= 0.230, d_loss_fake= 0.087, g_loss 2.546, d_loss 0.159\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 379/390 d_loss_real= 0.151, d_loss_fake= 0.084, g_loss 2.567, d_loss 0.118\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10 Batch 380/390 d_loss_real= 0.233, d_loss_fake= 0.086, g_loss 2.535, d_loss 0.160\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 381/390 d_loss_real= 0.095, d_loss_fake= 0.096, g_loss 2.428, d_loss 0.096\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 382/390 d_loss_real= 0.141, d_loss_fake= 0.155, g_loss 2.010, d_loss 0.148\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 10 Batch 383/390 d_loss_real= 0.103, d_loss_fake= 0.201, g_loss 1.850, d_loss 0.152\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10 Batch 384/390 d_loss_real= 0.078, d_loss_fake= 0.191, g_loss 1.967, d_loss 0.135\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 10 Batch 385/390 d_loss_real= 0.072, d_loss_fake= 0.191, g_loss 2.035, d_loss 0.132\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 386/390 d_loss_real= 0.128, d_loss_fake= 0.222, g_loss 1.941, d_loss 0.175\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 387/390 d_loss_real= 0.115, d_loss_fake= 0.211, g_loss 2.037, d_loss 0.163\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 10 Batch 388/390 d_loss_real= 0.144, d_loss_fake= 0.168, g_loss 2.214, d_loss 0.156\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10 Batch 389/390 d_loss_real= 0.225, d_loss_fake= 0.129, g_loss 2.404, d_loss 0.177\n",
            "2/2 [==============================] - 0s 13ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 Batch 390/390 d_loss_real= 0.275, d_loss_fake= 0.096, g_loss 2.613, d_loss 0.185\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 11 Batch 1/390 d_loss_real= 0.225, d_loss_fake= 0.082, g_loss 2.699, d_loss 0.154\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 11 Batch 2/390 d_loss_real= 0.288, d_loss_fake= 0.093, g_loss 2.520, d_loss 0.191\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 3/390 d_loss_real= 0.220, d_loss_fake= 0.110, g_loss 2.318, d_loss 0.165\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 4/390 d_loss_real= 0.320, d_loss_fake= 0.141, g_loss 2.087, d_loss 0.230\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 5/390 d_loss_real= 0.225, d_loss_fake= 0.208, g_loss 1.777, d_loss 0.217\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 6/390 d_loss_real= 0.148, d_loss_fake= 0.343, g_loss 1.451, d_loss 0.245\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 11 Batch 7/390 d_loss_real= 0.190, d_loss_fake= 0.364, g_loss 1.526, d_loss 0.277\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 8/390 d_loss_real= 0.234, d_loss_fake= 0.238, g_loss 1.897, d_loss 0.236\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 11 Batch 9/390 d_loss_real= 0.336, d_loss_fake= 0.171, g_loss 2.221, d_loss 0.254\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 10/390 d_loss_real= 0.407, d_loss_fake= 0.167, g_loss 2.130, d_loss 0.287\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 11 Batch 11/390 d_loss_real= 0.603, d_loss_fake= 0.267, g_loss 1.658, d_loss 0.435\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 11 Batch 12/390 d_loss_real= 0.381, d_loss_fake= 0.476, g_loss 1.186, d_loss 0.429\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 11 Batch 13/390 d_loss_real= 0.502, d_loss_fake= 0.630, g_loss 1.027, d_loss 0.566\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 11 Batch 14/390 d_loss_real= 0.474, d_loss_fake= 0.600, g_loss 1.123, d_loss 0.537\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 11 Batch 15/390 d_loss_real= 0.825, d_loss_fake= 0.508, g_loss 1.210, d_loss 0.667\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 11 Batch 16/390 d_loss_real= 0.762, d_loss_fake= 0.481, g_loss 1.217, d_loss 0.622\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 11 Batch 17/390 d_loss_real= 1.006, d_loss_fake= 0.534, g_loss 1.065, d_loss 0.770\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 18/390 d_loss_real= 0.970, d_loss_fake= 0.670, g_loss 0.874, d_loss 0.820\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 19/390 d_loss_real= 0.935, d_loss_fake= 0.857, g_loss 0.700, d_loss 0.896\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 20/390 d_loss_real= 0.987, d_loss_fake= 1.023, g_loss 0.609, d_loss 1.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 21/390 d_loss_real= 0.964, d_loss_fake= 1.063, g_loss 0.555, d_loss 1.014\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 22/390 d_loss_real= 0.872, d_loss_fake= 1.130, g_loss 0.512, d_loss 1.001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 11 Batch 23/390 d_loss_real= 0.963, d_loss_fake= 1.141, g_loss 0.528, d_loss 1.052\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 24/390 d_loss_real= 0.736, d_loss_fake= 1.051, g_loss 0.580, d_loss 0.893\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 25/390 d_loss_real= 0.970, d_loss_fake= 1.012, g_loss 0.587, d_loss 0.991\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 11 Batch 26/390 d_loss_real= 1.040, d_loss_fake= 0.996, g_loss 0.585, d_loss 1.018\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 11 Batch 27/390 d_loss_real= 1.300, d_loss_fake= 1.038, g_loss 0.535, d_loss 1.169\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 11 Batch 28/390 d_loss_real= 0.982, d_loss_fake= 1.093, g_loss 0.485, d_loss 1.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 29/390 d_loss_real= 0.788, d_loss_fake= 1.126, g_loss 0.480, d_loss 0.957\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 30/390 d_loss_real= 0.905, d_loss_fake= 1.095, g_loss 0.490, d_loss 1.000\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 31/390 d_loss_real= 1.035, d_loss_fake= 1.095, g_loss 0.487, d_loss 1.065\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 11 Batch 32/390 d_loss_real= 0.739, d_loss_fake= 1.061, g_loss 0.502, d_loss 0.900\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 33/390 d_loss_real= 0.746, d_loss_fake= 1.027, g_loss 0.508, d_loss 0.886\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 34/390 d_loss_real= 0.877, d_loss_fake= 1.005, g_loss 0.518, d_loss 0.941\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 35/390 d_loss_real= 0.730, d_loss_fake= 0.992, g_loss 0.536, d_loss 0.861\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 11 Batch 36/390 d_loss_real= 0.698, d_loss_fake= 0.981, g_loss 0.551, d_loss 0.840\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 37/390 d_loss_real= 0.557, d_loss_fake= 0.938, g_loss 0.570, d_loss 0.748\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 38/390 d_loss_real= 0.652, d_loss_fake= 0.911, g_loss 0.592, d_loss 0.781\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 39/390 d_loss_real= 0.532, d_loss_fake= 0.868, g_loss 0.609, d_loss 0.700\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 40/390 d_loss_real= 0.618, d_loss_fake= 0.880, g_loss 0.623, d_loss 0.749\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 41/390 d_loss_real= 0.816, d_loss_fake= 0.862, g_loss 0.628, d_loss 0.839\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 11 Batch 42/390 d_loss_real= 0.744, d_loss_fake= 0.855, g_loss 0.612, d_loss 0.799\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 43/390 d_loss_real= 0.915, d_loss_fake= 0.886, g_loss 0.595, d_loss 0.900\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 11 Batch 44/390 d_loss_real= 0.746, d_loss_fake= 0.918, g_loss 0.570, d_loss 0.832\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 11 Batch 45/390 d_loss_real= 0.716, d_loss_fake= 0.963, g_loss 0.535, d_loss 0.839\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 46/390 d_loss_real= 0.774, d_loss_fake= 1.009, g_loss 0.498, d_loss 0.891\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 47/390 d_loss_real= 0.590, d_loss_fake= 1.084, g_loss 0.473, d_loss 0.837\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 48/390 d_loss_real= 0.626, d_loss_fake= 1.129, g_loss 0.437, d_loss 0.877\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 49/390 d_loss_real= 0.614, d_loss_fake= 1.169, g_loss 0.431, d_loss 0.892\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 50/390 d_loss_real= 0.658, d_loss_fake= 1.204, g_loss 0.411, d_loss 0.931\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 11 Batch 51/390 d_loss_real= 0.551, d_loss_fake= 1.186, g_loss 0.413, d_loss 0.869\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 11 Batch 52/390 d_loss_real= 0.589, d_loss_fake= 1.151, g_loss 0.418, d_loss 0.870\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 11 Batch 53/390 d_loss_real= 0.581, d_loss_fake= 1.158, g_loss 0.435, d_loss 0.869\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 11 Batch 54/390 d_loss_real= 0.507, d_loss_fake= 1.135, g_loss 0.442, d_loss 0.821\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 11 Batch 55/390 d_loss_real= 0.571, d_loss_fake= 1.085, g_loss 0.460, d_loss 0.828\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 56/390 d_loss_real= 0.492, d_loss_fake= 1.067, g_loss 0.462, d_loss 0.780\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 57/390 d_loss_real= 0.437, d_loss_fake= 1.074, g_loss 0.474, d_loss 0.756\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 58/390 d_loss_real= 0.503, d_loss_fake= 1.060, g_loss 0.485, d_loss 0.782\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 59/390 d_loss_real= 0.596, d_loss_fake= 1.062, g_loss 0.484, d_loss 0.829\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 11 Batch 60/390 d_loss_real= 0.622, d_loss_fake= 1.035, g_loss 0.473, d_loss 0.829\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 11 Batch 61/390 d_loss_real= 0.583, d_loss_fake= 1.080, g_loss 0.486, d_loss 0.831\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 11 Batch 62/390 d_loss_real= 0.545, d_loss_fake= 1.065, g_loss 0.478, d_loss 0.805\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 11 Batch 63/390 d_loss_real= 0.512, d_loss_fake= 1.109, g_loss 0.478, d_loss 0.810\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 64/390 d_loss_real= 0.622, d_loss_fake= 1.054, g_loss 0.518, d_loss 0.838\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 65/390 d_loss_real= 0.700, d_loss_fake= 1.019, g_loss 0.524, d_loss 0.859\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 11 Batch 66/390 d_loss_real= 0.630, d_loss_fake= 0.979, g_loss 0.532, d_loss 0.805\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 67/390 d_loss_real= 0.719, d_loss_fake= 0.991, g_loss 0.555, d_loss 0.855\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 11 Batch 68/390 d_loss_real= 0.653, d_loss_fake= 0.969, g_loss 0.560, d_loss 0.811\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 69/390 d_loss_real= 0.761, d_loss_fake= 0.958, g_loss 0.592, d_loss 0.859\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 11 Batch 70/390 d_loss_real= 0.689, d_loss_fake= 0.900, g_loss 0.585, d_loss 0.794\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 11 Batch 71/390 d_loss_real= 0.818, d_loss_fake= 0.908, g_loss 0.584, d_loss 0.863\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 11 Batch 72/390 d_loss_real= 0.595, d_loss_fake= 0.883, g_loss 0.603, d_loss 0.739\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 73/390 d_loss_real= 0.673, d_loss_fake= 0.871, g_loss 0.595, d_loss 0.772\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 11 Batch 74/390 d_loss_real= 0.740, d_loss_fake= 0.871, g_loss 0.601, d_loss 0.806\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 11 Batch 75/390 d_loss_real= 0.543, d_loss_fake= 0.853, g_loss 0.616, d_loss 0.698\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 76/390 d_loss_real= 0.530, d_loss_fake= 0.837, g_loss 0.620, d_loss 0.683\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 11 Batch 77/390 d_loss_real= 0.604, d_loss_fake= 0.855, g_loss 0.618, d_loss 0.729\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 78/390 d_loss_real= 0.601, d_loss_fake= 0.857, g_loss 0.601, d_loss 0.729\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 79/390 d_loss_real= 0.602, d_loss_fake= 0.918, g_loss 0.573, d_loss 0.760\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 80/390 d_loss_real= 0.667, d_loss_fake= 0.996, g_loss 0.529, d_loss 0.831\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 11 Batch 81/390 d_loss_real= 0.691, d_loss_fake= 1.020, g_loss 0.482, d_loss 0.855\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 11 Batch 82/390 d_loss_real= 0.707, d_loss_fake= 1.150, g_loss 0.431, d_loss 0.929\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 83/390 d_loss_real= 0.715, d_loss_fake= 1.229, g_loss 0.393, d_loss 0.972\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 84/390 d_loss_real= 0.744, d_loss_fake= 1.241, g_loss 0.369, d_loss 0.993\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 85/390 d_loss_real= 0.714, d_loss_fake= 1.293, g_loss 0.360, d_loss 1.004\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 11 Batch 86/390 d_loss_real= 0.801, d_loss_fake= 1.298, g_loss 0.364, d_loss 1.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 87/390 d_loss_real= 0.830, d_loss_fake= 1.262, g_loss 0.379, d_loss 1.046\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 11 Batch 88/390 d_loss_real= 0.886, d_loss_fake= 1.271, g_loss 0.365, d_loss 1.079\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 89/390 d_loss_real= 0.873, d_loss_fake= 1.278, g_loss 0.363, d_loss 1.076\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 11 Batch 90/390 d_loss_real= 0.868, d_loss_fake= 1.275, g_loss 0.365, d_loss 1.071\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 11 Batch 91/390 d_loss_real= 0.954, d_loss_fake= 1.251, g_loss 0.369, d_loss 1.103\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 92/390 d_loss_real= 0.898, d_loss_fake= 1.252, g_loss 0.370, d_loss 1.075\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 93/390 d_loss_real= 0.948, d_loss_fake= 1.223, g_loss 0.375, d_loss 1.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 94/390 d_loss_real= 0.770, d_loss_fake= 1.200, g_loss 0.391, d_loss 0.985\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 11 Batch 95/390 d_loss_real= 0.729, d_loss_fake= 1.155, g_loss 0.411, d_loss 0.942\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 96/390 d_loss_real= 0.804, d_loss_fake= 1.109, g_loss 0.429, d_loss 0.956\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 11 Batch 97/390 d_loss_real= 0.746, d_loss_fake= 1.064, g_loss 0.456, d_loss 0.905\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 11 Batch 98/390 d_loss_real= 0.752, d_loss_fake= 1.021, g_loss 0.475, d_loss 0.887\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 99/390 d_loss_real= 0.846, d_loss_fake= 0.987, g_loss 0.496, d_loss 0.916\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 100/390 d_loss_real= 0.745, d_loss_fake= 0.955, g_loss 0.511, d_loss 0.850\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 101/390 d_loss_real= 0.852, d_loss_fake= 0.929, g_loss 0.526, d_loss 0.891\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 102/390 d_loss_real= 0.806, d_loss_fake= 0.931, g_loss 0.531, d_loss 0.868\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 103/390 d_loss_real= 0.761, d_loss_fake= 0.917, g_loss 0.535, d_loss 0.839\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 104/390 d_loss_real= 0.677, d_loss_fake= 0.905, g_loss 0.546, d_loss 0.791\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 11 Batch 105/390 d_loss_real= 0.696, d_loss_fake= 0.890, g_loss 0.557, d_loss 0.793\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 11 Batch 106/390 d_loss_real= 0.637, d_loss_fake= 0.881, g_loss 0.564, d_loss 0.759\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 11 Batch 107/390 d_loss_real= 0.677, d_loss_fake= 0.864, g_loss 0.571, d_loss 0.770\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 11 Batch 108/390 d_loss_real= 0.745, d_loss_fake= 0.853, g_loss 0.577, d_loss 0.799\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 109/390 d_loss_real= 0.584, d_loss_fake= 0.856, g_loss 0.582, d_loss 0.720\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 11 Batch 110/390 d_loss_real= 0.739, d_loss_fake= 0.847, g_loss 0.583, d_loss 0.793\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 11 Batch 111/390 d_loss_real= 0.653, d_loss_fake= 0.864, g_loss 0.566, d_loss 0.759\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 11 Batch 112/390 d_loss_real= 0.810, d_loss_fake= 0.912, g_loss 0.539, d_loss 0.861\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 113/390 d_loss_real= 0.658, d_loss_fake= 0.934, g_loss 0.524, d_loss 0.796\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 11 Batch 114/390 d_loss_real= 0.638, d_loss_fake= 0.945, g_loss 0.521, d_loss 0.791\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 11 Batch 115/390 d_loss_real= 0.747, d_loss_fake= 0.939, g_loss 0.531, d_loss 0.843\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 116/390 d_loss_real= 0.604, d_loss_fake= 0.919, g_loss 0.544, d_loss 0.762\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 117/390 d_loss_real= 0.662, d_loss_fake= 0.900, g_loss 0.557, d_loss 0.781\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 11 Batch 118/390 d_loss_real= 0.735, d_loss_fake= 0.883, g_loss 0.570, d_loss 0.809\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 119/390 d_loss_real= 0.722, d_loss_fake= 0.864, g_loss 0.581, d_loss 0.793\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 120/390 d_loss_real= 0.828, d_loss_fake= 0.861, g_loss 0.589, d_loss 0.844\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 11 Batch 121/390 d_loss_real= 0.717, d_loss_fake= 0.859, g_loss 0.586, d_loss 0.788\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 122/390 d_loss_real= 0.900, d_loss_fake= 0.856, g_loss 0.586, d_loss 0.878\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 11 Batch 123/390 d_loss_real= 0.869, d_loss_fake= 0.873, g_loss 0.576, d_loss 0.871\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 11 Batch 124/390 d_loss_real= 0.840, d_loss_fake= 0.886, g_loss 0.559, d_loss 0.863\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 11 Batch 125/390 d_loss_real= 0.850, d_loss_fake= 0.903, g_loss 0.550, d_loss 0.877\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 11 Batch 126/390 d_loss_real= 0.877, d_loss_fake= 0.923, g_loss 0.539, d_loss 0.900\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 127/390 d_loss_real= 0.859, d_loss_fake= 0.932, g_loss 0.521, d_loss 0.896\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 128/390 d_loss_real= 0.832, d_loss_fake= 0.956, g_loss 0.508, d_loss 0.894\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 129/390 d_loss_real= 0.874, d_loss_fake= 0.968, g_loss 0.507, d_loss 0.921\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 130/390 d_loss_real= 0.772, d_loss_fake= 0.964, g_loss 0.507, d_loss 0.868\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 11 Batch 131/390 d_loss_real= 0.880, d_loss_fake= 0.949, g_loss 0.516, d_loss 0.915\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 132/390 d_loss_real= 0.830, d_loss_fake= 0.923, g_loss 0.526, d_loss 0.876\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 11 Batch 133/390 d_loss_real= 0.747, d_loss_fake= 0.910, g_loss 0.546, d_loss 0.828\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 134/390 d_loss_real= 0.798, d_loss_fake= 0.883, g_loss 0.562, d_loss 0.841\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 135/390 d_loss_real= 0.823, d_loss_fake= 0.850, g_loss 0.582, d_loss 0.836\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 136/390 d_loss_real= 0.776, d_loss_fake= 0.828, g_loss 0.601, d_loss 0.802\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 11 Batch 137/390 d_loss_real= 0.865, d_loss_fake= 0.813, g_loss 0.615, d_loss 0.839\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 11 Batch 138/390 d_loss_real= 0.869, d_loss_fake= 0.794, g_loss 0.626, d_loss 0.832\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 11 Batch 139/390 d_loss_real= 0.834, d_loss_fake= 0.780, g_loss 0.634, d_loss 0.807\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 11 Batch 140/390 d_loss_real= 0.755, d_loss_fake= 0.769, g_loss 0.645, d_loss 0.762\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 141/390 d_loss_real= 0.778, d_loss_fake= 0.764, g_loss 0.651, d_loss 0.771\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 142/390 d_loss_real= 0.775, d_loss_fake= 0.758, g_loss 0.653, d_loss 0.767\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 11 Batch 143/390 d_loss_real= 0.763, d_loss_fake= 0.758, g_loss 0.652, d_loss 0.761\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 144/390 d_loss_real= 0.736, d_loss_fake= 0.755, g_loss 0.655, d_loss 0.745\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 145/390 d_loss_real= 0.732, d_loss_fake= 0.759, g_loss 0.656, d_loss 0.746\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 11 Batch 146/390 d_loss_real= 0.747, d_loss_fake= 0.752, g_loss 0.655, d_loss 0.750\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 11 Batch 147/390 d_loss_real= 0.682, d_loss_fake= 0.750, g_loss 0.663, d_loss 0.716\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 11 Batch 148/390 d_loss_real= 0.744, d_loss_fake= 0.742, g_loss 0.669, d_loss 0.743\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 149/390 d_loss_real= 0.747, d_loss_fake= 0.737, g_loss 0.673, d_loss 0.742\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 11 Batch 150/390 d_loss_real= 0.714, d_loss_fake= 0.728, g_loss 0.680, d_loss 0.721\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 11 Batch 151/390 d_loss_real= 0.728, d_loss_fake= 0.722, g_loss 0.684, d_loss 0.725\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 11 Batch 152/390 d_loss_real= 0.741, d_loss_fake= 0.715, g_loss 0.690, d_loss 0.728\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 153/390 d_loss_real= 0.749, d_loss_fake= 0.711, g_loss 0.693, d_loss 0.730\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 11 Batch 154/390 d_loss_real= 0.669, d_loss_fake= 0.708, g_loss 0.699, d_loss 0.689\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 11 Batch 155/390 d_loss_real= 0.720, d_loss_fake= 0.701, g_loss 0.705, d_loss 0.711\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 156/390 d_loss_real= 0.655, d_loss_fake= 0.696, g_loss 0.712, d_loss 0.675\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 157/390 d_loss_real= 0.687, d_loss_fake= 0.685, g_loss 0.718, d_loss 0.686\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 11 Batch 158/390 d_loss_real= 0.698, d_loss_fake= 0.678, g_loss 0.725, d_loss 0.688\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 11 Batch 159/390 d_loss_real= 0.686, d_loss_fake= 0.673, g_loss 0.731, d_loss 0.680\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 11 Batch 160/390 d_loss_real= 0.677, d_loss_fake= 0.667, g_loss 0.738, d_loss 0.672\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 161/390 d_loss_real= 0.696, d_loss_fake= 0.662, g_loss 0.738, d_loss 0.679\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 162/390 d_loss_real= 0.638, d_loss_fake= 0.664, g_loss 0.737, d_loss 0.651\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 11 Batch 163/390 d_loss_real= 0.612, d_loss_fake= 0.662, g_loss 0.737, d_loss 0.637\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 11 Batch 164/390 d_loss_real= 0.653, d_loss_fake= 0.665, g_loss 0.737, d_loss 0.659\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 11 Batch 165/390 d_loss_real= 0.629, d_loss_fake= 0.659, g_loss 0.742, d_loss 0.644\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 11 Batch 166/390 d_loss_real= 0.619, d_loss_fake= 0.659, g_loss 0.748, d_loss 0.639\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 167/390 d_loss_real= 0.652, d_loss_fake= 0.653, g_loss 0.750, d_loss 0.652\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 11 Batch 168/390 d_loss_real= 0.606, d_loss_fake= 0.647, g_loss 0.753, d_loss 0.627\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 169/390 d_loss_real= 0.600, d_loss_fake= 0.647, g_loss 0.758, d_loss 0.624\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 170/390 d_loss_real= 0.584, d_loss_fake= 0.646, g_loss 0.762, d_loss 0.615\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 171/390 d_loss_real= 0.588, d_loss_fake= 0.640, g_loss 0.765, d_loss 0.614\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 172/390 d_loss_real= 0.614, d_loss_fake= 0.641, g_loss 0.765, d_loss 0.627\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 11 Batch 173/390 d_loss_real= 0.601, d_loss_fake= 0.637, g_loss 0.767, d_loss 0.619\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 174/390 d_loss_real= 0.656, d_loss_fake= 0.641, g_loss 0.764, d_loss 0.648\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 175/390 d_loss_real= 0.583, d_loss_fake= 0.640, g_loss 0.760, d_loss 0.612\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 176/390 d_loss_real= 0.604, d_loss_fake= 0.641, g_loss 0.757, d_loss 0.623\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 177/390 d_loss_real= 0.580, d_loss_fake= 0.641, g_loss 0.762, d_loss 0.611\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 11 Batch 178/390 d_loss_real= 0.537, d_loss_fake= 0.642, g_loss 0.761, d_loss 0.589\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 179/390 d_loss_real= 0.579, d_loss_fake= 0.641, g_loss 0.762, d_loss 0.610\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 180/390 d_loss_real= 0.538, d_loss_fake= 0.645, g_loss 0.764, d_loss 0.591\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 181/390 d_loss_real= 0.561, d_loss_fake= 0.639, g_loss 0.765, d_loss 0.600\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 11 Batch 182/390 d_loss_real= 0.553, d_loss_fake= 0.637, g_loss 0.765, d_loss 0.595\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 11 Batch 183/390 d_loss_real= 0.578, d_loss_fake= 0.634, g_loss 0.765, d_loss 0.606\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 184/390 d_loss_real= 0.540, d_loss_fake= 0.644, g_loss 0.765, d_loss 0.592\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 11 Batch 185/390 d_loss_real= 0.537, d_loss_fake= 0.633, g_loss 0.768, d_loss 0.585\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 11 Batch 186/390 d_loss_real= 0.540, d_loss_fake= 0.640, g_loss 0.770, d_loss 0.590\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 187/390 d_loss_real= 0.549, d_loss_fake= 0.631, g_loss 0.771, d_loss 0.590\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 188/390 d_loss_real= 0.550, d_loss_fake= 0.631, g_loss 0.773, d_loss 0.591\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 11 Batch 189/390 d_loss_real= 0.545, d_loss_fake= 0.635, g_loss 0.775, d_loss 0.590\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 11 Batch 190/390 d_loss_real= 0.548, d_loss_fake= 0.636, g_loss 0.774, d_loss 0.592\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 191/390 d_loss_real= 0.549, d_loss_fake= 0.639, g_loss 0.777, d_loss 0.594\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 192/390 d_loss_real= 0.578, d_loss_fake= 0.634, g_loss 0.770, d_loss 0.606\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 11 Batch 193/390 d_loss_real= 0.544, d_loss_fake= 0.639, g_loss 0.759, d_loss 0.592\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 194/390 d_loss_real= 0.565, d_loss_fake= 0.652, g_loss 0.754, d_loss 0.608\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 11 Batch 195/390 d_loss_real= 0.527, d_loss_fake= 0.657, g_loss 0.743, d_loss 0.592\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 11 Batch 196/390 d_loss_real= 0.515, d_loss_fake= 0.671, g_loss 0.737, d_loss 0.593\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 197/390 d_loss_real= 0.558, d_loss_fake= 0.680, g_loss 0.729, d_loss 0.619\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 11 Batch 198/390 d_loss_real= 0.560, d_loss_fake= 0.710, g_loss 0.706, d_loss 0.635\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 199/390 d_loss_real= 0.579, d_loss_fake= 0.732, g_loss 0.691, d_loss 0.655\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 200/390 d_loss_real= 0.565, d_loss_fake= 0.759, g_loss 0.660, d_loss 0.662\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 11 Batch 201/390 d_loss_real= 0.646, d_loss_fake= 0.799, g_loss 0.625, d_loss 0.722\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 202/390 d_loss_real= 0.533, d_loss_fake= 0.850, g_loss 0.590, d_loss 0.691\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 11 Batch 203/390 d_loss_real= 0.545, d_loss_fake= 0.889, g_loss 0.554, d_loss 0.717\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 204/390 d_loss_real= 0.660, d_loss_fake= 0.943, g_loss 0.525, d_loss 0.802\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 205/390 d_loss_real= 0.586, d_loss_fake= 0.995, g_loss 0.488, d_loss 0.790\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 206/390 d_loss_real= 0.562, d_loss_fake= 1.024, g_loss 0.469, d_loss 0.793\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 207/390 d_loss_real= 0.669, d_loss_fake= 1.079, g_loss 0.446, d_loss 0.874\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 208/390 d_loss_real= 0.659, d_loss_fake= 1.106, g_loss 0.428, d_loss 0.882\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 11 Batch 209/390 d_loss_real= 0.613, d_loss_fake= 1.153, g_loss 0.419, d_loss 0.883\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 210/390 d_loss_real= 0.621, d_loss_fake= 1.160, g_loss 0.408, d_loss 0.890\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 11 Batch 211/390 d_loss_real= 0.584, d_loss_fake= 1.166, g_loss 0.399, d_loss 0.875\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 212/390 d_loss_real= 0.582, d_loss_fake= 1.183, g_loss 0.399, d_loss 0.882\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 213/390 d_loss_real= 0.575, d_loss_fake= 1.179, g_loss 0.398, d_loss 0.877\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 11 Batch 214/390 d_loss_real= 0.579, d_loss_fake= 1.190, g_loss 0.401, d_loss 0.884\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 215/390 d_loss_real= 0.606, d_loss_fake= 1.167, g_loss 0.402, d_loss 0.887\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 216/390 d_loss_real= 0.583, d_loss_fake= 1.174, g_loss 0.409, d_loss 0.878\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 217/390 d_loss_real= 0.559, d_loss_fake= 1.141, g_loss 0.420, d_loss 0.850\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 218/390 d_loss_real= 0.583, d_loss_fake= 1.109, g_loss 0.431, d_loss 0.846\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 219/390 d_loss_real= 0.554, d_loss_fake= 1.070, g_loss 0.448, d_loss 0.812\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 220/390 d_loss_real= 0.562, d_loss_fake= 1.040, g_loss 0.469, d_loss 0.801\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 221/390 d_loss_real= 0.524, d_loss_fake= 1.006, g_loss 0.488, d_loss 0.765\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 222/390 d_loss_real= 0.539, d_loss_fake= 0.966, g_loss 0.510, d_loss 0.753\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 223/390 d_loss_real= 0.524, d_loss_fake= 0.928, g_loss 0.533, d_loss 0.726\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 224/390 d_loss_real= 0.518, d_loss_fake= 0.896, g_loss 0.552, d_loss 0.707\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 11 Batch 225/390 d_loss_real= 0.498, d_loss_fake= 0.872, g_loss 0.569, d_loss 0.685\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 11 Batch 226/390 d_loss_real= 0.485, d_loss_fake= 0.855, g_loss 0.582, d_loss 0.670\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 227/390 d_loss_real= 0.436, d_loss_fake= 0.841, g_loss 0.592, d_loss 0.638\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 228/390 d_loss_real= 0.449, d_loss_fake= 0.836, g_loss 0.599, d_loss 0.642\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 229/390 d_loss_real= 0.515, d_loss_fake= 0.830, g_loss 0.611, d_loss 0.673\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 11 Batch 230/390 d_loss_real= 0.444, d_loss_fake= 0.817, g_loss 0.620, d_loss 0.630\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 11 Batch 231/390 d_loss_real= 0.443, d_loss_fake= 0.809, g_loss 0.632, d_loss 0.626\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 11 Batch 232/390 d_loss_real= 0.502, d_loss_fake= 0.809, g_loss 0.635, d_loss 0.655\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 11 Batch 233/390 d_loss_real= 0.482, d_loss_fake= 0.802, g_loss 0.639, d_loss 0.642\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 11 Batch 234/390 d_loss_real= 0.590, d_loss_fake= 0.786, g_loss 0.658, d_loss 0.688\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 11 Batch 235/390 d_loss_real= 0.555, d_loss_fake= 0.744, g_loss 0.694, d_loss 0.649\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 11 Batch 236/390 d_loss_real= 0.584, d_loss_fake= 0.701, g_loss 0.737, d_loss 0.642\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 237/390 d_loss_real= 0.756, d_loss_fake= 0.659, g_loss 0.781, d_loss 0.707\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 238/390 d_loss_real= 0.636, d_loss_fake= 0.619, g_loss 0.825, d_loss 0.627\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 239/390 d_loss_real= 0.686, d_loss_fake= 0.584, g_loss 0.858, d_loss 0.635\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 11 Batch 240/390 d_loss_real= 0.717, d_loss_fake= 0.567, g_loss 0.881, d_loss 0.642\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 241/390 d_loss_real= 0.781, d_loss_fake= 0.554, g_loss 0.895, d_loss 0.667\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 242/390 d_loss_real= 0.677, d_loss_fake= 0.549, g_loss 0.893, d_loss 0.613\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 243/390 d_loss_real= 0.760, d_loss_fake= 0.553, g_loss 0.880, d_loss 0.657\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 11 Batch 244/390 d_loss_real= 0.749, d_loss_fake= 0.573, g_loss 0.860, d_loss 0.661\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 11 Batch 245/390 d_loss_real= 0.745, d_loss_fake= 0.591, g_loss 0.835, d_loss 0.668\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 11 Batch 246/390 d_loss_real= 0.756, d_loss_fake= 0.616, g_loss 0.800, d_loss 0.686\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 247/390 d_loss_real= 0.636, d_loss_fake= 0.651, g_loss 0.766, d_loss 0.644\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 248/390 d_loss_real= 0.690, d_loss_fake= 0.679, g_loss 0.731, d_loss 0.685\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 249/390 d_loss_real= 0.588, d_loss_fake= 0.707, g_loss 0.711, d_loss 0.647\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 11 Batch 250/390 d_loss_real= 0.637, d_loss_fake= 0.726, g_loss 0.689, d_loss 0.682\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 251/390 d_loss_real= 0.635, d_loss_fake= 0.757, g_loss 0.673, d_loss 0.696\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 252/390 d_loss_real= 0.641, d_loss_fake= 0.763, g_loss 0.663, d_loss 0.702\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 11 Batch 253/390 d_loss_real= 0.718, d_loss_fake= 0.797, g_loss 0.641, d_loss 0.757\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 254/390 d_loss_real= 0.577, d_loss_fake= 0.808, g_loss 0.642, d_loss 0.693\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 255/390 d_loss_real= 0.561, d_loss_fake= 0.816, g_loss 0.639, d_loss 0.689\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 256/390 d_loss_real= 0.559, d_loss_fake= 0.822, g_loss 0.617, d_loss 0.690\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 11 Batch 257/390 d_loss_real= 0.670, d_loss_fake= 0.843, g_loss 0.602, d_loss 0.756\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 258/390 d_loss_real= 0.708, d_loss_fake= 0.857, g_loss 0.593, d_loss 0.783\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 259/390 d_loss_real= 0.643, d_loss_fake= 0.874, g_loss 0.585, d_loss 0.758\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 11 Batch 260/390 d_loss_real= 0.607, d_loss_fake= 0.906, g_loss 0.572, d_loss 0.757\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 261/390 d_loss_real= 0.563, d_loss_fake= 0.897, g_loss 0.561, d_loss 0.730\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 262/390 d_loss_real= 0.600, d_loss_fake= 0.904, g_loss 0.567, d_loss 0.752\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 11 Batch 263/390 d_loss_real= 0.599, d_loss_fake= 0.909, g_loss 0.566, d_loss 0.754\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 11 Batch 264/390 d_loss_real= 0.565, d_loss_fake= 0.880, g_loss 0.586, d_loss 0.722\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 11 Batch 265/390 d_loss_real= 0.707, d_loss_fake= 0.865, g_loss 0.599, d_loss 0.786\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 11 Batch 266/390 d_loss_real= 0.612, d_loss_fake= 0.852, g_loss 0.608, d_loss 0.732\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 267/390 d_loss_real= 0.615, d_loss_fake= 0.827, g_loss 0.611, d_loss 0.721\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 11 Batch 268/390 d_loss_real= 0.623, d_loss_fake= 0.823, g_loss 0.626, d_loss 0.723\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 11 Batch 269/390 d_loss_real= 0.572, d_loss_fake= 0.822, g_loss 0.628, d_loss 0.697\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 11 Batch 270/390 d_loss_real= 0.623, d_loss_fake= 0.807, g_loss 0.648, d_loss 0.715\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 271/390 d_loss_real= 0.673, d_loss_fake= 0.801, g_loss 0.639, d_loss 0.737\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 11 Batch 272/390 d_loss_real= 0.598, d_loss_fake= 0.781, g_loss 0.650, d_loss 0.690\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 11 Batch 273/390 d_loss_real= 0.572, d_loss_fake= 0.769, g_loss 0.663, d_loss 0.670\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 274/390 d_loss_real= 0.572, d_loss_fake= 0.764, g_loss 0.674, d_loss 0.668\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 11 Batch 275/390 d_loss_real= 0.538, d_loss_fake= 0.755, g_loss 0.681, d_loss 0.647\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 11 Batch 276/390 d_loss_real= 0.541, d_loss_fake= 0.732, g_loss 0.684, d_loss 0.636\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 277/390 d_loss_real= 0.605, d_loss_fake= 0.730, g_loss 0.695, d_loss 0.667\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 278/390 d_loss_real= 0.543, d_loss_fake= 0.719, g_loss 0.700, d_loss 0.631\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 11 Batch 279/390 d_loss_real= 0.543, d_loss_fake= 0.711, g_loss 0.713, d_loss 0.627\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 11 Batch 280/390 d_loss_real= 0.609, d_loss_fake= 0.721, g_loss 0.711, d_loss 0.665\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 11 Batch 281/390 d_loss_real= 0.615, d_loss_fake= 0.704, g_loss 0.722, d_loss 0.659\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 282/390 d_loss_real= 0.631, d_loss_fake= 0.710, g_loss 0.717, d_loss 0.671\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 283/390 d_loss_real= 0.520, d_loss_fake= 0.707, g_loss 0.727, d_loss 0.613\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 11 Batch 284/390 d_loss_real= 0.566, d_loss_fake= 0.707, g_loss 0.721, d_loss 0.637\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 285/390 d_loss_real= 0.605, d_loss_fake= 0.722, g_loss 0.707, d_loss 0.663\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 11 Batch 286/390 d_loss_real= 0.591, d_loss_fake= 0.745, g_loss 0.684, d_loss 0.668\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 287/390 d_loss_real= 0.651, d_loss_fake= 0.774, g_loss 0.651, d_loss 0.712\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 11 Batch 288/390 d_loss_real= 0.555, d_loss_fake= 0.808, g_loss 0.625, d_loss 0.682\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 11 Batch 289/390 d_loss_real= 0.605, d_loss_fake= 0.848, g_loss 0.597, d_loss 0.727\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 11 Batch 290/390 d_loss_real= 0.576, d_loss_fake= 0.871, g_loss 0.583, d_loss 0.723\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 11 Batch 291/390 d_loss_real= 0.662, d_loss_fake= 0.885, g_loss 0.578, d_loss 0.774\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 292/390 d_loss_real= 0.691, d_loss_fake= 0.877, g_loss 0.583, d_loss 0.784\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 11 Batch 293/390 d_loss_real= 0.639, d_loss_fake= 0.858, g_loss 0.595, d_loss 0.749\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 294/390 d_loss_real= 0.709, d_loss_fake= 0.830, g_loss 0.611, d_loss 0.769\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 11 Batch 295/390 d_loss_real= 0.641, d_loss_fake= 0.814, g_loss 0.621, d_loss 0.727\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 296/390 d_loss_real= 0.644, d_loss_fake= 0.804, g_loss 0.635, d_loss 0.724\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 297/390 d_loss_real= 0.752, d_loss_fake= 0.794, g_loss 0.637, d_loss 0.773\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 298/390 d_loss_real= 0.725, d_loss_fake= 0.789, g_loss 0.640, d_loss 0.757\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 299/390 d_loss_real= 0.740, d_loss_fake= 0.788, g_loss 0.642, d_loss 0.764\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 11 Batch 300/390 d_loss_real= 0.689, d_loss_fake= 0.784, g_loss 0.642, d_loss 0.737\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 301/390 d_loss_real= 0.765, d_loss_fake= 0.783, g_loss 0.641, d_loss 0.774\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 302/390 d_loss_real= 0.721, d_loss_fake= 0.786, g_loss 0.644, d_loss 0.754\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 303/390 d_loss_real= 0.730, d_loss_fake= 0.777, g_loss 0.646, d_loss 0.753\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 11 Batch 304/390 d_loss_real= 0.764, d_loss_fake= 0.775, g_loss 0.646, d_loss 0.769\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 11 Batch 305/390 d_loss_real= 0.691, d_loss_fake= 0.771, g_loss 0.651, d_loss 0.731\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 306/390 d_loss_real= 0.755, d_loss_fake= 0.772, g_loss 0.656, d_loss 0.764\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 307/390 d_loss_real= 0.902, d_loss_fake= 0.772, g_loss 0.652, d_loss 0.837\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 11 Batch 308/390 d_loss_real= 0.764, d_loss_fake= 0.770, g_loss 0.652, d_loss 0.767\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 309/390 d_loss_real= 0.741, d_loss_fake= 0.773, g_loss 0.652, d_loss 0.757\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 310/390 d_loss_real= 0.825, d_loss_fake= 0.768, g_loss 0.652, d_loss 0.797\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 11 Batch 311/390 d_loss_real= 0.723, d_loss_fake= 0.775, g_loss 0.648, d_loss 0.749\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 312/390 d_loss_real= 0.744, d_loss_fake= 0.777, g_loss 0.647, d_loss 0.761\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 11 Batch 313/390 d_loss_real= 0.841, d_loss_fake= 0.779, g_loss 0.641, d_loss 0.810\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 11 Batch 314/390 d_loss_real= 0.797, d_loss_fake= 0.786, g_loss 0.639, d_loss 0.791\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 315/390 d_loss_real= 0.762, d_loss_fake= 0.785, g_loss 0.630, d_loss 0.774\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 11 Batch 316/390 d_loss_real= 0.723, d_loss_fake= 0.797, g_loss 0.629, d_loss 0.760\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 317/390 d_loss_real= 0.804, d_loss_fake= 0.809, g_loss 0.621, d_loss 0.807\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 318/390 d_loss_real= 0.805, d_loss_fake= 0.812, g_loss 0.613, d_loss 0.809\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 11 Batch 319/390 d_loss_real= 0.883, d_loss_fake= 0.820, g_loss 0.602, d_loss 0.851\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 320/390 d_loss_real= 0.752, d_loss_fake= 0.837, g_loss 0.592, d_loss 0.794\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 11 Batch 321/390 d_loss_real= 0.805, d_loss_fake= 0.853, g_loss 0.586, d_loss 0.829\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 11 Batch 322/390 d_loss_real= 0.863, d_loss_fake= 0.859, g_loss 0.576, d_loss 0.861\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 323/390 d_loss_real= 0.692, d_loss_fake= 0.864, g_loss 0.580, d_loss 0.778\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 11 Batch 324/390 d_loss_real= 0.708, d_loss_fake= 0.857, g_loss 0.583, d_loss 0.782\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 11 Batch 325/390 d_loss_real= 0.738, d_loss_fake= 0.848, g_loss 0.593, d_loss 0.793\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 11 Batch 326/390 d_loss_real= 0.656, d_loss_fake= 0.832, g_loss 0.604, d_loss 0.744\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 11 Batch 327/390 d_loss_real= 0.657, d_loss_fake= 0.815, g_loss 0.622, d_loss 0.736\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 328/390 d_loss_real= 0.698, d_loss_fake= 0.799, g_loss 0.635, d_loss 0.748\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 329/390 d_loss_real= 0.669, d_loss_fake= 0.778, g_loss 0.646, d_loss 0.723\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 11 Batch 330/390 d_loss_real= 0.658, d_loss_fake= 0.767, g_loss 0.661, d_loss 0.712\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 331/390 d_loss_real= 0.573, d_loss_fake= 0.753, g_loss 0.675, d_loss 0.663\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 11 Batch 332/390 d_loss_real= 0.563, d_loss_fake= 0.742, g_loss 0.686, d_loss 0.653\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 333/390 d_loss_real= 0.617, d_loss_fake= 0.733, g_loss 0.690, d_loss 0.675\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 11 Batch 334/390 d_loss_real= 0.557, d_loss_fake= 0.728, g_loss 0.685, d_loss 0.643\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 335/390 d_loss_real= 0.620, d_loss_fake= 0.740, g_loss 0.676, d_loss 0.680\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 336/390 d_loss_real= 0.638, d_loss_fake= 0.749, g_loss 0.669, d_loss 0.694\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 337/390 d_loss_real= 0.596, d_loss_fake= 0.758, g_loss 0.662, d_loss 0.677\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 338/390 d_loss_real= 0.594, d_loss_fake= 0.754, g_loss 0.662, d_loss 0.674\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 339/390 d_loss_real= 0.677, d_loss_fake= 0.754, g_loss 0.667, d_loss 0.715\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 340/390 d_loss_real= 0.623, d_loss_fake= 0.741, g_loss 0.680, d_loss 0.682\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 11 Batch 341/390 d_loss_real= 0.614, d_loss_fake= 0.728, g_loss 0.695, d_loss 0.671\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 11 Batch 342/390 d_loss_real= 0.626, d_loss_fake= 0.708, g_loss 0.708, d_loss 0.667\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 11 Batch 343/390 d_loss_real= 0.674, d_loss_fake= 0.692, g_loss 0.722, d_loss 0.683\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 11 Batch 344/390 d_loss_real= 0.649, d_loss_fake= 0.677, g_loss 0.738, d_loss 0.663\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 11 Batch 345/390 d_loss_real= 0.705, d_loss_fake= 0.663, g_loss 0.751, d_loss 0.684\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 11 Batch 346/390 d_loss_real= 0.650, d_loss_fake= 0.650, g_loss 0.764, d_loss 0.650\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 347/390 d_loss_real= 0.667, d_loss_fake= 0.638, g_loss 0.777, d_loss 0.653\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 348/390 d_loss_real= 0.688, d_loss_fake= 0.630, g_loss 0.789, d_loss 0.659\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 11 Batch 349/390 d_loss_real= 0.713, d_loss_fake= 0.624, g_loss 0.792, d_loss 0.669\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 11 Batch 350/390 d_loss_real= 0.664, d_loss_fake= 0.620, g_loss 0.796, d_loss 0.642\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 351/390 d_loss_real= 0.694, d_loss_fake= 0.619, g_loss 0.792, d_loss 0.657\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 352/390 d_loss_real= 0.689, d_loss_fake= 0.620, g_loss 0.790, d_loss 0.654\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 11 Batch 353/390 d_loss_real= 0.622, d_loss_fake= 0.621, g_loss 0.788, d_loss 0.622\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 11 Batch 354/390 d_loss_real= 0.652, d_loss_fake= 0.622, g_loss 0.792, d_loss 0.637\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 355/390 d_loss_real= 0.634, d_loss_fake= 0.618, g_loss 0.793, d_loss 0.626\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 356/390 d_loss_real= 0.614, d_loss_fake= 0.618, g_loss 0.794, d_loss 0.616\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 11 Batch 357/390 d_loss_real= 0.698, d_loss_fake= 0.617, g_loss 0.793, d_loss 0.658\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 358/390 d_loss_real= 0.607, d_loss_fake= 0.614, g_loss 0.799, d_loss 0.611\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 359/390 d_loss_real= 0.639, d_loss_fake= 0.619, g_loss 0.798, d_loss 0.629\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 360/390 d_loss_real= 0.571, d_loss_fake= 0.616, g_loss 0.796, d_loss 0.594\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 11 Batch 361/390 d_loss_real= 0.619, d_loss_fake= 0.613, g_loss 0.802, d_loss 0.616\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 11 Batch 362/390 d_loss_real= 0.634, d_loss_fake= 0.613, g_loss 0.804, d_loss 0.624\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 11 Batch 363/390 d_loss_real= 0.617, d_loss_fake= 0.610, g_loss 0.802, d_loss 0.614\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 364/390 d_loss_real= 0.506, d_loss_fake= 0.610, g_loss 0.804, d_loss 0.558\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 365/390 d_loss_real= 0.567, d_loss_fake= 0.608, g_loss 0.809, d_loss 0.587\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 366/390 d_loss_real= 0.639, d_loss_fake= 0.609, g_loss 0.806, d_loss 0.624\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 367/390 d_loss_real= 0.591, d_loss_fake= 0.613, g_loss 0.802, d_loss 0.602\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 11 Batch 368/390 d_loss_real= 0.601, d_loss_fake= 0.618, g_loss 0.795, d_loss 0.610\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 369/390 d_loss_real= 0.674, d_loss_fake= 0.625, g_loss 0.786, d_loss 0.649\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 370/390 d_loss_real= 0.544, d_loss_fake= 0.635, g_loss 0.778, d_loss 0.590\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 371/390 d_loss_real= 0.524, d_loss_fake= 0.636, g_loss 0.774, d_loss 0.580\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 11 Batch 372/390 d_loss_real= 0.532, d_loss_fake= 0.639, g_loss 0.769, d_loss 0.585\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 11 Batch 373/390 d_loss_real= 0.530, d_loss_fake= 0.652, g_loss 0.764, d_loss 0.591\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 374/390 d_loss_real= 0.536, d_loss_fake= 0.648, g_loss 0.758, d_loss 0.592\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 375/390 d_loss_real= 0.522, d_loss_fake= 0.662, g_loss 0.738, d_loss 0.592\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 376/390 d_loss_real= 0.515, d_loss_fake= 0.683, g_loss 0.721, d_loss 0.599\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 377/390 d_loss_real= 0.570, d_loss_fake= 0.710, g_loss 0.710, d_loss 0.640\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 11 Batch 378/390 d_loss_real= 0.560, d_loss_fake= 0.730, g_loss 0.679, d_loss 0.645\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 379/390 d_loss_real= 0.527, d_loss_fake= 0.749, g_loss 0.657, d_loss 0.638\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 11 Batch 380/390 d_loss_real= 0.545, d_loss_fake= 0.790, g_loss 0.625, d_loss 0.667\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 381/390 d_loss_real= 0.560, d_loss_fake= 0.808, g_loss 0.608, d_loss 0.684\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 11 Batch 382/390 d_loss_real= 0.508, d_loss_fake= 0.831, g_loss 0.593, d_loss 0.669\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 11 Batch 383/390 d_loss_real= 0.479, d_loss_fake= 0.854, g_loss 0.577, d_loss 0.667\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 11 Batch 384/390 d_loss_real= 0.516, d_loss_fake= 0.871, g_loss 0.571, d_loss 0.694\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 385/390 d_loss_real= 0.522, d_loss_fake= 0.880, g_loss 0.556, d_loss 0.701\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 386/390 d_loss_real= 0.514, d_loss_fake= 0.890, g_loss 0.550, d_loss 0.702\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11 Batch 387/390 d_loss_real= 0.493, d_loss_fake= 0.903, g_loss 0.542, d_loss 0.698\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11 Batch 388/390 d_loss_real= 0.485, d_loss_fake= 0.910, g_loss 0.542, d_loss 0.697\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 11 Batch 389/390 d_loss_real= 0.521, d_loss_fake= 0.897, g_loss 0.543, d_loss 0.709\n",
            "2/2 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11 Batch 390/390 d_loss_real= 0.496, d_loss_fake= 0.892, g_loss 0.551, d_loss 0.694\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 1/390 d_loss_real= 0.462, d_loss_fake= 0.883, g_loss 0.558, d_loss 0.672\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 2/390 d_loss_real= 0.454, d_loss_fake= 0.865, g_loss 0.568, d_loss 0.659\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 3/390 d_loss_real= 0.449, d_loss_fake= 0.851, g_loss 0.582, d_loss 0.650\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 12 Batch 4/390 d_loss_real= 0.418, d_loss_fake= 0.829, g_loss 0.599, d_loss 0.624\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 5/390 d_loss_real= 0.402, d_loss_fake= 0.808, g_loss 0.617, d_loss 0.605\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 6/390 d_loss_real= 0.414, d_loss_fake= 0.783, g_loss 0.637, d_loss 0.599\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 7/390 d_loss_real= 0.415, d_loss_fake= 0.768, g_loss 0.657, d_loss 0.592\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 12 Batch 8/390 d_loss_real= 0.368, d_loss_fake= 0.746, g_loss 0.672, d_loss 0.557\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 9/390 d_loss_real= 0.358, d_loss_fake= 0.743, g_loss 0.682, d_loss 0.550\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 12 Batch 10/390 d_loss_real= 0.350, d_loss_fake= 0.733, g_loss 0.690, d_loss 0.542\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 11/390 d_loss_real= 0.380, d_loss_fake= 0.729, g_loss 0.696, d_loss 0.555\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 12/390 d_loss_real= 0.394, d_loss_fake= 0.718, g_loss 0.707, d_loss 0.556\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 12 Batch 13/390 d_loss_real= 0.459, d_loss_fake= 0.702, g_loss 0.727, d_loss 0.581\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 12 Batch 14/390 d_loss_real= 0.461, d_loss_fake= 0.679, g_loss 0.756, d_loss 0.570\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 15/390 d_loss_real= 0.506, d_loss_fake= 0.651, g_loss 0.788, d_loss 0.578\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 16/390 d_loss_real= 0.503, d_loss_fake= 0.616, g_loss 0.821, d_loss 0.560\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 12 Batch 17/390 d_loss_real= 0.592, d_loss_fake= 0.599, g_loss 0.846, d_loss 0.596\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 18/390 d_loss_real= 0.616, d_loss_fake= 0.587, g_loss 0.857, d_loss 0.602\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12 Batch 19/390 d_loss_real= 0.658, d_loss_fake= 0.585, g_loss 0.858, d_loss 0.622\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 12 Batch 20/390 d_loss_real= 0.581, d_loss_fake= 0.593, g_loss 0.845, d_loss 0.587\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 21/390 d_loss_real= 0.645, d_loss_fake= 0.613, g_loss 0.821, d_loss 0.629\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 22/390 d_loss_real= 0.668, d_loss_fake= 0.633, g_loss 0.793, d_loss 0.650\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 23/390 d_loss_real= 0.669, d_loss_fake= 0.659, g_loss 0.764, d_loss 0.664\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 24/390 d_loss_real= 0.613, d_loss_fake= 0.684, g_loss 0.743, d_loss 0.648\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 25/390 d_loss_real= 0.637, d_loss_fake= 0.697, g_loss 0.727, d_loss 0.667\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12 Batch 26/390 d_loss_real= 0.629, d_loss_fake= 0.720, g_loss 0.705, d_loss 0.675\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 12 Batch 27/390 d_loss_real= 0.673, d_loss_fake= 0.746, g_loss 0.677, d_loss 0.710\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 28/390 d_loss_real= 0.576, d_loss_fake= 0.794, g_loss 0.637, d_loss 0.685\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 29/390 d_loss_real= 0.689, d_loss_fake= 0.857, g_loss 0.587, d_loss 0.773\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 30/390 d_loss_real= 0.593, d_loss_fake= 0.930, g_loss 0.536, d_loss 0.761\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 31/390 d_loss_real= 0.616, d_loss_fake= 0.989, g_loss 0.497, d_loss 0.802\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12 Batch 32/390 d_loss_real= 0.597, d_loss_fake= 1.014, g_loss 0.481, d_loss 0.805\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 33/390 d_loss_real= 0.546, d_loss_fake= 1.031, g_loss 0.476, d_loss 0.789\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 34/390 d_loss_real= 0.571, d_loss_fake= 1.024, g_loss 0.480, d_loss 0.797\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 35/390 d_loss_real= 0.542, d_loss_fake= 0.998, g_loss 0.493, d_loss 0.770\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 36/390 d_loss_real= 0.549, d_loss_fake= 0.969, g_loss 0.510, d_loss 0.759\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 12 Batch 37/390 d_loss_real= 0.573, d_loss_fake= 0.944, g_loss 0.523, d_loss 0.758\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 38/390 d_loss_real= 0.555, d_loss_fake= 0.926, g_loss 0.537, d_loss 0.741\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 12 Batch 39/390 d_loss_real= 0.451, d_loss_fake= 0.902, g_loss 0.554, d_loss 0.677\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 40/390 d_loss_real= 0.488, d_loss_fake= 0.885, g_loss 0.565, d_loss 0.687\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 41/390 d_loss_real= 0.644, d_loss_fake= 0.864, g_loss 0.578, d_loss 0.754\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12 Batch 42/390 d_loss_real= 0.536, d_loss_fake= 0.853, g_loss 0.587, d_loss 0.694\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 43/390 d_loss_real= 0.521, d_loss_fake= 0.835, g_loss 0.603, d_loss 0.678\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 44/390 d_loss_real= 0.662, d_loss_fake= 0.817, g_loss 0.620, d_loss 0.739\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 45/390 d_loss_real= 0.457, d_loss_fake= 0.792, g_loss 0.639, d_loss 0.625\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12 Batch 46/390 d_loss_real= 0.596, d_loss_fake= 0.766, g_loss 0.660, d_loss 0.681\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 47/390 d_loss_real= 0.619, d_loss_fake= 0.743, g_loss 0.679, d_loss 0.681\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 48/390 d_loss_real= 0.553, d_loss_fake= 0.718, g_loss 0.700, d_loss 0.635\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 12 Batch 49/390 d_loss_real= 0.533, d_loss_fake= 0.703, g_loss 0.718, d_loss 0.618\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 50/390 d_loss_real= 0.531, d_loss_fake= 0.684, g_loss 0.738, d_loss 0.607\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 51/390 d_loss_real= 0.575, d_loss_fake= 0.666, g_loss 0.751, d_loss 0.621\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 52/390 d_loss_real= 0.504, d_loss_fake= 0.658, g_loss 0.761, d_loss 0.581\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 12 Batch 53/390 d_loss_real= 0.561, d_loss_fake= 0.646, g_loss 0.777, d_loss 0.603\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 54/390 d_loss_real= 0.560, d_loss_fake= 0.632, g_loss 0.785, d_loss 0.596\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 55/390 d_loss_real= 0.674, d_loss_fake= 0.624, g_loss 0.793, d_loss 0.649\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 56/390 d_loss_real= 0.529, d_loss_fake= 0.620, g_loss 0.797, d_loss 0.575\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 12 Batch 57/390 d_loss_real= 0.666, d_loss_fake= 0.617, g_loss 0.798, d_loss 0.641\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 58/390 d_loss_real= 0.534, d_loss_fake= 0.618, g_loss 0.803, d_loss 0.576\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 59/390 d_loss_real= 0.607, d_loss_fake= 0.613, g_loss 0.805, d_loss 0.610\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 60/390 d_loss_real= 0.630, d_loss_fake= 0.614, g_loss 0.804, d_loss 0.622\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 61/390 d_loss_real= 0.682, d_loss_fake= 0.618, g_loss 0.801, d_loss 0.650\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 62/390 d_loss_real= 0.677, d_loss_fake= 0.627, g_loss 0.792, d_loss 0.652\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 12 Batch 63/390 d_loss_real= 0.637, d_loss_fake= 0.638, g_loss 0.772, d_loss 0.637\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 64/390 d_loss_real= 0.658, d_loss_fake= 0.657, g_loss 0.754, d_loss 0.658\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 12 Batch 65/390 d_loss_real= 0.580, d_loss_fake= 0.678, g_loss 0.738, d_loss 0.629\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 66/390 d_loss_real= 0.625, d_loss_fake= 0.689, g_loss 0.730, d_loss 0.657\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 12 Batch 67/390 d_loss_real= 0.615, d_loss_fake= 0.680, g_loss 0.735, d_loss 0.648\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 68/390 d_loss_real= 0.617, d_loss_fake= 0.673, g_loss 0.748, d_loss 0.645\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12 Batch 69/390 d_loss_real= 0.592, d_loss_fake= 0.656, g_loss 0.766, d_loss 0.624\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 12 Batch 70/390 d_loss_real= 0.642, d_loss_fake= 0.639, g_loss 0.783, d_loss 0.640\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 12 Batch 71/390 d_loss_real= 0.618, d_loss_fake= 0.624, g_loss 0.801, d_loss 0.621\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 72/390 d_loss_real= 0.639, d_loss_fake= 0.610, g_loss 0.817, d_loss 0.625\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 12 Batch 73/390 d_loss_real= 0.695, d_loss_fake= 0.605, g_loss 0.825, d_loss 0.650\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 12 Batch 74/390 d_loss_real= 0.708, d_loss_fake= 0.606, g_loss 0.821, d_loss 0.657\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12 Batch 75/390 d_loss_real= 0.742, d_loss_fake= 0.607, g_loss 0.818, d_loss 0.675\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 76/390 d_loss_real= 0.655, d_loss_fake= 0.606, g_loss 0.813, d_loss 0.630\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 77/390 d_loss_real= 0.629, d_loss_fake= 0.611, g_loss 0.813, d_loss 0.620\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 78/390 d_loss_real= 0.667, d_loss_fake= 0.611, g_loss 0.813, d_loss 0.639\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 79/390 d_loss_real= 0.646, d_loss_fake= 0.618, g_loss 0.808, d_loss 0.632\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 80/390 d_loss_real= 0.636, d_loss_fake= 0.623, g_loss 0.797, d_loss 0.630\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 81/390 d_loss_real= 0.590, d_loss_fake= 0.633, g_loss 0.785, d_loss 0.612\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 82/390 d_loss_real= 0.645, d_loss_fake= 0.645, g_loss 0.777, d_loss 0.645\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 12 Batch 83/390 d_loss_real= 0.551, d_loss_fake= 0.663, g_loss 0.761, d_loss 0.607\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 84/390 d_loss_real= 0.643, d_loss_fake= 0.683, g_loss 0.736, d_loss 0.663\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 12 Batch 85/390 d_loss_real= 0.696, d_loss_fake= 0.709, g_loss 0.708, d_loss 0.703\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 86/390 d_loss_real= 0.641, d_loss_fake= 0.740, g_loss 0.683, d_loss 0.691\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 87/390 d_loss_real= 0.558, d_loss_fake= 0.762, g_loss 0.664, d_loss 0.660\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 88/390 d_loss_real= 0.638, d_loss_fake= 0.788, g_loss 0.645, d_loss 0.713\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 89/390 d_loss_real= 0.598, d_loss_fake= 0.801, g_loss 0.638, d_loss 0.699\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12 Batch 90/390 d_loss_real= 0.634, d_loss_fake= 0.816, g_loss 0.625, d_loss 0.725\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 91/390 d_loss_real= 0.662, d_loss_fake= 0.829, g_loss 0.613, d_loss 0.746\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 12 Batch 92/390 d_loss_real= 0.609, d_loss_fake= 0.837, g_loss 0.603, d_loss 0.723\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 93/390 d_loss_real= 0.757, d_loss_fake= 0.851, g_loss 0.594, d_loss 0.804\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 94/390 d_loss_real= 0.586, d_loss_fake= 0.853, g_loss 0.594, d_loss 0.720\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 95/390 d_loss_real= 0.628, d_loss_fake= 0.858, g_loss 0.595, d_loss 0.743\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 12 Batch 96/390 d_loss_real= 0.588, d_loss_fake= 0.851, g_loss 0.594, d_loss 0.719\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 97/390 d_loss_real= 0.625, d_loss_fake= 0.850, g_loss 0.596, d_loss 0.737\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 98/390 d_loss_real= 0.605, d_loss_fake= 0.840, g_loss 0.603, d_loss 0.722\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 99/390 d_loss_real= 0.543, d_loss_fake= 0.828, g_loss 0.616, d_loss 0.685\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 100/390 d_loss_real= 0.569, d_loss_fake= 0.820, g_loss 0.631, d_loss 0.695\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 12 Batch 101/390 d_loss_real= 0.605, d_loss_fake= 0.787, g_loss 0.650, d_loss 0.696\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 102/390 d_loss_real= 0.561, d_loss_fake= 0.764, g_loss 0.685, d_loss 0.663\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 103/390 d_loss_real= 0.648, d_loss_fake= 0.728, g_loss 0.702, d_loss 0.688\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 104/390 d_loss_real= 0.649, d_loss_fake= 0.708, g_loss 0.723, d_loss 0.679\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 12 Batch 105/390 d_loss_real= 0.635, d_loss_fake= 0.685, g_loss 0.740, d_loss 0.660\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 12 Batch 106/390 d_loss_real= 0.701, d_loss_fake= 0.675, g_loss 0.753, d_loss 0.688\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 107/390 d_loss_real= 0.726, d_loss_fake= 0.667, g_loss 0.764, d_loss 0.697\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 108/390 d_loss_real= 0.656, d_loss_fake= 0.659, g_loss 0.765, d_loss 0.658\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 109/390 d_loss_real= 0.619, d_loss_fake= 0.652, g_loss 0.770, d_loss 0.636\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 12 Batch 110/390 d_loss_real= 0.625, d_loss_fake= 0.644, g_loss 0.766, d_loss 0.634\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 111/390 d_loss_real= 0.627, d_loss_fake= 0.652, g_loss 0.764, d_loss 0.639\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 12 Batch 112/390 d_loss_real= 0.635, d_loss_fake= 0.656, g_loss 0.763, d_loss 0.646\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 113/390 d_loss_real= 0.590, d_loss_fake= 0.653, g_loss 0.760, d_loss 0.621\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 12 Batch 114/390 d_loss_real= 0.561, d_loss_fake= 0.654, g_loss 0.760, d_loss 0.607\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 115/390 d_loss_real= 0.562, d_loss_fake= 0.649, g_loss 0.765, d_loss 0.605\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 12 Batch 116/390 d_loss_real= 0.514, d_loss_fake= 0.643, g_loss 0.773, d_loss 0.578\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 12 Batch 117/390 d_loss_real= 0.520, d_loss_fake= 0.633, g_loss 0.781, d_loss 0.577\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 12 Batch 118/390 d_loss_real= 0.559, d_loss_fake= 0.626, g_loss 0.792, d_loss 0.592\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 119/390 d_loss_real= 0.519, d_loss_fake= 0.616, g_loss 0.801, d_loss 0.568\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 120/390 d_loss_real= 0.566, d_loss_fake= 0.611, g_loss 0.810, d_loss 0.588\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 121/390 d_loss_real= 0.479, d_loss_fake= 0.605, g_loss 0.817, d_loss 0.542\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 122/390 d_loss_real= 0.469, d_loss_fake= 0.604, g_loss 0.820, d_loss 0.536\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 123/390 d_loss_real= 0.519, d_loss_fake= 0.605, g_loss 0.822, d_loss 0.562\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 124/390 d_loss_real= 0.474, d_loss_fake= 0.616, g_loss 0.807, d_loss 0.545\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 125/390 d_loss_real= 0.477, d_loss_fake= 0.636, g_loss 0.789, d_loss 0.557\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 12 Batch 126/390 d_loss_real= 0.522, d_loss_fake= 0.655, g_loss 0.772, d_loss 0.589\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 127/390 d_loss_real= 0.509, d_loss_fake= 0.672, g_loss 0.759, d_loss 0.591\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 128/390 d_loss_real= 0.557, d_loss_fake= 0.678, g_loss 0.758, d_loss 0.617\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 129/390 d_loss_real= 0.571, d_loss_fake= 0.663, g_loss 0.776, d_loss 0.617\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 12 Batch 130/390 d_loss_real= 0.555, d_loss_fake= 0.638, g_loss 0.806, d_loss 0.597\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 12 Batch 131/390 d_loss_real= 0.617, d_loss_fake= 0.609, g_loss 0.839, d_loss 0.613\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 132/390 d_loss_real= 0.592, d_loss_fake= 0.577, g_loss 0.877, d_loss 0.585\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 133/390 d_loss_real= 0.646, d_loss_fake= 0.544, g_loss 0.911, d_loss 0.595\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 12 Batch 134/390 d_loss_real= 0.667, d_loss_fake= 0.523, g_loss 0.936, d_loss 0.595\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 135/390 d_loss_real= 0.628, d_loss_fake= 0.508, g_loss 0.954, d_loss 0.568\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 12 Batch 136/390 d_loss_real= 0.758, d_loss_fake= 0.500, g_loss 0.961, d_loss 0.629\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 137/390 d_loss_real= 0.766, d_loss_fake= 0.500, g_loss 0.951, d_loss 0.633\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 138/390 d_loss_real= 0.644, d_loss_fake= 0.508, g_loss 0.932, d_loss 0.576\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 139/390 d_loss_real= 0.608, d_loss_fake= 0.523, g_loss 0.917, d_loss 0.565\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 140/390 d_loss_real= 0.588, d_loss_fake= 0.535, g_loss 0.905, d_loss 0.561\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 141/390 d_loss_real= 0.521, d_loss_fake= 0.535, g_loss 0.903, d_loss 0.528\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12 Batch 142/390 d_loss_real= 0.667, d_loss_fake= 0.543, g_loss 0.890, d_loss 0.605\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 143/390 d_loss_real= 0.604, d_loss_fake= 0.551, g_loss 0.880, d_loss 0.577\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 144/390 d_loss_real= 0.563, d_loss_fake= 0.564, g_loss 0.869, d_loss 0.564\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 12 Batch 145/390 d_loss_real= 0.517, d_loss_fake= 0.569, g_loss 0.863, d_loss 0.543\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 12 Batch 146/390 d_loss_real= 0.581, d_loss_fake= 0.575, g_loss 0.859, d_loss 0.578\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 147/390 d_loss_real= 0.512, d_loss_fake= 0.571, g_loss 0.865, d_loss 0.542\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 12 Batch 148/390 d_loss_real= 0.554, d_loss_fake= 0.570, g_loss 0.868, d_loss 0.562\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 149/390 d_loss_real= 0.571, d_loss_fake= 0.577, g_loss 0.862, d_loss 0.574\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 150/390 d_loss_real= 0.594, d_loss_fake= 0.583, g_loss 0.846, d_loss 0.589\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 151/390 d_loss_real= 0.578, d_loss_fake= 0.598, g_loss 0.828, d_loss 0.588\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 12 Batch 152/390 d_loss_real= 0.545, d_loss_fake= 0.619, g_loss 0.818, d_loss 0.582\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 153/390 d_loss_real= 0.560, d_loss_fake= 0.631, g_loss 0.792, d_loss 0.595\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 154/390 d_loss_real= 0.481, d_loss_fake= 0.642, g_loss 0.780, d_loss 0.561\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 155/390 d_loss_real= 0.618, d_loss_fake= 0.653, g_loss 0.771, d_loss 0.636\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 156/390 d_loss_real= 0.522, d_loss_fake= 0.656, g_loss 0.762, d_loss 0.589\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12 Batch 157/390 d_loss_real= 0.432, d_loss_fake= 0.662, g_loss 0.758, d_loss 0.547\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 158/390 d_loss_real= 0.493, d_loss_fake= 0.672, g_loss 0.756, d_loss 0.583\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 12 Batch 159/390 d_loss_real= 0.504, d_loss_fake= 0.678, g_loss 0.754, d_loss 0.591\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 160/390 d_loss_real= 0.430, d_loss_fake= 0.680, g_loss 0.757, d_loss 0.555\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 161/390 d_loss_real= 0.442, d_loss_fake= 0.674, g_loss 0.757, d_loss 0.558\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12 Batch 162/390 d_loss_real= 0.455, d_loss_fake= 0.674, g_loss 0.764, d_loss 0.564\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 163/390 d_loss_real= 0.422, d_loss_fake= 0.662, g_loss 0.760, d_loss 0.542\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 164/390 d_loss_real= 0.371, d_loss_fake= 0.666, g_loss 0.764, d_loss 0.519\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 165/390 d_loss_real= 0.465, d_loss_fake= 0.668, g_loss 0.765, d_loss 0.567\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 166/390 d_loss_real= 0.314, d_loss_fake= 0.662, g_loss 0.769, d_loss 0.488\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 167/390 d_loss_real= 0.443, d_loss_fake= 0.661, g_loss 0.773, d_loss 0.552\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 168/390 d_loss_real= 0.408, d_loss_fake= 0.657, g_loss 0.772, d_loss 0.533\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 169/390 d_loss_real= 0.349, d_loss_fake= 0.649, g_loss 0.782, d_loss 0.499\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 170/390 d_loss_real= 0.412, d_loss_fake= 0.641, g_loss 0.794, d_loss 0.527\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12 Batch 171/390 d_loss_real= 0.484, d_loss_fake= 0.630, g_loss 0.800, d_loss 0.557\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 172/390 d_loss_real= 0.454, d_loss_fake= 0.626, g_loss 0.802, d_loss 0.540\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 173/390 d_loss_real= 0.366, d_loss_fake= 0.628, g_loss 0.799, d_loss 0.497\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 12 Batch 174/390 d_loss_real= 0.420, d_loss_fake= 0.637, g_loss 0.794, d_loss 0.528\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12 Batch 175/390 d_loss_real= 0.405, d_loss_fake= 0.640, g_loss 0.782, d_loss 0.523\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 12 Batch 176/390 d_loss_real= 0.416, d_loss_fake= 0.647, g_loss 0.778, d_loss 0.531\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 177/390 d_loss_real= 0.345, d_loss_fake= 0.650, g_loss 0.765, d_loss 0.498\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12 Batch 178/390 d_loss_real= 0.299, d_loss_fake= 0.665, g_loss 0.775, d_loss 0.482\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 12 Batch 179/390 d_loss_real= 0.405, d_loss_fake= 0.665, g_loss 0.770, d_loss 0.535\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 180/390 d_loss_real= 0.384, d_loss_fake= 0.659, g_loss 0.775, d_loss 0.522\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 181/390 d_loss_real= 0.403, d_loss_fake= 0.653, g_loss 0.769, d_loss 0.528\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 182/390 d_loss_real= 0.340, d_loss_fake= 0.669, g_loss 0.766, d_loss 0.504\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 12 Batch 183/390 d_loss_real= 0.415, d_loss_fake= 0.665, g_loss 0.774, d_loss 0.540\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 12 Batch 184/390 d_loss_real= 0.423, d_loss_fake= 0.676, g_loss 0.769, d_loss 0.549\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 185/390 d_loss_real= 0.471, d_loss_fake= 0.690, g_loss 0.759, d_loss 0.581\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 186/390 d_loss_real= 0.566, d_loss_fake= 0.716, g_loss 0.721, d_loss 0.641\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 187/390 d_loss_real= 0.471, d_loss_fake= 0.741, g_loss 0.697, d_loss 0.606\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 188/390 d_loss_real= 0.460, d_loss_fake= 0.757, g_loss 0.673, d_loss 0.608\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 189/390 d_loss_real= 0.546, d_loss_fake= 0.816, g_loss 0.670, d_loss 0.681\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 12 Batch 190/390 d_loss_real= 0.621, d_loss_fake= 0.835, g_loss 0.628, d_loss 0.728\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 191/390 d_loss_real= 0.678, d_loss_fake= 0.872, g_loss 0.597, d_loss 0.775\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 12 Batch 192/390 d_loss_real= 0.674, d_loss_fake= 0.928, g_loss 0.565, d_loss 0.801\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 193/390 d_loss_real= 0.820, d_loss_fake= 0.934, g_loss 0.536, d_loss 0.877\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 194/390 d_loss_real= 0.891, d_loss_fake= 0.976, g_loss 0.511, d_loss 0.934\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 195/390 d_loss_real= 0.823, d_loss_fake= 1.023, g_loss 0.489, d_loss 0.923\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 196/390 d_loss_real= 0.935, d_loss_fake= 1.038, g_loss 0.485, d_loss 0.986\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 12 Batch 197/390 d_loss_real= 0.870, d_loss_fake= 1.043, g_loss 0.481, d_loss 0.957\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 198/390 d_loss_real= 0.789, d_loss_fake= 1.026, g_loss 0.501, d_loss 0.907\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 12 Batch 199/390 d_loss_real= 1.083, d_loss_fake= 0.989, g_loss 0.510, d_loss 1.036\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 200/390 d_loss_real= 0.857, d_loss_fake= 0.969, g_loss 0.524, d_loss 0.913\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 201/390 d_loss_real= 0.928, d_loss_fake= 0.932, g_loss 0.539, d_loss 0.930\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 12 Batch 202/390 d_loss_real= 0.986, d_loss_fake= 0.916, g_loss 0.548, d_loss 0.951\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 203/390 d_loss_real= 0.763, d_loss_fake= 0.892, g_loss 0.561, d_loss 0.828\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 204/390 d_loss_real= 0.768, d_loss_fake= 0.877, g_loss 0.574, d_loss 0.822\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 205/390 d_loss_real= 0.827, d_loss_fake= 0.857, g_loss 0.595, d_loss 0.842\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 206/390 d_loss_real= 0.919, d_loss_fake= 0.828, g_loss 0.608, d_loss 0.874\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12 Batch 207/390 d_loss_real= 0.860, d_loss_fake= 0.808, g_loss 0.622, d_loss 0.834\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 208/390 d_loss_real= 0.731, d_loss_fake= 0.786, g_loss 0.638, d_loss 0.759\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 12 Batch 209/390 d_loss_real= 0.807, d_loss_fake= 0.764, g_loss 0.655, d_loss 0.786\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 210/390 d_loss_real= 0.748, d_loss_fake= 0.749, g_loss 0.668, d_loss 0.748\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 211/390 d_loss_real= 0.669, d_loss_fake= 0.733, g_loss 0.682, d_loss 0.701\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 212/390 d_loss_real= 0.675, d_loss_fake= 0.722, g_loss 0.695, d_loss 0.698\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 213/390 d_loss_real= 0.626, d_loss_fake= 0.707, g_loss 0.709, d_loss 0.667\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 12 Batch 214/390 d_loss_real= 0.590, d_loss_fake= 0.693, g_loss 0.723, d_loss 0.641\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 12 Batch 215/390 d_loss_real= 0.489, d_loss_fake= 0.679, g_loss 0.738, d_loss 0.584\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 12 Batch 216/390 d_loss_real= 0.534, d_loss_fake= 0.665, g_loss 0.755, d_loss 0.599\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 217/390 d_loss_real= 0.519, d_loss_fake= 0.652, g_loss 0.770, d_loss 0.586\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 218/390 d_loss_real= 0.581, d_loss_fake= 0.634, g_loss 0.784, d_loss 0.607\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 219/390 d_loss_real= 0.540, d_loss_fake= 0.627, g_loss 0.797, d_loss 0.583\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 12 Batch 220/390 d_loss_real= 0.573, d_loss_fake= 0.616, g_loss 0.805, d_loss 0.594\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12 Batch 221/390 d_loss_real= 0.472, d_loss_fake= 0.613, g_loss 0.811, d_loss 0.542\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12 Batch 222/390 d_loss_real= 0.571, d_loss_fake= 0.615, g_loss 0.809, d_loss 0.593\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 223/390 d_loss_real= 0.571, d_loss_fake= 0.633, g_loss 0.790, d_loss 0.602\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 12 Batch 224/390 d_loss_real= 0.593, d_loss_fake= 0.654, g_loss 0.763, d_loss 0.623\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 225/390 d_loss_real= 0.555, d_loss_fake= 0.683, g_loss 0.737, d_loss 0.619\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 226/390 d_loss_real= 0.506, d_loss_fake= 0.701, g_loss 0.721, d_loss 0.604\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 227/390 d_loss_real= 0.612, d_loss_fake= 0.712, g_loss 0.712, d_loss 0.662\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12 Batch 228/390 d_loss_real= 0.645, d_loss_fake= 0.717, g_loss 0.710, d_loss 0.681\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 229/390 d_loss_real= 0.637, d_loss_fake= 0.721, g_loss 0.706, d_loss 0.679\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 230/390 d_loss_real= 0.756, d_loss_fake= 0.723, g_loss 0.705, d_loss 0.740\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 231/390 d_loss_real= 0.689, d_loss_fake= 0.722, g_loss 0.705, d_loss 0.706\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 232/390 d_loss_real= 0.772, d_loss_fake= 0.729, g_loss 0.696, d_loss 0.751\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 233/390 d_loss_real= 0.771, d_loss_fake= 0.735, g_loss 0.687, d_loss 0.753\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12 Batch 234/390 d_loss_real= 0.753, d_loss_fake= 0.742, g_loss 0.689, d_loss 0.748\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 235/390 d_loss_real= 0.717, d_loss_fake= 0.731, g_loss 0.703, d_loss 0.724\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 12 Batch 236/390 d_loss_real= 0.798, d_loss_fake= 0.718, g_loss 0.711, d_loss 0.758\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 237/390 d_loss_real= 0.778, d_loss_fake= 0.705, g_loss 0.721, d_loss 0.742\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 238/390 d_loss_real= 0.827, d_loss_fake= 0.702, g_loss 0.719, d_loss 0.764\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 239/390 d_loss_real= 0.857, d_loss_fake= 0.713, g_loss 0.704, d_loss 0.785\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 240/390 d_loss_real= 0.945, d_loss_fake= 0.727, g_loss 0.690, d_loss 0.836\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 12 Batch 241/390 d_loss_real= 0.741, d_loss_fake= 0.742, g_loss 0.679, d_loss 0.742\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 242/390 d_loss_real= 0.823, d_loss_fake= 0.771, g_loss 0.660, d_loss 0.797\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 12 Batch 243/390 d_loss_real= 0.779, d_loss_fake= 0.787, g_loss 0.643, d_loss 0.783\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 12 Batch 244/390 d_loss_real= 0.847, d_loss_fake= 0.807, g_loss 0.635, d_loss 0.827\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12 Batch 245/390 d_loss_real= 0.781, d_loss_fake= 0.809, g_loss 0.630, d_loss 0.795\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12 Batch 246/390 d_loss_real= 0.758, d_loss_fake= 0.809, g_loss 0.630, d_loss 0.784\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 12 Batch 247/390 d_loss_real= 0.758, d_loss_fake= 0.800, g_loss 0.640, d_loss 0.779\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12 Batch 248/390 d_loss_real= 0.807, d_loss_fake= 0.786, g_loss 0.651, d_loss 0.796\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 249/390 d_loss_real= 0.766, d_loss_fake= 0.778, g_loss 0.666, d_loss 0.772\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12 Batch 250/390 d_loss_real= 0.716, d_loss_fake= 0.756, g_loss 0.679, d_loss 0.736\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 251/390 d_loss_real= 0.754, d_loss_fake= 0.745, g_loss 0.689, d_loss 0.750\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 252/390 d_loss_real= 0.715, d_loss_fake= 0.733, g_loss 0.695, d_loss 0.724\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 12 Batch 253/390 d_loss_real= 0.779, d_loss_fake= 0.725, g_loss 0.697, d_loss 0.752\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 254/390 d_loss_real= 0.658, d_loss_fake= 0.717, g_loss 0.706, d_loss 0.687\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 255/390 d_loss_real= 0.602, d_loss_fake= 0.710, g_loss 0.720, d_loss 0.656\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 256/390 d_loss_real= 0.566, d_loss_fake= 0.690, g_loss 0.732, d_loss 0.628\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12 Batch 257/390 d_loss_real= 0.620, d_loss_fake= 0.673, g_loss 0.749, d_loss 0.646\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 258/390 d_loss_real= 0.590, d_loss_fake= 0.662, g_loss 0.766, d_loss 0.626\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 259/390 d_loss_real= 0.600, d_loss_fake= 0.649, g_loss 0.769, d_loss 0.625\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 260/390 d_loss_real= 0.552, d_loss_fake= 0.642, g_loss 0.779, d_loss 0.597\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 261/390 d_loss_real= 0.537, d_loss_fake= 0.632, g_loss 0.795, d_loss 0.584\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 12 Batch 262/390 d_loss_real= 0.505, d_loss_fake= 0.626, g_loss 0.804, d_loss 0.565\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 12 Batch 263/390 d_loss_real= 0.523, d_loss_fake= 0.616, g_loss 0.814, d_loss 0.569\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 12 Batch 264/390 d_loss_real= 0.524, d_loss_fake= 0.606, g_loss 0.820, d_loss 0.565\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 265/390 d_loss_real= 0.530, d_loss_fake= 0.597, g_loss 0.824, d_loss 0.564\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 266/390 d_loss_real= 0.461, d_loss_fake= 0.597, g_loss 0.829, d_loss 0.529\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 12 Batch 267/390 d_loss_real= 0.524, d_loss_fake= 0.600, g_loss 0.826, d_loss 0.562\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 12 Batch 268/390 d_loss_real= 0.518, d_loss_fake= 0.610, g_loss 0.818, d_loss 0.564\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 269/390 d_loss_real= 0.537, d_loss_fake= 0.620, g_loss 0.800, d_loss 0.579\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 12 Batch 270/390 d_loss_real= 0.511, d_loss_fake= 0.646, g_loss 0.783, d_loss 0.579\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 271/390 d_loss_real= 0.435, d_loss_fake= 0.664, g_loss 0.752, d_loss 0.550\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 272/390 d_loss_real= 0.529, d_loss_fake= 0.693, g_loss 0.730, d_loss 0.611\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 273/390 d_loss_real= 0.660, d_loss_fake= 0.718, g_loss 0.692, d_loss 0.689\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 274/390 d_loss_real= 0.551, d_loss_fake= 0.751, g_loss 0.669, d_loss 0.651\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 275/390 d_loss_real= 0.617, d_loss_fake= 0.772, g_loss 0.656, d_loss 0.694\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 12 Batch 276/390 d_loss_real= 0.612, d_loss_fake= 0.784, g_loss 0.656, d_loss 0.698\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 277/390 d_loss_real= 0.574, d_loss_fake= 0.770, g_loss 0.664, d_loss 0.672\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 278/390 d_loss_real= 0.692, d_loss_fake= 0.751, g_loss 0.679, d_loss 0.721\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 279/390 d_loss_real= 0.670, d_loss_fake= 0.731, g_loss 0.696, d_loss 0.700\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 280/390 d_loss_real= 0.720, d_loss_fake= 0.724, g_loss 0.709, d_loss 0.722\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12 Batch 281/390 d_loss_real= 0.785, d_loss_fake= 0.712, g_loss 0.717, d_loss 0.749\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 282/390 d_loss_real= 0.640, d_loss_fake= 0.712, g_loss 0.709, d_loss 0.676\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 283/390 d_loss_real= 0.794, d_loss_fake= 0.727, g_loss 0.694, d_loss 0.761\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 12 Batch 284/390 d_loss_real= 0.741, d_loss_fake= 0.745, g_loss 0.680, d_loss 0.743\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 12 Batch 285/390 d_loss_real= 0.712, d_loss_fake= 0.752, g_loss 0.668, d_loss 0.732\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 286/390 d_loss_real= 0.637, d_loss_fake= 0.751, g_loss 0.674, d_loss 0.694\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 287/390 d_loss_real= 0.732, d_loss_fake= 0.749, g_loss 0.676, d_loss 0.741\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 288/390 d_loss_real= 0.724, d_loss_fake= 0.736, g_loss 0.684, d_loss 0.730\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 12 Batch 289/390 d_loss_real= 0.663, d_loss_fake= 0.730, g_loss 0.695, d_loss 0.696\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12 Batch 290/390 d_loss_real= 0.585, d_loss_fake= 0.716, g_loss 0.709, d_loss 0.651\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 291/390 d_loss_real= 0.573, d_loss_fake= 0.694, g_loss 0.726, d_loss 0.633\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 292/390 d_loss_real= 0.651, d_loss_fake= 0.683, g_loss 0.743, d_loss 0.667\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 293/390 d_loss_real= 0.590, d_loss_fake= 0.659, g_loss 0.765, d_loss 0.625\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 294/390 d_loss_real= 0.538, d_loss_fake= 0.638, g_loss 0.787, d_loss 0.588\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 295/390 d_loss_real= 0.601, d_loss_fake= 0.619, g_loss 0.808, d_loss 0.610\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 12 Batch 296/390 d_loss_real= 0.576, d_loss_fake= 0.607, g_loss 0.821, d_loss 0.591\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 297/390 d_loss_real= 0.566, d_loss_fake= 0.597, g_loss 0.829, d_loss 0.581\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 298/390 d_loss_real= 0.515, d_loss_fake= 0.595, g_loss 0.830, d_loss 0.555\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 299/390 d_loss_real= 0.480, d_loss_fake= 0.589, g_loss 0.837, d_loss 0.535\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 300/390 d_loss_real= 0.461, d_loss_fake= 0.587, g_loss 0.843, d_loss 0.524\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 12 Batch 301/390 d_loss_real= 0.480, d_loss_fake= 0.585, g_loss 0.846, d_loss 0.532\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12 Batch 302/390 d_loss_real= 0.558, d_loss_fake= 0.584, g_loss 0.847, d_loss 0.571\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 303/390 d_loss_real= 0.511, d_loss_fake= 0.582, g_loss 0.848, d_loss 0.546\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 304/390 d_loss_real= 0.457, d_loss_fake= 0.579, g_loss 0.855, d_loss 0.518\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 305/390 d_loss_real= 0.484, d_loss_fake= 0.580, g_loss 0.856, d_loss 0.532\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 306/390 d_loss_real= 0.501, d_loss_fake= 0.581, g_loss 0.853, d_loss 0.541\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 307/390 d_loss_real= 0.466, d_loss_fake= 0.586, g_loss 0.857, d_loss 0.526\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 12 Batch 308/390 d_loss_real= 0.468, d_loss_fake= 0.575, g_loss 0.866, d_loss 0.521\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 309/390 d_loss_real= 0.499, d_loss_fake= 0.557, g_loss 0.892, d_loss 0.528\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 310/390 d_loss_real= 0.597, d_loss_fake= 0.537, g_loss 0.921, d_loss 0.567\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 311/390 d_loss_real= 0.592, d_loss_fake= 0.515, g_loss 0.949, d_loss 0.553\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 312/390 d_loss_real= 0.560, d_loss_fake= 0.500, g_loss 0.966, d_loss 0.530\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 313/390 d_loss_real= 0.579, d_loss_fake= 0.494, g_loss 0.971, d_loss 0.537\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 314/390 d_loss_real= 0.541, d_loss_fake= 0.495, g_loss 0.966, d_loss 0.518\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 315/390 d_loss_real= 0.546, d_loss_fake= 0.496, g_loss 0.965, d_loss 0.521\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 316/390 d_loss_real= 0.553, d_loss_fake= 0.503, g_loss 0.951, d_loss 0.528\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 317/390 d_loss_real= 0.586, d_loss_fake= 0.511, g_loss 0.942, d_loss 0.549\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 318/390 d_loss_real= 0.526, d_loss_fake= 0.518, g_loss 0.934, d_loss 0.522\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 12 Batch 319/390 d_loss_real= 0.551, d_loss_fake= 0.524, g_loss 0.926, d_loss 0.538\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 12 Batch 320/390 d_loss_real= 0.495, d_loss_fake= 0.525, g_loss 0.928, d_loss 0.510\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 321/390 d_loss_real= 0.500, d_loss_fake= 0.523, g_loss 0.935, d_loss 0.512\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 322/390 d_loss_real= 0.512, d_loss_fake= 0.519, g_loss 0.939, d_loss 0.515\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 323/390 d_loss_real= 0.532, d_loss_fake= 0.522, g_loss 0.936, d_loss 0.527\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 324/390 d_loss_real= 0.512, d_loss_fake= 0.527, g_loss 0.923, d_loss 0.520\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 325/390 d_loss_real= 0.508, d_loss_fake= 0.543, g_loss 0.912, d_loss 0.526\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 326/390 d_loss_real= 0.518, d_loss_fake= 0.570, g_loss 0.873, d_loss 0.544\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 327/390 d_loss_real= 0.517, d_loss_fake= 0.620, g_loss 0.819, d_loss 0.568\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 328/390 d_loss_real= 0.541, d_loss_fake= 0.693, g_loss 0.744, d_loss 0.617\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 12 Batch 329/390 d_loss_real= 0.544, d_loss_fake= 0.767, g_loss 0.675, d_loss 0.655\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 330/390 d_loss_real= 0.595, d_loss_fake= 0.819, g_loss 0.634, d_loss 0.707\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 331/390 d_loss_real= 0.600, d_loss_fake= 0.841, g_loss 0.615, d_loss 0.721\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 12 Batch 332/390 d_loss_real= 0.630, d_loss_fake= 0.844, g_loss 0.608, d_loss 0.737\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 333/390 d_loss_real= 0.636, d_loss_fake= 0.835, g_loss 0.612, d_loss 0.736\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 334/390 d_loss_real= 0.705, d_loss_fake= 0.834, g_loss 0.618, d_loss 0.770\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12 Batch 335/390 d_loss_real= 0.657, d_loss_fake= 0.821, g_loss 0.622, d_loss 0.739\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 336/390 d_loss_real= 0.660, d_loss_fake= 0.807, g_loss 0.629, d_loss 0.734\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 12 Batch 337/390 d_loss_real= 0.616, d_loss_fake= 0.804, g_loss 0.633, d_loss 0.710\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 338/390 d_loss_real= 0.562, d_loss_fake= 0.795, g_loss 0.640, d_loss 0.679\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 339/390 d_loss_real= 0.584, d_loss_fake= 0.777, g_loss 0.650, d_loss 0.680\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 12 Batch 340/390 d_loss_real= 0.568, d_loss_fake= 0.760, g_loss 0.665, d_loss 0.664\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 341/390 d_loss_real= 0.505, d_loss_fake= 0.745, g_loss 0.676, d_loss 0.625\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 342/390 d_loss_real= 0.536, d_loss_fake= 0.733, g_loss 0.692, d_loss 0.635\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 12 Batch 343/390 d_loss_real= 0.519, d_loss_fake= 0.717, g_loss 0.705, d_loss 0.618\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 12 Batch 344/390 d_loss_real= 0.442, d_loss_fake= 0.712, g_loss 0.709, d_loss 0.577\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 12 Batch 345/390 d_loss_real= 0.488, d_loss_fake= 0.708, g_loss 0.715, d_loss 0.598\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 346/390 d_loss_real= 0.394, d_loss_fake= 0.703, g_loss 0.720, d_loss 0.548\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 347/390 d_loss_real= 0.441, d_loss_fake= 0.696, g_loss 0.731, d_loss 0.568\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 12 Batch 348/390 d_loss_real= 0.487, d_loss_fake= 0.677, g_loss 0.745, d_loss 0.582\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 349/390 d_loss_real= 0.425, d_loss_fake= 0.661, g_loss 0.764, d_loss 0.543\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 12 Batch 350/390 d_loss_real= 0.484, d_loss_fake= 0.642, g_loss 0.789, d_loss 0.563\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 351/390 d_loss_real= 0.516, d_loss_fake= 0.627, g_loss 0.800, d_loss 0.572\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 352/390 d_loss_real= 0.556, d_loss_fake= 0.614, g_loss 0.813, d_loss 0.585\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 12 Batch 353/390 d_loss_real= 0.550, d_loss_fake= 0.603, g_loss 0.820, d_loss 0.577\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 354/390 d_loss_real= 0.609, d_loss_fake= 0.600, g_loss 0.823, d_loss 0.604\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 355/390 d_loss_real= 0.564, d_loss_fake= 0.604, g_loss 0.815, d_loss 0.584\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 12 Batch 356/390 d_loss_real= 0.553, d_loss_fake= 0.608, g_loss 0.813, d_loss 0.581\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 357/390 d_loss_real= 0.508, d_loss_fake= 0.609, g_loss 0.810, d_loss 0.558\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 358/390 d_loss_real= 0.537, d_loss_fake= 0.609, g_loss 0.815, d_loss 0.573\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 12 Batch 359/390 d_loss_real= 0.530, d_loss_fake= 0.611, g_loss 0.809, d_loss 0.570\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 360/390 d_loss_real= 0.628, d_loss_fake= 0.611, g_loss 0.811, d_loss 0.619\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12 Batch 361/390 d_loss_real= 0.520, d_loss_fake= 0.615, g_loss 0.804, d_loss 0.567\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 12 Batch 362/390 d_loss_real= 0.524, d_loss_fake= 0.617, g_loss 0.804, d_loss 0.570\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12 Batch 363/390 d_loss_real= 0.593, d_loss_fake= 0.617, g_loss 0.810, d_loss 0.605\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 364/390 d_loss_real= 0.505, d_loss_fake= 0.615, g_loss 0.812, d_loss 0.560\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 12 Batch 365/390 d_loss_real= 0.473, d_loss_fake= 0.614, g_loss 0.818, d_loss 0.543\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12 Batch 366/390 d_loss_real= 0.481, d_loss_fake= 0.618, g_loss 0.815, d_loss 0.549\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 12 Batch 367/390 d_loss_real= 0.485, d_loss_fake= 0.614, g_loss 0.812, d_loss 0.550\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12 Batch 368/390 d_loss_real= 0.520, d_loss_fake= 0.617, g_loss 0.798, d_loss 0.569\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 369/390 d_loss_real= 0.487, d_loss_fake= 0.636, g_loss 0.783, d_loss 0.561\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 370/390 d_loss_real= 0.488, d_loss_fake= 0.664, g_loss 0.752, d_loss 0.576\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 12 Batch 371/390 d_loss_real= 0.572, d_loss_fake= 0.695, g_loss 0.721, d_loss 0.633\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 12 Batch 372/390 d_loss_real= 0.518, d_loss_fake= 0.723, g_loss 0.698, d_loss 0.620\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 12 Batch 373/390 d_loss_real= 0.517, d_loss_fake= 0.745, g_loss 0.677, d_loss 0.631\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 374/390 d_loss_real= 0.476, d_loss_fake= 0.755, g_loss 0.668, d_loss 0.616\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 12 Batch 375/390 d_loss_real= 0.522, d_loss_fake= 0.767, g_loss 0.660, d_loss 0.644\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 376/390 d_loss_real= 0.505, d_loss_fake= 0.766, g_loss 0.661, d_loss 0.636\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 377/390 d_loss_real= 0.506, d_loss_fake= 0.765, g_loss 0.663, d_loss 0.636\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 12 Batch 378/390 d_loss_real= 0.395, d_loss_fake= 0.759, g_loss 0.672, d_loss 0.577\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 379/390 d_loss_real= 0.488, d_loss_fake= 0.745, g_loss 0.674, d_loss 0.616\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 380/390 d_loss_real= 0.439, d_loss_fake= 0.742, g_loss 0.681, d_loss 0.591\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 381/390 d_loss_real= 0.428, d_loss_fake= 0.736, g_loss 0.689, d_loss 0.582\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 382/390 d_loss_real= 0.495, d_loss_fake= 0.731, g_loss 0.687, d_loss 0.613\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 383/390 d_loss_real= 0.500, d_loss_fake= 0.734, g_loss 0.686, d_loss 0.617\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 384/390 d_loss_real= 0.415, d_loss_fake= 0.736, g_loss 0.685, d_loss 0.575\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 385/390 d_loss_real= 0.443, d_loss_fake= 0.732, g_loss 0.686, d_loss 0.588\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 386/390 d_loss_real= 0.416, d_loss_fake= 0.727, g_loss 0.692, d_loss 0.572\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 12 Batch 387/390 d_loss_real= 0.469, d_loss_fake= 0.727, g_loss 0.698, d_loss 0.598\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12 Batch 388/390 d_loss_real= 0.426, d_loss_fake= 0.722, g_loss 0.701, d_loss 0.574\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12 Batch 389/390 d_loss_real= 0.356, d_loss_fake= 0.733, g_loss 0.707, d_loss 0.545\n",
            "2/2 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12 Batch 390/390 d_loss_real= 0.460, d_loss_fake= 0.732, g_loss 0.703, d_loss 0.596\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 13 Batch 1/390 d_loss_real= 0.477, d_loss_fake= 0.734, g_loss 0.703, d_loss 0.606\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 13 Batch 2/390 d_loss_real= 0.434, d_loss_fake= 0.757, g_loss 0.689, d_loss 0.595\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 3/390 d_loss_real= 0.526, d_loss_fake= 0.764, g_loss 0.680, d_loss 0.645\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 13 Batch 4/390 d_loss_real= 0.512, d_loss_fake= 0.766, g_loss 0.691, d_loss 0.639\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 13 Batch 5/390 d_loss_real= 0.571, d_loss_fake= 0.744, g_loss 0.707, d_loss 0.658\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 13 Batch 6/390 d_loss_real= 0.591, d_loss_fake= 0.722, g_loss 0.737, d_loss 0.656\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 7/390 d_loss_real= 0.523, d_loss_fake= 0.667, g_loss 0.784, d_loss 0.595\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 8/390 d_loss_real= 0.752, d_loss_fake= 0.635, g_loss 0.816, d_loss 0.694\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 9/390 d_loss_real= 0.648, d_loss_fake= 0.616, g_loss 0.842, d_loss 0.632\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 10/390 d_loss_real= 0.683, d_loss_fake= 0.601, g_loss 0.849, d_loss 0.642\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 11/390 d_loss_real= 0.701, d_loss_fake= 0.598, g_loss 0.853, d_loss 0.650\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 12/390 d_loss_real= 0.723, d_loss_fake= 0.607, g_loss 0.831, d_loss 0.665\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 13 Batch 13/390 d_loss_real= 0.640, d_loss_fake= 0.623, g_loss 0.811, d_loss 0.632\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 14/390 d_loss_real= 0.756, d_loss_fake= 0.656, g_loss 0.773, d_loss 0.706\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 13 Batch 15/390 d_loss_real= 0.628, d_loss_fake= 0.693, g_loss 0.747, d_loss 0.661\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 16/390 d_loss_real= 0.564, d_loss_fake= 0.711, g_loss 0.732, d_loss 0.637\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 17/390 d_loss_real= 0.550, d_loss_fake= 0.690, g_loss 0.737, d_loss 0.620\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 18/390 d_loss_real= 0.456, d_loss_fake= 0.683, g_loss 0.771, d_loss 0.569\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 13 Batch 19/390 d_loss_real= 0.461, d_loss_fake= 0.645, g_loss 0.802, d_loss 0.553\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 13 Batch 20/390 d_loss_real= 0.462, d_loss_fake= 0.606, g_loss 0.842, d_loss 0.534\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 21/390 d_loss_real= 0.511, d_loss_fake= 0.576, g_loss 0.900, d_loss 0.544\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 22/390 d_loss_real= 0.434, d_loss_fake= 0.537, g_loss 0.931, d_loss 0.486\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 23/390 d_loss_real= 0.493, d_loss_fake= 0.510, g_loss 0.958, d_loss 0.502\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 13 Batch 24/390 d_loss_real= 0.437, d_loss_fake= 0.488, g_loss 0.989, d_loss 0.463\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 25/390 d_loss_real= 0.404, d_loss_fake= 0.486, g_loss 0.996, d_loss 0.445\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 13 Batch 26/390 d_loss_real= 0.404, d_loss_fake= 0.491, g_loss 0.979, d_loss 0.447\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 27/390 d_loss_real= 0.405, d_loss_fake= 0.534, g_loss 0.942, d_loss 0.470\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 13 Batch 28/390 d_loss_real= 0.352, d_loss_fake= 0.560, g_loss 0.881, d_loss 0.456\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 29/390 d_loss_real= 0.366, d_loss_fake= 0.639, g_loss 0.834, d_loss 0.502\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 30/390 d_loss_real= 0.557, d_loss_fake= 0.656, g_loss 0.828, d_loss 0.607\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 31/390 d_loss_real= 0.431, d_loss_fake= 0.636, g_loss 0.854, d_loss 0.534\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 13 Batch 32/390 d_loss_real= 0.497, d_loss_fake= 0.592, g_loss 0.888, d_loss 0.544\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 33/390 d_loss_real= 0.456, d_loss_fake= 0.531, g_loss 0.980, d_loss 0.493\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 34/390 d_loss_real= 0.596, d_loss_fake= 0.477, g_loss 1.050, d_loss 0.536\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 13 Batch 35/390 d_loss_real= 0.684, d_loss_fake= 0.436, g_loss 1.095, d_loss 0.560\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 36/390 d_loss_real= 0.683, d_loss_fake= 0.418, g_loss 1.114, d_loss 0.551\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 37/390 d_loss_real= 0.649, d_loss_fake= 0.415, g_loss 1.108, d_loss 0.532\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 13 Batch 38/390 d_loss_real= 0.610, d_loss_fake= 0.421, g_loss 1.092, d_loss 0.515\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 13 Batch 39/390 d_loss_real= 0.672, d_loss_fake= 0.437, g_loss 1.055, d_loss 0.554\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 40/390 d_loss_real= 0.584, d_loss_fake= 0.455, g_loss 1.038, d_loss 0.519\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 13 Batch 41/390 d_loss_real= 0.554, d_loss_fake= 0.457, g_loss 1.048, d_loss 0.506\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 13 Batch 42/390 d_loss_real= 0.532, d_loss_fake= 0.450, g_loss 1.058, d_loss 0.491\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 43/390 d_loss_real= 0.547, d_loss_fake= 0.438, g_loss 1.089, d_loss 0.492\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 13 Batch 44/390 d_loss_real= 0.442, d_loss_fake= 0.418, g_loss 1.127, d_loss 0.430\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 45/390 d_loss_real= 0.578, d_loss_fake= 0.398, g_loss 1.166, d_loss 0.488\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 46/390 d_loss_real= 0.508, d_loss_fake= 0.382, g_loss 1.189, d_loss 0.445\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 13 Batch 47/390 d_loss_real= 0.533, d_loss_fake= 0.372, g_loss 1.206, d_loss 0.453\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 48/390 d_loss_real= 0.526, d_loss_fake= 0.369, g_loss 1.208, d_loss 0.448\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 49/390 d_loss_real= 0.448, d_loss_fake= 0.367, g_loss 1.218, d_loss 0.408\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 13 Batch 50/390 d_loss_real= 0.527, d_loss_fake= 0.364, g_loss 1.224, d_loss 0.445\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 13 Batch 51/390 d_loss_real= 0.501, d_loss_fake= 0.362, g_loss 1.236, d_loss 0.431\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 13 Batch 52/390 d_loss_real= 0.464, d_loss_fake= 0.357, g_loss 1.245, d_loss 0.410\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 53/390 d_loss_real= 0.435, d_loss_fake= 0.355, g_loss 1.247, d_loss 0.395\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 54/390 d_loss_real= 0.404, d_loss_fake= 0.351, g_loss 1.269, d_loss 0.378\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 13 Batch 55/390 d_loss_real= 0.442, d_loss_fake= 0.336, g_loss 1.311, d_loss 0.389\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 56/390 d_loss_real= 0.423, d_loss_fake= 0.319, g_loss 1.346, d_loss 0.371\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 57/390 d_loss_real= 0.401, d_loss_fake= 0.307, g_loss 1.375, d_loss 0.354\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 13 Batch 58/390 d_loss_real= 0.417, d_loss_fake= 0.298, g_loss 1.399, d_loss 0.358\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 13 Batch 59/390 d_loss_real= 0.328, d_loss_fake= 0.292, g_loss 1.431, d_loss 0.310\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 60/390 d_loss_real= 0.349, d_loss_fake= 0.282, g_loss 1.463, d_loss 0.316\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 13 Batch 61/390 d_loss_real= 0.316, d_loss_fake= 0.274, g_loss 1.484, d_loss 0.295\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 13 Batch 62/390 d_loss_real= 0.469, d_loss_fake= 0.271, g_loss 1.465, d_loss 0.370\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 63/390 d_loss_real= 0.392, d_loss_fake= 0.284, g_loss 1.431, d_loss 0.338\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 64/390 d_loss_real= 0.344, d_loss_fake= 0.294, g_loss 1.416, d_loss 0.319\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 65/390 d_loss_real= 0.363, d_loss_fake= 0.299, g_loss 1.394, d_loss 0.331\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 66/390 d_loss_real= 0.321, d_loss_fake= 0.302, g_loss 1.405, d_loss 0.311\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 67/390 d_loss_real= 0.471, d_loss_fake= 0.305, g_loss 1.390, d_loss 0.388\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 68/390 d_loss_real= 0.377, d_loss_fake= 0.315, g_loss 1.366, d_loss 0.346\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 69/390 d_loss_real= 0.377, d_loss_fake= 0.347, g_loss 1.299, d_loss 0.362\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 70/390 d_loss_real= 0.374, d_loss_fake= 0.396, g_loss 1.225, d_loss 0.385\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 13 Batch 71/390 d_loss_real= 0.386, d_loss_fake= 0.415, g_loss 1.170, d_loss 0.401\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 72/390 d_loss_real= 0.438, d_loss_fake= 0.438, g_loss 1.141, d_loss 0.438\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 13 Batch 73/390 d_loss_real= 0.422, d_loss_fake= 0.438, g_loss 1.118, d_loss 0.430\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 13 Batch 74/390 d_loss_real= 0.448, d_loss_fake= 0.447, g_loss 1.125, d_loss 0.447\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 13 Batch 75/390 d_loss_real= 0.453, d_loss_fake= 0.456, g_loss 1.126, d_loss 0.454\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 76/390 d_loss_real= 0.515, d_loss_fake= 0.440, g_loss 1.131, d_loss 0.477\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 13 Batch 77/390 d_loss_real= 0.559, d_loss_fake= 0.451, g_loss 1.129, d_loss 0.505\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 78/390 d_loss_real= 0.454, d_loss_fake= 0.443, g_loss 1.105, d_loss 0.448\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 13 Batch 79/390 d_loss_real= 0.578, d_loss_fake= 0.471, g_loss 1.082, d_loss 0.525\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 13 Batch 80/390 d_loss_real= 0.519, d_loss_fake= 0.471, g_loss 1.033, d_loss 0.495\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 81/390 d_loss_real= 0.444, d_loss_fake= 0.505, g_loss 1.011, d_loss 0.474\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 82/390 d_loss_real= 0.480, d_loss_fake= 0.517, g_loss 0.989, d_loss 0.498\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 83/390 d_loss_real= 0.432, d_loss_fake= 0.522, g_loss 0.990, d_loss 0.477\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 84/390 d_loss_real= 0.501, d_loss_fake= 0.529, g_loss 0.964, d_loss 0.515\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 13 Batch 85/390 d_loss_real= 0.399, d_loss_fake= 0.537, g_loss 0.974, d_loss 0.468\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 13 Batch 86/390 d_loss_real= 0.424, d_loss_fake= 0.529, g_loss 0.976, d_loss 0.477\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 87/390 d_loss_real= 0.406, d_loss_fake= 0.524, g_loss 0.964, d_loss 0.465\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 88/390 d_loss_real= 0.502, d_loss_fake= 0.556, g_loss 0.935, d_loss 0.529\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 89/390 d_loss_real= 0.482, d_loss_fake= 0.586, g_loss 0.877, d_loss 0.534\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 90/390 d_loss_real= 0.361, d_loss_fake= 0.636, g_loss 0.830, d_loss 0.498\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 13 Batch 91/390 d_loss_real= 0.522, d_loss_fake= 0.689, g_loss 0.774, d_loss 0.605\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 13 Batch 92/390 d_loss_real= 0.512, d_loss_fake= 0.730, g_loss 0.729, d_loss 0.621\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 93/390 d_loss_real= 0.434, d_loss_fake= 0.751, g_loss 0.692, d_loss 0.593\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 94/390 d_loss_real= 0.475, d_loss_fake= 0.793, g_loss 0.690, d_loss 0.634\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 13 Batch 95/390 d_loss_real= 0.465, d_loss_fake= 0.792, g_loss 0.685, d_loss 0.629\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 96/390 d_loss_real= 0.562, d_loss_fake= 0.809, g_loss 0.666, d_loss 0.686\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 13 Batch 97/390 d_loss_real= 0.562, d_loss_fake= 0.859, g_loss 0.637, d_loss 0.710\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 13 Batch 98/390 d_loss_real= 0.641, d_loss_fake= 0.858, g_loss 0.606, d_loss 0.750\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 99/390 d_loss_real= 0.478, d_loss_fake= 0.942, g_loss 0.554, d_loss 0.710\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 13 Batch 100/390 d_loss_real= 0.525, d_loss_fake= 0.976, g_loss 0.528, d_loss 0.751\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 13 Batch 101/390 d_loss_real= 0.678, d_loss_fake= 1.047, g_loss 0.497, d_loss 0.862\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 102/390 d_loss_real= 0.572, d_loss_fake= 1.094, g_loss 0.483, d_loss 0.833\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 103/390 d_loss_real= 0.581, d_loss_fake= 1.095, g_loss 0.487, d_loss 0.838\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 104/390 d_loss_real= 0.625, d_loss_fake= 1.052, g_loss 0.497, d_loss 0.839\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 105/390 d_loss_real= 0.558, d_loss_fake= 1.033, g_loss 0.511, d_loss 0.795\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 13 Batch 106/390 d_loss_real= 0.534, d_loss_fake= 0.983, g_loss 0.546, d_loss 0.759\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 107/390 d_loss_real= 0.582, d_loss_fake= 0.954, g_loss 0.571, d_loss 0.768\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 108/390 d_loss_real= 0.628, d_loss_fake= 0.918, g_loss 0.592, d_loss 0.773\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 109/390 d_loss_real= 0.686, d_loss_fake= 0.899, g_loss 0.608, d_loss 0.793\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 13 Batch 110/390 d_loss_real= 0.635, d_loss_fake= 0.858, g_loss 0.633, d_loss 0.746\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 111/390 d_loss_real= 0.653, d_loss_fake= 0.812, g_loss 0.641, d_loss 0.732\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 112/390 d_loss_real= 0.697, d_loss_fake= 0.800, g_loss 0.647, d_loss 0.749\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 113/390 d_loss_real= 0.558, d_loss_fake= 0.796, g_loss 0.645, d_loss 0.677\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 114/390 d_loss_real= 0.607, d_loss_fake= 0.773, g_loss 0.653, d_loss 0.690\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 13 Batch 115/390 d_loss_real= 0.564, d_loss_fake= 0.781, g_loss 0.680, d_loss 0.672\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 13 Batch 116/390 d_loss_real= 0.519, d_loss_fake= 0.727, g_loss 0.704, d_loss 0.623\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 117/390 d_loss_real= 0.513, d_loss_fake= 0.720, g_loss 0.722, d_loss 0.617\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 118/390 d_loss_real= 0.589, d_loss_fake= 0.723, g_loss 0.744, d_loss 0.656\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 119/390 d_loss_real= 0.515, d_loss_fake= 0.677, g_loss 0.785, d_loss 0.596\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 120/390 d_loss_real= 0.594, d_loss_fake= 0.669, g_loss 0.793, d_loss 0.631\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 121/390 d_loss_real= 0.592, d_loss_fake= 0.658, g_loss 0.801, d_loss 0.625\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 13 Batch 122/390 d_loss_real= 0.639, d_loss_fake= 0.672, g_loss 0.805, d_loss 0.655\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 123/390 d_loss_real= 0.610, d_loss_fake= 0.643, g_loss 0.819, d_loss 0.627\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 124/390 d_loss_real= 0.633, d_loss_fake= 0.646, g_loss 0.819, d_loss 0.639\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 13 Batch 125/390 d_loss_real= 0.715, d_loss_fake= 0.633, g_loss 0.824, d_loss 0.674\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 13 Batch 126/390 d_loss_real= 0.691, d_loss_fake= 0.622, g_loss 0.841, d_loss 0.656\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 127/390 d_loss_real= 0.703, d_loss_fake= 0.606, g_loss 0.874, d_loss 0.654\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 13 Batch 128/390 d_loss_real= 0.658, d_loss_fake= 0.590, g_loss 0.891, d_loss 0.624\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 13 Batch 129/390 d_loss_real= 0.793, d_loss_fake= 0.564, g_loss 0.909, d_loss 0.679\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 13 Batch 130/390 d_loss_real= 0.780, d_loss_fake= 0.552, g_loss 0.919, d_loss 0.666\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 13 Batch 131/390 d_loss_real= 0.810, d_loss_fake= 0.537, g_loss 0.946, d_loss 0.673\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 13 Batch 132/390 d_loss_real= 0.902, d_loss_fake= 0.542, g_loss 0.941, d_loss 0.722\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 133/390 d_loss_real= 0.714, d_loss_fake= 0.533, g_loss 0.926, d_loss 0.623\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 13 Batch 134/390 d_loss_real= 0.867, d_loss_fake= 0.546, g_loss 0.908, d_loss 0.706\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 135/390 d_loss_real= 0.863, d_loss_fake= 0.552, g_loss 0.891, d_loss 0.708\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 13 Batch 136/390 d_loss_real= 0.789, d_loss_fake= 0.569, g_loss 0.873, d_loss 0.679\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 13 Batch 137/390 d_loss_real= 0.750, d_loss_fake= 0.578, g_loss 0.861, d_loss 0.664\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 138/390 d_loss_real= 0.756, d_loss_fake= 0.570, g_loss 0.867, d_loss 0.663\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 139/390 d_loss_real= 0.734, d_loss_fake= 0.572, g_loss 0.881, d_loss 0.653\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 140/390 d_loss_real= 0.669, d_loss_fake= 0.558, g_loss 0.892, d_loss 0.614\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 13 Batch 141/390 d_loss_real= 0.761, d_loss_fake= 0.548, g_loss 0.913, d_loss 0.655\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 142/390 d_loss_real= 0.708, d_loss_fake= 0.530, g_loss 0.926, d_loss 0.619\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 13 Batch 143/390 d_loss_real= 0.706, d_loss_fake= 0.522, g_loss 0.941, d_loss 0.614\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 13 Batch 144/390 d_loss_real= 0.622, d_loss_fake= 0.510, g_loss 0.955, d_loss 0.566\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 13 Batch 145/390 d_loss_real= 0.656, d_loss_fake= 0.504, g_loss 0.969, d_loss 0.580\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 13 Batch 146/390 d_loss_real= 0.601, d_loss_fake= 0.495, g_loss 0.979, d_loss 0.548\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 13 Batch 147/390 d_loss_real= 0.671, d_loss_fake= 0.486, g_loss 0.993, d_loss 0.578\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 148/390 d_loss_real= 0.639, d_loss_fake= 0.483, g_loss 0.993, d_loss 0.561\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 149/390 d_loss_real= 0.614, d_loss_fake= 0.480, g_loss 1.003, d_loss 0.547\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 150/390 d_loss_real= 0.576, d_loss_fake= 0.476, g_loss 1.010, d_loss 0.526\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 151/390 d_loss_real= 0.585, d_loss_fake= 0.470, g_loss 1.021, d_loss 0.527\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 13 Batch 152/390 d_loss_real= 0.569, d_loss_fake= 0.464, g_loss 1.034, d_loss 0.516\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 153/390 d_loss_real= 0.630, d_loss_fake= 0.457, g_loss 1.040, d_loss 0.543\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 13 Batch 154/390 d_loss_real= 0.611, d_loss_fake= 0.455, g_loss 1.048, d_loss 0.533\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 155/390 d_loss_real= 0.548, d_loss_fake= 0.442, g_loss 1.059, d_loss 0.495\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 156/390 d_loss_real= 0.523, d_loss_fake= 0.443, g_loss 1.070, d_loss 0.483\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 13 Batch 157/390 d_loss_real= 0.545, d_loss_fake= 0.435, g_loss 1.067, d_loss 0.490\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 13 Batch 158/390 d_loss_real= 0.556, d_loss_fake= 0.437, g_loss 1.075, d_loss 0.496\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 159/390 d_loss_real= 0.536, d_loss_fake= 0.441, g_loss 1.060, d_loss 0.488\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 13 Batch 160/390 d_loss_real= 0.521, d_loss_fake= 0.448, g_loss 1.056, d_loss 0.485\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 161/390 d_loss_real= 0.449, d_loss_fake= 0.449, g_loss 1.062, d_loss 0.449\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 13 Batch 162/390 d_loss_real= 0.542, d_loss_fake= 0.456, g_loss 1.044, d_loss 0.499\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 13 Batch 163/390 d_loss_real= 0.476, d_loss_fake= 0.451, g_loss 1.050, d_loss 0.463\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 164/390 d_loss_real= 0.442, d_loss_fake= 0.450, g_loss 1.057, d_loss 0.446\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 165/390 d_loss_real= 0.439, d_loss_fake= 0.448, g_loss 1.053, d_loss 0.443\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 166/390 d_loss_real= 0.434, d_loss_fake= 0.442, g_loss 1.062, d_loss 0.438\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 167/390 d_loss_real= 0.456, d_loss_fake= 0.446, g_loss 1.051, d_loss 0.451\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 168/390 d_loss_real= 0.497, d_loss_fake= 0.457, g_loss 1.038, d_loss 0.477\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 169/390 d_loss_real= 0.452, d_loss_fake= 0.454, g_loss 1.034, d_loss 0.453\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 170/390 d_loss_real= 0.477, d_loss_fake= 0.463, g_loss 1.015, d_loss 0.470\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 13 Batch 171/390 d_loss_real= 0.420, d_loss_fake= 0.469, g_loss 1.008, d_loss 0.445\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 172/390 d_loss_real= 0.467, d_loss_fake= 0.485, g_loss 1.013, d_loss 0.476\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 173/390 d_loss_real= 0.385, d_loss_fake= 0.474, g_loss 1.020, d_loss 0.429\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 13 Batch 174/390 d_loss_real= 0.405, d_loss_fake= 0.466, g_loss 1.051, d_loss 0.436\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 13 Batch 175/390 d_loss_real= 0.448, d_loss_fake= 0.452, g_loss 1.063, d_loss 0.450\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 13 Batch 176/390 d_loss_real= 0.408, d_loss_fake= 0.433, g_loss 1.103, d_loss 0.421\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 13 Batch 177/390 d_loss_real= 0.422, d_loss_fake= 0.416, g_loss 1.126, d_loss 0.419\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 178/390 d_loss_real= 0.507, d_loss_fake= 0.404, g_loss 1.150, d_loss 0.455\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 179/390 d_loss_real= 0.447, d_loss_fake= 0.390, g_loss 1.167, d_loss 0.419\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 180/390 d_loss_real= 0.440, d_loss_fake= 0.383, g_loss 1.188, d_loss 0.412\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 13 Batch 181/390 d_loss_real= 0.416, d_loss_fake= 0.374, g_loss 1.207, d_loss 0.395\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 182/390 d_loss_real= 0.520, d_loss_fake= 0.365, g_loss 1.216, d_loss 0.442\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 183/390 d_loss_real= 0.436, d_loss_fake= 0.369, g_loss 1.233, d_loss 0.403\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 13 Batch 184/390 d_loss_real= 0.440, d_loss_fake= 0.362, g_loss 1.229, d_loss 0.401\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 185/390 d_loss_real= 0.472, d_loss_fake= 0.358, g_loss 1.251, d_loss 0.415\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 13 Batch 186/390 d_loss_real= 0.442, d_loss_fake= 0.356, g_loss 1.236, d_loss 0.399\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 13 Batch 187/390 d_loss_real= 0.502, d_loss_fake= 0.370, g_loss 1.224, d_loss 0.436\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 13 Batch 188/390 d_loss_real= 0.387, d_loss_fake= 0.378, g_loss 1.213, d_loss 0.382\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 13 Batch 189/390 d_loss_real= 0.433, d_loss_fake= 0.399, g_loss 1.180, d_loss 0.416\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 13 Batch 190/390 d_loss_real= 0.386, d_loss_fake= 0.402, g_loss 1.170, d_loss 0.394\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 191/390 d_loss_real= 0.489, d_loss_fake= 0.448, g_loss 1.122, d_loss 0.469\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 192/390 d_loss_real= 0.457, d_loss_fake= 0.457, g_loss 1.098, d_loss 0.457\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 13 Batch 193/390 d_loss_real= 0.374, d_loss_fake= 0.483, g_loss 1.075, d_loss 0.429\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 13 Batch 194/390 d_loss_real= 0.417, d_loss_fake= 0.480, g_loss 1.054, d_loss 0.448\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 195/390 d_loss_real= 0.451, d_loss_fake= 0.513, g_loss 0.998, d_loss 0.482\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 196/390 d_loss_real= 0.429, d_loss_fake= 0.551, g_loss 0.951, d_loss 0.490\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 13 Batch 197/390 d_loss_real= 0.478, d_loss_fake= 0.570, g_loss 0.889, d_loss 0.524\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 13 Batch 198/390 d_loss_real= 0.367, d_loss_fake= 0.598, g_loss 0.838, d_loss 0.482\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 199/390 d_loss_real= 0.434, d_loss_fake= 0.666, g_loss 0.818, d_loss 0.550\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 13 Batch 200/390 d_loss_real= 0.438, d_loss_fake= 0.669, g_loss 0.799, d_loss 0.553\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 13 Batch 201/390 d_loss_real= 0.347, d_loss_fake= 0.666, g_loss 0.782, d_loss 0.507\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 202/390 d_loss_real= 0.478, d_loss_fake= 0.654, g_loss 0.789, d_loss 0.566\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 13 Batch 203/390 d_loss_real= 0.377, d_loss_fake= 0.666, g_loss 0.758, d_loss 0.521\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 204/390 d_loss_real= 0.374, d_loss_fake= 0.681, g_loss 0.785, d_loss 0.527\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 205/390 d_loss_real= 0.412, d_loss_fake= 0.655, g_loss 0.808, d_loss 0.533\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 13 Batch 206/390 d_loss_real= 0.446, d_loss_fake= 0.657, g_loss 0.786, d_loss 0.552\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 13 Batch 207/390 d_loss_real= 0.379, d_loss_fake= 0.664, g_loss 0.796, d_loss 0.522\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 208/390 d_loss_real= 0.394, d_loss_fake= 0.647, g_loss 0.804, d_loss 0.520\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 209/390 d_loss_real= 0.245, d_loss_fake= 0.646, g_loss 0.803, d_loss 0.445\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 210/390 d_loss_real= 0.361, d_loss_fake= 0.627, g_loss 0.799, d_loss 0.494\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 211/390 d_loss_real= 0.356, d_loss_fake= 0.621, g_loss 0.809, d_loss 0.489\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 212/390 d_loss_real= 0.369, d_loss_fake= 0.630, g_loss 0.814, d_loss 0.500\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 213/390 d_loss_real= 0.370, d_loss_fake= 0.657, g_loss 0.797, d_loss 0.513\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 214/390 d_loss_real= 0.360, d_loss_fake= 0.670, g_loss 0.776, d_loss 0.515\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 13 Batch 215/390 d_loss_real= 0.349, d_loss_fake= 0.705, g_loss 0.748, d_loss 0.527\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 216/390 d_loss_real= 0.424, d_loss_fake= 0.765, g_loss 0.694, d_loss 0.594\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 217/390 d_loss_real= 0.390, d_loss_fake= 0.785, g_loss 0.693, d_loss 0.588\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 218/390 d_loss_real= 0.489, d_loss_fake= 0.813, g_loss 0.670, d_loss 0.651\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 219/390 d_loss_real= 0.451, d_loss_fake= 0.822, g_loss 0.652, d_loss 0.637\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 220/390 d_loss_real= 0.522, d_loss_fake= 0.880, g_loss 0.615, d_loss 0.701\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 13 Batch 221/390 d_loss_real= 0.559, d_loss_fake= 0.920, g_loss 0.598, d_loss 0.739\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 222/390 d_loss_real= 0.594, d_loss_fake= 0.908, g_loss 0.579, d_loss 0.751\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 13 Batch 223/390 d_loss_real= 0.633, d_loss_fake= 0.953, g_loss 0.561, d_loss 0.793\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 224/390 d_loss_real= 0.514, d_loss_fake= 0.962, g_loss 0.540, d_loss 0.738\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 225/390 d_loss_real= 0.559, d_loss_fake= 0.971, g_loss 0.536, d_loss 0.765\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 226/390 d_loss_real= 0.555, d_loss_fake= 0.984, g_loss 0.518, d_loss 0.770\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 13 Batch 227/390 d_loss_real= 0.597, d_loss_fake= 0.960, g_loss 0.529, d_loss 0.778\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 228/390 d_loss_real= 0.577, d_loss_fake= 0.961, g_loss 0.543, d_loss 0.769\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 229/390 d_loss_real= 0.584, d_loss_fake= 0.961, g_loss 0.552, d_loss 0.773\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 230/390 d_loss_real= 0.509, d_loss_fake= 0.945, g_loss 0.565, d_loss 0.727\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 13 Batch 231/390 d_loss_real= 0.465, d_loss_fake= 0.925, g_loss 0.577, d_loss 0.695\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 232/390 d_loss_real= 0.433, d_loss_fake= 0.863, g_loss 0.621, d_loss 0.648\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 13 Batch 233/390 d_loss_real= 0.450, d_loss_fake= 0.826, g_loss 0.656, d_loss 0.638\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 234/390 d_loss_real= 0.494, d_loss_fake= 0.787, g_loss 0.724, d_loss 0.641\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 235/390 d_loss_real= 0.493, d_loss_fake= 0.725, g_loss 0.774, d_loss 0.609\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 13 Batch 236/390 d_loss_real= 0.534, d_loss_fake= 0.709, g_loss 0.806, d_loss 0.621\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 237/390 d_loss_real= 0.473, d_loss_fake= 0.630, g_loss 0.854, d_loss 0.551\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 13 Batch 238/390 d_loss_real= 0.488, d_loss_fake= 0.609, g_loss 0.898, d_loss 0.548\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 13 Batch 239/390 d_loss_real= 0.451, d_loss_fake= 0.566, g_loss 0.918, d_loss 0.508\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 240/390 d_loss_real= 0.441, d_loss_fake= 0.515, g_loss 0.940, d_loss 0.478\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 13 Batch 241/390 d_loss_real= 0.496, d_loss_fake= 0.535, g_loss 0.953, d_loss 0.516\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 13 Batch 242/390 d_loss_real= 0.403, d_loss_fake= 0.515, g_loss 0.957, d_loss 0.459\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 243/390 d_loss_real= 0.433, d_loss_fake= 0.556, g_loss 0.948, d_loss 0.494\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 244/390 d_loss_real= 0.504, d_loss_fake= 0.540, g_loss 0.951, d_loss 0.522\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 245/390 d_loss_real= 0.504, d_loss_fake= 0.559, g_loss 0.950, d_loss 0.531\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 246/390 d_loss_real= 0.372, d_loss_fake= 0.530, g_loss 0.980, d_loss 0.451\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 247/390 d_loss_real= 0.392, d_loss_fake= 0.517, g_loss 1.022, d_loss 0.455\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 248/390 d_loss_real= 0.407, d_loss_fake= 0.498, g_loss 1.055, d_loss 0.452\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 249/390 d_loss_real= 0.392, d_loss_fake= 0.472, g_loss 1.082, d_loss 0.432\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 250/390 d_loss_real= 0.512, d_loss_fake= 0.460, g_loss 1.093, d_loss 0.486\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 13 Batch 251/390 d_loss_real= 0.525, d_loss_fake= 0.449, g_loss 1.118, d_loss 0.487\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 252/390 d_loss_real= 0.546, d_loss_fake= 0.427, g_loss 1.124, d_loss 0.487\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 253/390 d_loss_real= 0.355, d_loss_fake= 0.433, g_loss 1.111, d_loss 0.394\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 13 Batch 254/390 d_loss_real= 0.453, d_loss_fake= 0.429, g_loss 1.104, d_loss 0.441\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 255/390 d_loss_real= 0.563, d_loss_fake= 0.459, g_loss 1.078, d_loss 0.511\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 256/390 d_loss_real= 0.510, d_loss_fake= 0.479, g_loss 1.048, d_loss 0.495\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 257/390 d_loss_real= 0.530, d_loss_fake= 0.495, g_loss 1.006, d_loss 0.513\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 258/390 d_loss_real= 0.378, d_loss_fake= 0.520, g_loss 0.960, d_loss 0.449\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 259/390 d_loss_real= 0.373, d_loss_fake= 0.531, g_loss 0.975, d_loss 0.452\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 13 Batch 260/390 d_loss_real= 0.409, d_loss_fake= 0.518, g_loss 1.017, d_loss 0.464\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 13 Batch 261/390 d_loss_real= 0.505, d_loss_fake= 0.514, g_loss 1.031, d_loss 0.510\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 13 Batch 262/390 d_loss_real= 0.573, d_loss_fake= 0.535, g_loss 0.988, d_loss 0.554\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 13 Batch 263/390 d_loss_real= 0.577, d_loss_fake= 0.576, g_loss 0.956, d_loss 0.577\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 264/390 d_loss_real= 0.714, d_loss_fake= 0.605, g_loss 0.910, d_loss 0.660\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 13 Batch 265/390 d_loss_real= 0.570, d_loss_fake= 0.646, g_loss 0.872, d_loss 0.608\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 13 Batch 266/390 d_loss_real= 0.770, d_loss_fake= 0.749, g_loss 0.801, d_loss 0.759\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 267/390 d_loss_real= 0.668, d_loss_fake= 0.802, g_loss 0.770, d_loss 0.735\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 268/390 d_loss_real= 0.775, d_loss_fake= 0.783, g_loss 0.790, d_loss 0.779\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 13 Batch 269/390 d_loss_real= 0.839, d_loss_fake= 0.769, g_loss 0.788, d_loss 0.804\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 13 Batch 270/390 d_loss_real= 1.110, d_loss_fake= 0.764, g_loss 0.802, d_loss 0.937\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 13 Batch 271/390 d_loss_real= 0.953, d_loss_fake= 0.697, g_loss 0.849, d_loss 0.825\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 13 Batch 272/390 d_loss_real= 0.920, d_loss_fake= 0.659, g_loss 0.852, d_loss 0.789\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 13 Batch 273/390 d_loss_real= 0.690, d_loss_fake= 0.678, g_loss 0.864, d_loss 0.684\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 274/390 d_loss_real= 0.732, d_loss_fake= 0.668, g_loss 0.855, d_loss 0.700\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 13 Batch 275/390 d_loss_real= 0.913, d_loss_fake= 0.666, g_loss 0.864, d_loss 0.789\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 13 Batch 276/390 d_loss_real= 0.628, d_loss_fake= 0.710, g_loss 0.794, d_loss 0.669\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 277/390 d_loss_real= 0.718, d_loss_fake= 0.735, g_loss 0.719, d_loss 0.726\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 278/390 d_loss_real= 0.729, d_loss_fake= 0.839, g_loss 0.660, d_loss 0.784\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 279/390 d_loss_real= 0.677, d_loss_fake= 0.893, g_loss 0.649, d_loss 0.785\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 280/390 d_loss_real= 0.600, d_loss_fake= 0.925, g_loss 0.642, d_loss 0.762\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 13 Batch 281/390 d_loss_real= 0.624, d_loss_fake= 0.861, g_loss 0.642, d_loss 0.742\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 282/390 d_loss_real= 0.597, d_loss_fake= 0.879, g_loss 0.676, d_loss 0.738\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 13 Batch 283/390 d_loss_real= 0.800, d_loss_fake= 0.841, g_loss 0.669, d_loss 0.820\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 13 Batch 284/390 d_loss_real= 0.654, d_loss_fake= 0.848, g_loss 0.669, d_loss 0.751\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 285/390 d_loss_real= 0.711, d_loss_fake= 0.882, g_loss 0.659, d_loss 0.797\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 286/390 d_loss_real= 0.798, d_loss_fake= 0.856, g_loss 0.651, d_loss 0.827\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 13 Batch 287/390 d_loss_real= 0.781, d_loss_fake= 0.887, g_loss 0.628, d_loss 0.834\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 13 Batch 288/390 d_loss_real= 0.799, d_loss_fake= 0.868, g_loss 0.621, d_loss 0.834\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 13 Batch 289/390 d_loss_real= 0.824, d_loss_fake= 0.880, g_loss 0.608, d_loss 0.852\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 13 Batch 290/390 d_loss_real= 0.985, d_loss_fake= 0.878, g_loss 0.595, d_loss 0.931\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 13 Batch 291/390 d_loss_real= 0.933, d_loss_fake= 0.905, g_loss 0.575, d_loss 0.919\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 292/390 d_loss_real= 0.885, d_loss_fake= 0.967, g_loss 0.556, d_loss 0.926\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 293/390 d_loss_real= 0.960, d_loss_fake= 0.955, g_loss 0.557, d_loss 0.958\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 294/390 d_loss_real= 0.813, d_loss_fake= 0.965, g_loss 0.559, d_loss 0.889\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 295/390 d_loss_real= 0.890, d_loss_fake= 0.918, g_loss 0.579, d_loss 0.904\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 296/390 d_loss_real= 0.892, d_loss_fake= 0.866, g_loss 0.609, d_loss 0.879\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 13 Batch 297/390 d_loss_real= 0.760, d_loss_fake= 0.823, g_loss 0.660, d_loss 0.792\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 298/390 d_loss_real= 1.006, d_loss_fake= 0.763, g_loss 0.685, d_loss 0.884\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 299/390 d_loss_real= 0.778, d_loss_fake= 0.715, g_loss 0.733, d_loss 0.746\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 300/390 d_loss_real= 0.903, d_loss_fake= 0.686, g_loss 0.759, d_loss 0.795\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 13 Batch 301/390 d_loss_real= 0.874, d_loss_fake= 0.677, g_loss 0.761, d_loss 0.775\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 302/390 d_loss_real= 0.846, d_loss_fake= 0.681, g_loss 0.755, d_loss 0.763\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 13 Batch 303/390 d_loss_real= 0.725, d_loss_fake= 0.679, g_loss 0.741, d_loss 0.702\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 304/390 d_loss_real= 0.795, d_loss_fake= 0.675, g_loss 0.741, d_loss 0.735\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 305/390 d_loss_real= 0.744, d_loss_fake= 0.699, g_loss 0.731, d_loss 0.722\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 13 Batch 306/390 d_loss_real= 0.580, d_loss_fake= 0.682, g_loss 0.732, d_loss 0.631\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 307/390 d_loss_real= 0.716, d_loss_fake= 0.685, g_loss 0.742, d_loss 0.701\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 13 Batch 308/390 d_loss_real= 0.691, d_loss_fake= 0.679, g_loss 0.750, d_loss 0.685\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 13 Batch 309/390 d_loss_real= 0.641, d_loss_fake= 0.673, g_loss 0.776, d_loss 0.657\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 13 Batch 310/390 d_loss_real= 0.615, d_loss_fake= 0.666, g_loss 0.785, d_loss 0.641\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 13 Batch 311/390 d_loss_real= 0.596, d_loss_fake= 0.638, g_loss 0.799, d_loss 0.617\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 312/390 d_loss_real= 0.674, d_loss_fake= 0.629, g_loss 0.818, d_loss 0.651\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 13 Batch 313/390 d_loss_real= 0.705, d_loss_fake= 0.616, g_loss 0.833, d_loss 0.661\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 314/390 d_loss_real= 0.730, d_loss_fake= 0.610, g_loss 0.840, d_loss 0.670\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 315/390 d_loss_real= 0.699, d_loss_fake= 0.589, g_loss 0.859, d_loss 0.644\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 316/390 d_loss_real= 0.703, d_loss_fake= 0.586, g_loss 0.854, d_loss 0.644\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 317/390 d_loss_real= 0.672, d_loss_fake= 0.596, g_loss 0.842, d_loss 0.634\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 318/390 d_loss_real= 0.615, d_loss_fake= 0.592, g_loss 0.835, d_loss 0.604\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 13 Batch 319/390 d_loss_real= 0.648, d_loss_fake= 0.601, g_loss 0.827, d_loss 0.624\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 320/390 d_loss_real= 0.636, d_loss_fake= 0.621, g_loss 0.816, d_loss 0.629\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 321/390 d_loss_real= 0.671, d_loss_fake= 0.611, g_loss 0.837, d_loss 0.641\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 322/390 d_loss_real= 0.563, d_loss_fake= 0.596, g_loss 0.839, d_loss 0.579\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 323/390 d_loss_real= 0.679, d_loss_fake= 0.586, g_loss 0.855, d_loss 0.633\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 324/390 d_loss_real= 0.678, d_loss_fake= 0.566, g_loss 0.883, d_loss 0.622\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 325/390 d_loss_real= 0.590, d_loss_fake= 0.561, g_loss 0.884, d_loss 0.576\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 326/390 d_loss_real= 0.569, d_loss_fake= 0.562, g_loss 0.891, d_loss 0.565\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 327/390 d_loss_real= 0.547, d_loss_fake= 0.553, g_loss 0.908, d_loss 0.550\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 328/390 d_loss_real= 0.632, d_loss_fake= 0.547, g_loss 0.902, d_loss 0.589\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 13 Batch 329/390 d_loss_real= 0.561, d_loss_fake= 0.547, g_loss 0.909, d_loss 0.554\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 330/390 d_loss_real= 0.599, d_loss_fake= 0.543, g_loss 0.909, d_loss 0.571\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 13 Batch 331/390 d_loss_real= 0.525, d_loss_fake= 0.541, g_loss 0.917, d_loss 0.533\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 13 Batch 332/390 d_loss_real= 0.588, d_loss_fake= 0.535, g_loss 0.924, d_loss 0.562\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 13 Batch 333/390 d_loss_real= 0.632, d_loss_fake= 0.538, g_loss 0.922, d_loss 0.585\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 13 Batch 334/390 d_loss_real= 0.564, d_loss_fake= 0.535, g_loss 0.922, d_loss 0.550\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 13 Batch 335/390 d_loss_real= 0.605, d_loss_fake= 0.536, g_loss 0.924, d_loss 0.570\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 336/390 d_loss_real= 0.478, d_loss_fake= 0.539, g_loss 0.928, d_loss 0.508\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 337/390 d_loss_real= 0.547, d_loss_fake= 0.537, g_loss 0.924, d_loss 0.542\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 13 Batch 338/390 d_loss_real= 0.556, d_loss_fake= 0.530, g_loss 0.933, d_loss 0.543\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 339/390 d_loss_real= 0.559, d_loss_fake= 0.526, g_loss 0.935, d_loss 0.542\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 340/390 d_loss_real= 0.539, d_loss_fake= 0.527, g_loss 0.942, d_loss 0.533\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 341/390 d_loss_real= 0.564, d_loss_fake= 0.532, g_loss 0.945, d_loss 0.548\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 13 Batch 342/390 d_loss_real= 0.585, d_loss_fake= 0.522, g_loss 0.950, d_loss 0.554\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 343/390 d_loss_real= 0.565, d_loss_fake= 0.511, g_loss 0.946, d_loss 0.538\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 13 Batch 344/390 d_loss_real= 0.520, d_loss_fake= 0.520, g_loss 0.955, d_loss 0.520\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 345/390 d_loss_real= 0.487, d_loss_fake= 0.514, g_loss 0.954, d_loss 0.501\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 13 Batch 346/390 d_loss_real= 0.613, d_loss_fake= 0.507, g_loss 0.962, d_loss 0.560\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 347/390 d_loss_real= 0.515, d_loss_fake= 0.504, g_loss 0.958, d_loss 0.509\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 348/390 d_loss_real= 0.430, d_loss_fake= 0.509, g_loss 0.967, d_loss 0.470\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 13 Batch 349/390 d_loss_real= 0.511, d_loss_fake= 0.498, g_loss 0.984, d_loss 0.505\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 350/390 d_loss_real= 0.540, d_loss_fake= 0.496, g_loss 0.988, d_loss 0.518\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 13 Batch 351/390 d_loss_real= 0.517, d_loss_fake= 0.484, g_loss 0.994, d_loss 0.500\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 352/390 d_loss_real= 0.452, d_loss_fake= 0.483, g_loss 0.993, d_loss 0.468\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 353/390 d_loss_real= 0.484, d_loss_fake= 0.473, g_loss 1.014, d_loss 0.478\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 13 Batch 354/390 d_loss_real= 0.524, d_loss_fake= 0.469, g_loss 1.017, d_loss 0.496\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 13 Batch 355/390 d_loss_real= 0.479, d_loss_fake= 0.459, g_loss 1.035, d_loss 0.469\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 13 Batch 356/390 d_loss_real= 0.475, d_loss_fake= 0.458, g_loss 1.037, d_loss 0.466\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 357/390 d_loss_real= 0.483, d_loss_fake= 0.464, g_loss 1.032, d_loss 0.474\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 13 Batch 358/390 d_loss_real= 0.473, d_loss_fake= 0.464, g_loss 1.028, d_loss 0.468\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 13 Batch 359/390 d_loss_real= 0.588, d_loss_fake= 0.476, g_loss 1.031, d_loss 0.532\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 360/390 d_loss_real= 0.481, d_loss_fake= 0.465, g_loss 1.029, d_loss 0.473\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 361/390 d_loss_real= 0.473, d_loss_fake= 0.462, g_loss 1.049, d_loss 0.468\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 13 Batch 362/390 d_loss_real= 0.365, d_loss_fake= 0.453, g_loss 1.070, d_loss 0.409\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 363/390 d_loss_real= 0.540, d_loss_fake= 0.430, g_loss 1.087, d_loss 0.485\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 364/390 d_loss_real= 0.422, d_loss_fake= 0.423, g_loss 1.115, d_loss 0.422\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 13 Batch 365/390 d_loss_real= 0.433, d_loss_fake= 0.412, g_loss 1.119, d_loss 0.422\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 366/390 d_loss_real= 0.428, d_loss_fake= 0.414, g_loss 1.142, d_loss 0.421\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 13 Batch 367/390 d_loss_real= 0.414, d_loss_fake= 0.411, g_loss 1.119, d_loss 0.412\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 368/390 d_loss_real= 0.413, d_loss_fake= 0.410, g_loss 1.125, d_loss 0.412\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 13 Batch 369/390 d_loss_real= 0.367, d_loss_fake= 0.416, g_loss 1.111, d_loss 0.391\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 13 Batch 370/390 d_loss_real= 0.398, d_loss_fake= 0.446, g_loss 1.110, d_loss 0.422\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 371/390 d_loss_real= 0.390, d_loss_fake= 0.447, g_loss 1.090, d_loss 0.419\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 13 Batch 372/390 d_loss_real= 0.416, d_loss_fake= 0.462, g_loss 1.084, d_loss 0.439\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 373/390 d_loss_real= 0.410, d_loss_fake= 0.464, g_loss 1.023, d_loss 0.437\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 13 Batch 374/390 d_loss_real= 0.484, d_loss_fake= 0.481, g_loss 1.028, d_loss 0.483\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 13 Batch 375/390 d_loss_real= 0.391, d_loss_fake= 0.511, g_loss 1.003, d_loss 0.451\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 376/390 d_loss_real= 0.492, d_loss_fake= 0.520, g_loss 0.989, d_loss 0.506\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 13 Batch 377/390 d_loss_real= 0.495, d_loss_fake= 0.523, g_loss 0.944, d_loss 0.509\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 378/390 d_loss_real= 0.480, d_loss_fake= 0.548, g_loss 0.969, d_loss 0.514\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 379/390 d_loss_real= 0.515, d_loss_fake= 0.522, g_loss 0.942, d_loss 0.519\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 380/390 d_loss_real= 0.493, d_loss_fake= 0.525, g_loss 0.969, d_loss 0.509\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 13 Batch 381/390 d_loss_real= 0.564, d_loss_fake= 0.524, g_loss 0.980, d_loss 0.544\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 13 Batch 382/390 d_loss_real= 0.596, d_loss_fake= 0.522, g_loss 0.974, d_loss 0.559\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 13 Batch 383/390 d_loss_real= 0.458, d_loss_fake= 0.560, g_loss 0.956, d_loss 0.509\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 384/390 d_loss_real= 0.517, d_loss_fake= 0.555, g_loss 0.945, d_loss 0.536\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 385/390 d_loss_real= 0.614, d_loss_fake= 0.545, g_loss 0.929, d_loss 0.580\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 13 Batch 386/390 d_loss_real= 0.458, d_loss_fake= 0.558, g_loss 0.926, d_loss 0.508\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 13 Batch 387/390 d_loss_real= 0.470, d_loss_fake= 0.558, g_loss 0.934, d_loss 0.514\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13 Batch 388/390 d_loss_real= 0.471, d_loss_fake= 0.532, g_loss 0.950, d_loss 0.502\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13 Batch 389/390 d_loss_real= 0.480, d_loss_fake= 0.520, g_loss 0.951, d_loss 0.500\n",
            "2/2 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13 Batch 390/390 d_loss_real= 0.505, d_loss_fake= 0.549, g_loss 0.948, d_loss 0.527\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 14 Batch 1/390 d_loss_real= 0.458, d_loss_fake= 0.542, g_loss 0.940, d_loss 0.500\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 2/390 d_loss_real= 0.535, d_loss_fake= 0.536, g_loss 0.954, d_loss 0.536\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 14 Batch 3/390 d_loss_real= 0.523, d_loss_fake= 0.523, g_loss 0.957, d_loss 0.523\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 4/390 d_loss_real= 0.625, d_loss_fake= 0.527, g_loss 0.949, d_loss 0.576\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 5/390 d_loss_real= 0.584, d_loss_fake= 0.530, g_loss 0.945, d_loss 0.557\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 14 Batch 6/390 d_loss_real= 0.607, d_loss_fake= 0.526, g_loss 0.938, d_loss 0.566\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 7/390 d_loss_real= 0.486, d_loss_fake= 0.520, g_loss 0.953, d_loss 0.503\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 8/390 d_loss_real= 0.500, d_loss_fake= 0.535, g_loss 0.954, d_loss 0.518\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 9/390 d_loss_real= 0.577, d_loss_fake= 0.528, g_loss 0.964, d_loss 0.552\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 14 Batch 10/390 d_loss_real= 0.496, d_loss_fake= 0.524, g_loss 0.950, d_loss 0.510\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 11/390 d_loss_real= 0.500, d_loss_fake= 0.555, g_loss 0.941, d_loss 0.527\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 14 Batch 12/390 d_loss_real= 0.481, d_loss_fake= 0.568, g_loss 0.910, d_loss 0.525\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 13/390 d_loss_real= 0.416, d_loss_fake= 0.569, g_loss 0.909, d_loss 0.492\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 14/390 d_loss_real= 0.525, d_loss_fake= 0.549, g_loss 0.884, d_loss 0.537\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 15/390 d_loss_real= 0.529, d_loss_fake= 0.590, g_loss 0.857, d_loss 0.559\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 16/390 d_loss_real= 0.545, d_loss_fake= 0.628, g_loss 0.829, d_loss 0.586\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 14 Batch 17/390 d_loss_real= 0.513, d_loss_fake= 0.616, g_loss 0.832, d_loss 0.565\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 18/390 d_loss_real= 0.539, d_loss_fake= 0.626, g_loss 0.829, d_loss 0.583\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 19/390 d_loss_real= 0.521, d_loss_fake= 0.654, g_loss 0.775, d_loss 0.588\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 20/390 d_loss_real= 0.579, d_loss_fake= 0.643, g_loss 0.798, d_loss 0.611\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 21/390 d_loss_real= 0.458, d_loss_fake= 0.681, g_loss 0.767, d_loss 0.569\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 22/390 d_loss_real= 0.486, d_loss_fake= 0.647, g_loss 0.779, d_loss 0.566\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 14 Batch 23/390 d_loss_real= 0.630, d_loss_fake= 0.715, g_loss 0.781, d_loss 0.673\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 14 Batch 24/390 d_loss_real= 0.566, d_loss_fake= 0.654, g_loss 0.808, d_loss 0.610\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 25/390 d_loss_real= 0.472, d_loss_fake= 0.672, g_loss 0.806, d_loss 0.572\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 26/390 d_loss_real= 0.541, d_loss_fake= 0.646, g_loss 0.812, d_loss 0.593\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 14 Batch 27/390 d_loss_real= 0.582, d_loss_fake= 0.626, g_loss 0.826, d_loss 0.604\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 28/390 d_loss_real= 0.578, d_loss_fake= 0.636, g_loss 0.848, d_loss 0.607\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 29/390 d_loss_real= 0.474, d_loss_fake= 0.651, g_loss 0.780, d_loss 0.562\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 30/390 d_loss_real= 0.445, d_loss_fake= 0.689, g_loss 0.803, d_loss 0.567\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 31/390 d_loss_real= 0.385, d_loss_fake= 0.703, g_loss 0.796, d_loss 0.544\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 14 Batch 32/390 d_loss_real= 0.488, d_loss_fake= 0.680, g_loss 0.782, d_loss 0.584\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 33/390 d_loss_real= 0.637, d_loss_fake= 0.708, g_loss 0.775, d_loss 0.673\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 14 Batch 34/390 d_loss_real= 0.613, d_loss_fake= 0.714, g_loss 0.755, d_loss 0.664\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 14 Batch 35/390 d_loss_real= 0.503, d_loss_fake= 0.745, g_loss 0.758, d_loss 0.624\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 36/390 d_loss_real= 0.572, d_loss_fake= 0.744, g_loss 0.674, d_loss 0.658\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 14 Batch 37/390 d_loss_real= 0.489, d_loss_fake= 0.765, g_loss 0.705, d_loss 0.627\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 38/390 d_loss_real= 0.498, d_loss_fake= 0.759, g_loss 0.746, d_loss 0.628\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 39/390 d_loss_real= 0.620, d_loss_fake= 0.814, g_loss 0.716, d_loss 0.717\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 14 Batch 40/390 d_loss_real= 0.621, d_loss_fake= 0.797, g_loss 0.702, d_loss 0.709\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 14 Batch 41/390 d_loss_real= 0.679, d_loss_fake= 0.793, g_loss 0.678, d_loss 0.736\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 14 Batch 42/390 d_loss_real= 0.628, d_loss_fake= 0.832, g_loss 0.661, d_loss 0.730\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 14 Batch 43/390 d_loss_real= 0.842, d_loss_fake= 0.913, g_loss 0.637, d_loss 0.878\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 14 Batch 44/390 d_loss_real= 0.650, d_loss_fake= 0.966, g_loss 0.576, d_loss 0.808\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 14 Batch 45/390 d_loss_real= 0.774, d_loss_fake= 0.913, g_loss 0.591, d_loss 0.843\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 46/390 d_loss_real= 0.663, d_loss_fake= 0.903, g_loss 0.591, d_loss 0.783\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 47/390 d_loss_real= 0.697, d_loss_fake= 0.867, g_loss 0.629, d_loss 0.782\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 48/390 d_loss_real= 0.810, d_loss_fake= 0.812, g_loss 0.657, d_loss 0.811\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 49/390 d_loss_real= 0.889, d_loss_fake= 0.755, g_loss 0.715, d_loss 0.822\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 50/390 d_loss_real= 0.746, d_loss_fake= 0.726, g_loss 0.731, d_loss 0.736\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 51/390 d_loss_real= 0.719, d_loss_fake= 0.724, g_loss 0.746, d_loss 0.721\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 52/390 d_loss_real= 0.770, d_loss_fake= 0.699, g_loss 0.759, d_loss 0.735\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 53/390 d_loss_real= 0.705, d_loss_fake= 0.658, g_loss 0.788, d_loss 0.682\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 54/390 d_loss_real= 0.672, d_loss_fake= 0.654, g_loss 0.814, d_loss 0.663\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 55/390 d_loss_real= 0.764, d_loss_fake= 0.627, g_loss 0.806, d_loss 0.696\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 14 Batch 56/390 d_loss_real= 0.673, d_loss_fake= 0.629, g_loss 0.796, d_loss 0.651\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 57/390 d_loss_real= 0.692, d_loss_fake= 0.597, g_loss 0.803, d_loss 0.645\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 58/390 d_loss_real= 0.605, d_loss_fake= 0.640, g_loss 0.804, d_loss 0.622\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 14 Batch 59/390 d_loss_real= 0.618, d_loss_fake= 0.651, g_loss 0.817, d_loss 0.635\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 60/390 d_loss_real= 0.429, d_loss_fake= 0.615, g_loss 0.851, d_loss 0.522\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 14 Batch 61/390 d_loss_real= 0.504, d_loss_fake= 0.580, g_loss 0.879, d_loss 0.542\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 62/390 d_loss_real= 0.622, d_loss_fake= 0.549, g_loss 0.920, d_loss 0.585\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 14 Batch 63/390 d_loss_real= 0.571, d_loss_fake= 0.583, g_loss 0.970, d_loss 0.577\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 64/390 d_loss_real= 0.640, d_loss_fake= 0.503, g_loss 1.007, d_loss 0.572\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 65/390 d_loss_real= 0.537, d_loss_fake= 0.503, g_loss 1.026, d_loss 0.520\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 66/390 d_loss_real= 0.631, d_loss_fake= 0.472, g_loss 1.015, d_loss 0.551\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 67/390 d_loss_real= 0.581, d_loss_fake= 0.478, g_loss 0.998, d_loss 0.530\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 68/390 d_loss_real= 0.478, d_loss_fake= 0.520, g_loss 0.990, d_loss 0.499\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 69/390 d_loss_real= 0.581, d_loss_fake= 0.515, g_loss 0.999, d_loss 0.548\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 70/390 d_loss_real= 0.536, d_loss_fake= 0.511, g_loss 0.958, d_loss 0.524\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 71/390 d_loss_real= 0.475, d_loss_fake= 0.504, g_loss 0.948, d_loss 0.490\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 14 Batch 72/390 d_loss_real= 0.370, d_loss_fake= 0.524, g_loss 0.947, d_loss 0.447\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 73/390 d_loss_real= 0.595, d_loss_fake= 0.530, g_loss 0.957, d_loss 0.563\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 14 Batch 74/390 d_loss_real= 0.421, d_loss_fake= 0.544, g_loss 0.969, d_loss 0.482\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 75/390 d_loss_real= 0.511, d_loss_fake= 0.512, g_loss 0.941, d_loss 0.511\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 14 Batch 76/390 d_loss_real= 0.483, d_loss_fake= 0.519, g_loss 0.953, d_loss 0.501\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 77/390 d_loss_real= 0.476, d_loss_fake= 0.551, g_loss 0.940, d_loss 0.513\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 14 Batch 78/390 d_loss_real= 0.476, d_loss_fake= 0.527, g_loss 0.912, d_loss 0.502\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 79/390 d_loss_real= 0.534, d_loss_fake= 0.575, g_loss 0.930, d_loss 0.554\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 80/390 d_loss_real= 0.428, d_loss_fake= 0.566, g_loss 0.878, d_loss 0.497\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 14 Batch 81/390 d_loss_real= 0.565, d_loss_fake= 0.592, g_loss 0.920, d_loss 0.579\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 82/390 d_loss_real= 0.463, d_loss_fake= 0.639, g_loss 0.909, d_loss 0.551\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 14 Batch 83/390 d_loss_real= 0.496, d_loss_fake= 0.577, g_loss 0.879, d_loss 0.536\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 84/390 d_loss_real= 0.503, d_loss_fake= 0.565, g_loss 0.868, d_loss 0.534\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 14 Batch 85/390 d_loss_real= 0.584, d_loss_fake= 0.597, g_loss 0.892, d_loss 0.591\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 14 Batch 86/390 d_loss_real= 0.644, d_loss_fake= 0.645, g_loss 0.851, d_loss 0.645\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 14 Batch 87/390 d_loss_real= 0.470, d_loss_fake= 0.613, g_loss 0.837, d_loss 0.542\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 88/390 d_loss_real= 0.608, d_loss_fake= 0.661, g_loss 0.811, d_loss 0.635\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 89/390 d_loss_real= 0.541, d_loss_fake= 0.612, g_loss 0.827, d_loss 0.576\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 14 Batch 90/390 d_loss_real= 0.605, d_loss_fake= 0.652, g_loss 0.785, d_loss 0.628\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 91/390 d_loss_real= 0.544, d_loss_fake= 0.644, g_loss 0.787, d_loss 0.594\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 14 Batch 92/390 d_loss_real= 0.576, d_loss_fake= 0.624, g_loss 0.806, d_loss 0.600\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 14 Batch 93/390 d_loss_real= 0.491, d_loss_fake= 0.636, g_loss 0.790, d_loss 0.563\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 14 Batch 94/390 d_loss_real= 0.544, d_loss_fake= 0.640, g_loss 0.806, d_loss 0.592\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 95/390 d_loss_real= 0.535, d_loss_fake= 0.650, g_loss 0.786, d_loss 0.592\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 14 Batch 96/390 d_loss_real= 0.571, d_loss_fake= 0.660, g_loss 0.775, d_loss 0.616\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 97/390 d_loss_real= 0.624, d_loss_fake= 0.665, g_loss 0.780, d_loss 0.645\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 98/390 d_loss_real= 0.560, d_loss_fake= 0.658, g_loss 0.809, d_loss 0.609\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 14 Batch 99/390 d_loss_real= 0.623, d_loss_fake= 0.681, g_loss 0.784, d_loss 0.652\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 100/390 d_loss_real= 0.651, d_loss_fake= 0.631, g_loss 0.807, d_loss 0.641\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 14 Batch 101/390 d_loss_real= 0.625, d_loss_fake= 0.647, g_loss 0.799, d_loss 0.636\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 102/390 d_loss_real= 0.665, d_loss_fake= 0.637, g_loss 0.811, d_loss 0.651\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 103/390 d_loss_real= 0.607, d_loss_fake= 0.630, g_loss 0.795, d_loss 0.618\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 14 Batch 104/390 d_loss_real= 0.573, d_loss_fake= 0.635, g_loss 0.798, d_loss 0.604\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 105/390 d_loss_real= 0.588, d_loss_fake= 0.634, g_loss 0.802, d_loss 0.611\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 106/390 d_loss_real= 0.601, d_loss_fake= 0.629, g_loss 0.794, d_loss 0.615\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 14 Batch 107/390 d_loss_real= 0.559, d_loss_fake= 0.616, g_loss 0.798, d_loss 0.588\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 108/390 d_loss_real= 0.568, d_loss_fake= 0.615, g_loss 0.814, d_loss 0.592\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 109/390 d_loss_real= 0.563, d_loss_fake= 0.623, g_loss 0.841, d_loss 0.593\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 110/390 d_loss_real= 0.651, d_loss_fake= 0.620, g_loss 0.808, d_loss 0.635\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 111/390 d_loss_real= 0.532, d_loss_fake= 0.619, g_loss 0.814, d_loss 0.575\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 112/390 d_loss_real= 0.576, d_loss_fake= 0.635, g_loss 0.779, d_loss 0.605\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 14 Batch 113/390 d_loss_real= 0.573, d_loss_fake= 0.648, g_loss 0.775, d_loss 0.610\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 114/390 d_loss_real= 0.608, d_loss_fake= 0.641, g_loss 0.778, d_loss 0.625\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 115/390 d_loss_real= 0.487, d_loss_fake= 0.648, g_loss 0.789, d_loss 0.568\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 116/390 d_loss_real= 0.591, d_loss_fake= 0.662, g_loss 0.814, d_loss 0.626\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 117/390 d_loss_real= 0.585, d_loss_fake= 0.620, g_loss 0.813, d_loss 0.602\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 118/390 d_loss_real= 0.576, d_loss_fake= 0.619, g_loss 0.809, d_loss 0.598\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 14 Batch 119/390 d_loss_real= 0.625, d_loss_fake= 0.615, g_loss 0.812, d_loss 0.620\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 120/390 d_loss_real= 0.625, d_loss_fake= 0.654, g_loss 0.784, d_loss 0.640\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 14 Batch 121/390 d_loss_real= 0.560, d_loss_fake= 0.677, g_loss 0.773, d_loss 0.619\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 122/390 d_loss_real= 0.619, d_loss_fake= 0.693, g_loss 0.759, d_loss 0.656\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 123/390 d_loss_real= 0.618, d_loss_fake= 0.689, g_loss 0.729, d_loss 0.653\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 14 Batch 124/390 d_loss_real= 0.647, d_loss_fake= 0.706, g_loss 0.687, d_loss 0.676\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 125/390 d_loss_real= 0.581, d_loss_fake= 0.768, g_loss 0.713, d_loss 0.675\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 14 Batch 126/390 d_loss_real= 0.569, d_loss_fake= 0.705, g_loss 0.692, d_loss 0.637\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 14 Batch 127/390 d_loss_real= 0.570, d_loss_fake= 0.762, g_loss 0.713, d_loss 0.666\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 128/390 d_loss_real= 0.610, d_loss_fake= 0.728, g_loss 0.755, d_loss 0.669\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 14 Batch 129/390 d_loss_real= 0.811, d_loss_fake= 0.718, g_loss 0.747, d_loss 0.765\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 130/390 d_loss_real= 0.701, d_loss_fake= 0.741, g_loss 0.716, d_loss 0.721\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 131/390 d_loss_real= 0.689, d_loss_fake= 0.758, g_loss 0.720, d_loss 0.724\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 14 Batch 132/390 d_loss_real= 0.601, d_loss_fake= 0.750, g_loss 0.728, d_loss 0.675\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 133/390 d_loss_real= 0.645, d_loss_fake= 0.733, g_loss 0.708, d_loss 0.689\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 14 Batch 134/390 d_loss_real= 0.713, d_loss_fake= 0.722, g_loss 0.720, d_loss 0.718\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 135/390 d_loss_real= 0.599, d_loss_fake= 0.739, g_loss 0.710, d_loss 0.669\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 136/390 d_loss_real= 0.631, d_loss_fake= 0.705, g_loss 0.733, d_loss 0.668\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 137/390 d_loss_real= 0.744, d_loss_fake= 0.716, g_loss 0.729, d_loss 0.730\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 14 Batch 138/390 d_loss_real= 0.649, d_loss_fake= 0.716, g_loss 0.724, d_loss 0.683\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 139/390 d_loss_real= 0.657, d_loss_fake= 0.695, g_loss 0.741, d_loss 0.676\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 140/390 d_loss_real= 0.620, d_loss_fake= 0.684, g_loss 0.754, d_loss 0.652\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 141/390 d_loss_real= 0.622, d_loss_fake= 0.673, g_loss 0.769, d_loss 0.648\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 142/390 d_loss_real= 0.533, d_loss_fake= 0.647, g_loss 0.783, d_loss 0.590\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 143/390 d_loss_real= 0.707, d_loss_fake= 0.643, g_loss 0.791, d_loss 0.675\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 144/390 d_loss_real= 0.663, d_loss_fake= 0.641, g_loss 0.796, d_loss 0.652\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 145/390 d_loss_real= 0.778, d_loss_fake= 0.652, g_loss 0.785, d_loss 0.715\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 146/390 d_loss_real= 0.626, d_loss_fake= 0.655, g_loss 0.785, d_loss 0.640\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 147/390 d_loss_real= 0.664, d_loss_fake= 0.668, g_loss 0.785, d_loss 0.666\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 148/390 d_loss_real= 0.622, d_loss_fake= 0.663, g_loss 0.759, d_loss 0.643\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 14 Batch 149/390 d_loss_real= 0.560, d_loss_fake= 0.665, g_loss 0.769, d_loss 0.613\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 150/390 d_loss_real= 0.656, d_loss_fake= 0.632, g_loss 0.787, d_loss 0.644\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 151/390 d_loss_real= 0.627, d_loss_fake= 0.665, g_loss 0.796, d_loss 0.646\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 152/390 d_loss_real= 0.630, d_loss_fake= 0.631, g_loss 0.790, d_loss 0.631\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 153/390 d_loss_real= 0.654, d_loss_fake= 0.624, g_loss 0.812, d_loss 0.639\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 14 Batch 154/390 d_loss_real= 0.714, d_loss_fake= 0.605, g_loss 0.853, d_loss 0.659\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 155/390 d_loss_real= 0.547, d_loss_fake= 0.597, g_loss 0.870, d_loss 0.572\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 156/390 d_loss_real= 0.648, d_loss_fake= 0.543, g_loss 0.872, d_loss 0.596\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 157/390 d_loss_real= 0.595, d_loss_fake= 0.579, g_loss 0.890, d_loss 0.587\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 158/390 d_loss_real= 0.586, d_loss_fake= 0.568, g_loss 0.917, d_loss 0.577\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 159/390 d_loss_real= 0.545, d_loss_fake= 0.567, g_loss 0.895, d_loss 0.556\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 160/390 d_loss_real= 0.753, d_loss_fake= 0.539, g_loss 0.878, d_loss 0.646\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 161/390 d_loss_real= 0.515, d_loss_fake= 0.574, g_loss 0.861, d_loss 0.544\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 14 Batch 162/390 d_loss_real= 0.515, d_loss_fake= 0.559, g_loss 0.891, d_loss 0.537\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 163/390 d_loss_real= 0.423, d_loss_fake= 0.563, g_loss 0.901, d_loss 0.493\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 164/390 d_loss_real= 0.446, d_loss_fake= 0.535, g_loss 0.940, d_loss 0.490\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 14 Batch 165/390 d_loss_real= 0.466, d_loss_fake= 0.523, g_loss 0.973, d_loss 0.494\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 166/390 d_loss_real= 0.515, d_loss_fake= 0.493, g_loss 1.059, d_loss 0.504\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 167/390 d_loss_real= 0.613, d_loss_fake= 0.467, g_loss 1.077, d_loss 0.540\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 14 Batch 168/390 d_loss_real= 0.470, d_loss_fake= 0.439, g_loss 1.068, d_loss 0.455\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 14 Batch 169/390 d_loss_real= 0.606, d_loss_fake= 0.440, g_loss 1.090, d_loss 0.523\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 170/390 d_loss_real= 0.518, d_loss_fake= 0.438, g_loss 1.068, d_loss 0.478\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 171/390 d_loss_real= 0.444, d_loss_fake= 0.435, g_loss 1.083, d_loss 0.439\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 172/390 d_loss_real= 0.543, d_loss_fake= 0.436, g_loss 1.075, d_loss 0.489\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 173/390 d_loss_real= 0.503, d_loss_fake= 0.463, g_loss 1.048, d_loss 0.483\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 174/390 d_loss_real= 0.422, d_loss_fake= 0.468, g_loss 1.062, d_loss 0.445\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 14 Batch 175/390 d_loss_real= 0.559, d_loss_fake= 0.438, g_loss 1.048, d_loss 0.498\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 176/390 d_loss_real= 0.507, d_loss_fake= 0.470, g_loss 1.052, d_loss 0.488\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 14 Batch 177/390 d_loss_real= 0.449, d_loss_fake= 0.473, g_loss 1.102, d_loss 0.461\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 14 Batch 178/390 d_loss_real= 0.537, d_loss_fake= 0.477, g_loss 1.063, d_loss 0.507\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 14 Batch 179/390 d_loss_real= 0.484, d_loss_fake= 0.458, g_loss 1.083, d_loss 0.471\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 14 Batch 180/390 d_loss_real= 0.418, d_loss_fake= 0.452, g_loss 1.112, d_loss 0.435\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 14 Batch 181/390 d_loss_real= 0.536, d_loss_fake= 0.450, g_loss 1.102, d_loss 0.493\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 14 Batch 182/390 d_loss_real= 0.426, d_loss_fake= 0.428, g_loss 1.127, d_loss 0.427\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 183/390 d_loss_real= 0.613, d_loss_fake= 0.416, g_loss 1.139, d_loss 0.515\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 184/390 d_loss_real= 0.466, d_loss_fake= 0.457, g_loss 1.106, d_loss 0.461\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 185/390 d_loss_real= 0.511, d_loss_fake= 0.461, g_loss 1.058, d_loss 0.486\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 186/390 d_loss_real= 0.534, d_loss_fake= 0.508, g_loss 1.007, d_loss 0.521\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 187/390 d_loss_real= 0.566, d_loss_fake= 0.520, g_loss 0.976, d_loss 0.543\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 188/390 d_loss_real= 0.514, d_loss_fake= 0.532, g_loss 0.971, d_loss 0.523\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 189/390 d_loss_real= 0.490, d_loss_fake= 0.542, g_loss 0.910, d_loss 0.516\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 14 Batch 190/390 d_loss_real= 0.570, d_loss_fake= 0.567, g_loss 0.905, d_loss 0.568\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 191/390 d_loss_real= 0.511, d_loss_fake= 0.573, g_loss 0.903, d_loss 0.542\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 192/390 d_loss_real= 0.534, d_loss_fake= 0.571, g_loss 0.885, d_loss 0.553\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 14 Batch 193/390 d_loss_real= 0.603, d_loss_fake= 0.571, g_loss 0.892, d_loss 0.587\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 194/390 d_loss_real= 0.684, d_loss_fake= 0.562, g_loss 0.890, d_loss 0.623\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 14 Batch 195/390 d_loss_real= 0.531, d_loss_fake= 0.540, g_loss 0.924, d_loss 0.535\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 196/390 d_loss_real= 0.526, d_loss_fake= 0.540, g_loss 0.944, d_loss 0.533\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 197/390 d_loss_real= 0.743, d_loss_fake= 0.535, g_loss 0.970, d_loss 0.639\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 14 Batch 198/390 d_loss_real= 0.680, d_loss_fake= 0.535, g_loss 0.918, d_loss 0.608\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 14 Batch 199/390 d_loss_real= 0.604, d_loss_fake= 0.546, g_loss 0.919, d_loss 0.575\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 200/390 d_loss_real= 0.516, d_loss_fake= 0.550, g_loss 0.943, d_loss 0.533\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 201/390 d_loss_real= 0.543, d_loss_fake= 0.544, g_loss 0.988, d_loss 0.543\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 14 Batch 202/390 d_loss_real= 0.514, d_loss_fake= 0.503, g_loss 0.993, d_loss 0.509\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 203/390 d_loss_real= 0.606, d_loss_fake= 0.485, g_loss 1.025, d_loss 0.545\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 14 Batch 204/390 d_loss_real= 0.576, d_loss_fake= 0.469, g_loss 1.016, d_loss 0.523\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 14 Batch 205/390 d_loss_real= 0.420, d_loss_fake= 0.502, g_loss 1.068, d_loss 0.461\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 14 Batch 206/390 d_loss_real= 0.527, d_loss_fake= 0.465, g_loss 1.082, d_loss 0.496\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 207/390 d_loss_real= 0.631, d_loss_fake= 0.475, g_loss 1.052, d_loss 0.553\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 208/390 d_loss_real= 0.446, d_loss_fake= 0.509, g_loss 1.086, d_loss 0.477\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 209/390 d_loss_real= 0.542, d_loss_fake= 0.433, g_loss 1.072, d_loss 0.488\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 210/390 d_loss_real= 0.511, d_loss_fake= 0.502, g_loss 1.054, d_loss 0.506\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 211/390 d_loss_real= 0.498, d_loss_fake= 0.513, g_loss 1.068, d_loss 0.505\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 212/390 d_loss_real= 0.610, d_loss_fake= 0.496, g_loss 1.055, d_loss 0.553\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 213/390 d_loss_real= 0.473, d_loss_fake= 0.490, g_loss 1.034, d_loss 0.481\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 14 Batch 214/390 d_loss_real= 0.464, d_loss_fake= 0.497, g_loss 1.001, d_loss 0.481\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 215/390 d_loss_real= 0.575, d_loss_fake= 0.493, g_loss 1.024, d_loss 0.534\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 14 Batch 216/390 d_loss_real= 0.570, d_loss_fake= 0.521, g_loss 1.016, d_loss 0.546\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 217/390 d_loss_real= 0.624, d_loss_fake= 0.530, g_loss 0.999, d_loss 0.577\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 218/390 d_loss_real= 0.485, d_loss_fake= 0.549, g_loss 0.963, d_loss 0.517\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 219/390 d_loss_real= 0.582, d_loss_fake= 0.518, g_loss 0.970, d_loss 0.550\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 220/390 d_loss_real= 0.531, d_loss_fake= 0.492, g_loss 0.979, d_loss 0.512\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 221/390 d_loss_real= 0.509, d_loss_fake= 0.540, g_loss 0.988, d_loss 0.524\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 222/390 d_loss_real= 0.609, d_loss_fake= 0.527, g_loss 0.968, d_loss 0.568\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 223/390 d_loss_real= 0.644, d_loss_fake= 0.528, g_loss 0.944, d_loss 0.586\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 224/390 d_loss_real= 0.640, d_loss_fake= 0.543, g_loss 0.906, d_loss 0.591\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 225/390 d_loss_real= 0.573, d_loss_fake= 0.603, g_loss 0.918, d_loss 0.588\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 14 Batch 226/390 d_loss_real= 0.572, d_loss_fake= 0.581, g_loss 0.888, d_loss 0.576\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 14 Batch 227/390 d_loss_real= 0.631, d_loss_fake= 0.582, g_loss 0.859, d_loss 0.607\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 228/390 d_loss_real= 0.542, d_loss_fake= 0.608, g_loss 0.835, d_loss 0.575\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 229/390 d_loss_real= 0.553, d_loss_fake= 0.657, g_loss 0.823, d_loss 0.605\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 14 Batch 230/390 d_loss_real= 0.600, d_loss_fake= 0.683, g_loss 0.782, d_loss 0.642\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 14 Batch 231/390 d_loss_real= 0.558, d_loss_fake= 0.654, g_loss 0.782, d_loss 0.606\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 232/390 d_loss_real= 0.605, d_loss_fake= 0.690, g_loss 0.782, d_loss 0.647\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 233/390 d_loss_real= 0.685, d_loss_fake= 0.669, g_loss 0.836, d_loss 0.677\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 234/390 d_loss_real= 0.677, d_loss_fake= 0.660, g_loss 0.823, d_loss 0.669\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 14 Batch 235/390 d_loss_real= 0.773, d_loss_fake= 0.640, g_loss 0.814, d_loss 0.706\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 236/390 d_loss_real= 0.648, d_loss_fake= 0.658, g_loss 0.802, d_loss 0.653\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 14 Batch 237/390 d_loss_real= 0.688, d_loss_fake= 0.636, g_loss 0.824, d_loss 0.662\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 14 Batch 238/390 d_loss_real= 0.635, d_loss_fake= 0.616, g_loss 0.802, d_loss 0.626\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 14 Batch 239/390 d_loss_real= 0.724, d_loss_fake= 0.671, g_loss 0.794, d_loss 0.698\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 14 Batch 240/390 d_loss_real= 0.533, d_loss_fake= 0.680, g_loss 0.807, d_loss 0.607\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 14 Batch 241/390 d_loss_real= 0.577, d_loss_fake= 0.628, g_loss 0.837, d_loss 0.603\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 242/390 d_loss_real= 0.605, d_loss_fake= 0.601, g_loss 0.867, d_loss 0.603\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 14 Batch 243/390 d_loss_real= 0.627, d_loss_fake= 0.579, g_loss 0.896, d_loss 0.603\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 14 Batch 244/390 d_loss_real= 0.574, d_loss_fake= 0.562, g_loss 0.916, d_loss 0.568\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 245/390 d_loss_real= 0.453, d_loss_fake= 0.538, g_loss 0.950, d_loss 0.496\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 246/390 d_loss_real= 0.609, d_loss_fake= 0.531, g_loss 0.954, d_loss 0.570\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 14 Batch 247/390 d_loss_real= 0.556, d_loss_fake= 0.519, g_loss 0.946, d_loss 0.538\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 14 Batch 248/390 d_loss_real= 0.594, d_loss_fake= 0.560, g_loss 0.901, d_loss 0.577\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 249/390 d_loss_real= 0.553, d_loss_fake= 0.545, g_loss 0.899, d_loss 0.549\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 250/390 d_loss_real= 0.498, d_loss_fake= 0.606, g_loss 0.858, d_loss 0.552\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 251/390 d_loss_real= 0.575, d_loss_fake= 0.625, g_loss 0.855, d_loss 0.600\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 252/390 d_loss_real= 0.594, d_loss_fake= 0.638, g_loss 0.852, d_loss 0.616\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 253/390 d_loss_real= 0.577, d_loss_fake= 0.612, g_loss 0.903, d_loss 0.595\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 14 Batch 254/390 d_loss_real= 0.696, d_loss_fake= 0.567, g_loss 0.925, d_loss 0.631\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 255/390 d_loss_real= 0.564, d_loss_fake= 0.536, g_loss 0.960, d_loss 0.550\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 256/390 d_loss_real= 0.684, d_loss_fake= 0.523, g_loss 0.965, d_loss 0.604\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 14 Batch 257/390 d_loss_real= 0.644, d_loss_fake= 0.515, g_loss 0.989, d_loss 0.579\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 14 Batch 258/390 d_loss_real= 0.747, d_loss_fake= 0.507, g_loss 0.988, d_loss 0.627\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 259/390 d_loss_real= 0.644, d_loss_fake= 0.509, g_loss 0.981, d_loss 0.576\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 260/390 d_loss_real= 0.619, d_loss_fake= 0.515, g_loss 0.967, d_loss 0.567\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 261/390 d_loss_real= 0.645, d_loss_fake= 0.530, g_loss 0.968, d_loss 0.587\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 14 Batch 262/390 d_loss_real= 0.611, d_loss_fake= 0.519, g_loss 0.952, d_loss 0.565\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 14 Batch 263/390 d_loss_real= 0.672, d_loss_fake= 0.530, g_loss 0.952, d_loss 0.601\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 264/390 d_loss_real= 0.727, d_loss_fake= 0.537, g_loss 0.952, d_loss 0.632\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 265/390 d_loss_real= 0.683, d_loss_fake= 0.526, g_loss 0.953, d_loss 0.604\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 266/390 d_loss_real= 0.620, d_loss_fake= 0.515, g_loss 0.988, d_loss 0.567\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 267/390 d_loss_real= 0.692, d_loss_fake= 0.501, g_loss 0.982, d_loss 0.597\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 268/390 d_loss_real= 0.581, d_loss_fake= 0.509, g_loss 0.990, d_loss 0.545\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 269/390 d_loss_real= 0.542, d_loss_fake= 0.485, g_loss 1.022, d_loss 0.513\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 270/390 d_loss_real= 0.551, d_loss_fake= 0.473, g_loss 1.061, d_loss 0.512\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 271/390 d_loss_real= 0.555, d_loss_fake= 0.454, g_loss 1.063, d_loss 0.505\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 272/390 d_loss_real= 0.661, d_loss_fake= 0.452, g_loss 1.067, d_loss 0.556\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 14 Batch 273/390 d_loss_real= 0.695, d_loss_fake= 0.468, g_loss 1.062, d_loss 0.581\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 274/390 d_loss_real= 0.551, d_loss_fake= 0.470, g_loss 1.063, d_loss 0.510\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 14 Batch 275/390 d_loss_real= 0.686, d_loss_fake= 0.466, g_loss 1.039, d_loss 0.576\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 14 Batch 276/390 d_loss_real= 0.464, d_loss_fake= 0.473, g_loss 1.050, d_loss 0.469\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 14 Batch 277/390 d_loss_real= 0.626, d_loss_fake= 0.473, g_loss 1.031, d_loss 0.550\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 278/390 d_loss_real= 0.582, d_loss_fake= 0.469, g_loss 1.042, d_loss 0.526\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 279/390 d_loss_real= 0.526, d_loss_fake= 0.488, g_loss 1.017, d_loss 0.507\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 14 Batch 280/390 d_loss_real= 0.556, d_loss_fake= 0.513, g_loss 1.031, d_loss 0.534\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 281/390 d_loss_real= 0.586, d_loss_fake= 0.479, g_loss 1.056, d_loss 0.532\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 14 Batch 282/390 d_loss_real= 0.730, d_loss_fake= 0.473, g_loss 1.024, d_loss 0.601\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 14 Batch 283/390 d_loss_real= 0.553, d_loss_fake= 0.493, g_loss 1.030, d_loss 0.523\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 14 Batch 284/390 d_loss_real= 0.622, d_loss_fake= 0.478, g_loss 1.035, d_loss 0.550\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 285/390 d_loss_real= 0.417, d_loss_fake= 0.502, g_loss 1.058, d_loss 0.460\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 286/390 d_loss_real= 0.429, d_loss_fake= 0.467, g_loss 1.088, d_loss 0.448\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 287/390 d_loss_real= 0.563, d_loss_fake= 0.448, g_loss 1.130, d_loss 0.506\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 288/390 d_loss_real= 0.708, d_loss_fake= 0.434, g_loss 1.140, d_loss 0.571\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 14 Batch 289/390 d_loss_real= 0.670, d_loss_fake= 0.421, g_loss 1.131, d_loss 0.545\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 290/390 d_loss_real= 0.847, d_loss_fake= 0.431, g_loss 1.103, d_loss 0.639\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 291/390 d_loss_real= 0.718, d_loss_fake= 0.443, g_loss 1.075, d_loss 0.581\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 292/390 d_loss_real= 0.679, d_loss_fake= 0.465, g_loss 1.014, d_loss 0.572\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 293/390 d_loss_real= 0.460, d_loss_fake= 0.475, g_loss 1.005, d_loss 0.467\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 294/390 d_loss_real= 0.441, d_loss_fake= 0.478, g_loss 1.019, d_loss 0.459\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 14 Batch 295/390 d_loss_real= 0.484, d_loss_fake= 0.473, g_loss 1.047, d_loss 0.478\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 296/390 d_loss_real= 0.560, d_loss_fake= 0.452, g_loss 1.071, d_loss 0.506\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 14 Batch 297/390 d_loss_real= 0.552, d_loss_fake= 0.462, g_loss 1.084, d_loss 0.507\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 14 Batch 298/390 d_loss_real= 0.640, d_loss_fake= 0.444, g_loss 1.075, d_loss 0.542\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 299/390 d_loss_real= 0.581, d_loss_fake= 0.447, g_loss 1.088, d_loss 0.514\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 14 Batch 300/390 d_loss_real= 0.494, d_loss_fake= 0.428, g_loss 1.090, d_loss 0.461\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 301/390 d_loss_real= 0.592, d_loss_fake= 0.465, g_loss 1.084, d_loss 0.529\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 14 Batch 302/390 d_loss_real= 0.608, d_loss_fake= 0.466, g_loss 1.074, d_loss 0.537\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 14 Batch 303/390 d_loss_real= 0.492, d_loss_fake= 0.478, g_loss 1.062, d_loss 0.485\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 304/390 d_loss_real= 0.500, d_loss_fake= 0.479, g_loss 1.037, d_loss 0.490\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 14 Batch 305/390 d_loss_real= 0.478, d_loss_fake= 0.467, g_loss 1.038, d_loss 0.473\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 14 Batch 306/390 d_loss_real= 0.528, d_loss_fake= 0.476, g_loss 1.035, d_loss 0.502\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 307/390 d_loss_real= 0.460, d_loss_fake= 0.472, g_loss 0.993, d_loss 0.466\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 14 Batch 308/390 d_loss_real= 0.502, d_loss_fake= 0.459, g_loss 1.004, d_loss 0.481\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 14 Batch 309/390 d_loss_real= 0.511, d_loss_fake= 0.501, g_loss 1.007, d_loss 0.506\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 310/390 d_loss_real= 0.502, d_loss_fake= 0.470, g_loss 1.008, d_loss 0.486\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 311/390 d_loss_real= 0.529, d_loss_fake= 0.504, g_loss 0.998, d_loss 0.516\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 312/390 d_loss_real= 0.638, d_loss_fake= 0.475, g_loss 1.022, d_loss 0.557\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 14 Batch 313/390 d_loss_real= 0.427, d_loss_fake= 0.490, g_loss 1.025, d_loss 0.459\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 314/390 d_loss_real= 0.465, d_loss_fake= 0.478, g_loss 1.035, d_loss 0.472\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 315/390 d_loss_real= 0.518, d_loss_fake= 0.491, g_loss 1.020, d_loss 0.505\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 14 Batch 316/390 d_loss_real= 0.531, d_loss_fake= 0.494, g_loss 1.017, d_loss 0.513\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 317/390 d_loss_real= 0.517, d_loss_fake= 0.471, g_loss 1.014, d_loss 0.494\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 318/390 d_loss_real= 0.570, d_loss_fake= 0.502, g_loss 0.986, d_loss 0.536\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 14 Batch 319/390 d_loss_real= 0.424, d_loss_fake= 0.502, g_loss 0.966, d_loss 0.463\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 14 Batch 320/390 d_loss_real= 0.539, d_loss_fake= 0.521, g_loss 0.931, d_loss 0.530\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 14 Batch 321/390 d_loss_real= 0.455, d_loss_fake= 0.515, g_loss 0.940, d_loss 0.485\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 322/390 d_loss_real= 0.461, d_loss_fake= 0.520, g_loss 0.943, d_loss 0.491\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 323/390 d_loss_real= 0.500, d_loss_fake= 0.520, g_loss 0.957, d_loss 0.510\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 324/390 d_loss_real= 0.443, d_loss_fake= 0.510, g_loss 0.963, d_loss 0.476\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 14 Batch 325/390 d_loss_real= 0.485, d_loss_fake= 0.500, g_loss 0.969, d_loss 0.493\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 14 Batch 326/390 d_loss_real= 0.490, d_loss_fake= 0.505, g_loss 0.967, d_loss 0.498\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 327/390 d_loss_real= 0.520, d_loss_fake= 0.510, g_loss 0.957, d_loss 0.515\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 14 Batch 328/390 d_loss_real= 0.524, d_loss_fake= 0.515, g_loss 0.949, d_loss 0.519\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 329/390 d_loss_real= 0.383, d_loss_fake= 0.522, g_loss 0.936, d_loss 0.452\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 14 Batch 330/390 d_loss_real= 0.502, d_loss_fake= 0.529, g_loss 0.956, d_loss 0.515\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 331/390 d_loss_real= 0.400, d_loss_fake= 0.511, g_loss 0.968, d_loss 0.455\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 14 Batch 332/390 d_loss_real= 0.503, d_loss_fake= 0.490, g_loss 0.945, d_loss 0.497\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 333/390 d_loss_real= 0.474, d_loss_fake= 0.506, g_loss 0.947, d_loss 0.490\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 14 Batch 334/390 d_loss_real= 0.482, d_loss_fake= 0.510, g_loss 0.961, d_loss 0.496\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 14 Batch 335/390 d_loss_real= 0.424, d_loss_fake= 0.503, g_loss 0.962, d_loss 0.463\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 336/390 d_loss_real= 0.398, d_loss_fake= 0.518, g_loss 0.948, d_loss 0.458\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 337/390 d_loss_real= 0.412, d_loss_fake= 0.511, g_loss 0.939, d_loss 0.462\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 338/390 d_loss_real= 0.345, d_loss_fake= 0.519, g_loss 0.979, d_loss 0.432\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 14 Batch 339/390 d_loss_real= 0.474, d_loss_fake= 0.500, g_loss 0.957, d_loss 0.487\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 14 Batch 340/390 d_loss_real= 0.483, d_loss_fake= 0.505, g_loss 0.977, d_loss 0.494\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 14 Batch 341/390 d_loss_real= 0.524, d_loss_fake= 0.510, g_loss 0.969, d_loss 0.517\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 14 Batch 342/390 d_loss_real= 0.518, d_loss_fake= 0.513, g_loss 0.967, d_loss 0.516\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 343/390 d_loss_real= 0.514, d_loss_fake= 0.493, g_loss 0.930, d_loss 0.503\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 344/390 d_loss_real= 0.413, d_loss_fake= 0.533, g_loss 0.926, d_loss 0.473\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 345/390 d_loss_real= 0.436, d_loss_fake= 0.523, g_loss 0.936, d_loss 0.480\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 346/390 d_loss_real= 0.445, d_loss_fake= 0.530, g_loss 0.934, d_loss 0.488\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 14 Batch 347/390 d_loss_real= 0.363, d_loss_fake= 0.518, g_loss 0.936, d_loss 0.440\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 14 Batch 348/390 d_loss_real= 0.481, d_loss_fake= 0.534, g_loss 0.943, d_loss 0.508\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 349/390 d_loss_real= 0.384, d_loss_fake= 0.509, g_loss 0.974, d_loss 0.447\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 350/390 d_loss_real= 0.482, d_loss_fake= 0.497, g_loss 0.991, d_loss 0.489\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 14 Batch 351/390 d_loss_real= 0.503, d_loss_fake= 0.493, g_loss 0.990, d_loss 0.498\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 352/390 d_loss_real= 0.448, d_loss_fake= 0.501, g_loss 0.965, d_loss 0.475\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 353/390 d_loss_real= 0.555, d_loss_fake= 0.492, g_loss 0.981, d_loss 0.523\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 354/390 d_loss_real= 0.469, d_loss_fake= 0.506, g_loss 0.982, d_loss 0.487\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 355/390 d_loss_real= 0.572, d_loss_fake= 0.503, g_loss 0.962, d_loss 0.537\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 356/390 d_loss_real= 0.580, d_loss_fake= 0.502, g_loss 0.964, d_loss 0.541\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 357/390 d_loss_real= 0.442, d_loss_fake= 0.529, g_loss 0.947, d_loss 0.486\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 358/390 d_loss_real= 0.443, d_loss_fake= 0.515, g_loss 0.965, d_loss 0.479\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 359/390 d_loss_real= 0.570, d_loss_fake= 0.504, g_loss 0.984, d_loss 0.537\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 14 Batch 360/390 d_loss_real= 0.423, d_loss_fake= 0.498, g_loss 0.992, d_loss 0.461\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 14 Batch 361/390 d_loss_real= 0.529, d_loss_fake= 0.481, g_loss 1.011, d_loss 0.505\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 362/390 d_loss_real= 0.502, d_loss_fake= 0.468, g_loss 1.025, d_loss 0.485\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 363/390 d_loss_real= 0.549, d_loss_fake= 0.468, g_loss 1.031, d_loss 0.508\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 14 Batch 364/390 d_loss_real= 0.585, d_loss_fake= 0.474, g_loss 1.021, d_loss 0.530\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 365/390 d_loss_real= 0.600, d_loss_fake= 0.478, g_loss 1.011, d_loss 0.539\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 366/390 d_loss_real= 0.659, d_loss_fake= 0.491, g_loss 1.012, d_loss 0.575\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 367/390 d_loss_real= 0.542, d_loss_fake= 0.492, g_loss 1.014, d_loss 0.517\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 368/390 d_loss_real= 0.559, d_loss_fake= 0.483, g_loss 1.004, d_loss 0.521\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 369/390 d_loss_real= 0.512, d_loss_fake= 0.490, g_loss 1.001, d_loss 0.501\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14 Batch 370/390 d_loss_real= 0.512, d_loss_fake= 0.501, g_loss 1.007, d_loss 0.506\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 371/390 d_loss_real= 0.496, d_loss_fake= 0.486, g_loss 1.020, d_loss 0.491\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 372/390 d_loss_real= 0.625, d_loss_fake= 0.479, g_loss 1.000, d_loss 0.552\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 14 Batch 373/390 d_loss_real= 0.581, d_loss_fake= 0.494, g_loss 0.994, d_loss 0.538\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 374/390 d_loss_real= 0.614, d_loss_fake= 0.532, g_loss 0.978, d_loss 0.573\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 375/390 d_loss_real= 0.618, d_loss_fake= 0.587, g_loss 0.946, d_loss 0.603\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 376/390 d_loss_real= 0.643, d_loss_fake= 0.634, g_loss 0.926, d_loss 0.638\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14 Batch 377/390 d_loss_real= 0.665, d_loss_fake= 0.591, g_loss 0.877, d_loss 0.628\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 378/390 d_loss_real= 0.723, d_loss_fake= 0.603, g_loss 0.901, d_loss 0.663\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 379/390 d_loss_real= 0.808, d_loss_fake= 0.602, g_loss 0.876, d_loss 0.705\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 380/390 d_loss_real= 0.579, d_loss_fake= 0.584, g_loss 0.887, d_loss 0.582\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 381/390 d_loss_real= 0.673, d_loss_fake= 0.601, g_loss 0.900, d_loss 0.637\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 382/390 d_loss_real= 0.659, d_loss_fake= 0.593, g_loss 0.911, d_loss 0.626\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 14 Batch 383/390 d_loss_real= 0.680, d_loss_fake= 0.574, g_loss 0.908, d_loss 0.627\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 14 Batch 384/390 d_loss_real= 0.631, d_loss_fake= 0.588, g_loss 0.913, d_loss 0.610\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 385/390 d_loss_real= 0.627, d_loss_fake= 0.553, g_loss 0.920, d_loss 0.590\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 386/390 d_loss_real= 0.500, d_loss_fake= 0.540, g_loss 0.953, d_loss 0.520\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14 Batch 387/390 d_loss_real= 0.616, d_loss_fake= 0.527, g_loss 0.967, d_loss 0.571\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 14 Batch 388/390 d_loss_real= 0.621, d_loss_fake= 0.494, g_loss 0.955, d_loss 0.558\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14 Batch 389/390 d_loss_real= 0.381, d_loss_fake= 0.511, g_loss 0.984, d_loss 0.446\n",
            "2/2 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14 Batch 390/390 d_loss_real= 0.440, d_loss_fake= 0.520, g_loss 0.985, d_loss 0.480\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 15 Batch 1/390 d_loss_real= 0.497, d_loss_fake= 0.487, g_loss 1.017, d_loss 0.492\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 2/390 d_loss_real= 0.310, d_loss_fake= 0.501, g_loss 1.025, d_loss 0.406\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 3/390 d_loss_real= 0.448, d_loss_fake= 0.494, g_loss 1.010, d_loss 0.471\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 4/390 d_loss_real= 0.462, d_loss_fake= 0.487, g_loss 1.010, d_loss 0.474\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 5/390 d_loss_real= 0.403, d_loss_fake= 0.482, g_loss 1.048, d_loss 0.443\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 6/390 d_loss_real= 0.393, d_loss_fake= 0.515, g_loss 1.085, d_loss 0.454\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 7/390 d_loss_real= 0.528, d_loss_fake= 0.487, g_loss 1.110, d_loss 0.508\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 8/390 d_loss_real= 0.578, d_loss_fake= 0.453, g_loss 1.105, d_loss 0.516\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 9/390 d_loss_real= 0.465, d_loss_fake= 0.416, g_loss 1.121, d_loss 0.440\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 10/390 d_loss_real= 0.613, d_loss_fake= 0.444, g_loss 1.092, d_loss 0.529\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 11/390 d_loss_real= 0.619, d_loss_fake= 0.442, g_loss 1.099, d_loss 0.531\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 12/390 d_loss_real= 0.480, d_loss_fake= 0.444, g_loss 1.066, d_loss 0.462\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 13/390 d_loss_real= 0.643, d_loss_fake= 0.474, g_loss 1.056, d_loss 0.559\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 14/390 d_loss_real= 0.518, d_loss_fake= 0.477, g_loss 1.048, d_loss 0.497\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 15/390 d_loss_real= 0.430, d_loss_fake= 0.455, g_loss 1.079, d_loss 0.442\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 16/390 d_loss_real= 0.409, d_loss_fake= 0.455, g_loss 1.093, d_loss 0.432\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 17/390 d_loss_real= 0.587, d_loss_fake= 0.427, g_loss 1.118, d_loss 0.507\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 18/390 d_loss_real= 0.662, d_loss_fake= 0.435, g_loss 1.096, d_loss 0.548\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 19/390 d_loss_real= 0.568, d_loss_fake= 0.451, g_loss 1.048, d_loss 0.510\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 20/390 d_loss_real= 0.507, d_loss_fake= 0.481, g_loss 1.013, d_loss 0.494\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 21/390 d_loss_real= 0.525, d_loss_fake= 0.515, g_loss 0.976, d_loss 0.520\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 22/390 d_loss_real= 0.517, d_loss_fake= 0.532, g_loss 0.947, d_loss 0.524\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 23/390 d_loss_real= 0.484, d_loss_fake= 0.528, g_loss 0.959, d_loss 0.506\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 24/390 d_loss_real= 0.441, d_loss_fake= 0.539, g_loss 0.979, d_loss 0.490\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 25/390 d_loss_real= 0.562, d_loss_fake= 0.485, g_loss 1.028, d_loss 0.523\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 26/390 d_loss_real= 0.591, d_loss_fake= 0.476, g_loss 1.070, d_loss 0.533\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 15 Batch 27/390 d_loss_real= 0.475, d_loss_fake= 0.453, g_loss 1.092, d_loss 0.464\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 28/390 d_loss_real= 0.536, d_loss_fake= 0.456, g_loss 1.088, d_loss 0.496\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 29/390 d_loss_real= 0.614, d_loss_fake= 0.446, g_loss 1.088, d_loss 0.530\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 15 Batch 30/390 d_loss_real= 0.504, d_loss_fake= 0.449, g_loss 1.062, d_loss 0.477\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 31/390 d_loss_real= 0.468, d_loss_fake= 0.454, g_loss 1.030, d_loss 0.461\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 32/390 d_loss_real= 0.488, d_loss_fake= 0.448, g_loss 1.030, d_loss 0.468\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 33/390 d_loss_real= 0.479, d_loss_fake= 0.481, g_loss 0.998, d_loss 0.480\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 15 Batch 34/390 d_loss_real= 0.421, d_loss_fake= 0.488, g_loss 0.996, d_loss 0.455\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 35/390 d_loss_real= 0.517, d_loss_fake= 0.488, g_loss 0.994, d_loss 0.502\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 36/390 d_loss_real= 0.448, d_loss_fake= 0.490, g_loss 1.007, d_loss 0.469\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 15 Batch 37/390 d_loss_real= 0.439, d_loss_fake= 0.462, g_loss 1.050, d_loss 0.450\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 38/390 d_loss_real= 0.498, d_loss_fake= 0.448, g_loss 1.085, d_loss 0.473\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 15 Batch 39/390 d_loss_real= 0.482, d_loss_fake= 0.433, g_loss 1.089, d_loss 0.457\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 40/390 d_loss_real= 0.447, d_loss_fake= 0.413, g_loss 1.123, d_loss 0.430\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 41/390 d_loss_real= 0.590, d_loss_fake= 0.416, g_loss 1.128, d_loss 0.503\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 42/390 d_loss_real= 0.604, d_loss_fake= 0.426, g_loss 1.123, d_loss 0.515\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 43/390 d_loss_real= 0.411, d_loss_fake= 0.413, g_loss 1.115, d_loss 0.412\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 44/390 d_loss_real= 0.470, d_loss_fake= 0.419, g_loss 1.128, d_loss 0.444\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 15 Batch 45/390 d_loss_real= 0.434, d_loss_fake= 0.412, g_loss 1.106, d_loss 0.423\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 15 Batch 46/390 d_loss_real= 0.384, d_loss_fake= 0.424, g_loss 1.123, d_loss 0.404\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 15 Batch 47/390 d_loss_real= 0.392, d_loss_fake= 0.417, g_loss 1.165, d_loss 0.404\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 48/390 d_loss_real= 0.375, d_loss_fake= 0.408, g_loss 1.181, d_loss 0.392\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 49/390 d_loss_real= 0.380, d_loss_fake= 0.384, g_loss 1.186, d_loss 0.382\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 50/390 d_loss_real= 0.417, d_loss_fake= 0.378, g_loss 1.170, d_loss 0.397\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 51/390 d_loss_real= 0.470, d_loss_fake= 0.404, g_loss 1.231, d_loss 0.437\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 52/390 d_loss_real= 0.404, d_loss_fake= 0.377, g_loss 1.215, d_loss 0.390\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 53/390 d_loss_real= 0.505, d_loss_fake= 0.391, g_loss 1.198, d_loss 0.448\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 15 Batch 54/390 d_loss_real= 0.391, d_loss_fake= 0.394, g_loss 1.196, d_loss 0.393\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 15 Batch 55/390 d_loss_real= 0.472, d_loss_fake= 0.366, g_loss 1.171, d_loss 0.419\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 56/390 d_loss_real= 0.389, d_loss_fake= 0.377, g_loss 1.165, d_loss 0.383\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 57/390 d_loss_real= 0.344, d_loss_fake= 0.406, g_loss 1.160, d_loss 0.375\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 58/390 d_loss_real= 0.389, d_loss_fake= 0.395, g_loss 1.160, d_loss 0.392\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 59/390 d_loss_real= 0.423, d_loss_fake= 0.393, g_loss 1.173, d_loss 0.408\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 60/390 d_loss_real= 0.304, d_loss_fake= 0.415, g_loss 1.196, d_loss 0.359\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 15 Batch 61/390 d_loss_real= 0.405, d_loss_fake= 0.374, g_loss 1.192, d_loss 0.390\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 62/390 d_loss_real= 0.380, d_loss_fake= 0.378, g_loss 1.238, d_loss 0.379\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 63/390 d_loss_real= 0.555, d_loss_fake= 0.398, g_loss 1.228, d_loss 0.476\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 64/390 d_loss_real= 0.413, d_loss_fake= 0.375, g_loss 1.230, d_loss 0.394\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 15 Batch 65/390 d_loss_real= 0.384, d_loss_fake= 0.358, g_loss 1.229, d_loss 0.371\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 66/390 d_loss_real= 0.467, d_loss_fake= 0.380, g_loss 1.251, d_loss 0.424\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 67/390 d_loss_real= 0.348, d_loss_fake= 0.370, g_loss 1.160, d_loss 0.359\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 15 Batch 68/390 d_loss_real= 0.466, d_loss_fake= 0.391, g_loss 1.201, d_loss 0.429\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 69/390 d_loss_real= 0.514, d_loss_fake= 0.418, g_loss 1.121, d_loss 0.466\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 15 Batch 70/390 d_loss_real= 0.515, d_loss_fake= 0.430, g_loss 1.080, d_loss 0.472\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 15 Batch 71/390 d_loss_real= 0.521, d_loss_fake= 0.459, g_loss 1.009, d_loss 0.490\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 15 Batch 72/390 d_loss_real= 0.408, d_loss_fake= 0.519, g_loss 0.987, d_loss 0.464\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 15 Batch 73/390 d_loss_real= 0.406, d_loss_fake= 0.515, g_loss 0.967, d_loss 0.460\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 74/390 d_loss_real= 0.445, d_loss_fake= 0.535, g_loss 1.013, d_loss 0.490\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 75/390 d_loss_real= 0.370, d_loss_fake= 0.496, g_loss 0.978, d_loss 0.433\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 15 Batch 76/390 d_loss_real= 0.411, d_loss_fake= 0.561, g_loss 1.037, d_loss 0.486\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 77/390 d_loss_real= 0.511, d_loss_fake= 0.485, g_loss 1.050, d_loss 0.498\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 15 Batch 78/390 d_loss_real= 0.488, d_loss_fake= 0.520, g_loss 1.034, d_loss 0.504\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 79/390 d_loss_real= 0.524, d_loss_fake= 0.459, g_loss 1.008, d_loss 0.492\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 15 Batch 80/390 d_loss_real= 0.713, d_loss_fake= 0.519, g_loss 1.029, d_loss 0.616\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 15 Batch 81/390 d_loss_real= 0.570, d_loss_fake= 0.524, g_loss 1.016, d_loss 0.547\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 15 Batch 82/390 d_loss_real= 0.564, d_loss_fake= 0.535, g_loss 0.982, d_loss 0.550\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 83/390 d_loss_real= 0.533, d_loss_fake= 0.558, g_loss 0.967, d_loss 0.546\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 84/390 d_loss_real= 0.603, d_loss_fake= 0.518, g_loss 0.961, d_loss 0.561\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 85/390 d_loss_real= 0.449, d_loss_fake= 0.545, g_loss 0.976, d_loss 0.497\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 86/390 d_loss_real= 0.426, d_loss_fake= 0.536, g_loss 1.055, d_loss 0.481\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 15 Batch 87/390 d_loss_real= 0.385, d_loss_fake= 0.489, g_loss 1.067, d_loss 0.437\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 88/390 d_loss_real= 0.552, d_loss_fake= 0.482, g_loss 1.132, d_loss 0.517\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 15 Batch 89/390 d_loss_real= 0.572, d_loss_fake= 0.514, g_loss 1.092, d_loss 0.543\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 90/390 d_loss_real= 0.415, d_loss_fake= 0.454, g_loss 1.113, d_loss 0.434\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 91/390 d_loss_real= 0.547, d_loss_fake= 0.480, g_loss 1.050, d_loss 0.513\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 15 Batch 92/390 d_loss_real= 0.636, d_loss_fake= 0.492, g_loss 1.061, d_loss 0.564\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 93/390 d_loss_real= 0.644, d_loss_fake= 0.507, g_loss 0.989, d_loss 0.575\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 94/390 d_loss_real= 0.449, d_loss_fake= 0.574, g_loss 0.988, d_loss 0.511\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 15 Batch 95/390 d_loss_real= 0.539, d_loss_fake= 0.550, g_loss 0.918, d_loss 0.544\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 96/390 d_loss_real= 0.511, d_loss_fake= 0.544, g_loss 0.918, d_loss 0.528\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 15 Batch 97/390 d_loss_real= 0.498, d_loss_fake= 0.601, g_loss 0.933, d_loss 0.549\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 15 Batch 98/390 d_loss_real= 0.652, d_loss_fake= 0.573, g_loss 0.973, d_loss 0.613\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 15 Batch 99/390 d_loss_real= 0.704, d_loss_fake= 0.534, g_loss 0.965, d_loss 0.619\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 100/390 d_loss_real= 0.677, d_loss_fake= 0.550, g_loss 0.950, d_loss 0.614\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 101/390 d_loss_real= 0.780, d_loss_fake= 0.570, g_loss 0.937, d_loss 0.675\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 15 Batch 102/390 d_loss_real= 0.669, d_loss_fake= 0.528, g_loss 0.900, d_loss 0.599\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 103/390 d_loss_real= 0.634, d_loss_fake= 0.570, g_loss 0.919, d_loss 0.602\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 104/390 d_loss_real= 0.616, d_loss_fake= 0.521, g_loss 0.963, d_loss 0.568\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 105/390 d_loss_real= 0.654, d_loss_fake= 0.495, g_loss 1.016, d_loss 0.574\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 106/390 d_loss_real= 0.709, d_loss_fake= 0.491, g_loss 1.018, d_loss 0.600\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 107/390 d_loss_real= 0.651, d_loss_fake= 0.485, g_loss 1.024, d_loss 0.568\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 108/390 d_loss_real= 0.580, d_loss_fake= 0.490, g_loss 1.001, d_loss 0.535\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 109/390 d_loss_real= 0.430, d_loss_fake= 0.484, g_loss 1.011, d_loss 0.457\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 15 Batch 110/390 d_loss_real= 0.705, d_loss_fake= 0.475, g_loss 1.035, d_loss 0.590\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 111/390 d_loss_real= 0.675, d_loss_fake= 0.470, g_loss 1.011, d_loss 0.572\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 112/390 d_loss_real= 0.643, d_loss_fake= 0.482, g_loss 1.027, d_loss 0.563\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 113/390 d_loss_real= 0.621, d_loss_fake= 0.487, g_loss 1.024, d_loss 0.554\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 114/390 d_loss_real= 0.542, d_loss_fake= 0.488, g_loss 1.060, d_loss 0.515\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 15 Batch 115/390 d_loss_real= 0.647, d_loss_fake= 0.455, g_loss 1.067, d_loss 0.551\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 116/390 d_loss_real= 0.687, d_loss_fake= 0.444, g_loss 1.098, d_loss 0.565\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 15 Batch 117/390 d_loss_real= 0.664, d_loss_fake= 0.452, g_loss 1.063, d_loss 0.558\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 118/390 d_loss_real= 0.565, d_loss_fake= 0.456, g_loss 1.059, d_loss 0.511\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 15 Batch 119/390 d_loss_real= 0.600, d_loss_fake= 0.465, g_loss 1.038, d_loss 0.533\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 15 Batch 120/390 d_loss_real= 0.484, d_loss_fake= 0.452, g_loss 1.063, d_loss 0.468\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 121/390 d_loss_real= 0.522, d_loss_fake= 0.438, g_loss 1.152, d_loss 0.480\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 122/390 d_loss_real= 0.562, d_loss_fake= 0.408, g_loss 1.171, d_loss 0.485\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 15 Batch 123/390 d_loss_real= 0.631, d_loss_fake= 0.392, g_loss 1.191, d_loss 0.512\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 124/390 d_loss_real= 0.457, d_loss_fake= 0.386, g_loss 1.213, d_loss 0.421\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 15 Batch 125/390 d_loss_real= 0.465, d_loss_fake= 0.364, g_loss 1.268, d_loss 0.415\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 126/390 d_loss_real= 0.723, d_loss_fake= 0.361, g_loss 1.258, d_loss 0.542\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 127/390 d_loss_real= 0.571, d_loss_fake= 0.373, g_loss 1.242, d_loss 0.472\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 128/390 d_loss_real= 0.439, d_loss_fake= 0.379, g_loss 1.207, d_loss 0.409\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 129/390 d_loss_real= 0.517, d_loss_fake= 0.372, g_loss 1.211, d_loss 0.444\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 130/390 d_loss_real= 0.511, d_loss_fake= 0.381, g_loss 1.216, d_loss 0.446\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 15 Batch 131/390 d_loss_real= 0.615, d_loss_fake= 0.380, g_loss 1.210, d_loss 0.498\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 132/390 d_loss_real= 0.594, d_loss_fake= 0.371, g_loss 1.195, d_loss 0.483\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 15 Batch 133/390 d_loss_real= 0.492, d_loss_fake= 0.388, g_loss 1.200, d_loss 0.440\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 134/390 d_loss_real= 0.551, d_loss_fake= 0.382, g_loss 1.189, d_loss 0.467\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 15 Batch 135/390 d_loss_real= 0.634, d_loss_fake= 0.393, g_loss 1.172, d_loss 0.513\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 15 Batch 136/390 d_loss_real= 0.472, d_loss_fake= 0.398, g_loss 1.182, d_loss 0.435\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 137/390 d_loss_real= 0.497, d_loss_fake= 0.405, g_loss 1.188, d_loss 0.451\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 138/390 d_loss_real= 0.556, d_loss_fake= 0.397, g_loss 1.208, d_loss 0.477\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 15 Batch 139/390 d_loss_real= 0.530, d_loss_fake= 0.376, g_loss 1.242, d_loss 0.453\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 140/390 d_loss_real= 0.507, d_loss_fake= 0.365, g_loss 1.286, d_loss 0.436\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 15 Batch 141/390 d_loss_real= 0.562, d_loss_fake= 0.346, g_loss 1.302, d_loss 0.454\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 15 Batch 142/390 d_loss_real= 0.544, d_loss_fake= 0.361, g_loss 1.253, d_loss 0.453\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 15 Batch 143/390 d_loss_real= 0.562, d_loss_fake= 0.382, g_loss 1.228, d_loss 0.472\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 144/390 d_loss_real= 0.542, d_loss_fake= 0.384, g_loss 1.199, d_loss 0.463\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 145/390 d_loss_real= 0.492, d_loss_fake= 0.412, g_loss 1.127, d_loss 0.452\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 146/390 d_loss_real= 0.474, d_loss_fake= 0.435, g_loss 1.139, d_loss 0.454\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 147/390 d_loss_real= 0.493, d_loss_fake= 0.428, g_loss 1.123, d_loss 0.460\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 148/390 d_loss_real= 0.514, d_loss_fake= 0.403, g_loss 1.190, d_loss 0.458\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 149/390 d_loss_real= 0.435, d_loss_fake= 0.391, g_loss 1.181, d_loss 0.413\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 15 Batch 150/390 d_loss_real= 0.534, d_loss_fake= 0.382, g_loss 1.214, d_loss 0.458\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 151/390 d_loss_real= 0.479, d_loss_fake= 0.370, g_loss 1.229, d_loss 0.425\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 152/390 d_loss_real= 0.616, d_loss_fake= 0.369, g_loss 1.241, d_loss 0.492\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 153/390 d_loss_real= 0.474, d_loss_fake= 0.387, g_loss 1.204, d_loss 0.431\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 154/390 d_loss_real= 0.470, d_loss_fake= 0.384, g_loss 1.171, d_loss 0.427\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 155/390 d_loss_real= 0.465, d_loss_fake= 0.436, g_loss 1.209, d_loss 0.450\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 156/390 d_loss_real= 0.531, d_loss_fake= 0.437, g_loss 1.129, d_loss 0.484\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 157/390 d_loss_real= 0.466, d_loss_fake= 0.420, g_loss 1.163, d_loss 0.443\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 15 Batch 158/390 d_loss_real= 0.596, d_loss_fake= 0.430, g_loss 1.228, d_loss 0.513\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 159/390 d_loss_real= 0.642, d_loss_fake= 0.433, g_loss 1.218, d_loss 0.538\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 15 Batch 160/390 d_loss_real= 0.560, d_loss_fake= 0.381, g_loss 1.181, d_loss 0.471\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 15 Batch 161/390 d_loss_real= 0.626, d_loss_fake= 0.439, g_loss 1.155, d_loss 0.532\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 162/390 d_loss_real= 0.612, d_loss_fake= 0.441, g_loss 1.144, d_loss 0.527\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 163/390 d_loss_real= 0.602, d_loss_fake= 0.420, g_loss 1.101, d_loss 0.511\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 15 Batch 164/390 d_loss_real= 0.527, d_loss_fake= 0.444, g_loss 1.131, d_loss 0.486\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 165/390 d_loss_real= 0.466, d_loss_fake= 0.426, g_loss 1.163, d_loss 0.446\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 15 Batch 166/390 d_loss_real= 0.541, d_loss_fake= 0.392, g_loss 1.159, d_loss 0.467\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 167/390 d_loss_real= 0.642, d_loss_fake= 0.420, g_loss 1.132, d_loss 0.531\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 15 Batch 168/390 d_loss_real= 0.580, d_loss_fake= 0.415, g_loss 1.111, d_loss 0.497\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 169/390 d_loss_real= 0.468, d_loss_fake= 0.443, g_loss 1.049, d_loss 0.456\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 170/390 d_loss_real= 0.507, d_loss_fake= 0.476, g_loss 1.027, d_loss 0.492\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 15 Batch 171/390 d_loss_real= 0.601, d_loss_fake= 0.499, g_loss 0.946, d_loss 0.550\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 172/390 d_loss_real= 0.403, d_loss_fake= 0.527, g_loss 0.967, d_loss 0.465\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 15 Batch 173/390 d_loss_real= 0.468, d_loss_fake= 0.554, g_loss 0.956, d_loss 0.511\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 174/390 d_loss_real= 0.385, d_loss_fake= 0.546, g_loss 0.954, d_loss 0.465\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 15 Batch 175/390 d_loss_real= 0.589, d_loss_fake= 0.545, g_loss 0.955, d_loss 0.567\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 176/390 d_loss_real= 0.482, d_loss_fake= 0.516, g_loss 0.942, d_loss 0.499\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 177/390 d_loss_real= 0.438, d_loss_fake= 0.500, g_loss 0.983, d_loss 0.469\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 178/390 d_loss_real= 0.445, d_loss_fake= 0.508, g_loss 0.998, d_loss 0.476\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 15 Batch 179/390 d_loss_real= 0.500, d_loss_fake= 0.526, g_loss 1.013, d_loss 0.513\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 180/390 d_loss_real= 0.374, d_loss_fake= 0.500, g_loss 1.021, d_loss 0.437\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 181/390 d_loss_real= 0.545, d_loss_fake= 0.484, g_loss 1.042, d_loss 0.514\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 15 Batch 182/390 d_loss_real= 0.590, d_loss_fake= 0.477, g_loss 1.039, d_loss 0.533\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 15 Batch 183/390 d_loss_real= 0.401, d_loss_fake= 0.462, g_loss 1.084, d_loss 0.432\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 184/390 d_loss_real= 0.377, d_loss_fake= 0.457, g_loss 1.118, d_loss 0.417\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 185/390 d_loss_real= 0.414, d_loss_fake= 0.435, g_loss 1.200, d_loss 0.424\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 186/390 d_loss_real= 0.416, d_loss_fake= 0.414, g_loss 1.269, d_loss 0.415\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 187/390 d_loss_real= 0.522, d_loss_fake= 0.369, g_loss 1.285, d_loss 0.446\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 15 Batch 188/390 d_loss_real= 0.468, d_loss_fake= 0.345, g_loss 1.277, d_loss 0.407\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 15 Batch 189/390 d_loss_real= 0.397, d_loss_fake= 0.384, g_loss 1.286, d_loss 0.391\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 190/390 d_loss_real= 0.460, d_loss_fake= 0.377, g_loss 1.302, d_loss 0.419\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 191/390 d_loss_real= 0.561, d_loss_fake= 0.371, g_loss 1.299, d_loss 0.466\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 192/390 d_loss_real= 0.378, d_loss_fake= 0.383, g_loss 1.312, d_loss 0.381\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 193/390 d_loss_real= 0.587, d_loss_fake= 0.354, g_loss 1.318, d_loss 0.470\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 194/390 d_loss_real= 0.600, d_loss_fake= 0.367, g_loss 1.268, d_loss 0.483\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 195/390 d_loss_real= 0.779, d_loss_fake= 0.392, g_loss 1.225, d_loss 0.585\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 196/390 d_loss_real= 0.671, d_loss_fake= 0.407, g_loss 1.207, d_loss 0.539\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 197/390 d_loss_real= 0.653, d_loss_fake= 0.421, g_loss 1.165, d_loss 0.537\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 198/390 d_loss_real= 0.566, d_loss_fake= 0.435, g_loss 1.145, d_loss 0.501\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 15 Batch 199/390 d_loss_real= 0.783, d_loss_fake= 0.446, g_loss 1.126, d_loss 0.615\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 15 Batch 200/390 d_loss_real= 0.480, d_loss_fake= 0.437, g_loss 1.172, d_loss 0.459\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 201/390 d_loss_real= 0.687, d_loss_fake= 0.408, g_loss 1.216, d_loss 0.548\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 202/390 d_loss_real= 0.601, d_loss_fake= 0.385, g_loss 1.282, d_loss 0.493\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 203/390 d_loss_real= 0.632, d_loss_fake= 0.348, g_loss 1.335, d_loss 0.490\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 204/390 d_loss_real= 0.575, d_loss_fake= 0.333, g_loss 1.348, d_loss 0.454\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 205/390 d_loss_real= 0.817, d_loss_fake= 0.332, g_loss 1.319, d_loss 0.574\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 206/390 d_loss_real= 0.584, d_loss_fake= 0.347, g_loss 1.273, d_loss 0.466\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 207/390 d_loss_real= 0.616, d_loss_fake= 0.377, g_loss 1.240, d_loss 0.497\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 208/390 d_loss_real= 0.521, d_loss_fake= 0.379, g_loss 1.259, d_loss 0.450\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 15 Batch 209/390 d_loss_real= 0.548, d_loss_fake= 0.356, g_loss 1.294, d_loss 0.452\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 210/390 d_loss_real= 0.586, d_loss_fake= 0.346, g_loss 1.314, d_loss 0.466\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 211/390 d_loss_real= 0.683, d_loss_fake= 0.348, g_loss 1.286, d_loss 0.515\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 212/390 d_loss_real= 0.564, d_loss_fake= 0.364, g_loss 1.242, d_loss 0.464\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 213/390 d_loss_real= 0.406, d_loss_fake= 0.380, g_loss 1.245, d_loss 0.393\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 15 Batch 214/390 d_loss_real= 0.555, d_loss_fake= 0.366, g_loss 1.262, d_loss 0.460\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 15 Batch 215/390 d_loss_real= 0.482, d_loss_fake= 0.359, g_loss 1.310, d_loss 0.420\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 216/390 d_loss_real= 0.509, d_loss_fake= 0.342, g_loss 1.340, d_loss 0.425\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 15 Batch 217/390 d_loss_real= 0.506, d_loss_fake= 0.326, g_loss 1.382, d_loss 0.416\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 218/390 d_loss_real= 0.663, d_loss_fake= 0.320, g_loss 1.362, d_loss 0.491\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 15 Batch 219/390 d_loss_real= 0.580, d_loss_fake= 0.324, g_loss 1.325, d_loss 0.452\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 15 Batch 220/390 d_loss_real= 0.544, d_loss_fake= 0.350, g_loss 1.271, d_loss 0.447\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 221/390 d_loss_real= 0.553, d_loss_fake= 0.377, g_loss 1.203, d_loss 0.465\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 222/390 d_loss_real= 0.396, d_loss_fake= 0.410, g_loss 1.173, d_loss 0.403\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 15 Batch 223/390 d_loss_real= 0.490, d_loss_fake= 0.412, g_loss 1.158, d_loss 0.451\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 15 Batch 224/390 d_loss_real= 0.537, d_loss_fake= 0.401, g_loss 1.176, d_loss 0.469\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 225/390 d_loss_real= 0.525, d_loss_fake= 0.386, g_loss 1.211, d_loss 0.455\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 15 Batch 226/390 d_loss_real= 0.471, d_loss_fake= 0.381, g_loss 1.271, d_loss 0.426\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 15 Batch 227/390 d_loss_real= 0.592, d_loss_fake= 0.359, g_loss 1.259, d_loss 0.475\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 228/390 d_loss_real= 0.502, d_loss_fake= 0.361, g_loss 1.240, d_loss 0.431\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 229/390 d_loss_real= 0.495, d_loss_fake= 0.402, g_loss 1.196, d_loss 0.449\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 230/390 d_loss_real= 0.433, d_loss_fake= 0.403, g_loss 1.138, d_loss 0.418\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 231/390 d_loss_real= 0.558, d_loss_fake= 0.436, g_loss 1.146, d_loss 0.497\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 15 Batch 232/390 d_loss_real= 0.597, d_loss_fake= 0.465, g_loss 1.064, d_loss 0.531\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 15 Batch 233/390 d_loss_real= 0.674, d_loss_fake= 0.480, g_loss 1.043, d_loss 0.577\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 234/390 d_loss_real= 0.509, d_loss_fake= 0.463, g_loss 1.047, d_loss 0.486\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 15 Batch 235/390 d_loss_real= 0.531, d_loss_fake= 0.440, g_loss 1.090, d_loss 0.485\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 236/390 d_loss_real= 0.528, d_loss_fake= 0.435, g_loss 1.140, d_loss 0.481\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 15 Batch 237/390 d_loss_real= 0.593, d_loss_fake= 0.413, g_loss 1.197, d_loss 0.503\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 15 Batch 238/390 d_loss_real= 0.720, d_loss_fake= 0.389, g_loss 1.242, d_loss 0.554\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 239/390 d_loss_real= 0.607, d_loss_fake= 0.363, g_loss 1.273, d_loss 0.485\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 240/390 d_loss_real= 0.570, d_loss_fake= 0.369, g_loss 1.251, d_loss 0.469\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 15 Batch 241/390 d_loss_real= 0.557, d_loss_fake= 0.379, g_loss 1.245, d_loss 0.468\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 242/390 d_loss_real= 0.648, d_loss_fake= 0.377, g_loss 1.208, d_loss 0.513\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 15 Batch 243/390 d_loss_real= 0.529, d_loss_fake= 0.403, g_loss 1.133, d_loss 0.466\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 15 Batch 244/390 d_loss_real= 0.546, d_loss_fake= 0.428, g_loss 1.084, d_loss 0.487\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 245/390 d_loss_real= 0.380, d_loss_fake= 0.459, g_loss 1.095, d_loss 0.419\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 246/390 d_loss_real= 0.518, d_loss_fake= 0.451, g_loss 1.097, d_loss 0.484\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 247/390 d_loss_real= 0.425, d_loss_fake= 0.445, g_loss 1.126, d_loss 0.435\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 15 Batch 248/390 d_loss_real= 0.524, d_loss_fake= 0.418, g_loss 1.156, d_loss 0.471\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 249/390 d_loss_real= 0.430, d_loss_fake= 0.399, g_loss 1.207, d_loss 0.415\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 250/390 d_loss_real= 0.400, d_loss_fake= 0.379, g_loss 1.236, d_loss 0.389\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 251/390 d_loss_real= 0.485, d_loss_fake= 0.362, g_loss 1.247, d_loss 0.424\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 15 Batch 252/390 d_loss_real= 0.620, d_loss_fake= 0.366, g_loss 1.260, d_loss 0.493\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 253/390 d_loss_real= 0.471, d_loss_fake= 0.369, g_loss 1.243, d_loss 0.420\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 254/390 d_loss_real= 0.464, d_loss_fake= 0.384, g_loss 1.197, d_loss 0.424\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 255/390 d_loss_real= 0.572, d_loss_fake= 0.388, g_loss 1.169, d_loss 0.480\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 256/390 d_loss_real= 0.417, d_loss_fake= 0.398, g_loss 1.207, d_loss 0.407\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 15 Batch 257/390 d_loss_real= 0.437, d_loss_fake= 0.391, g_loss 1.178, d_loss 0.414\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 258/390 d_loss_real= 0.394, d_loss_fake= 0.403, g_loss 1.244, d_loss 0.399\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 259/390 d_loss_real= 0.419, d_loss_fake= 0.393, g_loss 1.256, d_loss 0.406\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 260/390 d_loss_real= 0.405, d_loss_fake= 0.346, g_loss 1.273, d_loss 0.376\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 15 Batch 261/390 d_loss_real= 0.599, d_loss_fake= 0.357, g_loss 1.267, d_loss 0.478\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 262/390 d_loss_real= 0.508, d_loss_fake= 0.367, g_loss 1.235, d_loss 0.437\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 15 Batch 263/390 d_loss_real= 0.440, d_loss_fake= 0.376, g_loss 1.195, d_loss 0.408\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 264/390 d_loss_real= 0.411, d_loss_fake= 0.397, g_loss 1.206, d_loss 0.404\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 265/390 d_loss_real= 0.492, d_loss_fake= 0.403, g_loss 1.223, d_loss 0.447\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 15 Batch 266/390 d_loss_real= 0.394, d_loss_fake= 0.383, g_loss 1.253, d_loss 0.389\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 267/390 d_loss_real= 0.457, d_loss_fake= 0.349, g_loss 1.279, d_loss 0.403\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 268/390 d_loss_real= 0.556, d_loss_fake= 0.360, g_loss 1.286, d_loss 0.458\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 269/390 d_loss_real= 0.511, d_loss_fake= 0.366, g_loss 1.287, d_loss 0.439\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 270/390 d_loss_real= 0.428, d_loss_fake= 0.375, g_loss 1.232, d_loss 0.402\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 271/390 d_loss_real= 0.561, d_loss_fake= 0.398, g_loss 1.209, d_loss 0.480\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 272/390 d_loss_real= 0.523, d_loss_fake= 0.395, g_loss 1.204, d_loss 0.459\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 15 Batch 273/390 d_loss_real= 0.488, d_loss_fake= 0.399, g_loss 1.221, d_loss 0.443\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 274/390 d_loss_real= 0.600, d_loss_fake= 0.403, g_loss 1.237, d_loss 0.502\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 275/390 d_loss_real= 0.495, d_loss_fake= 0.390, g_loss 1.219, d_loss 0.443\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 276/390 d_loss_real= 0.515, d_loss_fake= 0.370, g_loss 1.268, d_loss 0.443\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 277/390 d_loss_real= 0.490, d_loss_fake= 0.356, g_loss 1.319, d_loss 0.423\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 278/390 d_loss_real= 0.678, d_loss_fake= 0.345, g_loss 1.314, d_loss 0.511\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 15 Batch 279/390 d_loss_real= 0.540, d_loss_fake= 0.333, g_loss 1.316, d_loss 0.437\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 280/390 d_loss_real= 0.497, d_loss_fake= 0.332, g_loss 1.305, d_loss 0.415\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 15 Batch 281/390 d_loss_real= 0.375, d_loss_fake= 0.335, g_loss 1.310, d_loss 0.355\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 282/390 d_loss_real= 0.481, d_loss_fake= 0.339, g_loss 1.336, d_loss 0.410\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 15 Batch 283/390 d_loss_real= 0.339, d_loss_fake= 0.324, g_loss 1.378, d_loss 0.331\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 284/390 d_loss_real= 0.400, d_loss_fake= 0.308, g_loss 1.412, d_loss 0.354\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 285/390 d_loss_real= 0.469, d_loss_fake= 0.304, g_loss 1.402, d_loss 0.386\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 286/390 d_loss_real= 0.384, d_loss_fake= 0.299, g_loss 1.393, d_loss 0.341\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 15 Batch 287/390 d_loss_real= 0.399, d_loss_fake= 0.318, g_loss 1.382, d_loss 0.358\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 288/390 d_loss_real= 0.308, d_loss_fake= 0.303, g_loss 1.388, d_loss 0.306\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 15 Batch 289/390 d_loss_real= 0.495, d_loss_fake= 0.309, g_loss 1.382, d_loss 0.402\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 290/390 d_loss_real= 0.439, d_loss_fake= 0.323, g_loss 1.345, d_loss 0.381\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 291/390 d_loss_real= 0.435, d_loss_fake= 0.338, g_loss 1.292, d_loss 0.387\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 292/390 d_loss_real= 0.379, d_loss_fake= 0.339, g_loss 1.295, d_loss 0.359\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 293/390 d_loss_real= 0.421, d_loss_fake= 0.356, g_loss 1.240, d_loss 0.388\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 294/390 d_loss_real= 0.481, d_loss_fake= 0.372, g_loss 1.253, d_loss 0.426\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 295/390 d_loss_real= 0.479, d_loss_fake= 0.387, g_loss 1.196, d_loss 0.433\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 296/390 d_loss_real= 0.332, d_loss_fake= 0.423, g_loss 1.228, d_loss 0.378\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 297/390 d_loss_real= 0.408, d_loss_fake= 0.396, g_loss 1.216, d_loss 0.402\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 298/390 d_loss_real= 0.428, d_loss_fake= 0.406, g_loss 1.186, d_loss 0.417\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 299/390 d_loss_real= 0.330, d_loss_fake= 0.412, g_loss 1.168, d_loss 0.371\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 15 Batch 300/390 d_loss_real= 0.435, d_loss_fake= 0.428, g_loss 1.195, d_loss 0.431\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 301/390 d_loss_real= 0.422, d_loss_fake= 0.454, g_loss 1.117, d_loss 0.438\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 15 Batch 302/390 d_loss_real= 0.382, d_loss_fake= 0.444, g_loss 1.116, d_loss 0.413\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 15 Batch 303/390 d_loss_real= 0.610, d_loss_fake= 0.438, g_loss 1.067, d_loss 0.524\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 15 Batch 304/390 d_loss_real= 0.417, d_loss_fake= 0.474, g_loss 1.044, d_loss 0.446\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 305/390 d_loss_real= 0.603, d_loss_fake= 0.481, g_loss 1.050, d_loss 0.542\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 15 Batch 306/390 d_loss_real= 0.436, d_loss_fake= 0.500, g_loss 1.010, d_loss 0.468\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 307/390 d_loss_real= 0.506, d_loss_fake= 0.492, g_loss 1.041, d_loss 0.499\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 308/390 d_loss_real= 0.629, d_loss_fake= 0.475, g_loss 1.071, d_loss 0.552\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 15 Batch 309/390 d_loss_real= 0.483, d_loss_fake= 0.466, g_loss 1.115, d_loss 0.474\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 15 Batch 310/390 d_loss_real= 0.524, d_loss_fake= 0.451, g_loss 1.143, d_loss 0.487\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 311/390 d_loss_real= 0.468, d_loss_fake= 0.414, g_loss 1.154, d_loss 0.441\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 15 Batch 312/390 d_loss_real= 0.404, d_loss_fake= 0.400, g_loss 1.191, d_loss 0.402\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 313/390 d_loss_real= 0.369, d_loss_fake= 0.407, g_loss 1.163, d_loss 0.388\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 314/390 d_loss_real= 0.464, d_loss_fake= 0.450, g_loss 1.115, d_loss 0.457\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 315/390 d_loss_real= 0.411, d_loss_fake= 0.447, g_loss 1.104, d_loss 0.429\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 15 Batch 316/390 d_loss_real= 0.411, d_loss_fake= 0.480, g_loss 1.086, d_loss 0.446\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 317/390 d_loss_real= 0.461, d_loss_fake= 0.469, g_loss 1.116, d_loss 0.465\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 318/390 d_loss_real= 0.549, d_loss_fake= 0.453, g_loss 1.153, d_loss 0.501\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 319/390 d_loss_real= 0.759, d_loss_fake= 0.438, g_loss 1.133, d_loss 0.599\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 15 Batch 320/390 d_loss_real= 0.622, d_loss_fake= 0.454, g_loss 1.118, d_loss 0.538\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 15 Batch 321/390 d_loss_real= 0.540, d_loss_fake= 0.461, g_loss 1.120, d_loss 0.501\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 15 Batch 322/390 d_loss_real= 0.601, d_loss_fake= 0.447, g_loss 1.099, d_loss 0.524\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 15 Batch 323/390 d_loss_real= 0.670, d_loss_fake= 0.451, g_loss 1.094, d_loss 0.561\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 15 Batch 324/390 d_loss_real= 0.592, d_loss_fake= 0.467, g_loss 1.100, d_loss 0.530\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 325/390 d_loss_real= 0.637, d_loss_fake= 0.457, g_loss 1.119, d_loss 0.547\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 326/390 d_loss_real= 0.555, d_loss_fake= 0.421, g_loss 1.200, d_loss 0.488\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 327/390 d_loss_real= 0.602, d_loss_fake= 0.396, g_loss 1.231, d_loss 0.499\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 328/390 d_loss_real= 0.594, d_loss_fake= 0.373, g_loss 1.251, d_loss 0.484\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 329/390 d_loss_real= 0.681, d_loss_fake= 0.369, g_loss 1.249, d_loss 0.525\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 330/390 d_loss_real= 0.531, d_loss_fake= 0.370, g_loss 1.227, d_loss 0.451\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 331/390 d_loss_real= 0.353, d_loss_fake= 0.381, g_loss 1.251, d_loss 0.367\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 15 Batch 332/390 d_loss_real= 0.556, d_loss_fake= 0.371, g_loss 1.247, d_loss 0.464\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 333/390 d_loss_real= 0.699, d_loss_fake= 0.385, g_loss 1.233, d_loss 0.542\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 334/390 d_loss_real= 0.629, d_loss_fake= 0.375, g_loss 1.269, d_loss 0.502\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 335/390 d_loss_real= 0.559, d_loss_fake= 0.348, g_loss 1.339, d_loss 0.454\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 336/390 d_loss_real= 0.505, d_loss_fake= 0.345, g_loss 1.348, d_loss 0.425\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 337/390 d_loss_real= 0.501, d_loss_fake= 0.335, g_loss 1.351, d_loss 0.418\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 338/390 d_loss_real= 0.541, d_loss_fake= 0.335, g_loss 1.344, d_loss 0.438\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 339/390 d_loss_real= 0.474, d_loss_fake= 0.339, g_loss 1.338, d_loss 0.407\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 15 Batch 340/390 d_loss_real= 0.433, d_loss_fake= 0.339, g_loss 1.338, d_loss 0.386\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 341/390 d_loss_real= 0.472, d_loss_fake= 0.335, g_loss 1.329, d_loss 0.403\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 342/390 d_loss_real= 0.600, d_loss_fake= 0.340, g_loss 1.306, d_loss 0.470\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 343/390 d_loss_real= 0.527, d_loss_fake= 0.358, g_loss 1.266, d_loss 0.442\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 344/390 d_loss_real= 0.574, d_loss_fake= 0.368, g_loss 1.224, d_loss 0.471\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 345/390 d_loss_real= 0.590, d_loss_fake= 0.377, g_loss 1.233, d_loss 0.483\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 346/390 d_loss_real= 0.392, d_loss_fake= 0.381, g_loss 1.265, d_loss 0.386\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 347/390 d_loss_real= 0.461, d_loss_fake= 0.356, g_loss 1.281, d_loss 0.409\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 348/390 d_loss_real= 0.521, d_loss_fake= 0.349, g_loss 1.289, d_loss 0.435\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 349/390 d_loss_real= 0.479, d_loss_fake= 0.377, g_loss 1.270, d_loss 0.428\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 350/390 d_loss_real= 0.491, d_loss_fake= 0.391, g_loss 1.276, d_loss 0.441\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 351/390 d_loss_real= 0.378, d_loss_fake= 0.362, g_loss 1.276, d_loss 0.370\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 352/390 d_loss_real= 0.460, d_loss_fake= 0.372, g_loss 1.270, d_loss 0.416\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 353/390 d_loss_real= 0.569, d_loss_fake= 0.374, g_loss 1.225, d_loss 0.471\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 15 Batch 354/390 d_loss_real= 0.587, d_loss_fake= 0.402, g_loss 1.213, d_loss 0.494\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 355/390 d_loss_real= 0.350, d_loss_fake= 0.398, g_loss 1.158, d_loss 0.374\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 356/390 d_loss_real= 0.529, d_loss_fake= 0.406, g_loss 1.146, d_loss 0.467\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 15 Batch 357/390 d_loss_real= 0.549, d_loss_fake= 0.418, g_loss 1.146, d_loss 0.483\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 358/390 d_loss_real= 0.441, d_loss_fake= 0.424, g_loss 1.163, d_loss 0.432\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 15 Batch 359/390 d_loss_real= 0.372, d_loss_fake= 0.402, g_loss 1.179, d_loss 0.387\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 15 Batch 360/390 d_loss_real= 0.525, d_loss_fake= 0.409, g_loss 1.186, d_loss 0.467\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 361/390 d_loss_real= 0.593, d_loss_fake= 0.407, g_loss 1.178, d_loss 0.500\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 362/390 d_loss_real= 0.659, d_loss_fake= 0.411, g_loss 1.111, d_loss 0.535\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 363/390 d_loss_real= 0.469, d_loss_fake= 0.452, g_loss 1.123, d_loss 0.460\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 15 Batch 364/390 d_loss_real= 0.408, d_loss_fake= 0.430, g_loss 1.122, d_loss 0.419\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 15 Batch 365/390 d_loss_real= 0.626, d_loss_fake= 0.394, g_loss 1.179, d_loss 0.510\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 15 Batch 366/390 d_loss_real= 0.419, d_loss_fake= 0.387, g_loss 1.192, d_loss 0.403\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 367/390 d_loss_real= 0.499, d_loss_fake= 0.364, g_loss 1.244, d_loss 0.432\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 15 Batch 368/390 d_loss_real= 0.524, d_loss_fake= 0.375, g_loss 1.235, d_loss 0.449\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 15 Batch 369/390 d_loss_real= 0.592, d_loss_fake= 0.374, g_loss 1.227, d_loss 0.483\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 370/390 d_loss_real= 0.596, d_loss_fake= 0.382, g_loss 1.184, d_loss 0.489\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 15 Batch 371/390 d_loss_real= 0.511, d_loss_fake= 0.398, g_loss 1.167, d_loss 0.455\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 372/390 d_loss_real= 0.471, d_loss_fake= 0.399, g_loss 1.151, d_loss 0.435\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 373/390 d_loss_real= 0.404, d_loss_fake= 0.395, g_loss 1.165, d_loss 0.399\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 374/390 d_loss_real= 0.507, d_loss_fake= 0.389, g_loss 1.197, d_loss 0.448\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 375/390 d_loss_real= 0.547, d_loss_fake= 0.374, g_loss 1.215, d_loss 0.461\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 376/390 d_loss_real= 0.506, d_loss_fake= 0.363, g_loss 1.230, d_loss 0.435\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 377/390 d_loss_real= 0.366, d_loss_fake= 0.367, g_loss 1.238, d_loss 0.367\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 378/390 d_loss_real= 0.443, d_loss_fake= 0.379, g_loss 1.276, d_loss 0.411\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 379/390 d_loss_real= 0.414, d_loss_fake= 0.361, g_loss 1.283, d_loss 0.388\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 15 Batch 380/390 d_loss_real= 0.445, d_loss_fake= 0.334, g_loss 1.289, d_loss 0.389\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15 Batch 381/390 d_loss_real= 0.532, d_loss_fake= 0.348, g_loss 1.272, d_loss 0.440\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 15 Batch 382/390 d_loss_real= 0.395, d_loss_fake= 0.336, g_loss 1.297, d_loss 0.365\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15 Batch 383/390 d_loss_real= 0.397, d_loss_fake= 0.317, g_loss 1.252, d_loss 0.357\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 384/390 d_loss_real= 0.368, d_loss_fake= 0.351, g_loss 1.241, d_loss 0.359\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 15 Batch 385/390 d_loss_real= 0.344, d_loss_fake= 0.370, g_loss 1.237, d_loss 0.357\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 15 Batch 386/390 d_loss_real= 0.447, d_loss_fake= 0.383, g_loss 1.246, d_loss 0.415\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 15 Batch 387/390 d_loss_real= 0.431, d_loss_fake= 0.355, g_loss 1.224, d_loss 0.393\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15 Batch 388/390 d_loss_real= 0.421, d_loss_fake= 0.356, g_loss 1.258, d_loss 0.388\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 15 Batch 389/390 d_loss_real= 0.546, d_loss_fake= 0.350, g_loss 1.298, d_loss 0.448\n",
            "2/2 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15 Batch 390/390 d_loss_real= 0.405, d_loss_fake= 0.342, g_loss 1.265, d_loss 0.374\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 16 Batch 1/390 d_loss_real= 0.590, d_loss_fake= 0.347, g_loss 1.244, d_loss 0.468\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 2/390 d_loss_real= 0.300, d_loss_fake= 0.352, g_loss 1.244, d_loss 0.326\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 3/390 d_loss_real= 0.421, d_loss_fake= 0.362, g_loss 1.208, d_loss 0.392\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 4/390 d_loss_real= 0.542, d_loss_fake= 0.386, g_loss 1.163, d_loss 0.464\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 16 Batch 5/390 d_loss_real= 0.336, d_loss_fake= 0.386, g_loss 1.197, d_loss 0.361\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 16 Batch 6/390 d_loss_real= 0.394, d_loss_fake= 0.383, g_loss 1.191, d_loss 0.389\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 16 Batch 7/390 d_loss_real= 0.393, d_loss_fake= 0.375, g_loss 1.216, d_loss 0.384\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 8/390 d_loss_real= 0.453, d_loss_fake= 0.377, g_loss 1.228, d_loss 0.415\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 9/390 d_loss_real= 0.507, d_loss_fake= 0.376, g_loss 1.223, d_loss 0.442\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 10/390 d_loss_real= 0.476, d_loss_fake= 0.381, g_loss 1.200, d_loss 0.429\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 16 Batch 11/390 d_loss_real= 0.543, d_loss_fake= 0.415, g_loss 1.202, d_loss 0.479\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 12/390 d_loss_real= 0.361, d_loss_fake= 0.428, g_loss 1.167, d_loss 0.394\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 16 Batch 13/390 d_loss_real= 0.531, d_loss_fake= 0.412, g_loss 1.212, d_loss 0.472\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 16 Batch 14/390 d_loss_real= 0.453, d_loss_fake= 0.405, g_loss 1.145, d_loss 0.429\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 16 Batch 15/390 d_loss_real= 0.541, d_loss_fake= 0.375, g_loss 1.258, d_loss 0.458\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 16/390 d_loss_real= 0.473, d_loss_fake= 0.439, g_loss 1.092, d_loss 0.456\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 16 Batch 17/390 d_loss_real= 0.479, d_loss_fake= 0.382, g_loss 1.202, d_loss 0.431\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 16 Batch 18/390 d_loss_real= 0.492, d_loss_fake= 0.416, g_loss 1.141, d_loss 0.454\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 19/390 d_loss_real= 0.524, d_loss_fake= 0.467, g_loss 1.100, d_loss 0.495\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 16 Batch 20/390 d_loss_real= 0.337, d_loss_fake= 0.479, g_loss 1.034, d_loss 0.408\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 21/390 d_loss_real= 0.541, d_loss_fake= 0.439, g_loss 1.081, d_loss 0.490\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 16 Batch 22/390 d_loss_real= 0.413, d_loss_fake= 0.419, g_loss 1.143, d_loss 0.416\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 16 Batch 23/390 d_loss_real= 0.455, d_loss_fake= 0.456, g_loss 1.201, d_loss 0.456\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 16 Batch 24/390 d_loss_real= 0.615, d_loss_fake= 0.414, g_loss 1.184, d_loss 0.515\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 25/390 d_loss_real= 0.583, d_loss_fake= 0.337, g_loss 1.275, d_loss 0.460\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 16 Batch 26/390 d_loss_real= 0.506, d_loss_fake= 0.395, g_loss 1.217, d_loss 0.450\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 16 Batch 27/390 d_loss_real= 0.506, d_loss_fake= 0.389, g_loss 1.195, d_loss 0.448\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 28/390 d_loss_real= 0.469, d_loss_fake= 0.391, g_loss 1.176, d_loss 0.430\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 29/390 d_loss_real= 0.548, d_loss_fake= 0.456, g_loss 1.091, d_loss 0.502\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 30/390 d_loss_real= 0.365, d_loss_fake= 0.411, g_loss 1.168, d_loss 0.388\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 31/390 d_loss_real= 0.578, d_loss_fake= 0.375, g_loss 1.211, d_loss 0.477\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 32/390 d_loss_real= 0.544, d_loss_fake= 0.394, g_loss 1.131, d_loss 0.469\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 33/390 d_loss_real= 0.612, d_loss_fake= 0.363, g_loss 1.177, d_loss 0.488\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 16 Batch 34/390 d_loss_real= 0.485, d_loss_fake= 0.391, g_loss 1.157, d_loss 0.438\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 35/390 d_loss_real= 0.397, d_loss_fake= 0.433, g_loss 1.193, d_loss 0.415\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 36/390 d_loss_real= 0.426, d_loss_fake= 0.373, g_loss 1.240, d_loss 0.399\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 37/390 d_loss_real= 0.562, d_loss_fake= 0.360, g_loss 1.286, d_loss 0.461\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 38/390 d_loss_real= 0.522, d_loss_fake= 0.334, g_loss 1.325, d_loss 0.428\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 16 Batch 39/390 d_loss_real= 0.496, d_loss_fake= 0.319, g_loss 1.375, d_loss 0.408\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 40/390 d_loss_real= 0.664, d_loss_fake= 0.300, g_loss 1.422, d_loss 0.482\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 16 Batch 41/390 d_loss_real= 0.613, d_loss_fake= 0.324, g_loss 1.324, d_loss 0.468\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 16 Batch 42/390 d_loss_real= 0.521, d_loss_fake= 0.346, g_loss 1.320, d_loss 0.433\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 43/390 d_loss_real= 0.492, d_loss_fake= 0.352, g_loss 1.260, d_loss 0.422\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 44/390 d_loss_real= 0.420, d_loss_fake= 0.367, g_loss 1.251, d_loss 0.393\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 45/390 d_loss_real= 0.375, d_loss_fake= 0.357, g_loss 1.271, d_loss 0.366\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 16 Batch 46/390 d_loss_real= 0.519, d_loss_fake= 0.349, g_loss 1.260, d_loss 0.434\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 16 Batch 47/390 d_loss_real= 0.488, d_loss_fake= 0.345, g_loss 1.290, d_loss 0.417\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 48/390 d_loss_real= 0.524, d_loss_fake= 0.344, g_loss 1.335, d_loss 0.434\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 49/390 d_loss_real= 0.530, d_loss_fake= 0.333, g_loss 1.320, d_loss 0.431\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 16 Batch 50/390 d_loss_real= 0.451, d_loss_fake= 0.331, g_loss 1.363, d_loss 0.391\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 51/390 d_loss_real= 0.361, d_loss_fake= 0.307, g_loss 1.370, d_loss 0.334\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 52/390 d_loss_real= 0.678, d_loss_fake= 0.325, g_loss 1.377, d_loss 0.501\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 16 Batch 53/390 d_loss_real= 0.318, d_loss_fake= 0.310, g_loss 1.382, d_loss 0.314\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 16 Batch 54/390 d_loss_real= 0.594, d_loss_fake= 0.305, g_loss 1.359, d_loss 0.449\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 55/390 d_loss_real= 0.369, d_loss_fake= 0.319, g_loss 1.345, d_loss 0.344\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 56/390 d_loss_real= 0.480, d_loss_fake= 0.331, g_loss 1.305, d_loss 0.406\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 16 Batch 57/390 d_loss_real= 0.402, d_loss_fake= 0.339, g_loss 1.333, d_loss 0.370\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 16 Batch 58/390 d_loss_real= 0.447, d_loss_fake= 0.336, g_loss 1.323, d_loss 0.391\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 59/390 d_loss_real= 0.421, d_loss_fake= 0.329, g_loss 1.356, d_loss 0.375\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 16 Batch 60/390 d_loss_real= 0.452, d_loss_fake= 0.319, g_loss 1.393, d_loss 0.385\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 16 Batch 61/390 d_loss_real= 0.469, d_loss_fake= 0.310, g_loss 1.417, d_loss 0.389\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 16 Batch 62/390 d_loss_real= 0.419, d_loss_fake= 0.285, g_loss 1.458, d_loss 0.352\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 16 Batch 63/390 d_loss_real= 0.472, d_loss_fake= 0.284, g_loss 1.469, d_loss 0.378\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 16 Batch 64/390 d_loss_real= 0.639, d_loss_fake= 0.281, g_loss 1.428, d_loss 0.460\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 16 Batch 65/390 d_loss_real= 0.515, d_loss_fake= 0.302, g_loss 1.346, d_loss 0.408\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 66/390 d_loss_real= 0.475, d_loss_fake= 0.342, g_loss 1.309, d_loss 0.408\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 67/390 d_loss_real= 0.372, d_loss_fake= 0.330, g_loss 1.344, d_loss 0.351\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 68/390 d_loss_real= 0.407, d_loss_fake= 0.314, g_loss 1.390, d_loss 0.360\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 16 Batch 69/390 d_loss_real= 0.603, d_loss_fake= 0.309, g_loss 1.394, d_loss 0.456\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 70/390 d_loss_real= 0.397, d_loss_fake= 0.294, g_loss 1.451, d_loss 0.345\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 16 Batch 71/390 d_loss_real= 0.561, d_loss_fake= 0.285, g_loss 1.453, d_loss 0.423\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 16 Batch 72/390 d_loss_real= 0.552, d_loss_fake= 0.286, g_loss 1.428, d_loss 0.419\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 16 Batch 73/390 d_loss_real= 0.453, d_loss_fake= 0.293, g_loss 1.410, d_loss 0.373\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 74/390 d_loss_real= 0.486, d_loss_fake= 0.309, g_loss 1.372, d_loss 0.397\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 75/390 d_loss_real= 0.401, d_loss_fake= 0.306, g_loss 1.382, d_loss 0.354\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 76/390 d_loss_real= 0.474, d_loss_fake= 0.309, g_loss 1.383, d_loss 0.391\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 77/390 d_loss_real= 0.404, d_loss_fake= 0.305, g_loss 1.374, d_loss 0.355\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 78/390 d_loss_real= 0.439, d_loss_fake= 0.305, g_loss 1.395, d_loss 0.372\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 16 Batch 79/390 d_loss_real= 0.418, d_loss_fake= 0.295, g_loss 1.395, d_loss 0.357\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 80/390 d_loss_real= 0.474, d_loss_fake= 0.301, g_loss 1.388, d_loss 0.387\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 16 Batch 81/390 d_loss_real= 0.484, d_loss_fake= 0.304, g_loss 1.380, d_loss 0.394\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 82/390 d_loss_real= 0.390, d_loss_fake= 0.323, g_loss 1.352, d_loss 0.357\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 83/390 d_loss_real= 0.472, d_loss_fake= 0.324, g_loss 1.319, d_loss 0.398\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 84/390 d_loss_real= 0.465, d_loss_fake= 0.336, g_loss 1.313, d_loss 0.400\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 85/390 d_loss_real= 0.481, d_loss_fake= 0.343, g_loss 1.277, d_loss 0.412\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 86/390 d_loss_real= 0.306, d_loss_fake= 0.344, g_loss 1.284, d_loss 0.325\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 16 Batch 87/390 d_loss_real= 0.415, d_loss_fake= 0.359, g_loss 1.285, d_loss 0.387\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 88/390 d_loss_real= 0.483, d_loss_fake= 0.361, g_loss 1.248, d_loss 0.422\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 89/390 d_loss_real= 0.480, d_loss_fake= 0.362, g_loss 1.225, d_loss 0.421\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 90/390 d_loss_real= 0.516, d_loss_fake= 0.377, g_loss 1.238, d_loss 0.447\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 91/390 d_loss_real= 0.339, d_loss_fake= 0.380, g_loss 1.215, d_loss 0.360\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 92/390 d_loss_real= 0.319, d_loss_fake= 0.367, g_loss 1.242, d_loss 0.343\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 16 Batch 93/390 d_loss_real= 0.307, d_loss_fake= 0.379, g_loss 1.237, d_loss 0.343\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 94/390 d_loss_real= 0.389, d_loss_fake= 0.367, g_loss 1.245, d_loss 0.378\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 95/390 d_loss_real= 0.421, d_loss_fake= 0.383, g_loss 1.252, d_loss 0.402\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 16 Batch 96/390 d_loss_real= 0.482, d_loss_fake= 0.397, g_loss 1.213, d_loss 0.439\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 97/390 d_loss_real= 0.634, d_loss_fake= 0.402, g_loss 1.181, d_loss 0.518\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 98/390 d_loss_real= 0.435, d_loss_fake= 0.413, g_loss 1.146, d_loss 0.424\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 16 Batch 99/390 d_loss_real= 0.422, d_loss_fake= 0.419, g_loss 1.153, d_loss 0.420\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 100/390 d_loss_real= 0.412, d_loss_fake= 0.437, g_loss 1.113, d_loss 0.425\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 101/390 d_loss_real= 0.354, d_loss_fake= 0.445, g_loss 1.129, d_loss 0.399\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 16 Batch 102/390 d_loss_real= 0.411, d_loss_fake= 0.419, g_loss 1.160, d_loss 0.415\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 103/390 d_loss_real= 0.410, d_loss_fake= 0.399, g_loss 1.217, d_loss 0.404\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 16 Batch 104/390 d_loss_real= 0.285, d_loss_fake= 0.355, g_loss 1.272, d_loss 0.320\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 105/390 d_loss_real= 0.496, d_loss_fake= 0.334, g_loss 1.326, d_loss 0.415\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 106/390 d_loss_real= 0.475, d_loss_fake= 0.330, g_loss 1.342, d_loss 0.403\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 107/390 d_loss_real= 0.361, d_loss_fake= 0.332, g_loss 1.333, d_loss 0.347\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 108/390 d_loss_real= 0.403, d_loss_fake= 0.333, g_loss 1.279, d_loss 0.368\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 16 Batch 109/390 d_loss_real= 0.332, d_loss_fake= 0.350, g_loss 1.277, d_loss 0.341\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 110/390 d_loss_real= 0.370, d_loss_fake= 0.377, g_loss 1.236, d_loss 0.373\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 16 Batch 111/390 d_loss_real= 0.313, d_loss_fake= 0.371, g_loss 1.242, d_loss 0.342\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 16 Batch 112/390 d_loss_real= 0.359, d_loss_fake= 0.372, g_loss 1.265, d_loss 0.365\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 113/390 d_loss_real= 0.414, d_loss_fake= 0.364, g_loss 1.275, d_loss 0.389\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 114/390 d_loss_real= 0.481, d_loss_fake= 0.349, g_loss 1.318, d_loss 0.415\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 16 Batch 115/390 d_loss_real= 0.485, d_loss_fake= 0.346, g_loss 1.303, d_loss 0.416\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 16 Batch 116/390 d_loss_real= 0.515, d_loss_fake= 0.377, g_loss 1.302, d_loss 0.446\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 117/390 d_loss_real= 0.436, d_loss_fake= 0.353, g_loss 1.268, d_loss 0.394\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 118/390 d_loss_real= 0.442, d_loss_fake= 0.358, g_loss 1.228, d_loss 0.400\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 16 Batch 119/390 d_loss_real= 0.471, d_loss_fake= 0.397, g_loss 1.234, d_loss 0.434\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 120/390 d_loss_real= 0.482, d_loss_fake= 0.384, g_loss 1.243, d_loss 0.433\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 16 Batch 121/390 d_loss_real= 0.568, d_loss_fake= 0.375, g_loss 1.284, d_loss 0.472\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 16 Batch 122/390 d_loss_real= 0.505, d_loss_fake= 0.348, g_loss 1.333, d_loss 0.427\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 123/390 d_loss_real= 0.596, d_loss_fake= 0.345, g_loss 1.333, d_loss 0.471\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 16 Batch 124/390 d_loss_real= 0.492, d_loss_fake= 0.322, g_loss 1.399, d_loss 0.407\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 125/390 d_loss_real= 0.487, d_loss_fake= 0.316, g_loss 1.412, d_loss 0.401\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 126/390 d_loss_real= 0.501, d_loss_fake= 0.289, g_loss 1.430, d_loss 0.395\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 16 Batch 127/390 d_loss_real= 0.398, d_loss_fake= 0.290, g_loss 1.442, d_loss 0.344\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 16 Batch 128/390 d_loss_real= 0.452, d_loss_fake= 0.284, g_loss 1.471, d_loss 0.368\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 129/390 d_loss_real= 0.358, d_loss_fake= 0.279, g_loss 1.484, d_loss 0.319\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 130/390 d_loss_real= 0.474, d_loss_fake= 0.275, g_loss 1.493, d_loss 0.375\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 16 Batch 131/390 d_loss_real= 0.452, d_loss_fake= 0.265, g_loss 1.507, d_loss 0.358\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 132/390 d_loss_real= 0.409, d_loss_fake= 0.263, g_loss 1.499, d_loss 0.336\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 133/390 d_loss_real= 0.447, d_loss_fake= 0.275, g_loss 1.450, d_loss 0.361\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 134/390 d_loss_real= 0.304, d_loss_fake= 0.294, g_loss 1.422, d_loss 0.299\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 135/390 d_loss_real= 0.522, d_loss_fake= 0.302, g_loss 1.480, d_loss 0.412\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 136/390 d_loss_real= 0.382, d_loss_fake= 0.292, g_loss 1.472, d_loss 0.337\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 137/390 d_loss_real= 0.382, d_loss_fake= 0.294, g_loss 1.533, d_loss 0.338\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 138/390 d_loss_real= 0.450, d_loss_fake= 0.259, g_loss 1.547, d_loss 0.355\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 139/390 d_loss_real= 0.364, d_loss_fake= 0.257, g_loss 1.527, d_loss 0.310\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 140/390 d_loss_real= 0.438, d_loss_fake= 0.279, g_loss 1.501, d_loss 0.358\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 141/390 d_loss_real= 0.522, d_loss_fake= 0.295, g_loss 1.463, d_loss 0.408\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 142/390 d_loss_real= 0.394, d_loss_fake= 0.288, g_loss 1.506, d_loss 0.341\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 143/390 d_loss_real= 0.448, d_loss_fake= 0.288, g_loss 1.499, d_loss 0.368\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 16 Batch 144/390 d_loss_real= 0.369, d_loss_fake= 0.290, g_loss 1.486, d_loss 0.330\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 16 Batch 145/390 d_loss_real= 0.486, d_loss_fake= 0.285, g_loss 1.473, d_loss 0.386\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 16 Batch 146/390 d_loss_real= 0.392, d_loss_fake= 0.277, g_loss 1.487, d_loss 0.335\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 147/390 d_loss_real= 0.469, d_loss_fake= 0.290, g_loss 1.482, d_loss 0.379\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 148/390 d_loss_real= 0.516, d_loss_fake= 0.290, g_loss 1.459, d_loss 0.403\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 149/390 d_loss_real= 0.327, d_loss_fake= 0.292, g_loss 1.447, d_loss 0.309\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 16 Batch 150/390 d_loss_real= 0.568, d_loss_fake= 0.297, g_loss 1.425, d_loss 0.433\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 151/390 d_loss_real= 0.421, d_loss_fake= 0.315, g_loss 1.362, d_loss 0.368\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 16 Batch 152/390 d_loss_real= 0.487, d_loss_fake= 0.326, g_loss 1.330, d_loss 0.406\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 153/390 d_loss_real= 0.450, d_loss_fake= 0.354, g_loss 1.297, d_loss 0.402\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 154/390 d_loss_real= 0.320, d_loss_fake= 0.361, g_loss 1.278, d_loss 0.340\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 16 Batch 155/390 d_loss_real= 0.387, d_loss_fake= 0.375, g_loss 1.261, d_loss 0.381\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 156/390 d_loss_real= 0.259, d_loss_fake= 0.352, g_loss 1.287, d_loss 0.306\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 16 Batch 157/390 d_loss_real= 0.397, d_loss_fake= 0.341, g_loss 1.313, d_loss 0.369\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 158/390 d_loss_real= 0.493, d_loss_fake= 0.343, g_loss 1.343, d_loss 0.418\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 16 Batch 159/390 d_loss_real= 0.516, d_loss_fake= 0.338, g_loss 1.348, d_loss 0.427\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 160/390 d_loss_real= 0.409, d_loss_fake= 0.352, g_loss 1.333, d_loss 0.381\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 161/390 d_loss_real= 0.440, d_loss_fake= 0.373, g_loss 1.245, d_loss 0.407\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 162/390 d_loss_real= 0.401, d_loss_fake= 0.370, g_loss 1.255, d_loss 0.386\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 16 Batch 163/390 d_loss_real= 0.473, d_loss_fake= 0.380, g_loss 1.246, d_loss 0.426\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 16 Batch 164/390 d_loss_real= 0.396, d_loss_fake= 0.366, g_loss 1.246, d_loss 0.381\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 165/390 d_loss_real= 0.548, d_loss_fake= 0.377, g_loss 1.277, d_loss 0.463\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 16 Batch 166/390 d_loss_real= 0.351, d_loss_fake= 0.355, g_loss 1.353, d_loss 0.353\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 16 Batch 167/390 d_loss_real= 0.394, d_loss_fake= 0.331, g_loss 1.379, d_loss 0.363\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 16 Batch 168/390 d_loss_real= 0.348, d_loss_fake= 0.307, g_loss 1.418, d_loss 0.327\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 16 Batch 169/390 d_loss_real= 0.376, d_loss_fake= 0.282, g_loss 1.550, d_loss 0.329\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 16 Batch 170/390 d_loss_real= 0.440, d_loss_fake= 0.317, g_loss 1.383, d_loss 0.378\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 16 Batch 171/390 d_loss_real= 0.456, d_loss_fake= 0.323, g_loss 1.338, d_loss 0.389\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 172/390 d_loss_real= 0.552, d_loss_fake= 0.336, g_loss 1.288, d_loss 0.444\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 173/390 d_loss_real= 0.412, d_loss_fake= 0.362, g_loss 1.354, d_loss 0.387\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 174/390 d_loss_real= 0.328, d_loss_fake= 0.337, g_loss 1.398, d_loss 0.333\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 175/390 d_loss_real= 0.387, d_loss_fake= 0.317, g_loss 1.432, d_loss 0.352\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 16 Batch 176/390 d_loss_real= 0.547, d_loss_fake= 0.276, g_loss 1.496, d_loss 0.412\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 16 Batch 177/390 d_loss_real= 0.497, d_loss_fake= 0.323, g_loss 1.396, d_loss 0.410\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 16 Batch 178/390 d_loss_real= 0.521, d_loss_fake= 0.317, g_loss 1.353, d_loss 0.419\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 179/390 d_loss_real= 0.536, d_loss_fake= 0.357, g_loss 1.299, d_loss 0.446\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 180/390 d_loss_real= 0.278, d_loss_fake= 0.411, g_loss 1.232, d_loss 0.344\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 181/390 d_loss_real= 0.406, d_loss_fake= 0.396, g_loss 1.250, d_loss 0.401\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 182/390 d_loss_real= 0.501, d_loss_fake= 0.380, g_loss 1.266, d_loss 0.441\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 16 Batch 183/390 d_loss_real= 0.490, d_loss_fake= 0.375, g_loss 1.301, d_loss 0.432\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 16 Batch 184/390 d_loss_real= 0.567, d_loss_fake= 0.341, g_loss 1.308, d_loss 0.454\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 16 Batch 185/390 d_loss_real= 0.394, d_loss_fake= 0.347, g_loss 1.392, d_loss 0.370\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 16 Batch 186/390 d_loss_real= 0.590, d_loss_fake= 0.318, g_loss 1.432, d_loss 0.454\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 16 Batch 187/390 d_loss_real= 0.337, d_loss_fake= 0.307, g_loss 1.475, d_loss 0.322\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 188/390 d_loss_real= 0.549, d_loss_fake= 0.301, g_loss 1.456, d_loss 0.425\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 189/390 d_loss_real= 0.535, d_loss_fake= 0.298, g_loss 1.436, d_loss 0.417\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 16 Batch 190/390 d_loss_real= 0.497, d_loss_fake= 0.311, g_loss 1.409, d_loss 0.404\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 191/390 d_loss_real= 0.411, d_loss_fake= 0.328, g_loss 1.400, d_loss 0.370\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 16 Batch 192/390 d_loss_real= 0.506, d_loss_fake= 0.313, g_loss 1.402, d_loss 0.409\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 16 Batch 193/390 d_loss_real= 0.577, d_loss_fake= 0.315, g_loss 1.423, d_loss 0.446\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 194/390 d_loss_real= 0.444, d_loss_fake= 0.304, g_loss 1.436, d_loss 0.374\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 195/390 d_loss_real= 0.406, d_loss_fake= 0.299, g_loss 1.479, d_loss 0.353\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 16 Batch 196/390 d_loss_real= 0.544, d_loss_fake= 0.292, g_loss 1.470, d_loss 0.418\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 197/390 d_loss_real= 0.501, d_loss_fake= 0.290, g_loss 1.465, d_loss 0.396\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 198/390 d_loss_real= 0.421, d_loss_fake= 0.294, g_loss 1.467, d_loss 0.358\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 199/390 d_loss_real= 0.518, d_loss_fake= 0.294, g_loss 1.439, d_loss 0.406\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 16 Batch 200/390 d_loss_real= 0.482, d_loss_fake= 0.303, g_loss 1.438, d_loss 0.392\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 201/390 d_loss_real= 0.506, d_loss_fake= 0.292, g_loss 1.476, d_loss 0.399\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 202/390 d_loss_real= 0.398, d_loss_fake= 0.273, g_loss 1.508, d_loss 0.335\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 203/390 d_loss_real= 0.511, d_loss_fake= 0.269, g_loss 1.531, d_loss 0.390\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 204/390 d_loss_real= 0.351, d_loss_fake= 0.289, g_loss 1.495, d_loss 0.320\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 205/390 d_loss_real= 0.435, d_loss_fake= 0.275, g_loss 1.481, d_loss 0.355\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 16 Batch 206/390 d_loss_real= 0.571, d_loss_fake= 0.302, g_loss 1.449, d_loss 0.437\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 207/390 d_loss_real= 0.603, d_loss_fake= 0.309, g_loss 1.415, d_loss 0.456\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 208/390 d_loss_real= 0.527, d_loss_fake= 0.346, g_loss 1.366, d_loss 0.436\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 209/390 d_loss_real= 0.449, d_loss_fake= 0.356, g_loss 1.304, d_loss 0.402\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 210/390 d_loss_real= 0.501, d_loss_fake= 0.361, g_loss 1.357, d_loss 0.431\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 211/390 d_loss_real= 0.561, d_loss_fake= 0.312, g_loss 1.440, d_loss 0.436\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 212/390 d_loss_real= 0.532, d_loss_fake= 0.280, g_loss 1.474, d_loss 0.406\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 213/390 d_loss_real= 0.845, d_loss_fake= 0.288, g_loss 1.484, d_loss 0.566\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 16 Batch 214/390 d_loss_real= 0.432, d_loss_fake= 0.293, g_loss 1.479, d_loss 0.362\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 215/390 d_loss_real= 0.372, d_loss_fake= 0.286, g_loss 1.449, d_loss 0.329\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 216/390 d_loss_real= 0.566, d_loss_fake= 0.310, g_loss 1.419, d_loss 0.438\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 16 Batch 217/390 d_loss_real= 0.506, d_loss_fake= 0.331, g_loss 1.344, d_loss 0.419\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 16 Batch 218/390 d_loss_real= 0.483, d_loss_fake= 0.341, g_loss 1.354, d_loss 0.412\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 16 Batch 219/390 d_loss_real= 0.439, d_loss_fake= 0.322, g_loss 1.388, d_loss 0.380\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 220/390 d_loss_real= 0.460, d_loss_fake= 0.299, g_loss 1.443, d_loss 0.380\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 221/390 d_loss_real= 0.489, d_loss_fake= 0.288, g_loss 1.490, d_loss 0.389\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 222/390 d_loss_real= 0.432, d_loss_fake= 0.255, g_loss 1.520, d_loss 0.344\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 223/390 d_loss_real= 0.565, d_loss_fake= 0.267, g_loss 1.537, d_loss 0.416\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 224/390 d_loss_real= 0.572, d_loss_fake= 0.269, g_loss 1.457, d_loss 0.421\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 225/390 d_loss_real= 0.448, d_loss_fake= 0.307, g_loss 1.378, d_loss 0.377\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 226/390 d_loss_real= 0.507, d_loss_fake= 0.333, g_loss 1.299, d_loss 0.420\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 227/390 d_loss_real= 0.434, d_loss_fake= 0.359, g_loss 1.225, d_loss 0.396\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 228/390 d_loss_real= 0.341, d_loss_fake= 0.375, g_loss 1.290, d_loss 0.358\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 16 Batch 229/390 d_loss_real= 0.286, d_loss_fake= 0.338, g_loss 1.381, d_loss 0.312\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 230/390 d_loss_real= 0.340, d_loss_fake= 0.293, g_loss 1.504, d_loss 0.317\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 231/390 d_loss_real= 0.380, d_loss_fake= 0.261, g_loss 1.570, d_loss 0.320\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 232/390 d_loss_real= 0.307, d_loss_fake= 0.238, g_loss 1.599, d_loss 0.272\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 233/390 d_loss_real= 0.434, d_loss_fake= 0.236, g_loss 1.638, d_loss 0.335\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 234/390 d_loss_real= 0.442, d_loss_fake= 0.239, g_loss 1.600, d_loss 0.340\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 235/390 d_loss_real= 0.606, d_loss_fake= 0.257, g_loss 1.446, d_loss 0.431\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 16 Batch 236/390 d_loss_real= 0.391, d_loss_fake= 0.297, g_loss 1.382, d_loss 0.344\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 237/390 d_loss_real= 0.332, d_loss_fake= 0.326, g_loss 1.328, d_loss 0.329\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 16 Batch 238/390 d_loss_real= 0.520, d_loss_fake= 0.342, g_loss 1.302, d_loss 0.431\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 16 Batch 239/390 d_loss_real= 0.403, d_loss_fake= 0.351, g_loss 1.292, d_loss 0.377\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 240/390 d_loss_real= 0.333, d_loss_fake= 0.339, g_loss 1.318, d_loss 0.336\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 16 Batch 241/390 d_loss_real= 0.494, d_loss_fake= 0.326, g_loss 1.327, d_loss 0.410\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 242/390 d_loss_real= 0.609, d_loss_fake= 0.319, g_loss 1.336, d_loss 0.464\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 16 Batch 243/390 d_loss_real= 0.394, d_loss_fake= 0.322, g_loss 1.331, d_loss 0.358\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 16 Batch 244/390 d_loss_real= 0.448, d_loss_fake= 0.336, g_loss 1.303, d_loss 0.392\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 245/390 d_loss_real= 0.468, d_loss_fake= 0.344, g_loss 1.303, d_loss 0.406\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 16 Batch 246/390 d_loss_real= 0.402, d_loss_fake= 0.347, g_loss 1.289, d_loss 0.375\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 247/390 d_loss_real= 0.436, d_loss_fake= 0.360, g_loss 1.279, d_loss 0.398\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 16 Batch 248/390 d_loss_real= 0.437, d_loss_fake= 0.370, g_loss 1.235, d_loss 0.403\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 249/390 d_loss_real= 0.512, d_loss_fake= 0.370, g_loss 1.272, d_loss 0.441\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 250/390 d_loss_real= 0.439, d_loss_fake= 0.347, g_loss 1.334, d_loss 0.393\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 251/390 d_loss_real= 0.527, d_loss_fake= 0.325, g_loss 1.396, d_loss 0.426\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 16 Batch 252/390 d_loss_real= 0.556, d_loss_fake= 0.307, g_loss 1.425, d_loss 0.431\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 16 Batch 253/390 d_loss_real= 0.466, d_loss_fake= 0.301, g_loss 1.424, d_loss 0.384\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 254/390 d_loss_real= 0.445, d_loss_fake= 0.303, g_loss 1.402, d_loss 0.374\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 255/390 d_loss_real= 0.244, d_loss_fake= 0.288, g_loss 1.430, d_loss 0.266\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 256/390 d_loss_real= 0.371, d_loss_fake= 0.300, g_loss 1.432, d_loss 0.336\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 16 Batch 257/390 d_loss_real= 0.477, d_loss_fake= 0.291, g_loss 1.423, d_loss 0.384\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 16 Batch 258/390 d_loss_real= 0.457, d_loss_fake= 0.298, g_loss 1.384, d_loss 0.378\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 259/390 d_loss_real= 0.512, d_loss_fake= 0.296, g_loss 1.353, d_loss 0.404\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 260/390 d_loss_real= 0.420, d_loss_fake= 0.334, g_loss 1.287, d_loss 0.377\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 261/390 d_loss_real= 0.475, d_loss_fake= 0.358, g_loss 1.313, d_loss 0.417\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 16 Batch 262/390 d_loss_real= 0.426, d_loss_fake= 0.328, g_loss 1.313, d_loss 0.377\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 263/390 d_loss_real= 0.427, d_loss_fake= 0.341, g_loss 1.317, d_loss 0.384\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 264/390 d_loss_real= 0.432, d_loss_fake= 0.328, g_loss 1.356, d_loss 0.380\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 16 Batch 265/390 d_loss_real= 0.417, d_loss_fake= 0.319, g_loss 1.393, d_loss 0.368\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 16 Batch 266/390 d_loss_real= 0.463, d_loss_fake= 0.294, g_loss 1.401, d_loss 0.379\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 267/390 d_loss_real= 0.576, d_loss_fake= 0.283, g_loss 1.415, d_loss 0.429\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 16 Batch 268/390 d_loss_real= 0.468, d_loss_fake= 0.297, g_loss 1.410, d_loss 0.382\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 269/390 d_loss_real= 0.437, d_loss_fake= 0.293, g_loss 1.392, d_loss 0.365\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 16 Batch 270/390 d_loss_real= 0.377, d_loss_fake= 0.309, g_loss 1.384, d_loss 0.343\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 271/390 d_loss_real= 0.408, d_loss_fake= 0.318, g_loss 1.362, d_loss 0.363\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 272/390 d_loss_real= 0.448, d_loss_fake= 0.313, g_loss 1.372, d_loss 0.380\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 16 Batch 273/390 d_loss_real= 0.451, d_loss_fake= 0.334, g_loss 1.298, d_loss 0.392\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 16 Batch 274/390 d_loss_real= 0.312, d_loss_fake= 0.344, g_loss 1.350, d_loss 0.328\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 16 Batch 275/390 d_loss_real= 0.617, d_loss_fake= 0.339, g_loss 1.305, d_loss 0.478\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 16 Batch 276/390 d_loss_real= 0.443, d_loss_fake= 0.336, g_loss 1.344, d_loss 0.390\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 277/390 d_loss_real= 0.491, d_loss_fake= 0.326, g_loss 1.393, d_loss 0.408\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 278/390 d_loss_real= 0.533, d_loss_fake= 0.318, g_loss 1.394, d_loss 0.426\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 279/390 d_loss_real= 0.427, d_loss_fake= 0.281, g_loss 1.492, d_loss 0.354\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 280/390 d_loss_real= 0.383, d_loss_fake= 0.290, g_loss 1.477, d_loss 0.337\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 16 Batch 281/390 d_loss_real= 0.527, d_loss_fake= 0.286, g_loss 1.440, d_loss 0.407\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 16 Batch 282/390 d_loss_real= 0.365, d_loss_fake= 0.291, g_loss 1.468, d_loss 0.328\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 16 Batch 283/390 d_loss_real= 0.531, d_loss_fake= 0.299, g_loss 1.454, d_loss 0.415\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 284/390 d_loss_real= 0.332, d_loss_fake= 0.299, g_loss 1.440, d_loss 0.316\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 285/390 d_loss_real= 0.331, d_loss_fake= 0.292, g_loss 1.439, d_loss 0.311\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 16 Batch 286/390 d_loss_real= 0.353, d_loss_fake= 0.281, g_loss 1.536, d_loss 0.317\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 16 Batch 287/390 d_loss_real= 0.350, d_loss_fake= 0.267, g_loss 1.593, d_loss 0.308\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 16 Batch 288/390 d_loss_real= 0.430, d_loss_fake= 0.248, g_loss 1.548, d_loss 0.339\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 289/390 d_loss_real= 0.266, d_loss_fake= 0.275, g_loss 1.572, d_loss 0.270\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 16 Batch 290/390 d_loss_real= 0.373, d_loss_fake= 0.261, g_loss 1.557, d_loss 0.317\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 291/390 d_loss_real= 0.377, d_loss_fake= 0.285, g_loss 1.521, d_loss 0.331\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 292/390 d_loss_real= 0.473, d_loss_fake= 0.260, g_loss 1.609, d_loss 0.366\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 16 Batch 293/390 d_loss_real= 0.267, d_loss_fake= 0.260, g_loss 1.597, d_loss 0.263\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 294/390 d_loss_real= 0.349, d_loss_fake= 0.257, g_loss 1.616, d_loss 0.303\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 295/390 d_loss_real= 0.306, d_loss_fake= 0.266, g_loss 1.625, d_loss 0.286\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 296/390 d_loss_real= 0.380, d_loss_fake= 0.259, g_loss 1.650, d_loss 0.319\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 16 Batch 297/390 d_loss_real= 0.502, d_loss_fake= 0.245, g_loss 1.614, d_loss 0.373\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 16 Batch 298/390 d_loss_real= 0.506, d_loss_fake= 0.267, g_loss 1.548, d_loss 0.387\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 16 Batch 299/390 d_loss_real= 0.568, d_loss_fake= 0.372, g_loss 1.447, d_loss 0.470\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 16 Batch 300/390 d_loss_real= 0.537, d_loss_fake= 0.435, g_loss 1.362, d_loss 0.486\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 301/390 d_loss_real= 0.465, d_loss_fake= 0.400, g_loss 1.436, d_loss 0.433\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 16 Batch 302/390 d_loss_real= 0.627, d_loss_fake= 0.323, g_loss 1.560, d_loss 0.475\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 16 Batch 303/390 d_loss_real= 0.589, d_loss_fake= 0.265, g_loss 1.667, d_loss 0.427\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 16 Batch 304/390 d_loss_real= 0.684, d_loss_fake= 0.241, g_loss 1.678, d_loss 0.463\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 16 Batch 305/390 d_loss_real= 0.776, d_loss_fake= 0.229, g_loss 1.660, d_loss 0.503\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 16 Batch 306/390 d_loss_real= 0.385, d_loss_fake= 0.237, g_loss 1.610, d_loss 0.311\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 307/390 d_loss_real= 0.414, d_loss_fake= 0.264, g_loss 1.558, d_loss 0.339\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 16 Batch 308/390 d_loss_real= 0.318, d_loss_fake= 0.262, g_loss 1.597, d_loss 0.290\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 309/390 d_loss_real= 0.384, d_loss_fake= 0.256, g_loss 1.594, d_loss 0.320\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 310/390 d_loss_real= 0.377, d_loss_fake= 0.258, g_loss 1.607, d_loss 0.318\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 16 Batch 311/390 d_loss_real= 0.384, d_loss_fake= 0.244, g_loss 1.602, d_loss 0.314\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 312/390 d_loss_real= 0.310, d_loss_fake= 0.243, g_loss 1.597, d_loss 0.277\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 16 Batch 313/390 d_loss_real= 0.338, d_loss_fake= 0.246, g_loss 1.586, d_loss 0.292\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 16 Batch 314/390 d_loss_real= 0.431, d_loss_fake= 0.250, g_loss 1.528, d_loss 0.341\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 315/390 d_loss_real= 0.465, d_loss_fake= 0.281, g_loss 1.482, d_loss 0.373\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 316/390 d_loss_real= 0.418, d_loss_fake= 0.292, g_loss 1.437, d_loss 0.355\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 16 Batch 317/390 d_loss_real= 0.318, d_loss_fake= 0.320, g_loss 1.415, d_loss 0.319\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 318/390 d_loss_real= 0.291, d_loss_fake= 0.322, g_loss 1.397, d_loss 0.306\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 319/390 d_loss_real= 0.380, d_loss_fake= 0.308, g_loss 1.414, d_loss 0.344\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 16 Batch 320/390 d_loss_real= 0.397, d_loss_fake= 0.312, g_loss 1.401, d_loss 0.354\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 321/390 d_loss_real= 0.298, d_loss_fake= 0.320, g_loss 1.382, d_loss 0.309\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 16 Batch 322/390 d_loss_real= 0.529, d_loss_fake= 0.325, g_loss 1.400, d_loss 0.427\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 323/390 d_loss_real= 0.447, d_loss_fake= 0.332, g_loss 1.361, d_loss 0.390\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 324/390 d_loss_real= 0.350, d_loss_fake= 0.337, g_loss 1.374, d_loss 0.343\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 325/390 d_loss_real= 0.292, d_loss_fake= 0.352, g_loss 1.359, d_loss 0.322\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 326/390 d_loss_real= 0.446, d_loss_fake= 0.331, g_loss 1.392, d_loss 0.388\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 327/390 d_loss_real= 0.423, d_loss_fake= 0.310, g_loss 1.430, d_loss 0.367\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 328/390 d_loss_real= 0.780, d_loss_fake= 0.320, g_loss 1.453, d_loss 0.550\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 329/390 d_loss_real= 0.525, d_loss_fake= 0.313, g_loss 1.410, d_loss 0.419\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 16 Batch 330/390 d_loss_real= 0.628, d_loss_fake= 0.322, g_loss 1.392, d_loss 0.475\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 331/390 d_loss_real= 0.511, d_loss_fake= 0.317, g_loss 1.354, d_loss 0.414\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 332/390 d_loss_real= 0.590, d_loss_fake= 0.333, g_loss 1.321, d_loss 0.461\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 16 Batch 333/390 d_loss_real= 0.709, d_loss_fake= 0.360, g_loss 1.275, d_loss 0.534\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 334/390 d_loss_real= 0.509, d_loss_fake= 0.369, g_loss 1.262, d_loss 0.439\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 335/390 d_loss_real= 0.382, d_loss_fake= 0.352, g_loss 1.303, d_loss 0.367\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 336/390 d_loss_real= 0.562, d_loss_fake= 0.341, g_loss 1.344, d_loss 0.452\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 337/390 d_loss_real= 0.383, d_loss_fake= 0.314, g_loss 1.427, d_loss 0.349\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 338/390 d_loss_real= 0.522, d_loss_fake= 0.295, g_loss 1.498, d_loss 0.408\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 16 Batch 339/390 d_loss_real= 0.513, d_loss_fake= 0.299, g_loss 1.488, d_loss 0.406\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 340/390 d_loss_real= 0.385, d_loss_fake= 0.285, g_loss 1.465, d_loss 0.335\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 341/390 d_loss_real= 0.397, d_loss_fake= 0.305, g_loss 1.376, d_loss 0.351\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 342/390 d_loss_real= 0.250, d_loss_fake= 0.331, g_loss 1.353, d_loss 0.290\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 16 Batch 343/390 d_loss_real= 0.328, d_loss_fake= 0.339, g_loss 1.378, d_loss 0.334\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 16 Batch 344/390 d_loss_real= 0.343, d_loss_fake= 0.333, g_loss 1.393, d_loss 0.338\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 345/390 d_loss_real= 0.309, d_loss_fake= 0.302, g_loss 1.537, d_loss 0.306\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 346/390 d_loss_real= 0.384, d_loss_fake= 0.257, g_loss 1.618, d_loss 0.320\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 347/390 d_loss_real= 0.329, d_loss_fake= 0.232, g_loss 1.705, d_loss 0.280\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 16 Batch 348/390 d_loss_real= 0.334, d_loss_fake= 0.210, g_loss 1.775, d_loss 0.272\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 349/390 d_loss_real= 0.457, d_loss_fake= 0.198, g_loss 1.766, d_loss 0.328\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 350/390 d_loss_real= 0.312, d_loss_fake= 0.216, g_loss 1.660, d_loss 0.264\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 351/390 d_loss_real= 0.496, d_loss_fake= 0.247, g_loss 1.558, d_loss 0.372\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 16 Batch 352/390 d_loss_real= 0.319, d_loss_fake= 0.281, g_loss 1.476, d_loss 0.300\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 16 Batch 353/390 d_loss_real= 0.269, d_loss_fake= 0.293, g_loss 1.464, d_loss 0.281\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 354/390 d_loss_real= 0.346, d_loss_fake= 0.311, g_loss 1.504, d_loss 0.329\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 355/390 d_loss_real= 0.489, d_loss_fake= 0.287, g_loss 1.578, d_loss 0.388\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 16 Batch 356/390 d_loss_real= 0.457, d_loss_fake= 0.262, g_loss 1.687, d_loss 0.359\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 16 Batch 357/390 d_loss_real= 0.536, d_loss_fake= 0.222, g_loss 1.756, d_loss 0.379\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 16 Batch 358/390 d_loss_real= 0.510, d_loss_fake= 0.214, g_loss 1.762, d_loss 0.362\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 16 Batch 359/390 d_loss_real= 0.427, d_loss_fake= 0.244, g_loss 1.635, d_loss 0.336\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 16 Batch 360/390 d_loss_real= 0.359, d_loss_fake= 0.291, g_loss 1.541, d_loss 0.325\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 16 Batch 361/390 d_loss_real= 0.314, d_loss_fake= 0.314, g_loss 1.541, d_loss 0.314\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 16 Batch 362/390 d_loss_real= 0.447, d_loss_fake= 0.290, g_loss 1.655, d_loss 0.369\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 16 Batch 363/390 d_loss_real= 0.579, d_loss_fake= 0.235, g_loss 1.793, d_loss 0.407\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 364/390 d_loss_real= 0.417, d_loss_fake= 0.221, g_loss 1.838, d_loss 0.319\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 16 Batch 365/390 d_loss_real= 0.459, d_loss_fake= 0.199, g_loss 1.837, d_loss 0.329\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 16 Batch 366/390 d_loss_real= 0.460, d_loss_fake= 0.212, g_loss 1.803, d_loss 0.336\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 16 Batch 367/390 d_loss_real= 0.609, d_loss_fake= 0.222, g_loss 1.713, d_loss 0.416\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 16 Batch 368/390 d_loss_real= 0.442, d_loss_fake= 0.261, g_loss 1.582, d_loss 0.351\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 16 Batch 369/390 d_loss_real= 0.374, d_loss_fake= 0.258, g_loss 1.696, d_loss 0.316\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 16 Batch 370/390 d_loss_real= 0.324, d_loss_fake= 0.236, g_loss 1.679, d_loss 0.280\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 371/390 d_loss_real= 0.451, d_loss_fake= 0.288, g_loss 1.543, d_loss 0.369\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 16 Batch 372/390 d_loss_real= 0.227, d_loss_fake= 0.273, g_loss 1.670, d_loss 0.250\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 16 Batch 373/390 d_loss_real= 0.407, d_loss_fake= 0.221, g_loss 1.825, d_loss 0.314\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 16 Batch 374/390 d_loss_real= 0.419, d_loss_fake= 0.179, g_loss 1.948, d_loss 0.299\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 375/390 d_loss_real= 0.387, d_loss_fake= 0.162, g_loss 1.997, d_loss 0.274\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 16 Batch 376/390 d_loss_real= 0.420, d_loss_fake= 0.159, g_loss 1.969, d_loss 0.290\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 16 Batch 377/390 d_loss_real= 0.391, d_loss_fake= 0.172, g_loss 1.901, d_loss 0.282\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 16 Batch 378/390 d_loss_real= 0.420, d_loss_fake= 0.194, g_loss 1.837, d_loss 0.307\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 379/390 d_loss_real= 0.471, d_loss_fake= 0.214, g_loss 1.689, d_loss 0.343\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 380/390 d_loss_real= 0.404, d_loss_fake= 0.243, g_loss 1.654, d_loss 0.323\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 381/390 d_loss_real= 0.407, d_loss_fake= 0.236, g_loss 1.707, d_loss 0.321\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 382/390 d_loss_real= 0.305, d_loss_fake= 0.204, g_loss 1.866, d_loss 0.255\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16 Batch 383/390 d_loss_real= 0.285, d_loss_fake= 0.177, g_loss 1.954, d_loss 0.231\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 384/390 d_loss_real= 0.371, d_loss_fake= 0.166, g_loss 1.942, d_loss 0.268\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 385/390 d_loss_real= 0.606, d_loss_fake= 0.176, g_loss 1.877, d_loss 0.391\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16 Batch 386/390 d_loss_real= 0.421, d_loss_fake= 0.192, g_loss 1.792, d_loss 0.307\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 16 Batch 387/390 d_loss_real= 0.635, d_loss_fake= 0.215, g_loss 1.679, d_loss 0.425\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 16 Batch 388/390 d_loss_real= 0.405, d_loss_fake= 0.246, g_loss 1.602, d_loss 0.325\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16 Batch 389/390 d_loss_real= 0.357, d_loss_fake= 0.259, g_loss 1.543, d_loss 0.308\n",
            "2/2 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16 Batch 390/390 d_loss_real= 0.235, d_loss_fake= 0.253, g_loss 1.559, d_loss 0.244\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 17 Batch 1/390 d_loss_real= 0.368, d_loss_fake= 0.267, g_loss 1.569, d_loss 0.317\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 2/390 d_loss_real= 0.295, d_loss_fake= 0.252, g_loss 1.622, d_loss 0.273\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 17 Batch 3/390 d_loss_real= 0.331, d_loss_fake= 0.229, g_loss 1.624, d_loss 0.280\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 17 Batch 4/390 d_loss_real= 0.399, d_loss_fake= 0.228, g_loss 1.650, d_loss 0.314\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 5/390 d_loss_real= 0.499, d_loss_fake= 0.233, g_loss 1.618, d_loss 0.366\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 6/390 d_loss_real= 0.474, d_loss_fake= 0.265, g_loss 1.525, d_loss 0.370\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 7/390 d_loss_real= 0.394, d_loss_fake= 0.288, g_loss 1.394, d_loss 0.341\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 8/390 d_loss_real= 0.254, d_loss_fake= 0.318, g_loss 1.326, d_loss 0.286\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 17 Batch 9/390 d_loss_real= 0.285, d_loss_fake= 0.352, g_loss 1.275, d_loss 0.318\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 17 Batch 10/390 d_loss_real= 0.360, d_loss_fake= 0.381, g_loss 1.243, d_loss 0.370\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 11/390 d_loss_real= 0.398, d_loss_fake= 0.362, g_loss 1.237, d_loss 0.380\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 12/390 d_loss_real= 0.310, d_loss_fake= 0.374, g_loss 1.266, d_loss 0.342\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 17 Batch 13/390 d_loss_real= 0.400, d_loss_fake= 0.361, g_loss 1.262, d_loss 0.381\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 17 Batch 14/390 d_loss_real= 0.282, d_loss_fake= 0.366, g_loss 1.265, d_loss 0.324\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 15/390 d_loss_real= 0.367, d_loss_fake= 0.330, g_loss 1.295, d_loss 0.348\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 17 Batch 16/390 d_loss_real= 0.392, d_loss_fake= 0.339, g_loss 1.270, d_loss 0.366\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 17 Batch 17/390 d_loss_real= 0.431, d_loss_fake= 0.371, g_loss 1.213, d_loss 0.401\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 18/390 d_loss_real= 0.327, d_loss_fake= 0.380, g_loss 1.215, d_loss 0.353\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 19/390 d_loss_real= 0.392, d_loss_fake= 0.381, g_loss 1.223, d_loss 0.386\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 20/390 d_loss_real= 0.357, d_loss_fake= 0.390, g_loss 1.217, d_loss 0.374\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 17 Batch 21/390 d_loss_real= 0.356, d_loss_fake= 0.375, g_loss 1.190, d_loss 0.366\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 22/390 d_loss_real= 0.460, d_loss_fake= 0.385, g_loss 1.200, d_loss 0.422\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 17 Batch 23/390 d_loss_real= 0.497, d_loss_fake= 0.387, g_loss 1.203, d_loss 0.442\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 17 Batch 24/390 d_loss_real= 0.270, d_loss_fake= 0.361, g_loss 1.289, d_loss 0.316\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 25/390 d_loss_real= 0.246, d_loss_fake= 0.334, g_loss 1.387, d_loss 0.290\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 26/390 d_loss_real= 0.352, d_loss_fake= 0.294, g_loss 1.476, d_loss 0.323\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 27/390 d_loss_real= 0.399, d_loss_fake= 0.267, g_loss 1.555, d_loss 0.333\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 28/390 d_loss_real= 0.390, d_loss_fake= 0.242, g_loss 1.566, d_loss 0.316\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 29/390 d_loss_real= 0.392, d_loss_fake= 0.258, g_loss 1.532, d_loss 0.325\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 30/390 d_loss_real= 0.342, d_loss_fake= 0.267, g_loss 1.485, d_loss 0.305\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 31/390 d_loss_real= 0.574, d_loss_fake= 0.278, g_loss 1.415, d_loss 0.426\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 32/390 d_loss_real= 0.491, d_loss_fake= 0.312, g_loss 1.385, d_loss 0.401\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 33/390 d_loss_real= 0.276, d_loss_fake= 0.309, g_loss 1.373, d_loss 0.292\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 17 Batch 34/390 d_loss_real= 0.380, d_loss_fake= 0.311, g_loss 1.424, d_loss 0.346\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 35/390 d_loss_real= 0.341, d_loss_fake= 0.278, g_loss 1.478, d_loss 0.309\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 17 Batch 36/390 d_loss_real= 0.274, d_loss_fake= 0.264, g_loss 1.587, d_loss 0.269\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 37/390 d_loss_real= 0.338, d_loss_fake= 0.247, g_loss 1.584, d_loss 0.293\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 38/390 d_loss_real= 0.329, d_loss_fake= 0.233, g_loss 1.634, d_loss 0.281\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 39/390 d_loss_real= 0.386, d_loss_fake= 0.235, g_loss 1.657, d_loss 0.310\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 17 Batch 40/390 d_loss_real= 0.476, d_loss_fake= 0.229, g_loss 1.617, d_loss 0.353\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 17 Batch 41/390 d_loss_real= 0.455, d_loss_fake= 0.247, g_loss 1.563, d_loss 0.351\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 17 Batch 42/390 d_loss_real= 0.362, d_loss_fake= 0.264, g_loss 1.480, d_loss 0.313\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 43/390 d_loss_real= 0.270, d_loss_fake= 0.288, g_loss 1.463, d_loss 0.279\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 17 Batch 44/390 d_loss_real= 0.255, d_loss_fake= 0.289, g_loss 1.474, d_loss 0.272\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 17 Batch 45/390 d_loss_real= 0.334, d_loss_fake= 0.265, g_loss 1.541, d_loss 0.299\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 46/390 d_loss_real= 0.458, d_loss_fake= 0.247, g_loss 1.603, d_loss 0.353\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 17 Batch 47/390 d_loss_real= 0.491, d_loss_fake= 0.243, g_loss 1.600, d_loss 0.367\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 48/390 d_loss_real= 0.327, d_loss_fake= 0.245, g_loss 1.613, d_loss 0.286\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 17 Batch 49/390 d_loss_real= 0.391, d_loss_fake= 0.238, g_loss 1.623, d_loss 0.315\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 17 Batch 50/390 d_loss_real= 0.352, d_loss_fake= 0.246, g_loss 1.577, d_loss 0.299\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 17 Batch 51/390 d_loss_real= 0.362, d_loss_fake= 0.245, g_loss 1.580, d_loss 0.304\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 52/390 d_loss_real= 0.326, d_loss_fake= 0.249, g_loss 1.595, d_loss 0.287\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 53/390 d_loss_real= 0.391, d_loss_fake= 0.245, g_loss 1.614, d_loss 0.318\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 54/390 d_loss_real= 0.460, d_loss_fake= 0.247, g_loss 1.634, d_loss 0.353\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 17 Batch 55/390 d_loss_real= 0.362, d_loss_fake= 0.237, g_loss 1.621, d_loss 0.300\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 17 Batch 56/390 d_loss_real= 0.361, d_loss_fake= 0.248, g_loss 1.604, d_loss 0.305\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 57/390 d_loss_real= 0.289, d_loss_fake= 0.242, g_loss 1.620, d_loss 0.265\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 58/390 d_loss_real= 0.457, d_loss_fake= 0.240, g_loss 1.639, d_loss 0.349\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 59/390 d_loss_real= 0.478, d_loss_fake= 0.249, g_loss 1.675, d_loss 0.364\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 17 Batch 60/390 d_loss_real= 0.523, d_loss_fake= 0.249, g_loss 1.626, d_loss 0.386\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 61/390 d_loss_real= 0.543, d_loss_fake= 0.250, g_loss 1.623, d_loss 0.396\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 62/390 d_loss_real= 0.419, d_loss_fake= 0.241, g_loss 1.574, d_loss 0.330\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 63/390 d_loss_real= 0.532, d_loss_fake= 0.245, g_loss 1.602, d_loss 0.389\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 64/390 d_loss_real= 0.413, d_loss_fake= 0.248, g_loss 1.611, d_loss 0.330\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 65/390 d_loss_real= 0.476, d_loss_fake= 0.262, g_loss 1.563, d_loss 0.369\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 17 Batch 66/390 d_loss_real= 0.506, d_loss_fake= 0.259, g_loss 1.564, d_loss 0.382\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 67/390 d_loss_real= 0.469, d_loss_fake= 0.259, g_loss 1.529, d_loss 0.364\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 68/390 d_loss_real= 0.241, d_loss_fake= 0.259, g_loss 1.586, d_loss 0.250\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 17 Batch 69/390 d_loss_real= 0.401, d_loss_fake= 0.241, g_loss 1.604, d_loss 0.321\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 17 Batch 70/390 d_loss_real= 0.467, d_loss_fake= 0.254, g_loss 1.583, d_loss 0.361\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 17 Batch 71/390 d_loss_real= 0.436, d_loss_fake= 0.246, g_loss 1.584, d_loss 0.341\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 72/390 d_loss_real= 0.722, d_loss_fake= 0.259, g_loss 1.531, d_loss 0.490\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 17 Batch 73/390 d_loss_real= 0.351, d_loss_fake= 0.277, g_loss 1.504, d_loss 0.314\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 17 Batch 74/390 d_loss_real= 0.380, d_loss_fake= 0.275, g_loss 1.460, d_loss 0.328\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 75/390 d_loss_real= 0.399, d_loss_fake= 0.289, g_loss 1.498, d_loss 0.344\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 76/390 d_loss_real= 0.376, d_loss_fake= 0.271, g_loss 1.528, d_loss 0.324\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 77/390 d_loss_real= 0.314, d_loss_fake= 0.262, g_loss 1.534, d_loss 0.288\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 78/390 d_loss_real= 0.522, d_loss_fake= 0.257, g_loss 1.522, d_loss 0.389\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 79/390 d_loss_real= 0.550, d_loss_fake= 0.270, g_loss 1.455, d_loss 0.410\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 17 Batch 80/390 d_loss_real= 0.298, d_loss_fake= 0.319, g_loss 1.394, d_loss 0.309\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 81/390 d_loss_real= 0.614, d_loss_fake= 0.342, g_loss 1.329, d_loss 0.478\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 82/390 d_loss_real= 0.420, d_loss_fake= 0.337, g_loss 1.351, d_loss 0.378\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 83/390 d_loss_real= 0.405, d_loss_fake= 0.328, g_loss 1.346, d_loss 0.366\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 17 Batch 84/390 d_loss_real= 0.326, d_loss_fake= 0.314, g_loss 1.406, d_loss 0.320\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 85/390 d_loss_real= 0.496, d_loss_fake= 0.294, g_loss 1.406, d_loss 0.395\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 86/390 d_loss_real= 0.335, d_loss_fake= 0.301, g_loss 1.444, d_loss 0.318\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 17 Batch 87/390 d_loss_real= 0.492, d_loss_fake= 0.284, g_loss 1.415, d_loss 0.388\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 88/390 d_loss_real= 0.450, d_loss_fake= 0.308, g_loss 1.399, d_loss 0.379\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 89/390 d_loss_real= 0.604, d_loss_fake= 0.316, g_loss 1.354, d_loss 0.460\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 90/390 d_loss_real= 0.349, d_loss_fake= 0.324, g_loss 1.383, d_loss 0.337\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 91/390 d_loss_real= 0.438, d_loss_fake= 0.341, g_loss 1.288, d_loss 0.389\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 17 Batch 92/390 d_loss_real= 0.348, d_loss_fake= 0.331, g_loss 1.303, d_loss 0.340\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 17 Batch 93/390 d_loss_real= 0.447, d_loss_fake= 0.335, g_loss 1.376, d_loss 0.391\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 17 Batch 94/390 d_loss_real= 0.351, d_loss_fake= 0.319, g_loss 1.481, d_loss 0.335\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 95/390 d_loss_real= 0.474, d_loss_fake= 0.270, g_loss 1.495, d_loss 0.372\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 96/390 d_loss_real= 0.426, d_loss_fake= 0.264, g_loss 1.484, d_loss 0.345\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 97/390 d_loss_real= 0.297, d_loss_fake= 0.272, g_loss 1.482, d_loss 0.285\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 98/390 d_loss_real= 0.480, d_loss_fake= 0.272, g_loss 1.461, d_loss 0.376\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 17 Batch 99/390 d_loss_real= 0.356, d_loss_fake= 0.281, g_loss 1.424, d_loss 0.318\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 100/390 d_loss_real= 0.304, d_loss_fake= 0.291, g_loss 1.430, d_loss 0.297\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 101/390 d_loss_real= 0.437, d_loss_fake= 0.305, g_loss 1.408, d_loss 0.371\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 17 Batch 102/390 d_loss_real= 0.419, d_loss_fake= 0.333, g_loss 1.412, d_loss 0.376\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 17 Batch 103/390 d_loss_real= 0.296, d_loss_fake= 0.309, g_loss 1.464, d_loss 0.302\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 17 Batch 104/390 d_loss_real= 0.354, d_loss_fake= 0.271, g_loss 1.584, d_loss 0.313\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 17 Batch 105/390 d_loss_real= 0.332, d_loss_fake= 0.245, g_loss 1.669, d_loss 0.289\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 106/390 d_loss_real= 0.497, d_loss_fake= 0.233, g_loss 1.676, d_loss 0.365\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 17 Batch 107/390 d_loss_real= 0.500, d_loss_fake= 0.230, g_loss 1.599, d_loss 0.365\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 17 Batch 108/390 d_loss_real= 0.472, d_loss_fake= 0.252, g_loss 1.512, d_loss 0.362\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 17 Batch 109/390 d_loss_real= 0.546, d_loss_fake= 0.296, g_loss 1.429, d_loss 0.421\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 110/390 d_loss_real= 0.431, d_loss_fake= 0.292, g_loss 1.432, d_loss 0.362\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 111/390 d_loss_real= 0.412, d_loss_fake= 0.294, g_loss 1.493, d_loss 0.353\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 112/390 d_loss_real= 0.337, d_loss_fake= 0.264, g_loss 1.603, d_loss 0.300\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 113/390 d_loss_real= 0.467, d_loss_fake= 0.238, g_loss 1.666, d_loss 0.352\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 17 Batch 114/390 d_loss_real= 0.535, d_loss_fake= 0.231, g_loss 1.707, d_loss 0.383\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 17 Batch 115/390 d_loss_real= 0.515, d_loss_fake= 0.210, g_loss 1.688, d_loss 0.362\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 17 Batch 116/390 d_loss_real= 0.476, d_loss_fake= 0.228, g_loss 1.633, d_loss 0.352\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 117/390 d_loss_real= 0.374, d_loss_fake= 0.240, g_loss 1.567, d_loss 0.307\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 17 Batch 118/390 d_loss_real= 0.540, d_loss_fake= 0.268, g_loss 1.469, d_loss 0.404\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 119/390 d_loss_real= 0.394, d_loss_fake= 0.308, g_loss 1.470, d_loss 0.351\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 120/390 d_loss_real= 0.325, d_loss_fake= 0.292, g_loss 1.502, d_loss 0.309\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 17 Batch 121/390 d_loss_real= 0.330, d_loss_fake= 0.272, g_loss 1.526, d_loss 0.301\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 122/390 d_loss_real= 0.490, d_loss_fake= 0.251, g_loss 1.596, d_loss 0.371\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 123/390 d_loss_real= 0.312, d_loss_fake= 0.249, g_loss 1.637, d_loss 0.280\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 17 Batch 124/390 d_loss_real= 0.391, d_loss_fake= 0.236, g_loss 1.680, d_loss 0.314\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 17 Batch 125/390 d_loss_real= 0.361, d_loss_fake= 0.222, g_loss 1.665, d_loss 0.291\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 126/390 d_loss_real= 0.438, d_loss_fake= 0.236, g_loss 1.629, d_loss 0.337\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 127/390 d_loss_real= 0.393, d_loss_fake= 0.254, g_loss 1.572, d_loss 0.324\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 17 Batch 128/390 d_loss_real= 0.506, d_loss_fake= 0.260, g_loss 1.594, d_loss 0.383\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 17 Batch 129/390 d_loss_real= 0.412, d_loss_fake= 0.252, g_loss 1.542, d_loss 0.332\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 130/390 d_loss_real= 0.380, d_loss_fake= 0.249, g_loss 1.596, d_loss 0.314\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 17 Batch 131/390 d_loss_real= 0.340, d_loss_fake= 0.239, g_loss 1.580, d_loss 0.289\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 132/390 d_loss_real= 0.413, d_loss_fake= 0.244, g_loss 1.619, d_loss 0.329\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 133/390 d_loss_real= 0.447, d_loss_fake= 0.252, g_loss 1.628, d_loss 0.349\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 134/390 d_loss_real= 0.395, d_loss_fake= 0.248, g_loss 1.511, d_loss 0.321\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 17 Batch 135/390 d_loss_real= 0.314, d_loss_fake= 0.273, g_loss 1.494, d_loss 0.293\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 136/390 d_loss_real= 0.279, d_loss_fake= 0.292, g_loss 1.464, d_loss 0.286\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 137/390 d_loss_real= 0.349, d_loss_fake= 0.276, g_loss 1.513, d_loss 0.313\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 17 Batch 138/390 d_loss_real= 0.298, d_loss_fake= 0.266, g_loss 1.578, d_loss 0.282\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 17 Batch 139/390 d_loss_real= 0.335, d_loss_fake= 0.253, g_loss 1.600, d_loss 0.294\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 140/390 d_loss_real= 0.228, d_loss_fake= 0.235, g_loss 1.655, d_loss 0.232\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 17 Batch 141/390 d_loss_real= 0.393, d_loss_fake= 0.245, g_loss 1.634, d_loss 0.319\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 142/390 d_loss_real= 0.356, d_loss_fake= 0.238, g_loss 1.632, d_loss 0.297\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 143/390 d_loss_real= 0.401, d_loss_fake= 0.238, g_loss 1.585, d_loss 0.320\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 144/390 d_loss_real= 0.251, d_loss_fake= 0.250, g_loss 1.570, d_loss 0.251\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 17 Batch 145/390 d_loss_real= 0.354, d_loss_fake= 0.242, g_loss 1.621, d_loss 0.298\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 146/390 d_loss_real= 0.392, d_loss_fake= 0.242, g_loss 1.666, d_loss 0.317\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 147/390 d_loss_real= 0.490, d_loss_fake= 0.242, g_loss 1.669, d_loss 0.366\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 148/390 d_loss_real= 0.315, d_loss_fake= 0.244, g_loss 1.591, d_loss 0.279\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 149/390 d_loss_real= 0.564, d_loss_fake= 0.262, g_loss 1.549, d_loss 0.413\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 150/390 d_loss_real= 0.417, d_loss_fake= 0.275, g_loss 1.466, d_loss 0.346\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 151/390 d_loss_real= 0.399, d_loss_fake= 0.289, g_loss 1.454, d_loss 0.344\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 152/390 d_loss_real= 0.393, d_loss_fake= 0.283, g_loss 1.500, d_loss 0.338\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 17 Batch 153/390 d_loss_real= 0.350, d_loss_fake= 0.266, g_loss 1.543, d_loss 0.308\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 154/390 d_loss_real= 0.392, d_loss_fake= 0.260, g_loss 1.624, d_loss 0.326\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 155/390 d_loss_real= 0.361, d_loss_fake= 0.236, g_loss 1.671, d_loss 0.298\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 156/390 d_loss_real= 0.346, d_loss_fake= 0.224, g_loss 1.698, d_loss 0.285\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 17 Batch 157/390 d_loss_real= 0.400, d_loss_fake= 0.238, g_loss 1.661, d_loss 0.319\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 17 Batch 158/390 d_loss_real= 0.507, d_loss_fake= 0.253, g_loss 1.563, d_loss 0.380\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 159/390 d_loss_real= 0.385, d_loss_fake= 0.279, g_loss 1.460, d_loss 0.332\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 17 Batch 160/390 d_loss_real= 0.419, d_loss_fake= 0.305, g_loss 1.383, d_loss 0.362\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 17 Batch 161/390 d_loss_real= 0.472, d_loss_fake= 0.348, g_loss 1.374, d_loss 0.410\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 17 Batch 162/390 d_loss_real= 0.356, d_loss_fake= 0.326, g_loss 1.368, d_loss 0.341\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 163/390 d_loss_real= 0.390, d_loss_fake= 0.316, g_loss 1.425, d_loss 0.353\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 17 Batch 164/390 d_loss_real= 0.270, d_loss_fake= 0.283, g_loss 1.514, d_loss 0.277\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 17 Batch 165/390 d_loss_real= 0.292, d_loss_fake= 0.253, g_loss 1.627, d_loss 0.273\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 17 Batch 166/390 d_loss_real= 0.527, d_loss_fake= 0.232, g_loss 1.652, d_loss 0.380\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 167/390 d_loss_real= 0.268, d_loss_fake= 0.219, g_loss 1.720, d_loss 0.243\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 168/390 d_loss_real= 0.459, d_loss_fake= 0.223, g_loss 1.688, d_loss 0.341\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 169/390 d_loss_real= 0.504, d_loss_fake= 0.232, g_loss 1.596, d_loss 0.368\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 170/390 d_loss_real= 0.363, d_loss_fake= 0.243, g_loss 1.592, d_loss 0.303\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 171/390 d_loss_real= 0.376, d_loss_fake= 0.252, g_loss 1.524, d_loss 0.314\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 17 Batch 172/390 d_loss_real= 0.338, d_loss_fake= 0.285, g_loss 1.502, d_loss 0.312\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 17 Batch 173/390 d_loss_real= 0.318, d_loss_fake= 0.285, g_loss 1.511, d_loss 0.301\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 17 Batch 174/390 d_loss_real= 0.441, d_loss_fake= 0.275, g_loss 1.535, d_loss 0.358\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 175/390 d_loss_real= 0.498, d_loss_fake= 0.268, g_loss 1.480, d_loss 0.383\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 17 Batch 176/390 d_loss_real= 0.334, d_loss_fake= 0.271, g_loss 1.494, d_loss 0.302\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 177/390 d_loss_real= 0.338, d_loss_fake= 0.256, g_loss 1.607, d_loss 0.297\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 178/390 d_loss_real= 0.377, d_loss_fake= 0.246, g_loss 1.641, d_loss 0.311\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 17 Batch 179/390 d_loss_real= 0.310, d_loss_fake= 0.227, g_loss 1.665, d_loss 0.269\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 17 Batch 180/390 d_loss_real= 0.443, d_loss_fake= 0.222, g_loss 1.638, d_loss 0.333\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 181/390 d_loss_real= 0.265, d_loss_fake= 0.242, g_loss 1.623, d_loss 0.253\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 17 Batch 182/390 d_loss_real= 0.272, d_loss_fake= 0.247, g_loss 1.580, d_loss 0.260\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 17 Batch 183/390 d_loss_real= 0.413, d_loss_fake= 0.247, g_loss 1.597, d_loss 0.330\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 184/390 d_loss_real= 0.472, d_loss_fake= 0.240, g_loss 1.588, d_loss 0.356\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 17 Batch 185/390 d_loss_real= 0.313, d_loss_fake= 0.240, g_loss 1.592, d_loss 0.276\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 186/390 d_loss_real= 0.346, d_loss_fake= 0.247, g_loss 1.594, d_loss 0.297\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 17 Batch 187/390 d_loss_real= 0.332, d_loss_fake= 0.233, g_loss 1.630, d_loss 0.283\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 17 Batch 188/390 d_loss_real= 0.405, d_loss_fake= 0.220, g_loss 1.675, d_loss 0.312\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 189/390 d_loss_real= 0.372, d_loss_fake= 0.209, g_loss 1.691, d_loss 0.291\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 17 Batch 190/390 d_loss_real= 0.353, d_loss_fake= 0.218, g_loss 1.681, d_loss 0.286\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 191/390 d_loss_real= 0.430, d_loss_fake= 0.215, g_loss 1.639, d_loss 0.322\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 17 Batch 192/390 d_loss_real= 0.598, d_loss_fake= 0.232, g_loss 1.546, d_loss 0.415\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 193/390 d_loss_real= 0.298, d_loss_fake= 0.260, g_loss 1.491, d_loss 0.279\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 17 Batch 194/390 d_loss_real= 0.426, d_loss_fake= 0.285, g_loss 1.470, d_loss 0.356\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 195/390 d_loss_real= 0.357, d_loss_fake= 0.275, g_loss 1.490, d_loss 0.316\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Epoch 17 Batch 196/390 d_loss_real= 0.374, d_loss_fake= 0.278, g_loss 1.512, d_loss 0.326\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 17 Batch 197/390 d_loss_real= 0.337, d_loss_fake= 0.253, g_loss 1.568, d_loss 0.295\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 17 Batch 198/390 d_loss_real= 0.402, d_loss_fake= 0.227, g_loss 1.613, d_loss 0.315\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 199/390 d_loss_real= 0.366, d_loss_fake= 0.233, g_loss 1.619, d_loss 0.299\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 200/390 d_loss_real= 0.433, d_loss_fake= 0.229, g_loss 1.617, d_loss 0.331\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 17 Batch 201/390 d_loss_real= 0.414, d_loss_fake= 0.243, g_loss 1.545, d_loss 0.328\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 202/390 d_loss_real= 0.395, d_loss_fake= 0.260, g_loss 1.473, d_loss 0.328\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 17 Batch 203/390 d_loss_real= 0.232, d_loss_fake= 0.288, g_loss 1.490, d_loss 0.260\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 17 Batch 204/390 d_loss_real= 0.502, d_loss_fake= 0.271, g_loss 1.478, d_loss 0.386\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 17 Batch 205/390 d_loss_real= 0.416, d_loss_fake= 0.280, g_loss 1.453, d_loss 0.348\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 17 Batch 206/390 d_loss_real= 0.253, d_loss_fake= 0.281, g_loss 1.541, d_loss 0.267\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 207/390 d_loss_real= 0.352, d_loss_fake= 0.263, g_loss 1.588, d_loss 0.308\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 208/390 d_loss_real= 0.531, d_loss_fake= 0.236, g_loss 1.647, d_loss 0.384\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 209/390 d_loss_real= 0.460, d_loss_fake= 0.243, g_loss 1.583, d_loss 0.351\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 210/390 d_loss_real= 0.543, d_loss_fake= 0.245, g_loss 1.514, d_loss 0.394\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 17 Batch 211/390 d_loss_real= 0.447, d_loss_fake= 0.280, g_loss 1.473, d_loss 0.363\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 17 Batch 212/390 d_loss_real= 0.323, d_loss_fake= 0.278, g_loss 1.428, d_loss 0.300\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 213/390 d_loss_real= 0.302, d_loss_fake= 0.302, g_loss 1.469, d_loss 0.302\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 17 Batch 214/390 d_loss_real= 0.398, d_loss_fake= 0.264, g_loss 1.598, d_loss 0.331\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 215/390 d_loss_real= 0.394, d_loss_fake= 0.221, g_loss 1.687, d_loss 0.307\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 216/390 d_loss_real= 0.462, d_loss_fake= 0.202, g_loss 1.739, d_loss 0.332\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 217/390 d_loss_real= 0.462, d_loss_fake= 0.216, g_loss 1.697, d_loss 0.339\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 218/390 d_loss_real= 0.385, d_loss_fake= 0.225, g_loss 1.693, d_loss 0.305\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 219/390 d_loss_real= 0.471, d_loss_fake= 0.223, g_loss 1.598, d_loss 0.347\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 220/390 d_loss_real= 0.239, d_loss_fake= 0.242, g_loss 1.586, d_loss 0.241\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 221/390 d_loss_real= 0.407, d_loss_fake= 0.265, g_loss 1.496, d_loss 0.336\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 222/390 d_loss_real= 0.408, d_loss_fake= 0.304, g_loss 1.424, d_loss 0.356\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 223/390 d_loss_real= 0.389, d_loss_fake= 0.313, g_loss 1.391, d_loss 0.351\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 224/390 d_loss_real= 0.311, d_loss_fake= 0.285, g_loss 1.531, d_loss 0.298\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 225/390 d_loss_real= 0.397, d_loss_fake= 0.260, g_loss 1.577, d_loss 0.328\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 226/390 d_loss_real= 0.454, d_loss_fake= 0.240, g_loss 1.597, d_loss 0.347\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 227/390 d_loss_real= 0.500, d_loss_fake= 0.245, g_loss 1.604, d_loss 0.372\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 228/390 d_loss_real= 0.404, d_loss_fake= 0.242, g_loss 1.598, d_loss 0.323\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 229/390 d_loss_real= 0.558, d_loss_fake= 0.248, g_loss 1.591, d_loss 0.403\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 17 Batch 230/390 d_loss_real= 0.453, d_loss_fake= 0.266, g_loss 1.529, d_loss 0.360\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 17 Batch 231/390 d_loss_real= 0.356, d_loss_fake= 0.241, g_loss 1.593, d_loss 0.298\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 232/390 d_loss_real= 0.424, d_loss_fake= 0.238, g_loss 1.637, d_loss 0.331\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 17 Batch 233/390 d_loss_real= 0.445, d_loss_fake= 0.239, g_loss 1.668, d_loss 0.342\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 17 Batch 234/390 d_loss_real= 0.278, d_loss_fake= 0.225, g_loss 1.685, d_loss 0.251\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 235/390 d_loss_real= 0.495, d_loss_fake= 0.228, g_loss 1.649, d_loss 0.361\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 236/390 d_loss_real= 0.513, d_loss_fake= 0.237, g_loss 1.593, d_loss 0.375\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 237/390 d_loss_real= 0.360, d_loss_fake= 0.264, g_loss 1.511, d_loss 0.312\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 238/390 d_loss_real= 0.416, d_loss_fake= 0.289, g_loss 1.421, d_loss 0.352\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 17 Batch 239/390 d_loss_real= 0.344, d_loss_fake= 0.303, g_loss 1.476, d_loss 0.324\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 17 Batch 240/390 d_loss_real= 0.383, d_loss_fake= 0.269, g_loss 1.593, d_loss 0.326\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 241/390 d_loss_real= 0.400, d_loss_fake= 0.246, g_loss 1.566, d_loss 0.323\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 17 Batch 242/390 d_loss_real= 0.504, d_loss_fake= 0.257, g_loss 1.566, d_loss 0.380\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 17 Batch 243/390 d_loss_real= 0.369, d_loss_fake= 0.252, g_loss 1.606, d_loss 0.311\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 244/390 d_loss_real= 0.467, d_loss_fake= 0.242, g_loss 1.635, d_loss 0.354\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 245/390 d_loss_real= 0.311, d_loss_fake= 0.229, g_loss 1.648, d_loss 0.270\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 17 Batch 246/390 d_loss_real= 0.430, d_loss_fake= 0.246, g_loss 1.610, d_loss 0.338\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 247/390 d_loss_real= 0.512, d_loss_fake= 0.252, g_loss 1.577, d_loss 0.382\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 17 Batch 248/390 d_loss_real= 0.488, d_loss_fake= 0.251, g_loss 1.567, d_loss 0.369\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 249/390 d_loss_real= 0.248, d_loss_fake= 0.250, g_loss 1.619, d_loss 0.249\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 250/390 d_loss_real= 0.301, d_loss_fake= 0.240, g_loss 1.663, d_loss 0.271\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 17 Batch 251/390 d_loss_real= 0.293, d_loss_fake= 0.226, g_loss 1.696, d_loss 0.259\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 252/390 d_loss_real= 0.467, d_loss_fake= 0.226, g_loss 1.716, d_loss 0.346\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 17 Batch 253/390 d_loss_real= 0.463, d_loss_fake= 0.226, g_loss 1.679, d_loss 0.344\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 254/390 d_loss_real= 0.588, d_loss_fake= 0.231, g_loss 1.609, d_loss 0.410\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 255/390 d_loss_real= 0.354, d_loss_fake= 0.248, g_loss 1.577, d_loss 0.301\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 17 Batch 256/390 d_loss_real= 0.516, d_loss_fake= 0.254, g_loss 1.504, d_loss 0.385\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 17 Batch 257/390 d_loss_real= 0.411, d_loss_fake= 0.257, g_loss 1.534, d_loss 0.334\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 17 Batch 258/390 d_loss_real= 0.261, d_loss_fake= 0.272, g_loss 1.638, d_loss 0.266\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 259/390 d_loss_real= 0.389, d_loss_fake= 0.231, g_loss 1.695, d_loss 0.310\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 17 Batch 260/390 d_loss_real= 0.456, d_loss_fake= 0.226, g_loss 1.718, d_loss 0.341\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 17 Batch 261/390 d_loss_real= 0.465, d_loss_fake= 0.219, g_loss 1.716, d_loss 0.342\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 17 Batch 262/390 d_loss_real= 0.388, d_loss_fake= 0.237, g_loss 1.623, d_loss 0.312\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 263/390 d_loss_real= 0.293, d_loss_fake= 0.257, g_loss 1.623, d_loss 0.275\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 264/390 d_loss_real= 0.321, d_loss_fake= 0.253, g_loss 1.603, d_loss 0.287\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 265/390 d_loss_real= 0.352, d_loss_fake= 0.257, g_loss 1.539, d_loss 0.305\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 17 Batch 266/390 d_loss_real= 0.299, d_loss_fake= 0.272, g_loss 1.550, d_loss 0.286\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 17 Batch 267/390 d_loss_real= 0.466, d_loss_fake= 0.249, g_loss 1.608, d_loss 0.357\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 17 Batch 268/390 d_loss_real= 0.394, d_loss_fake= 0.234, g_loss 1.676, d_loss 0.314\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 17 Batch 269/390 d_loss_real= 0.410, d_loss_fake= 0.219, g_loss 1.708, d_loss 0.314\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 270/390 d_loss_real= 0.528, d_loss_fake= 0.219, g_loss 1.716, d_loss 0.374\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 271/390 d_loss_real= 0.462, d_loss_fake= 0.217, g_loss 1.701, d_loss 0.339\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 272/390 d_loss_real= 0.365, d_loss_fake= 0.231, g_loss 1.587, d_loss 0.298\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 273/390 d_loss_real= 0.401, d_loss_fake= 0.250, g_loss 1.597, d_loss 0.326\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 17 Batch 274/390 d_loss_real= 0.480, d_loss_fake= 0.263, g_loss 1.567, d_loss 0.372\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 17 Batch 275/390 d_loss_real= 0.302, d_loss_fake= 0.269, g_loss 1.580, d_loss 0.285\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 276/390 d_loss_real= 0.462, d_loss_fake= 0.247, g_loss 1.589, d_loss 0.354\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 17 Batch 277/390 d_loss_real= 0.416, d_loss_fake= 0.255, g_loss 1.567, d_loss 0.335\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 278/390 d_loss_real= 0.381, d_loss_fake= 0.244, g_loss 1.599, d_loss 0.312\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 279/390 d_loss_real= 0.443, d_loss_fake= 0.232, g_loss 1.639, d_loss 0.337\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 280/390 d_loss_real= 0.310, d_loss_fake= 0.217, g_loss 1.669, d_loss 0.263\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 17 Batch 281/390 d_loss_real= 0.453, d_loss_fake= 0.218, g_loss 1.709, d_loss 0.335\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 17 Batch 282/390 d_loss_real= 0.404, d_loss_fake= 0.218, g_loss 1.660, d_loss 0.311\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 283/390 d_loss_real= 0.462, d_loss_fake= 0.229, g_loss 1.600, d_loss 0.346\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 17 Batch 284/390 d_loss_real= 0.314, d_loss_fake= 0.246, g_loss 1.589, d_loss 0.280\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 17 Batch 285/390 d_loss_real= 0.356, d_loss_fake= 0.247, g_loss 1.579, d_loss 0.301\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 17 Batch 286/390 d_loss_real= 0.252, d_loss_fake= 0.251, g_loss 1.561, d_loss 0.252\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 287/390 d_loss_real= 0.428, d_loss_fake= 0.250, g_loss 1.571, d_loss 0.339\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 17 Batch 288/390 d_loss_real= 0.418, d_loss_fake= 0.254, g_loss 1.552, d_loss 0.336\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 17 Batch 289/390 d_loss_real= 0.410, d_loss_fake= 0.262, g_loss 1.535, d_loss 0.336\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 17 Batch 290/390 d_loss_real= 0.536, d_loss_fake= 0.260, g_loss 1.531, d_loss 0.398\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 291/390 d_loss_real= 0.443, d_loss_fake= 0.279, g_loss 1.540, d_loss 0.361\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 292/390 d_loss_real= 0.328, d_loss_fake= 0.252, g_loss 1.583, d_loss 0.290\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 293/390 d_loss_real= 0.314, d_loss_fake= 0.242, g_loss 1.592, d_loss 0.278\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 17 Batch 294/390 d_loss_real= 0.587, d_loss_fake= 0.249, g_loss 1.592, d_loss 0.418\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 295/390 d_loss_real= 0.366, d_loss_fake= 0.236, g_loss 1.566, d_loss 0.301\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 296/390 d_loss_real= 0.302, d_loss_fake= 0.252, g_loss 1.575, d_loss 0.277\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 297/390 d_loss_real= 0.357, d_loss_fake= 0.248, g_loss 1.599, d_loss 0.303\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 298/390 d_loss_real= 0.436, d_loss_fake= 0.241, g_loss 1.625, d_loss 0.339\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 299/390 d_loss_real= 0.280, d_loss_fake= 0.226, g_loss 1.603, d_loss 0.253\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 300/390 d_loss_real= 0.335, d_loss_fake= 0.237, g_loss 1.630, d_loss 0.286\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 301/390 d_loss_real= 0.551, d_loss_fake= 0.249, g_loss 1.503, d_loss 0.400\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 17 Batch 302/390 d_loss_real= 0.237, d_loss_fake= 0.273, g_loss 1.450, d_loss 0.255\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 303/390 d_loss_real= 0.314, d_loss_fake= 0.283, g_loss 1.475, d_loss 0.298\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 17 Batch 304/390 d_loss_real= 0.406, d_loss_fake= 0.271, g_loss 1.540, d_loss 0.338\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 17 Batch 305/390 d_loss_real= 0.581, d_loss_fake= 0.263, g_loss 1.539, d_loss 0.422\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 17 Batch 306/390 d_loss_real= 0.247, d_loss_fake= 0.272, g_loss 1.520, d_loss 0.259\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 307/390 d_loss_real= 0.347, d_loss_fake= 0.262, g_loss 1.617, d_loss 0.304\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 308/390 d_loss_real= 0.448, d_loss_fake= 0.239, g_loss 1.607, d_loss 0.344\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 309/390 d_loss_real= 0.354, d_loss_fake= 0.237, g_loss 1.621, d_loss 0.296\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 310/390 d_loss_real= 0.246, d_loss_fake= 0.234, g_loss 1.632, d_loss 0.240\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 17 Batch 311/390 d_loss_real= 0.357, d_loss_fake= 0.220, g_loss 1.683, d_loss 0.288\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 17 Batch 312/390 d_loss_real= 0.239, d_loss_fake= 0.216, g_loss 1.696, d_loss 0.228\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 313/390 d_loss_real= 0.384, d_loss_fake= 0.225, g_loss 1.651, d_loss 0.304\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 314/390 d_loss_real= 0.298, d_loss_fake= 0.235, g_loss 1.591, d_loss 0.266\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 17 Batch 315/390 d_loss_real= 0.395, d_loss_fake= 0.255, g_loss 1.538, d_loss 0.325\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 316/390 d_loss_real= 0.293, d_loss_fake= 0.258, g_loss 1.530, d_loss 0.276\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 17 Batch 317/390 d_loss_real= 0.236, d_loss_fake= 0.266, g_loss 1.455, d_loss 0.251\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 17 Batch 318/390 d_loss_real= 0.224, d_loss_fake= 0.269, g_loss 1.610, d_loss 0.246\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 17 Batch 319/390 d_loss_real= 0.299, d_loss_fake= 0.222, g_loss 1.698, d_loss 0.260\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 17 Batch 320/390 d_loss_real= 0.412, d_loss_fake= 0.201, g_loss 1.784, d_loss 0.306\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 321/390 d_loss_real= 0.503, d_loss_fake= 0.191, g_loss 1.743, d_loss 0.347\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 322/390 d_loss_real= 0.291, d_loss_fake= 0.222, g_loss 1.616, d_loss 0.257\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 323/390 d_loss_real= 0.316, d_loss_fake= 0.245, g_loss 1.580, d_loss 0.281\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 324/390 d_loss_real= 0.420, d_loss_fake= 0.265, g_loss 1.526, d_loss 0.342\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 17 Batch 325/390 d_loss_real= 0.215, d_loss_fake= 0.267, g_loss 1.556, d_loss 0.241\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 326/390 d_loss_real= 0.358, d_loss_fake= 0.249, g_loss 1.628, d_loss 0.303\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 327/390 d_loss_real= 0.382, d_loss_fake= 0.215, g_loss 1.714, d_loss 0.298\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 328/390 d_loss_real= 0.419, d_loss_fake= 0.224, g_loss 1.710, d_loss 0.322\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 17 Batch 329/390 d_loss_real= 0.367, d_loss_fake= 0.239, g_loss 1.673, d_loss 0.303\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 17 Batch 330/390 d_loss_real= 0.465, d_loss_fake= 0.232, g_loss 1.609, d_loss 0.349\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 331/390 d_loss_real= 0.443, d_loss_fake= 0.232, g_loss 1.602, d_loss 0.337\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 332/390 d_loss_real= 0.425, d_loss_fake= 0.272, g_loss 1.493, d_loss 0.348\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 17 Batch 333/390 d_loss_real= 0.348, d_loss_fake= 0.317, g_loss 1.410, d_loss 0.333\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 334/390 d_loss_real= 0.302, d_loss_fake= 0.311, g_loss 1.388, d_loss 0.307\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 17 Batch 335/390 d_loss_real= 0.297, d_loss_fake= 0.322, g_loss 1.429, d_loss 0.310\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 17 Batch 336/390 d_loss_real= 0.289, d_loss_fake= 0.295, g_loss 1.534, d_loss 0.292\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 337/390 d_loss_real= 0.367, d_loss_fake= 0.261, g_loss 1.637, d_loss 0.314\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 338/390 d_loss_real= 0.440, d_loss_fake= 0.246, g_loss 1.685, d_loss 0.343\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 339/390 d_loss_real= 0.480, d_loss_fake= 0.216, g_loss 1.643, d_loss 0.348\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 340/390 d_loss_real= 0.246, d_loss_fake= 0.231, g_loss 1.689, d_loss 0.238\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 17 Batch 341/390 d_loss_real= 0.326, d_loss_fake= 0.215, g_loss 1.695, d_loss 0.270\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 342/390 d_loss_real= 0.322, d_loss_fake= 0.209, g_loss 1.721, d_loss 0.266\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 343/390 d_loss_real= 0.455, d_loss_fake= 0.247, g_loss 1.619, d_loss 0.351\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 17 Batch 344/390 d_loss_real= 0.332, d_loss_fake= 0.235, g_loss 1.590, d_loss 0.284\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 17 Batch 345/390 d_loss_real= 0.374, d_loss_fake= 0.258, g_loss 1.632, d_loss 0.316\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 346/390 d_loss_real= 0.315, d_loss_fake= 0.241, g_loss 1.620, d_loss 0.278\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 17 Batch 347/390 d_loss_real= 0.315, d_loss_fake= 0.222, g_loss 1.705, d_loss 0.269\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 17 Batch 348/390 d_loss_real= 0.423, d_loss_fake= 0.226, g_loss 1.743, d_loss 0.324\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 17 Batch 349/390 d_loss_real= 0.512, d_loss_fake= 0.199, g_loss 1.753, d_loss 0.356\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 17 Batch 350/390 d_loss_real= 0.373, d_loss_fake= 0.212, g_loss 1.741, d_loss 0.293\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 17 Batch 351/390 d_loss_real= 0.483, d_loss_fake= 0.212, g_loss 1.716, d_loss 0.347\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 17 Batch 352/390 d_loss_real= 0.430, d_loss_fake= 0.221, g_loss 1.641, d_loss 0.325\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 353/390 d_loss_real= 0.160, d_loss_fake= 0.246, g_loss 1.650, d_loss 0.203\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 17 Batch 354/390 d_loss_real= 0.305, d_loss_fake= 0.251, g_loss 1.677, d_loss 0.278\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 17 Batch 355/390 d_loss_real= 0.314, d_loss_fake= 0.208, g_loss 1.732, d_loss 0.261\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 17 Batch 356/390 d_loss_real= 0.297, d_loss_fake= 0.206, g_loss 1.694, d_loss 0.251\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 17 Batch 357/390 d_loss_real= 0.349, d_loss_fake= 0.218, g_loss 1.702, d_loss 0.283\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 358/390 d_loss_real= 0.308, d_loss_fake= 0.205, g_loss 1.706, d_loss 0.256\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 359/390 d_loss_real= 0.388, d_loss_fake= 0.211, g_loss 1.757, d_loss 0.299\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 360/390 d_loss_real= 0.436, d_loss_fake= 0.229, g_loss 1.782, d_loss 0.332\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 361/390 d_loss_real= 0.571, d_loss_fake= 0.207, g_loss 1.803, d_loss 0.389\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 362/390 d_loss_real= 0.345, d_loss_fake= 0.192, g_loss 1.799, d_loss 0.268\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 363/390 d_loss_real= 0.416, d_loss_fake= 0.204, g_loss 1.771, d_loss 0.310\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 364/390 d_loss_real= 0.351, d_loss_fake= 0.202, g_loss 1.699, d_loss 0.276\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 17 Batch 365/390 d_loss_real= 0.431, d_loss_fake= 0.226, g_loss 1.628, d_loss 0.329\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 366/390 d_loss_real= 0.321, d_loss_fake= 0.263, g_loss 1.535, d_loss 0.292\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 17 Batch 367/390 d_loss_real= 0.346, d_loss_fake= 0.244, g_loss 1.595, d_loss 0.295\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 368/390 d_loss_real= 0.302, d_loss_fake= 0.231, g_loss 1.625, d_loss 0.267\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 369/390 d_loss_real= 0.401, d_loss_fake= 0.220, g_loss 1.701, d_loss 0.311\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 17 Batch 370/390 d_loss_real= 0.325, d_loss_fake= 0.207, g_loss 1.797, d_loss 0.266\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 17 Batch 371/390 d_loss_real= 0.273, d_loss_fake= 0.188, g_loss 1.861, d_loss 0.231\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 372/390 d_loss_real= 0.439, d_loss_fake= 0.176, g_loss 1.848, d_loss 0.308\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 17 Batch 373/390 d_loss_real= 0.485, d_loss_fake= 0.185, g_loss 1.777, d_loss 0.335\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 17 Batch 374/390 d_loss_real= 0.512, d_loss_fake= 0.232, g_loss 1.539, d_loss 0.372\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 17 Batch 375/390 d_loss_real= 0.358, d_loss_fake= 0.285, g_loss 1.519, d_loss 0.321\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 17 Batch 376/390 d_loss_real= 0.242, d_loss_fake= 0.262, g_loss 1.547, d_loss 0.252\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 17 Batch 377/390 d_loss_real= 0.375, d_loss_fake= 0.239, g_loss 1.621, d_loss 0.307\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 378/390 d_loss_real= 0.219, d_loss_fake= 0.208, g_loss 1.758, d_loss 0.214\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 379/390 d_loss_real= 0.368, d_loss_fake= 0.208, g_loss 1.720, d_loss 0.288\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 17 Batch 380/390 d_loss_real= 0.296, d_loss_fake= 0.204, g_loss 1.757, d_loss 0.250\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 17 Batch 381/390 d_loss_real= 0.345, d_loss_fake= 0.194, g_loss 1.798, d_loss 0.269\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 17 Batch 382/390 d_loss_real= 0.373, d_loss_fake= 0.192, g_loss 1.804, d_loss 0.282\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17 Batch 383/390 d_loss_real= 0.428, d_loss_fake= 0.197, g_loss 1.757, d_loss 0.313\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 17 Batch 384/390 d_loss_real= 0.327, d_loss_fake= 0.206, g_loss 1.713, d_loss 0.266\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 385/390 d_loss_real= 0.302, d_loss_fake= 0.221, g_loss 1.653, d_loss 0.261\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 17 Batch 386/390 d_loss_real= 0.295, d_loss_fake= 0.223, g_loss 1.679, d_loss 0.259\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 17 Batch 387/390 d_loss_real= 0.322, d_loss_fake= 0.226, g_loss 1.661, d_loss 0.274\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 17 Batch 388/390 d_loss_real= 0.535, d_loss_fake= 0.225, g_loss 1.648, d_loss 0.380\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17 Batch 389/390 d_loss_real= 0.272, d_loss_fake= 0.225, g_loss 1.673, d_loss 0.249\n",
            "2/2 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17 Batch 390/390 d_loss_real= 0.404, d_loss_fake= 0.215, g_loss 1.711, d_loss 0.310\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 1/390 d_loss_real= 0.600, d_loss_fake= 0.224, g_loss 1.631, d_loss 0.412\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 2/390 d_loss_real= 0.415, d_loss_fake= 0.226, g_loss 1.685, d_loss 0.321\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 3/390 d_loss_real= 0.207, d_loss_fake= 0.234, g_loss 1.621, d_loss 0.220\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 4/390 d_loss_real= 0.379, d_loss_fake= 0.237, g_loss 1.704, d_loss 0.308\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 18 Batch 5/390 d_loss_real= 0.237, d_loss_fake= 0.201, g_loss 1.822, d_loss 0.219\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 6/390 d_loss_real= 0.268, d_loss_fake= 0.202, g_loss 1.822, d_loss 0.235\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 7/390 d_loss_real= 0.582, d_loss_fake= 0.184, g_loss 1.842, d_loss 0.383\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 8/390 d_loss_real= 0.482, d_loss_fake= 0.184, g_loss 1.796, d_loss 0.333\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 18 Batch 9/390 d_loss_real= 0.436, d_loss_fake= 0.219, g_loss 1.665, d_loss 0.327\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 10/390 d_loss_real= 0.261, d_loss_fake= 0.231, g_loss 1.666, d_loss 0.246\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 11/390 d_loss_real= 0.274, d_loss_fake= 0.222, g_loss 1.701, d_loss 0.248\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 12/390 d_loss_real= 0.343, d_loss_fake= 0.211, g_loss 1.740, d_loss 0.277\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 13/390 d_loss_real= 0.372, d_loss_fake= 0.209, g_loss 1.787, d_loss 0.291\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 18 Batch 14/390 d_loss_real= 0.450, d_loss_fake= 0.195, g_loss 1.793, d_loss 0.322\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 15/390 d_loss_real= 0.285, d_loss_fake= 0.193, g_loss 1.789, d_loss 0.239\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 16/390 d_loss_real= 0.426, d_loss_fake= 0.197, g_loss 1.785, d_loss 0.311\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 17/390 d_loss_real= 0.418, d_loss_fake= 0.198, g_loss 1.771, d_loss 0.308\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 18/390 d_loss_real= 0.364, d_loss_fake= 0.216, g_loss 1.727, d_loss 0.290\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 19/390 d_loss_real= 0.404, d_loss_fake= 0.216, g_loss 1.688, d_loss 0.310\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 20/390 d_loss_real= 0.314, d_loss_fake= 0.229, g_loss 1.627, d_loss 0.271\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 21/390 d_loss_real= 0.506, d_loss_fake= 0.245, g_loss 1.622, d_loss 0.375\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 18 Batch 22/390 d_loss_real= 0.306, d_loss_fake= 0.240, g_loss 1.665, d_loss 0.273\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 18 Batch 23/390 d_loss_real= 0.387, d_loss_fake= 0.219, g_loss 1.718, d_loss 0.303\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 24/390 d_loss_real= 0.300, d_loss_fake= 0.198, g_loss 1.806, d_loss 0.249\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 25/390 d_loss_real= 0.295, d_loss_fake= 0.180, g_loss 1.859, d_loss 0.237\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 18 Batch 26/390 d_loss_real= 0.532, d_loss_fake= 0.174, g_loss 1.905, d_loss 0.353\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 18 Batch 27/390 d_loss_real= 0.319, d_loss_fake= 0.189, g_loss 1.829, d_loss 0.254\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 18 Batch 28/390 d_loss_real= 0.424, d_loss_fake= 0.183, g_loss 1.815, d_loss 0.303\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 29/390 d_loss_real= 0.337, d_loss_fake= 0.206, g_loss 1.729, d_loss 0.271\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 30/390 d_loss_real= 0.346, d_loss_fake= 0.229, g_loss 1.579, d_loss 0.288\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 18 Batch 31/390 d_loss_real= 0.322, d_loss_fake= 0.245, g_loss 1.569, d_loss 0.284\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 18 Batch 32/390 d_loss_real= 0.397, d_loss_fake= 0.250, g_loss 1.596, d_loss 0.324\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 33/390 d_loss_real= 0.284, d_loss_fake= 0.281, g_loss 1.569, d_loss 0.283\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 34/390 d_loss_real= 0.117, d_loss_fake= 0.219, g_loss 1.735, d_loss 0.168\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 35/390 d_loss_real= 0.417, d_loss_fake= 0.193, g_loss 1.904, d_loss 0.305\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 18 Batch 36/390 d_loss_real= 0.400, d_loss_fake= 0.172, g_loss 1.888, d_loss 0.286\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 37/390 d_loss_real= 0.443, d_loss_fake= 0.186, g_loss 1.878, d_loss 0.314\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 38/390 d_loss_real= 0.464, d_loss_fake= 0.185, g_loss 1.732, d_loss 0.324\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 39/390 d_loss_real= 0.269, d_loss_fake= 0.234, g_loss 1.561, d_loss 0.251\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 40/390 d_loss_real= 0.332, d_loss_fake= 0.292, g_loss 1.476, d_loss 0.312\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 18 Batch 41/390 d_loss_real= 0.457, d_loss_fake= 0.304, g_loss 1.507, d_loss 0.380\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 18 Batch 42/390 d_loss_real= 0.240, d_loss_fake= 0.275, g_loss 1.658, d_loss 0.257\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 43/390 d_loss_real= 0.191, d_loss_fake= 0.200, g_loss 1.860, d_loss 0.196\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 18 Batch 44/390 d_loss_real= 0.351, d_loss_fake= 0.168, g_loss 2.024, d_loss 0.260\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 18 Batch 45/390 d_loss_real= 0.516, d_loss_fake= 0.148, g_loss 2.060, d_loss 0.332\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 46/390 d_loss_real= 0.364, d_loss_fake= 0.155, g_loss 2.001, d_loss 0.259\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 18 Batch 47/390 d_loss_real= 0.444, d_loss_fake= 0.171, g_loss 1.836, d_loss 0.308\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 48/390 d_loss_real= 0.182, d_loss_fake= 0.202, g_loss 1.694, d_loss 0.192\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 18 Batch 49/390 d_loss_real= 0.408, d_loss_fake= 0.244, g_loss 1.567, d_loss 0.326\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 18 Batch 50/390 d_loss_real= 0.367, d_loss_fake= 0.277, g_loss 1.586, d_loss 0.322\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 51/390 d_loss_real= 0.279, d_loss_fake= 0.233, g_loss 1.751, d_loss 0.256\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 18 Batch 52/390 d_loss_real= 0.323, d_loss_fake= 0.181, g_loss 1.913, d_loss 0.252\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 53/390 d_loss_real= 0.398, d_loss_fake= 0.161, g_loss 1.974, d_loss 0.280\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 18 Batch 54/390 d_loss_real= 0.465, d_loss_fake= 0.174, g_loss 1.833, d_loss 0.319\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 55/390 d_loss_real= 0.428, d_loss_fake= 0.199, g_loss 1.808, d_loss 0.313\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 56/390 d_loss_real= 0.359, d_loss_fake= 0.218, g_loss 1.628, d_loss 0.289\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 57/390 d_loss_real= 0.137, d_loss_fake= 0.231, g_loss 1.834, d_loss 0.184\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 18 Batch 58/390 d_loss_real= 0.563, d_loss_fake= 0.204, g_loss 1.842, d_loss 0.383\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 59/390 d_loss_real= 0.254, d_loss_fake= 0.166, g_loss 2.018, d_loss 0.210\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 60/390 d_loss_real= 0.281, d_loss_fake= 0.141, g_loss 2.089, d_loss 0.211\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 61/390 d_loss_real= 0.503, d_loss_fake= 0.139, g_loss 2.050, d_loss 0.321\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 62/390 d_loss_real= 0.529, d_loss_fake= 0.152, g_loss 1.906, d_loss 0.340\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 63/390 d_loss_real= 0.309, d_loss_fake= 0.188, g_loss 1.775, d_loss 0.248\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 64/390 d_loss_real= 0.236, d_loss_fake= 0.228, g_loss 1.641, d_loss 0.232\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 18 Batch 65/390 d_loss_real= 0.457, d_loss_fake= 0.244, g_loss 1.660, d_loss 0.351\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 18 Batch 66/390 d_loss_real= 0.450, d_loss_fake= 0.257, g_loss 1.626, d_loss 0.353\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 67/390 d_loss_real= 0.298, d_loss_fake= 0.221, g_loss 1.800, d_loss 0.260\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 18 Batch 68/390 d_loss_real= 0.310, d_loss_fake= 0.187, g_loss 1.950, d_loss 0.248\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 69/390 d_loss_real= 0.345, d_loss_fake= 0.163, g_loss 1.951, d_loss 0.254\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 18 Batch 70/390 d_loss_real= 0.510, d_loss_fake= 0.163, g_loss 1.925, d_loss 0.336\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 71/390 d_loss_real= 0.531, d_loss_fake= 0.191, g_loss 1.815, d_loss 0.361\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 72/390 d_loss_real= 0.304, d_loss_fake= 0.206, g_loss 1.700, d_loss 0.255\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 18 Batch 73/390 d_loss_real= 0.235, d_loss_fake= 0.213, g_loss 1.681, d_loss 0.224\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 18 Batch 74/390 d_loss_real= 0.380, d_loss_fake= 0.213, g_loss 1.716, d_loss 0.297\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 75/390 d_loss_real= 0.324, d_loss_fake= 0.210, g_loss 1.754, d_loss 0.267\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 18 Batch 76/390 d_loss_real= 0.362, d_loss_fake= 0.195, g_loss 1.814, d_loss 0.279\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 77/390 d_loss_real= 0.374, d_loss_fake= 0.187, g_loss 1.806, d_loss 0.280\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 78/390 d_loss_real= 0.264, d_loss_fake= 0.217, g_loss 1.796, d_loss 0.241\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 79/390 d_loss_real= 0.471, d_loss_fake= 0.200, g_loss 1.736, d_loss 0.336\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 80/390 d_loss_real= 0.248, d_loss_fake= 0.216, g_loss 1.803, d_loss 0.232\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 81/390 d_loss_real= 0.318, d_loss_fake= 0.216, g_loss 1.787, d_loss 0.267\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 18 Batch 82/390 d_loss_real= 0.441, d_loss_fake= 0.217, g_loss 1.779, d_loss 0.329\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 83/390 d_loss_real= 0.230, d_loss_fake= 0.207, g_loss 1.796, d_loss 0.219\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 18 Batch 84/390 d_loss_real= 0.381, d_loss_fake= 0.207, g_loss 1.741, d_loss 0.294\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 85/390 d_loss_real= 0.299, d_loss_fake= 0.223, g_loss 1.701, d_loss 0.261\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 86/390 d_loss_real= 0.381, d_loss_fake= 0.236, g_loss 1.650, d_loss 0.309\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 87/390 d_loss_real= 0.354, d_loss_fake= 0.229, g_loss 1.657, d_loss 0.291\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 88/390 d_loss_real= 0.276, d_loss_fake= 0.223, g_loss 1.671, d_loss 0.249\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 18 Batch 89/390 d_loss_real= 0.356, d_loss_fake= 0.242, g_loss 1.648, d_loss 0.299\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 18 Batch 90/390 d_loss_real= 0.224, d_loss_fake= 0.233, g_loss 1.671, d_loss 0.229\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 91/390 d_loss_real= 0.310, d_loss_fake= 0.232, g_loss 1.705, d_loss 0.271\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 92/390 d_loss_real= 0.295, d_loss_fake= 0.224, g_loss 1.725, d_loss 0.259\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 93/390 d_loss_real= 0.258, d_loss_fake= 0.218, g_loss 1.687, d_loss 0.238\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 94/390 d_loss_real= 0.236, d_loss_fake= 0.218, g_loss 1.692, d_loss 0.227\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 95/390 d_loss_real= 0.333, d_loss_fake= 0.214, g_loss 1.643, d_loss 0.273\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 96/390 d_loss_real= 0.403, d_loss_fake= 0.230, g_loss 1.679, d_loss 0.316\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 97/390 d_loss_real= 0.196, d_loss_fake= 0.223, g_loss 1.723, d_loss 0.209\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 18 Batch 98/390 d_loss_real= 0.276, d_loss_fake= 0.215, g_loss 1.803, d_loss 0.246\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 99/390 d_loss_real= 0.243, d_loss_fake= 0.181, g_loss 1.882, d_loss 0.212\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 100/390 d_loss_real= 0.469, d_loss_fake= 0.174, g_loss 1.907, d_loss 0.321\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 101/390 d_loss_real= 0.300, d_loss_fake= 0.181, g_loss 1.857, d_loss 0.240\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 102/390 d_loss_real= 0.328, d_loss_fake= 0.196, g_loss 1.717, d_loss 0.262\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 103/390 d_loss_real= 0.460, d_loss_fake= 0.225, g_loss 1.723, d_loss 0.342\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 104/390 d_loss_real= 0.457, d_loss_fake= 0.230, g_loss 1.705, d_loss 0.344\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 105/390 d_loss_real= 0.275, d_loss_fake= 0.222, g_loss 1.792, d_loss 0.248\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 106/390 d_loss_real= 0.351, d_loss_fake= 0.171, g_loss 1.955, d_loss 0.261\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 107/390 d_loss_real= 0.346, d_loss_fake= 0.163, g_loss 1.980, d_loss 0.254\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 18 Batch 108/390 d_loss_real= 0.336, d_loss_fake= 0.160, g_loss 1.948, d_loss 0.248\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 109/390 d_loss_real= 0.538, d_loss_fake= 0.185, g_loss 1.853, d_loss 0.362\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 18 Batch 110/390 d_loss_real= 0.408, d_loss_fake= 0.196, g_loss 1.684, d_loss 0.302\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 111/390 d_loss_real= 0.317, d_loss_fake= 0.266, g_loss 1.568, d_loss 0.292\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 18 Batch 112/390 d_loss_real= 0.295, d_loss_fake= 0.243, g_loss 1.527, d_loss 0.269\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 113/390 d_loss_real= 0.399, d_loss_fake= 0.270, g_loss 1.609, d_loss 0.334\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 114/390 d_loss_real= 0.379, d_loss_fake= 0.235, g_loss 1.743, d_loss 0.307\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 18 Batch 115/390 d_loss_real= 0.348, d_loss_fake= 0.197, g_loss 1.875, d_loss 0.273\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 116/390 d_loss_real= 0.271, d_loss_fake= 0.166, g_loss 1.985, d_loss 0.218\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 18 Batch 117/390 d_loss_real= 0.415, d_loss_fake= 0.156, g_loss 1.972, d_loss 0.286\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 18 Batch 118/390 d_loss_real= 0.423, d_loss_fake= 0.163, g_loss 1.919, d_loss 0.293\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 119/390 d_loss_real= 0.408, d_loss_fake= 0.187, g_loss 1.776, d_loss 0.297\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 18 Batch 120/390 d_loss_real= 0.221, d_loss_fake= 0.229, g_loss 1.644, d_loss 0.225\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 121/390 d_loss_real= 0.293, d_loss_fake= 0.241, g_loss 1.601, d_loss 0.267\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 18 Batch 122/390 d_loss_real= 0.356, d_loss_fake= 0.243, g_loss 1.683, d_loss 0.300\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 123/390 d_loss_real= 0.299, d_loss_fake= 0.202, g_loss 1.801, d_loss 0.250\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 18 Batch 124/390 d_loss_real= 0.354, d_loss_fake= 0.175, g_loss 1.964, d_loss 0.264\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 18 Batch 125/390 d_loss_real= 0.270, d_loss_fake= 0.158, g_loss 1.977, d_loss 0.214\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 18 Batch 126/390 d_loss_real= 0.536, d_loss_fake= 0.172, g_loss 1.941, d_loss 0.354\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 18 Batch 127/390 d_loss_real= 0.390, d_loss_fake= 0.180, g_loss 1.866, d_loss 0.285\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 128/390 d_loss_real= 0.397, d_loss_fake= 0.191, g_loss 1.826, d_loss 0.294\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 129/390 d_loss_real= 0.287, d_loss_fake= 0.199, g_loss 1.727, d_loss 0.243\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 18 Batch 130/390 d_loss_real= 0.380, d_loss_fake= 0.213, g_loss 1.690, d_loss 0.297\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 131/390 d_loss_real= 0.323, d_loss_fake= 0.259, g_loss 1.652, d_loss 0.291\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 132/390 d_loss_real= 0.415, d_loss_fake= 0.236, g_loss 1.738, d_loss 0.326\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 133/390 d_loss_real= 0.374, d_loss_fake= 0.207, g_loss 1.768, d_loss 0.291\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 18 Batch 134/390 d_loss_real= 0.351, d_loss_fake= 0.197, g_loss 1.800, d_loss 0.274\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 135/390 d_loss_real= 0.254, d_loss_fake= 0.188, g_loss 1.829, d_loss 0.221\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 18 Batch 136/390 d_loss_real= 0.357, d_loss_fake= 0.198, g_loss 1.821, d_loss 0.277\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 18 Batch 137/390 d_loss_real= 0.454, d_loss_fake= 0.194, g_loss 1.807, d_loss 0.324\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 138/390 d_loss_real= 0.299, d_loss_fake= 0.205, g_loss 1.800, d_loss 0.252\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 139/390 d_loss_real= 0.346, d_loss_fake= 0.191, g_loss 1.816, d_loss 0.268\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 140/390 d_loss_real= 0.416, d_loss_fake= 0.201, g_loss 1.784, d_loss 0.309\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 18 Batch 141/390 d_loss_real= 0.467, d_loss_fake= 0.218, g_loss 1.708, d_loss 0.342\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 18 Batch 142/390 d_loss_real= 0.301, d_loss_fake= 0.219, g_loss 1.719, d_loss 0.260\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 18 Batch 143/390 d_loss_real= 0.298, d_loss_fake= 0.204, g_loss 1.780, d_loss 0.251\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 144/390 d_loss_real= 0.241, d_loss_fake= 0.183, g_loss 1.878, d_loss 0.212\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 18 Batch 145/390 d_loss_real= 0.245, d_loss_fake= 0.166, g_loss 1.948, d_loss 0.205\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 146/390 d_loss_real= 0.406, d_loss_fake= 0.165, g_loss 1.917, d_loss 0.286\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 147/390 d_loss_real= 0.304, d_loss_fake= 0.163, g_loss 1.899, d_loss 0.233\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 148/390 d_loss_real= 0.237, d_loss_fake= 0.169, g_loss 1.896, d_loss 0.203\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 18 Batch 149/390 d_loss_real= 0.391, d_loss_fake= 0.185, g_loss 1.762, d_loss 0.288\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 150/390 d_loss_real= 0.224, d_loss_fake= 0.201, g_loss 1.692, d_loss 0.212\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 151/390 d_loss_real= 0.317, d_loss_fake= 0.218, g_loss 1.651, d_loss 0.267\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 18 Batch 152/390 d_loss_real= 0.409, d_loss_fake= 0.247, g_loss 1.683, d_loss 0.328\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 153/390 d_loss_real= 0.347, d_loss_fake= 0.235, g_loss 1.802, d_loss 0.291\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 18 Batch 154/390 d_loss_real= 0.396, d_loss_fake= 0.177, g_loss 2.025, d_loss 0.286\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 18 Batch 155/390 d_loss_real= 0.478, d_loss_fake= 0.151, g_loss 2.061, d_loss 0.314\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 156/390 d_loss_real= 0.441, d_loss_fake= 0.147, g_loss 2.020, d_loss 0.294\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 18 Batch 157/390 d_loss_real= 0.458, d_loss_fake= 0.158, g_loss 1.892, d_loss 0.308\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 158/390 d_loss_real= 0.300, d_loss_fake= 0.181, g_loss 1.795, d_loss 0.240\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 159/390 d_loss_real= 0.239, d_loss_fake= 0.206, g_loss 1.720, d_loss 0.223\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 160/390 d_loss_real= 0.352, d_loss_fake= 0.229, g_loss 1.696, d_loss 0.291\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 161/390 d_loss_real= 0.481, d_loss_fake= 0.223, g_loss 1.690, d_loss 0.352\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 18 Batch 162/390 d_loss_real= 0.327, d_loss_fake= 0.217, g_loss 1.726, d_loss 0.272\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 163/390 d_loss_real= 0.343, d_loss_fake= 0.208, g_loss 1.811, d_loss 0.275\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 164/390 d_loss_real= 0.319, d_loss_fake= 0.193, g_loss 1.844, d_loss 0.256\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 165/390 d_loss_real= 0.316, d_loss_fake= 0.185, g_loss 1.873, d_loss 0.251\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 166/390 d_loss_real= 0.448, d_loss_fake= 0.197, g_loss 1.816, d_loss 0.323\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 167/390 d_loss_real= 0.469, d_loss_fake= 0.203, g_loss 1.806, d_loss 0.336\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 168/390 d_loss_real= 0.507, d_loss_fake= 0.206, g_loss 1.752, d_loss 0.357\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 169/390 d_loss_real= 0.548, d_loss_fake= 0.219, g_loss 1.749, d_loss 0.384\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 170/390 d_loss_real= 0.380, d_loss_fake= 0.202, g_loss 1.842, d_loss 0.291\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 18 Batch 171/390 d_loss_real= 0.436, d_loss_fake= 0.202, g_loss 1.935, d_loss 0.319\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 172/390 d_loss_real= 0.357, d_loss_fake= 0.187, g_loss 1.908, d_loss 0.272\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 173/390 d_loss_real= 0.477, d_loss_fake= 0.188, g_loss 1.812, d_loss 0.332\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 174/390 d_loss_real= 0.387, d_loss_fake= 0.212, g_loss 1.769, d_loss 0.300\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 18 Batch 175/390 d_loss_real= 0.522, d_loss_fake= 0.217, g_loss 1.757, d_loss 0.369\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 176/390 d_loss_real= 0.228, d_loss_fake= 0.200, g_loss 1.805, d_loss 0.214\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 18 Batch 177/390 d_loss_real= 0.381, d_loss_fake= 0.192, g_loss 1.789, d_loss 0.286\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 18 Batch 178/390 d_loss_real= 0.358, d_loss_fake= 0.193, g_loss 1.820, d_loss 0.276\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 179/390 d_loss_real= 0.360, d_loss_fake= 0.204, g_loss 1.806, d_loss 0.282\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 18 Batch 180/390 d_loss_real= 0.310, d_loss_fake= 0.180, g_loss 1.856, d_loss 0.245\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 18 Batch 181/390 d_loss_real= 0.249, d_loss_fake= 0.190, g_loss 1.871, d_loss 0.219\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 182/390 d_loss_real= 0.323, d_loss_fake= 0.186, g_loss 1.892, d_loss 0.255\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 183/390 d_loss_real= 0.316, d_loss_fake= 0.170, g_loss 1.923, d_loss 0.243\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 184/390 d_loss_real= 0.439, d_loss_fake= 0.180, g_loss 1.889, d_loss 0.309\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 185/390 d_loss_real= 0.437, d_loss_fake= 0.186, g_loss 1.863, d_loss 0.312\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 186/390 d_loss_real= 0.330, d_loss_fake= 0.204, g_loss 1.698, d_loss 0.267\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 187/390 d_loss_real= 0.473, d_loss_fake= 0.259, g_loss 1.570, d_loss 0.366\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 188/390 d_loss_real= 0.382, d_loss_fake= 0.260, g_loss 1.571, d_loss 0.321\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 18 Batch 189/390 d_loss_real= 0.280, d_loss_fake= 0.229, g_loss 1.716, d_loss 0.255\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 18 Batch 190/390 d_loss_real= 0.384, d_loss_fake= 0.214, g_loss 1.896, d_loss 0.299\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 191/390 d_loss_real= 0.413, d_loss_fake= 0.193, g_loss 1.887, d_loss 0.303\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 192/390 d_loss_real= 0.366, d_loss_fake= 0.186, g_loss 1.809, d_loss 0.276\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 193/390 d_loss_real= 0.365, d_loss_fake= 0.185, g_loss 1.826, d_loss 0.275\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 194/390 d_loss_real= 0.378, d_loss_fake= 0.194, g_loss 1.812, d_loss 0.286\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 195/390 d_loss_real= 0.401, d_loss_fake= 0.207, g_loss 1.738, d_loss 0.304\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 18 Batch 196/390 d_loss_real= 0.240, d_loss_fake= 0.239, g_loss 1.671, d_loss 0.239\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 197/390 d_loss_real= 0.329, d_loss_fake= 0.234, g_loss 1.654, d_loss 0.281\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 18 Batch 198/390 d_loss_real= 0.239, d_loss_fake= 0.225, g_loss 1.642, d_loss 0.232\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 199/390 d_loss_real= 0.390, d_loss_fake= 0.228, g_loss 1.731, d_loss 0.309\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 200/390 d_loss_real= 0.261, d_loss_fake= 0.191, g_loss 1.837, d_loss 0.226\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 201/390 d_loss_real= 0.317, d_loss_fake= 0.202, g_loss 1.805, d_loss 0.260\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 202/390 d_loss_real= 0.299, d_loss_fake= 0.205, g_loss 1.830, d_loss 0.252\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 203/390 d_loss_real= 0.253, d_loss_fake= 0.200, g_loss 1.777, d_loss 0.226\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 204/390 d_loss_real= 0.213, d_loss_fake= 0.189, g_loss 1.857, d_loss 0.201\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 205/390 d_loss_real= 0.210, d_loss_fake= 0.192, g_loss 1.900, d_loss 0.201\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 206/390 d_loss_real= 0.352, d_loss_fake= 0.189, g_loss 1.908, d_loss 0.270\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 207/390 d_loss_real= 0.292, d_loss_fake= 0.184, g_loss 1.835, d_loss 0.238\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 208/390 d_loss_real= 0.408, d_loss_fake= 0.193, g_loss 1.827, d_loss 0.301\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 18 Batch 209/390 d_loss_real= 0.238, d_loss_fake= 0.198, g_loss 1.799, d_loss 0.218\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 210/390 d_loss_real= 0.301, d_loss_fake= 0.189, g_loss 1.962, d_loss 0.245\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 211/390 d_loss_real= 0.397, d_loss_fake= 0.149, g_loss 2.058, d_loss 0.273\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 18 Batch 212/390 d_loss_real= 0.428, d_loss_fake= 0.168, g_loss 2.024, d_loss 0.298\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 18 Batch 213/390 d_loss_real= 0.310, d_loss_fake= 0.149, g_loss 2.029, d_loss 0.230\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 18 Batch 214/390 d_loss_real= 0.233, d_loss_fake= 0.162, g_loss 1.980, d_loss 0.197\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 215/390 d_loss_real= 0.313, d_loss_fake= 0.170, g_loss 1.878, d_loss 0.242\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 216/390 d_loss_real= 0.131, d_loss_fake= 0.180, g_loss 1.883, d_loss 0.156\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 217/390 d_loss_real= 0.323, d_loss_fake= 0.166, g_loss 1.989, d_loss 0.245\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 18 Batch 218/390 d_loss_real= 0.285, d_loss_fake= 0.156, g_loss 1.993, d_loss 0.220\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 18 Batch 219/390 d_loss_real= 0.344, d_loss_fake= 0.153, g_loss 1.994, d_loss 0.248\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 18 Batch 220/390 d_loss_real= 0.363, d_loss_fake= 0.167, g_loss 1.895, d_loss 0.265\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 221/390 d_loss_real= 0.471, d_loss_fake= 0.188, g_loss 1.792, d_loss 0.329\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 222/390 d_loss_real= 0.283, d_loss_fake= 0.202, g_loss 1.797, d_loss 0.242\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 18 Batch 223/390 d_loss_real= 0.364, d_loss_fake= 0.179, g_loss 1.933, d_loss 0.271\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 18 Batch 224/390 d_loss_real= 0.291, d_loss_fake= 0.178, g_loss 1.969, d_loss 0.235\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 225/390 d_loss_real= 0.372, d_loss_fake= 0.164, g_loss 1.964, d_loss 0.268\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 226/390 d_loss_real= 0.463, d_loss_fake= 0.160, g_loss 2.003, d_loss 0.311\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 227/390 d_loss_real= 0.434, d_loss_fake= 0.169, g_loss 1.890, d_loss 0.302\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 18 Batch 228/390 d_loss_real= 0.277, d_loss_fake= 0.182, g_loss 1.882, d_loss 0.229\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 229/390 d_loss_real= 0.323, d_loss_fake= 0.191, g_loss 1.833, d_loss 0.257\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 230/390 d_loss_real= 0.367, d_loss_fake= 0.193, g_loss 1.842, d_loss 0.280\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 231/390 d_loss_real= 0.240, d_loss_fake= 0.181, g_loss 1.913, d_loss 0.210\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 18 Batch 232/390 d_loss_real= 0.239, d_loss_fake= 0.177, g_loss 1.937, d_loss 0.208\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 233/390 d_loss_real= 0.365, d_loss_fake= 0.163, g_loss 1.929, d_loss 0.264\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 234/390 d_loss_real= 0.197, d_loss_fake= 0.170, g_loss 1.954, d_loss 0.184\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 18 Batch 235/390 d_loss_real= 0.423, d_loss_fake= 0.173, g_loss 1.908, d_loss 0.298\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 236/390 d_loss_real= 0.348, d_loss_fake= 0.193, g_loss 1.830, d_loss 0.271\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 237/390 d_loss_real= 0.409, d_loss_fake= 0.205, g_loss 1.776, d_loss 0.307\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 238/390 d_loss_real= 0.328, d_loss_fake= 0.196, g_loss 1.813, d_loss 0.262\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 18 Batch 239/390 d_loss_real= 0.323, d_loss_fake= 0.196, g_loss 1.752, d_loss 0.260\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 240/390 d_loss_real= 0.173, d_loss_fake= 0.207, g_loss 1.806, d_loss 0.190\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 18 Batch 241/390 d_loss_real= 0.366, d_loss_fake= 0.179, g_loss 1.934, d_loss 0.273\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 242/390 d_loss_real= 0.371, d_loss_fake= 0.168, g_loss 1.949, d_loss 0.270\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 243/390 d_loss_real= 0.289, d_loss_fake= 0.178, g_loss 1.917, d_loss 0.234\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 18 Batch 244/390 d_loss_real= 0.357, d_loss_fake= 0.173, g_loss 1.894, d_loss 0.265\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 245/390 d_loss_real= 0.466, d_loss_fake= 0.191, g_loss 1.761, d_loss 0.328\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 18 Batch 246/390 d_loss_real= 0.220, d_loss_fake= 0.212, g_loss 1.703, d_loss 0.216\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 247/390 d_loss_real= 0.315, d_loss_fake= 0.225, g_loss 1.617, d_loss 0.270\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 18 Batch 248/390 d_loss_real= 0.360, d_loss_fake= 0.239, g_loss 1.653, d_loss 0.299\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 249/390 d_loss_real= 0.212, d_loss_fake= 0.217, g_loss 1.746, d_loss 0.215\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 250/390 d_loss_real= 0.245, d_loss_fake= 0.189, g_loss 1.829, d_loss 0.217\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 18 Batch 251/390 d_loss_real= 0.317, d_loss_fake= 0.187, g_loss 1.794, d_loss 0.252\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 252/390 d_loss_real= 0.485, d_loss_fake= 0.206, g_loss 1.705, d_loss 0.345\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 253/390 d_loss_real= 0.235, d_loss_fake= 0.242, g_loss 1.628, d_loss 0.239\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 18 Batch 254/390 d_loss_real= 0.288, d_loss_fake= 0.271, g_loss 1.498, d_loss 0.280\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 255/390 d_loss_real= 0.301, d_loss_fake= 0.314, g_loss 1.402, d_loss 0.307\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 256/390 d_loss_real= 0.209, d_loss_fake= 0.279, g_loss 1.550, d_loss 0.244\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 18 Batch 257/390 d_loss_real= 0.251, d_loss_fake= 0.268, g_loss 1.680, d_loss 0.260\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 258/390 d_loss_real= 0.298, d_loss_fake= 0.225, g_loss 1.758, d_loss 0.262\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 259/390 d_loss_real= 0.274, d_loss_fake= 0.189, g_loss 1.892, d_loss 0.232\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 260/390 d_loss_real= 0.473, d_loss_fake= 0.203, g_loss 1.896, d_loss 0.338\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 18 Batch 261/390 d_loss_real= 0.259, d_loss_fake= 0.205, g_loss 1.805, d_loss 0.232\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 18 Batch 262/390 d_loss_real= 0.400, d_loss_fake= 0.212, g_loss 1.673, d_loss 0.306\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 263/390 d_loss_real= 0.418, d_loss_fake= 0.251, g_loss 1.537, d_loss 0.334\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 18 Batch 264/390 d_loss_real= 0.457, d_loss_fake= 0.294, g_loss 1.470, d_loss 0.376\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 265/390 d_loss_real= 0.220, d_loss_fake= 0.286, g_loss 1.581, d_loss 0.253\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 266/390 d_loss_real= 0.263, d_loss_fake= 0.229, g_loss 1.789, d_loss 0.246\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 18 Batch 267/390 d_loss_real= 0.237, d_loss_fake= 0.171, g_loss 2.060, d_loss 0.204\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 268/390 d_loss_real= 0.458, d_loss_fake= 0.155, g_loss 2.045, d_loss 0.306\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 18 Batch 269/390 d_loss_real= 0.442, d_loss_fake= 0.153, g_loss 1.969, d_loss 0.298\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 270/390 d_loss_real= 0.499, d_loss_fake= 0.170, g_loss 1.877, d_loss 0.334\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 271/390 d_loss_real= 0.640, d_loss_fake= 0.216, g_loss 1.643, d_loss 0.428\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 18 Batch 272/390 d_loss_real= 0.523, d_loss_fake= 0.266, g_loss 1.526, d_loss 0.395\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 18 Batch 273/390 d_loss_real= 0.204, d_loss_fake= 0.304, g_loss 1.665, d_loss 0.254\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 274/390 d_loss_real= 0.310, d_loss_fake= 0.223, g_loss 1.910, d_loss 0.267\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 18 Batch 275/390 d_loss_real= 0.432, d_loss_fake= 0.148, g_loss 2.105, d_loss 0.290\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 276/390 d_loss_real= 0.327, d_loss_fake= 0.126, g_loss 2.252, d_loss 0.226\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 277/390 d_loss_real= 0.410, d_loss_fake= 0.124, g_loss 2.184, d_loss 0.267\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 278/390 d_loss_real= 0.771, d_loss_fake= 0.148, g_loss 1.956, d_loss 0.459\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 279/390 d_loss_real= 0.556, d_loss_fake= 0.185, g_loss 1.703, d_loss 0.370\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 18 Batch 280/390 d_loss_real= 0.319, d_loss_fake= 0.253, g_loss 1.513, d_loss 0.286\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 18 Batch 281/390 d_loss_real= 0.390, d_loss_fake= 0.283, g_loss 1.462, d_loss 0.336\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 282/390 d_loss_real= 0.240, d_loss_fake= 0.301, g_loss 1.559, d_loss 0.271\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 283/390 d_loss_real= 0.272, d_loss_fake= 0.215, g_loss 1.803, d_loss 0.244\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 284/390 d_loss_real= 0.374, d_loss_fake= 0.184, g_loss 1.941, d_loss 0.279\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 18 Batch 285/390 d_loss_real= 0.333, d_loss_fake= 0.166, g_loss 2.003, d_loss 0.249\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 286/390 d_loss_real= 0.320, d_loss_fake= 0.163, g_loss 1.964, d_loss 0.242\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 287/390 d_loss_real= 0.443, d_loss_fake= 0.172, g_loss 1.893, d_loss 0.308\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 288/390 d_loss_real= 0.327, d_loss_fake= 0.190, g_loss 1.764, d_loss 0.259\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 289/390 d_loss_real= 0.312, d_loss_fake= 0.210, g_loss 1.670, d_loss 0.261\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 18 Batch 290/390 d_loss_real= 0.394, d_loss_fake= 0.238, g_loss 1.563, d_loss 0.316\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 291/390 d_loss_real= 0.367, d_loss_fake= 0.288, g_loss 1.475, d_loss 0.327\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 292/390 d_loss_real= 0.197, d_loss_fake= 0.282, g_loss 1.533, d_loss 0.239\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 293/390 d_loss_real= 0.244, d_loss_fake= 0.244, g_loss 1.675, d_loss 0.244\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 294/390 d_loss_real= 0.405, d_loss_fake= 0.208, g_loss 1.843, d_loss 0.307\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 295/390 d_loss_real= 0.265, d_loss_fake= 0.185, g_loss 1.886, d_loss 0.225\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 296/390 d_loss_real= 0.370, d_loss_fake= 0.173, g_loss 1.899, d_loss 0.272\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 297/390 d_loss_real= 0.232, d_loss_fake= 0.173, g_loss 1.912, d_loss 0.203\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 298/390 d_loss_real= 0.383, d_loss_fake= 0.177, g_loss 1.849, d_loss 0.280\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 18 Batch 299/390 d_loss_real= 0.421, d_loss_fake= 0.196, g_loss 1.752, d_loss 0.309\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 300/390 d_loss_real= 0.532, d_loss_fake= 0.236, g_loss 1.619, d_loss 0.384\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 301/390 d_loss_real= 0.248, d_loss_fake= 0.242, g_loss 1.619, d_loss 0.245\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 18 Batch 302/390 d_loss_real= 0.245, d_loss_fake= 0.243, g_loss 1.777, d_loss 0.244\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 303/390 d_loss_real= 0.343, d_loss_fake= 0.182, g_loss 1.923, d_loss 0.262\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 304/390 d_loss_real= 0.210, d_loss_fake= 0.153, g_loss 1.971, d_loss 0.182\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 18 Batch 305/390 d_loss_real= 0.253, d_loss_fake= 0.158, g_loss 1.958, d_loss 0.206\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 306/390 d_loss_real= 0.411, d_loss_fake= 0.178, g_loss 1.865, d_loss 0.294\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 307/390 d_loss_real= 0.593, d_loss_fake= 0.196, g_loss 1.726, d_loss 0.395\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 18 Batch 308/390 d_loss_real= 0.346, d_loss_fake= 0.215, g_loss 1.632, d_loss 0.281\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 309/390 d_loss_real= 0.339, d_loss_fake= 0.274, g_loss 1.621, d_loss 0.307\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 18 Batch 310/390 d_loss_real= 0.337, d_loss_fake= 0.240, g_loss 1.702, d_loss 0.288\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 18 Batch 311/390 d_loss_real= 0.276, d_loss_fake= 0.195, g_loss 1.902, d_loss 0.236\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 18 Batch 312/390 d_loss_real= 0.409, d_loss_fake= 0.154, g_loss 1.984, d_loss 0.281\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 313/390 d_loss_real= 0.338, d_loss_fake= 0.150, g_loss 1.995, d_loss 0.244\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 314/390 d_loss_real= 0.308, d_loss_fake= 0.158, g_loss 1.978, d_loss 0.233\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 315/390 d_loss_real= 0.434, d_loss_fake= 0.161, g_loss 1.905, d_loss 0.298\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 316/390 d_loss_real= 0.454, d_loss_fake= 0.184, g_loss 1.802, d_loss 0.319\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 317/390 d_loss_real= 0.277, d_loss_fake= 0.227, g_loss 1.691, d_loss 0.252\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 318/390 d_loss_real= 0.249, d_loss_fake= 0.233, g_loss 1.678, d_loss 0.241\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 18 Batch 319/390 d_loss_real= 0.306, d_loss_fake= 0.222, g_loss 1.740, d_loss 0.264\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 320/390 d_loss_real= 0.295, d_loss_fake= 0.188, g_loss 1.853, d_loss 0.241\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 321/390 d_loss_real= 0.308, d_loss_fake= 0.188, g_loss 1.870, d_loss 0.248\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 322/390 d_loss_real= 0.237, d_loss_fake= 0.176, g_loss 1.919, d_loss 0.206\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 18 Batch 323/390 d_loss_real= 0.396, d_loss_fake= 0.179, g_loss 1.888, d_loss 0.288\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 324/390 d_loss_real= 0.423, d_loss_fake= 0.183, g_loss 1.846, d_loss 0.303\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 325/390 d_loss_real= 0.330, d_loss_fake= 0.184, g_loss 1.833, d_loss 0.257\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 18 Batch 326/390 d_loss_real= 0.264, d_loss_fake= 0.188, g_loss 1.822, d_loss 0.226\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 327/390 d_loss_real= 0.403, d_loss_fake= 0.204, g_loss 1.794, d_loss 0.304\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 18 Batch 328/390 d_loss_real= 0.276, d_loss_fake= 0.195, g_loss 1.787, d_loss 0.235\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 329/390 d_loss_real= 0.296, d_loss_fake= 0.186, g_loss 1.868, d_loss 0.241\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 330/390 d_loss_real= 0.222, d_loss_fake= 0.171, g_loss 1.977, d_loss 0.196\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 331/390 d_loss_real= 0.183, d_loss_fake= 0.154, g_loss 2.006, d_loss 0.168\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 18 Batch 332/390 d_loss_real= 0.149, d_loss_fake= 0.157, g_loss 2.058, d_loss 0.153\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 18 Batch 333/390 d_loss_real= 0.287, d_loss_fake= 0.140, g_loss 2.077, d_loss 0.213\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 334/390 d_loss_real= 0.488, d_loss_fake= 0.151, g_loss 1.893, d_loss 0.319\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 335/390 d_loss_real= 0.444, d_loss_fake= 0.197, g_loss 1.706, d_loss 0.321\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 336/390 d_loss_real= 0.319, d_loss_fake= 0.239, g_loss 1.642, d_loss 0.279\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 18 Batch 337/390 d_loss_real= 0.231, d_loss_fake= 0.259, g_loss 1.691, d_loss 0.245\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 18 Batch 338/390 d_loss_real= 0.248, d_loss_fake= 0.206, g_loss 1.891, d_loss 0.227\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 339/390 d_loss_real= 0.324, d_loss_fake= 0.169, g_loss 1.965, d_loss 0.246\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 340/390 d_loss_real= 0.301, d_loss_fake= 0.145, g_loss 2.105, d_loss 0.223\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 341/390 d_loss_real= 0.463, d_loss_fake= 0.144, g_loss 2.049, d_loss 0.304\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 342/390 d_loss_real= 0.308, d_loss_fake= 0.152, g_loss 1.973, d_loss 0.230\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 18 Batch 343/390 d_loss_real= 0.425, d_loss_fake= 0.187, g_loss 1.848, d_loss 0.306\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 344/390 d_loss_real= 0.366, d_loss_fake= 0.204, g_loss 1.777, d_loss 0.285\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 18 Batch 345/390 d_loss_real= 0.202, d_loss_fake= 0.207, g_loss 1.813, d_loss 0.205\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 346/390 d_loss_real= 0.247, d_loss_fake= 0.184, g_loss 1.915, d_loss 0.216\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 347/390 d_loss_real= 0.406, d_loss_fake= 0.162, g_loss 1.986, d_loss 0.284\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 18 Batch 348/390 d_loss_real= 0.243, d_loss_fake= 0.159, g_loss 2.017, d_loss 0.201\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 18 Batch 349/390 d_loss_real= 0.284, d_loss_fake= 0.154, g_loss 2.004, d_loss 0.219\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 350/390 d_loss_real= 0.304, d_loss_fake= 0.153, g_loss 2.016, d_loss 0.229\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 351/390 d_loss_real= 0.351, d_loss_fake= 0.155, g_loss 1.977, d_loss 0.253\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 352/390 d_loss_real= 0.237, d_loss_fake= 0.166, g_loss 1.865, d_loss 0.202\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 18 Batch 353/390 d_loss_real= 0.295, d_loss_fake= 0.182, g_loss 1.848, d_loss 0.239\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 354/390 d_loss_real= 0.336, d_loss_fake= 0.183, g_loss 1.919, d_loss 0.260\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 355/390 d_loss_real= 0.278, d_loss_fake= 0.163, g_loss 2.017, d_loss 0.221\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 356/390 d_loss_real= 0.347, d_loss_fake= 0.167, g_loss 1.979, d_loss 0.257\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 357/390 d_loss_real= 0.300, d_loss_fake= 0.162, g_loss 1.995, d_loss 0.231\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 358/390 d_loss_real= 0.320, d_loss_fake= 0.156, g_loss 1.986, d_loss 0.238\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 18 Batch 359/390 d_loss_real= 0.297, d_loss_fake= 0.160, g_loss 2.036, d_loss 0.229\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 360/390 d_loss_real= 0.350, d_loss_fake= 0.155, g_loss 1.947, d_loss 0.252\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 361/390 d_loss_real= 0.397, d_loss_fake= 0.172, g_loss 1.909, d_loss 0.285\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 18 Batch 362/390 d_loss_real= 0.403, d_loss_fake= 0.201, g_loss 1.858, d_loss 0.302\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 18 Batch 363/390 d_loss_real= 0.315, d_loss_fake= 0.169, g_loss 1.935, d_loss 0.242\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 18 Batch 364/390 d_loss_real= 0.363, d_loss_fake= 0.177, g_loss 1.924, d_loss 0.270\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 18 Batch 365/390 d_loss_real= 0.303, d_loss_fake= 0.172, g_loss 1.936, d_loss 0.238\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 366/390 d_loss_real= 0.348, d_loss_fake= 0.171, g_loss 1.926, d_loss 0.260\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 18 Batch 367/390 d_loss_real= 0.417, d_loss_fake= 0.189, g_loss 1.884, d_loss 0.303\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 368/390 d_loss_real= 0.150, d_loss_fake= 0.195, g_loss 1.938, d_loss 0.173\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 18 Batch 369/390 d_loss_real= 0.297, d_loss_fake= 0.159, g_loss 1.983, d_loss 0.228\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 370/390 d_loss_real= 0.388, d_loss_fake= 0.176, g_loss 1.927, d_loss 0.282\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18 Batch 371/390 d_loss_real= 0.356, d_loss_fake= 0.179, g_loss 1.900, d_loss 0.268\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 372/390 d_loss_real= 0.271, d_loss_fake= 0.178, g_loss 1.888, d_loss 0.225\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 373/390 d_loss_real= 0.409, d_loss_fake= 0.176, g_loss 1.947, d_loss 0.293\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 18 Batch 374/390 d_loss_real= 0.228, d_loss_fake= 0.162, g_loss 2.029, d_loss 0.195\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 18 Batch 375/390 d_loss_real= 0.306, d_loss_fake= 0.156, g_loss 2.084, d_loss 0.231\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 376/390 d_loss_real= 0.488, d_loss_fake= 0.152, g_loss 2.049, d_loss 0.320\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 18 Batch 377/390 d_loss_real= 0.281, d_loss_fake= 0.165, g_loss 2.035, d_loss 0.223\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 378/390 d_loss_real= 0.339, d_loss_fake= 0.158, g_loss 2.058, d_loss 0.248\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 18 Batch 379/390 d_loss_real= 0.202, d_loss_fake= 0.141, g_loss 2.116, d_loss 0.171\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 18 Batch 380/390 d_loss_real= 0.390, d_loss_fake= 0.145, g_loss 2.157, d_loss 0.267\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 381/390 d_loss_real= 0.336, d_loss_fake= 0.140, g_loss 2.115, d_loss 0.238\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 382/390 d_loss_real= 0.273, d_loss_fake= 0.150, g_loss 2.015, d_loss 0.211\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 383/390 d_loss_real= 0.366, d_loss_fake= 0.157, g_loss 1.969, d_loss 0.262\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 384/390 d_loss_real= 0.279, d_loss_fake= 0.186, g_loss 1.914, d_loss 0.232\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 18 Batch 385/390 d_loss_real= 0.406, d_loss_fake= 0.210, g_loss 1.891, d_loss 0.308\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 386/390 d_loss_real= 0.362, d_loss_fake= 0.187, g_loss 2.019, d_loss 0.275\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18 Batch 387/390 d_loss_real= 0.473, d_loss_fake= 0.147, g_loss 2.114, d_loss 0.310\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18 Batch 388/390 d_loss_real= 0.420, d_loss_fake= 0.151, g_loss 2.060, d_loss 0.285\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18 Batch 389/390 d_loss_real= 0.368, d_loss_fake= 0.163, g_loss 1.930, d_loss 0.266\n",
            "2/2 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18 Batch 390/390 d_loss_real= 0.446, d_loss_fake= 0.200, g_loss 1.842, d_loss 0.323\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 19 Batch 1/390 d_loss_real= 0.233, d_loss_fake= 0.197, g_loss 1.868, d_loss 0.215\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 2/390 d_loss_real= 0.428, d_loss_fake= 0.184, g_loss 1.993, d_loss 0.306\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 3/390 d_loss_real= 0.362, d_loss_fake= 0.173, g_loss 2.068, d_loss 0.267\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 4/390 d_loss_real= 0.454, d_loss_fake= 0.152, g_loss 2.122, d_loss 0.303\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 5/390 d_loss_real= 0.351, d_loss_fake= 0.134, g_loss 2.206, d_loss 0.242\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 19 Batch 6/390 d_loss_real= 0.434, d_loss_fake= 0.148, g_loss 2.092, d_loss 0.291\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 19 Batch 7/390 d_loss_real= 0.455, d_loss_fake= 0.162, g_loss 1.978, d_loss 0.308\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 19 Batch 8/390 d_loss_real= 0.433, d_loss_fake= 0.183, g_loss 1.826, d_loss 0.308\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 9/390 d_loss_real= 0.180, d_loss_fake= 0.222, g_loss 1.869, d_loss 0.201\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 10/390 d_loss_real= 0.321, d_loss_fake= 0.206, g_loss 1.909, d_loss 0.263\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 11/390 d_loss_real= 0.226, d_loss_fake= 0.171, g_loss 2.100, d_loss 0.198\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 12/390 d_loss_real= 0.266, d_loss_fake= 0.127, g_loss 2.282, d_loss 0.197\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 13/390 d_loss_real= 0.244, d_loss_fake= 0.119, g_loss 2.295, d_loss 0.182\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 19 Batch 14/390 d_loss_real= 0.409, d_loss_fake= 0.123, g_loss 2.195, d_loss 0.266\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 15/390 d_loss_real= 0.436, d_loss_fake= 0.148, g_loss 2.061, d_loss 0.292\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 16/390 d_loss_real= 0.299, d_loss_fake= 0.174, g_loss 1.923, d_loss 0.237\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 17/390 d_loss_real= 0.151, d_loss_fake= 0.193, g_loss 1.874, d_loss 0.172\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 18/390 d_loss_real= 0.244, d_loss_fake= 0.193, g_loss 1.894, d_loss 0.218\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 19/390 d_loss_real= 0.424, d_loss_fake= 0.198, g_loss 1.833, d_loss 0.311\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 19 Batch 20/390 d_loss_real= 0.230, d_loss_fake= 0.178, g_loss 1.929, d_loss 0.204\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 21/390 d_loss_real= 0.285, d_loss_fake= 0.160, g_loss 2.073, d_loss 0.223\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 19 Batch 22/390 d_loss_real= 0.392, d_loss_fake= 0.140, g_loss 2.139, d_loss 0.266\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 23/390 d_loss_real= 0.482, d_loss_fake= 0.150, g_loss 2.037, d_loss 0.316\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 19 Batch 24/390 d_loss_real= 0.295, d_loss_fake= 0.168, g_loss 2.028, d_loss 0.231\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 25/390 d_loss_real= 0.432, d_loss_fake= 0.165, g_loss 1.918, d_loss 0.299\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 26/390 d_loss_real= 0.354, d_loss_fake= 0.178, g_loss 1.857, d_loss 0.266\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 27/390 d_loss_real= 0.475, d_loss_fake= 0.195, g_loss 1.877, d_loss 0.335\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 28/390 d_loss_real= 0.570, d_loss_fake= 0.202, g_loss 1.765, d_loss 0.386\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 29/390 d_loss_real= 0.338, d_loss_fake= 0.194, g_loss 1.848, d_loss 0.266\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 30/390 d_loss_real= 0.230, d_loss_fake= 0.199, g_loss 1.884, d_loss 0.215\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 31/390 d_loss_real= 0.214, d_loss_fake= 0.162, g_loss 2.004, d_loss 0.188\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 32/390 d_loss_real= 0.306, d_loss_fake= 0.150, g_loss 2.080, d_loss 0.228\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 19 Batch 33/390 d_loss_real= 0.330, d_loss_fake= 0.146, g_loss 2.060, d_loss 0.238\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 19 Batch 34/390 d_loss_real= 0.385, d_loss_fake= 0.143, g_loss 2.002, d_loss 0.264\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 35/390 d_loss_real= 0.267, d_loss_fake= 0.168, g_loss 1.903, d_loss 0.218\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 36/390 d_loss_real= 0.143, d_loss_fake= 0.166, g_loss 1.895, d_loss 0.155\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 37/390 d_loss_real= 0.340, d_loss_fake= 0.186, g_loss 1.856, d_loss 0.263\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 38/390 d_loss_real= 0.230, d_loss_fake= 0.179, g_loss 1.883, d_loss 0.204\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 39/390 d_loss_real= 0.330, d_loss_fake= 0.167, g_loss 1.931, d_loss 0.249\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 40/390 d_loss_real= 0.306, d_loss_fake= 0.166, g_loss 1.966, d_loss 0.236\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 19 Batch 41/390 d_loss_real= 0.399, d_loss_fake= 0.165, g_loss 1.902, d_loss 0.282\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 19 Batch 42/390 d_loss_real= 0.320, d_loss_fake= 0.171, g_loss 1.934, d_loss 0.245\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 19 Batch 43/390 d_loss_real= 0.445, d_loss_fake= 0.172, g_loss 1.838, d_loss 0.308\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 19 Batch 44/390 d_loss_real= 0.246, d_loss_fake= 0.194, g_loss 1.808, d_loss 0.220\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 45/390 d_loss_real= 0.271, d_loss_fake= 0.206, g_loss 1.837, d_loss 0.238\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 19 Batch 46/390 d_loss_real= 0.238, d_loss_fake= 0.179, g_loss 1.998, d_loss 0.209\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 47/390 d_loss_real= 0.266, d_loss_fake= 0.156, g_loss 2.046, d_loss 0.211\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 19 Batch 48/390 d_loss_real= 0.245, d_loss_fake= 0.148, g_loss 2.063, d_loss 0.196\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 19 Batch 49/390 d_loss_real= 0.221, d_loss_fake= 0.142, g_loss 2.060, d_loss 0.181\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 19 Batch 50/390 d_loss_real= 0.370, d_loss_fake= 0.149, g_loss 2.039, d_loss 0.259\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 19 Batch 51/390 d_loss_real= 0.300, d_loss_fake= 0.157, g_loss 1.953, d_loss 0.229\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 19 Batch 52/390 d_loss_real= 0.179, d_loss_fake= 0.174, g_loss 1.941, d_loss 0.176\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 53/390 d_loss_real= 0.335, d_loss_fake= 0.171, g_loss 1.928, d_loss 0.253\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 19 Batch 54/390 d_loss_real= 0.238, d_loss_fake= 0.159, g_loss 1.944, d_loss 0.199\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 55/390 d_loss_real= 0.258, d_loss_fake= 0.161, g_loss 1.976, d_loss 0.209\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 56/390 d_loss_real= 0.258, d_loss_fake= 0.165, g_loss 2.029, d_loss 0.212\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 57/390 d_loss_real= 0.305, d_loss_fake= 0.148, g_loss 2.118, d_loss 0.227\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 58/390 d_loss_real= 0.336, d_loss_fake= 0.136, g_loss 2.136, d_loss 0.236\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 59/390 d_loss_real= 0.293, d_loss_fake= 0.131, g_loss 2.105, d_loss 0.212\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 60/390 d_loss_real= 0.386, d_loss_fake= 0.148, g_loss 2.044, d_loss 0.267\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 61/390 d_loss_real= 0.336, d_loss_fake= 0.172, g_loss 1.907, d_loss 0.254\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 62/390 d_loss_real= 0.230, d_loss_fake= 0.185, g_loss 1.928, d_loss 0.207\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 19 Batch 63/390 d_loss_real= 0.230, d_loss_fake= 0.166, g_loss 1.931, d_loss 0.198\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 64/390 d_loss_real= 0.278, d_loss_fake= 0.155, g_loss 2.028, d_loss 0.217\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 65/390 d_loss_real= 0.089, d_loss_fake= 0.148, g_loss 2.062, d_loss 0.119\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 66/390 d_loss_real= 0.405, d_loss_fake= 0.153, g_loss 2.024, d_loss 0.279\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 67/390 d_loss_real= 0.226, d_loss_fake= 0.157, g_loss 1.970, d_loss 0.191\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 68/390 d_loss_real= 0.335, d_loss_fake= 0.159, g_loss 2.007, d_loss 0.247\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 19 Batch 69/390 d_loss_real= 0.400, d_loss_fake= 0.165, g_loss 2.012, d_loss 0.283\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 19 Batch 70/390 d_loss_real= 0.409, d_loss_fake= 0.156, g_loss 2.006, d_loss 0.282\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 19 Batch 71/390 d_loss_real= 0.307, d_loss_fake= 0.172, g_loss 1.948, d_loss 0.240\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 72/390 d_loss_real= 0.349, d_loss_fake= 0.170, g_loss 1.859, d_loss 0.259\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 73/390 d_loss_real= 0.343, d_loss_fake= 0.189, g_loss 1.873, d_loss 0.266\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 74/390 d_loss_real= 0.278, d_loss_fake= 0.188, g_loss 1.909, d_loss 0.233\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 75/390 d_loss_real= 0.287, d_loss_fake= 0.172, g_loss 1.935, d_loss 0.230\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 76/390 d_loss_real= 0.143, d_loss_fake= 0.156, g_loss 2.039, d_loss 0.150\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 77/390 d_loss_real= 0.317, d_loss_fake= 0.149, g_loss 2.090, d_loss 0.233\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 78/390 d_loss_real= 0.405, d_loss_fake= 0.163, g_loss 1.956, d_loss 0.284\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 79/390 d_loss_real= 0.255, d_loss_fake= 0.168, g_loss 1.878, d_loss 0.212\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 80/390 d_loss_real= 0.352, d_loss_fake= 0.194, g_loss 1.770, d_loss 0.273\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 81/390 d_loss_real= 0.267, d_loss_fake= 0.215, g_loss 1.674, d_loss 0.241\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 82/390 d_loss_real= 0.204, d_loss_fake= 0.224, g_loss 1.773, d_loss 0.214\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 83/390 d_loss_real= 0.152, d_loss_fake= 0.167, g_loss 2.072, d_loss 0.159\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 84/390 d_loss_real= 0.247, d_loss_fake= 0.153, g_loss 2.137, d_loss 0.200\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 19 Batch 85/390 d_loss_real= 0.406, d_loss_fake= 0.121, g_loss 2.285, d_loss 0.263\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 86/390 d_loss_real= 0.354, d_loss_fake= 0.128, g_loss 2.180, d_loss 0.241\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 19 Batch 87/390 d_loss_real= 0.447, d_loss_fake= 0.142, g_loss 2.039, d_loss 0.294\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 19 Batch 88/390 d_loss_real= 0.298, d_loss_fake= 0.157, g_loss 1.891, d_loss 0.227\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 89/390 d_loss_real= 0.277, d_loss_fake= 0.190, g_loss 1.845, d_loss 0.233\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 19 Batch 90/390 d_loss_real= 0.342, d_loss_fake= 0.233, g_loss 1.834, d_loss 0.288\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 91/390 d_loss_real= 0.205, d_loss_fake= 0.185, g_loss 2.084, d_loss 0.195\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 92/390 d_loss_real= 0.224, d_loss_fake= 0.141, g_loss 2.240, d_loss 0.183\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 93/390 d_loss_real= 0.339, d_loss_fake= 0.122, g_loss 2.246, d_loss 0.230\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 19 Batch 94/390 d_loss_real= 0.297, d_loss_fake= 0.116, g_loss 2.286, d_loss 0.207\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 95/390 d_loss_real= 0.332, d_loss_fake= 0.125, g_loss 2.161, d_loss 0.228\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 96/390 d_loss_real= 0.208, d_loss_fake= 0.141, g_loss 2.017, d_loss 0.174\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 19 Batch 97/390 d_loss_real= 0.242, d_loss_fake= 0.162, g_loss 1.879, d_loss 0.202\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 98/390 d_loss_real= 0.255, d_loss_fake= 0.193, g_loss 1.770, d_loss 0.224\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 19 Batch 99/390 d_loss_real= 0.263, d_loss_fake= 0.202, g_loss 1.787, d_loss 0.233\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 100/390 d_loss_real= 0.197, d_loss_fake= 0.213, g_loss 1.817, d_loss 0.205\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 19 Batch 101/390 d_loss_real= 0.140, d_loss_fake= 0.177, g_loss 1.996, d_loss 0.158\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 19 Batch 102/390 d_loss_real= 0.203, d_loss_fake= 0.142, g_loss 2.178, d_loss 0.172\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 103/390 d_loss_real= 0.272, d_loss_fake= 0.120, g_loss 2.214, d_loss 0.196\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 19 Batch 104/390 d_loss_real= 0.304, d_loss_fake= 0.123, g_loss 2.181, d_loss 0.213\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 19 Batch 105/390 d_loss_real= 0.447, d_loss_fake= 0.140, g_loss 2.016, d_loss 0.294\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 19 Batch 106/390 d_loss_real= 0.272, d_loss_fake= 0.181, g_loss 1.890, d_loss 0.227\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 107/390 d_loss_real= 0.329, d_loss_fake= 0.220, g_loss 1.784, d_loss 0.275\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 108/390 d_loss_real= 0.106, d_loss_fake= 0.251, g_loss 1.779, d_loss 0.179\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 19 Batch 109/390 d_loss_real= 0.319, d_loss_fake= 0.195, g_loss 1.963, d_loss 0.257\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 110/390 d_loss_real= 0.307, d_loss_fake= 0.153, g_loss 2.084, d_loss 0.230\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 111/390 d_loss_real= 0.278, d_loss_fake= 0.147, g_loss 2.165, d_loss 0.212\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 112/390 d_loss_real= 0.281, d_loss_fake= 0.143, g_loss 2.121, d_loss 0.212\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 19 Batch 113/390 d_loss_real= 0.525, d_loss_fake= 0.162, g_loss 1.940, d_loss 0.343\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 114/390 d_loss_real= 0.338, d_loss_fake= 0.198, g_loss 1.722, d_loss 0.268\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 115/390 d_loss_real= 0.214, d_loss_fake= 0.280, g_loss 1.664, d_loss 0.247\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 116/390 d_loss_real= 0.364, d_loss_fake= 0.231, g_loss 1.729, d_loss 0.298\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 19 Batch 117/390 d_loss_real= 0.239, d_loss_fake= 0.209, g_loss 1.946, d_loss 0.224\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 118/390 d_loss_real= 0.520, d_loss_fake= 0.163, g_loss 2.123, d_loss 0.342\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 119/390 d_loss_real= 0.323, d_loss_fake= 0.133, g_loss 2.201, d_loss 0.228\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 120/390 d_loss_real= 0.508, d_loss_fake= 0.137, g_loss 2.130, d_loss 0.322\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 19 Batch 121/390 d_loss_real= 0.372, d_loss_fake= 0.146, g_loss 2.005, d_loss 0.259\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 122/390 d_loss_real= 0.254, d_loss_fake= 0.172, g_loss 1.971, d_loss 0.213\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 123/390 d_loss_real= 0.398, d_loss_fake= 0.181, g_loss 1.900, d_loss 0.290\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 124/390 d_loss_real= 0.327, d_loss_fake= 0.195, g_loss 1.797, d_loss 0.261\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 125/390 d_loss_real= 0.388, d_loss_fake= 0.200, g_loss 1.738, d_loss 0.294\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 19 Batch 126/390 d_loss_real= 0.400, d_loss_fake= 0.224, g_loss 1.757, d_loss 0.312\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 19 Batch 127/390 d_loss_real= 0.225, d_loss_fake= 0.216, g_loss 1.850, d_loss 0.221\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 128/390 d_loss_real= 0.248, d_loss_fake= 0.168, g_loss 2.008, d_loss 0.208\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 129/390 d_loss_real= 0.457, d_loss_fake= 0.160, g_loss 2.006, d_loss 0.308\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 130/390 d_loss_real= 0.478, d_loss_fake= 0.170, g_loss 1.945, d_loss 0.324\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 131/390 d_loss_real= 0.148, d_loss_fake= 0.173, g_loss 1.984, d_loss 0.160\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 132/390 d_loss_real= 0.379, d_loss_fake= 0.185, g_loss 1.863, d_loss 0.282\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 133/390 d_loss_real= 0.241, d_loss_fake= 0.199, g_loss 1.889, d_loss 0.220\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 134/390 d_loss_real= 0.319, d_loss_fake= 0.191, g_loss 1.917, d_loss 0.255\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 19 Batch 135/390 d_loss_real= 0.297, d_loss_fake= 0.184, g_loss 1.935, d_loss 0.240\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 136/390 d_loss_real= 0.352, d_loss_fake= 0.178, g_loss 2.050, d_loss 0.265\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 19 Batch 137/390 d_loss_real= 0.364, d_loss_fake= 0.151, g_loss 2.087, d_loss 0.258\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 19 Batch 138/390 d_loss_real= 0.466, d_loss_fake= 0.156, g_loss 2.043, d_loss 0.311\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 19 Batch 139/390 d_loss_real= 0.307, d_loss_fake= 0.168, g_loss 2.037, d_loss 0.237\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 140/390 d_loss_real= 0.338, d_loss_fake= 0.169, g_loss 2.085, d_loss 0.254\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 141/390 d_loss_real= 0.224, d_loss_fake= 0.142, g_loss 2.035, d_loss 0.183\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 142/390 d_loss_real= 0.310, d_loss_fake= 0.178, g_loss 1.874, d_loss 0.244\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 143/390 d_loss_real= 0.375, d_loss_fake= 0.215, g_loss 1.972, d_loss 0.295\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 144/390 d_loss_real= 0.334, d_loss_fake= 0.182, g_loss 2.053, d_loss 0.258\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 19 Batch 145/390 d_loss_real= 0.473, d_loss_fake= 0.153, g_loss 2.088, d_loss 0.313\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 146/390 d_loss_real= 0.300, d_loss_fake= 0.131, g_loss 2.153, d_loss 0.216\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 19 Batch 147/390 d_loss_real= 0.265, d_loss_fake= 0.147, g_loss 2.092, d_loss 0.206\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 148/390 d_loss_real= 0.265, d_loss_fake= 0.158, g_loss 2.081, d_loss 0.212\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 149/390 d_loss_real= 0.297, d_loss_fake= 0.176, g_loss 1.990, d_loss 0.237\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 150/390 d_loss_real= 0.214, d_loss_fake= 0.170, g_loss 1.986, d_loss 0.192\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 151/390 d_loss_real= 0.402, d_loss_fake= 0.172, g_loss 2.028, d_loss 0.287\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 152/390 d_loss_real= 0.213, d_loss_fake= 0.154, g_loss 2.116, d_loss 0.183\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 19 Batch 153/390 d_loss_real= 0.308, d_loss_fake= 0.139, g_loss 2.146, d_loss 0.224\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 19 Batch 154/390 d_loss_real= 0.337, d_loss_fake= 0.137, g_loss 2.130, d_loss 0.237\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 155/390 d_loss_real= 0.308, d_loss_fake= 0.137, g_loss 2.063, d_loss 0.222\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 19 Batch 156/390 d_loss_real= 0.428, d_loss_fake= 0.168, g_loss 2.009, d_loss 0.298\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 157/390 d_loss_real= 0.218, d_loss_fake= 0.147, g_loss 2.037, d_loss 0.183\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 158/390 d_loss_real= 0.235, d_loss_fake= 0.150, g_loss 2.071, d_loss 0.193\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 19 Batch 159/390 d_loss_real= 0.271, d_loss_fake= 0.153, g_loss 2.129, d_loss 0.212\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 19 Batch 160/390 d_loss_real= 0.298, d_loss_fake= 0.141, g_loss 2.131, d_loss 0.219\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 19 Batch 161/390 d_loss_real= 0.339, d_loss_fake= 0.155, g_loss 2.082, d_loss 0.247\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 162/390 d_loss_real= 0.289, d_loss_fake= 0.153, g_loss 2.099, d_loss 0.221\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 163/390 d_loss_real= 0.488, d_loss_fake= 0.152, g_loss 2.024, d_loss 0.320\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 164/390 d_loss_real= 0.409, d_loss_fake= 0.162, g_loss 1.972, d_loss 0.285\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 165/390 d_loss_real= 0.286, d_loss_fake= 0.174, g_loss 1.874, d_loss 0.230\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 166/390 d_loss_real= 0.361, d_loss_fake= 0.185, g_loss 1.901, d_loss 0.273\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 167/390 d_loss_real= 0.133, d_loss_fake= 0.163, g_loss 1.986, d_loss 0.148\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 168/390 d_loss_real= 0.257, d_loss_fake= 0.156, g_loss 1.995, d_loss 0.207\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 169/390 d_loss_real= 0.517, d_loss_fake= 0.162, g_loss 2.008, d_loss 0.340\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 170/390 d_loss_real= 0.291, d_loss_fake= 0.152, g_loss 1.982, d_loss 0.222\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 171/390 d_loss_real= 0.323, d_loss_fake= 0.158, g_loss 1.963, d_loss 0.241\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 172/390 d_loss_real= 0.445, d_loss_fake= 0.175, g_loss 1.887, d_loss 0.310\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 173/390 d_loss_real= 0.395, d_loss_fake= 0.192, g_loss 1.842, d_loss 0.293\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 174/390 d_loss_real= 0.218, d_loss_fake= 0.202, g_loss 1.824, d_loss 0.210\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 19 Batch 175/390 d_loss_real= 0.412, d_loss_fake= 0.203, g_loss 1.780, d_loss 0.307\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 19 Batch 176/390 d_loss_real= 0.272, d_loss_fake= 0.205, g_loss 1.799, d_loss 0.239\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 19 Batch 177/390 d_loss_real= 0.276, d_loss_fake= 0.199, g_loss 1.849, d_loss 0.238\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 178/390 d_loss_real= 0.324, d_loss_fake= 0.188, g_loss 1.855, d_loss 0.256\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 179/390 d_loss_real= 0.206, d_loss_fake= 0.177, g_loss 1.927, d_loss 0.191\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 180/390 d_loss_real= 0.292, d_loss_fake= 0.167, g_loss 1.977, d_loss 0.230\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 181/390 d_loss_real= 0.268, d_loss_fake= 0.154, g_loss 2.001, d_loss 0.211\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 182/390 d_loss_real= 0.379, d_loss_fake= 0.158, g_loss 1.947, d_loss 0.268\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 183/390 d_loss_real= 0.331, d_loss_fake= 0.173, g_loss 1.835, d_loss 0.252\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 19 Batch 184/390 d_loss_real= 0.188, d_loss_fake= 0.197, g_loss 1.761, d_loss 0.193\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 19 Batch 185/390 d_loss_real= 0.154, d_loss_fake= 0.206, g_loss 1.766, d_loss 0.180\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 19 Batch 186/390 d_loss_real= 0.326, d_loss_fake= 0.199, g_loss 1.778, d_loss 0.263\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 19 Batch 187/390 d_loss_real= 0.239, d_loss_fake= 0.200, g_loss 1.876, d_loss 0.219\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 188/390 d_loss_real= 0.183, d_loss_fake= 0.175, g_loss 2.041, d_loss 0.179\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 189/390 d_loss_real= 0.301, d_loss_fake= 0.139, g_loss 2.138, d_loss 0.220\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 19 Batch 190/390 d_loss_real= 0.354, d_loss_fake= 0.140, g_loss 2.081, d_loss 0.247\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 191/390 d_loss_real= 0.295, d_loss_fake= 0.154, g_loss 2.019, d_loss 0.225\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 192/390 d_loss_real= 0.271, d_loss_fake= 0.159, g_loss 2.012, d_loss 0.215\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 193/390 d_loss_real= 0.438, d_loss_fake= 0.141, g_loss 2.163, d_loss 0.290\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 194/390 d_loss_real= 0.110, d_loss_fake= 0.126, g_loss 2.286, d_loss 0.118\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 19 Batch 195/390 d_loss_real= 0.328, d_loss_fake= 0.111, g_loss 2.367, d_loss 0.219\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 196/390 d_loss_real= 0.386, d_loss_fake= 0.107, g_loss 2.262, d_loss 0.246\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 197/390 d_loss_real= 0.229, d_loss_fake= 0.119, g_loss 2.221, d_loss 0.174\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 198/390 d_loss_real= 0.487, d_loss_fake= 0.150, g_loss 2.009, d_loss 0.319\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 19 Batch 199/390 d_loss_real= 0.202, d_loss_fake= 0.202, g_loss 1.918, d_loss 0.202\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 200/390 d_loss_real= 0.150, d_loss_fake= 0.196, g_loss 2.018, d_loss 0.173\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 201/390 d_loss_real= 0.289, d_loss_fake= 0.148, g_loss 2.234, d_loss 0.219\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 19 Batch 202/390 d_loss_real= 0.346, d_loss_fake= 0.111, g_loss 2.389, d_loss 0.229\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 19 Batch 203/390 d_loss_real= 0.299, d_loss_fake= 0.104, g_loss 2.417, d_loss 0.201\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 19 Batch 204/390 d_loss_real= 0.320, d_loss_fake= 0.099, g_loss 2.470, d_loss 0.210\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 205/390 d_loss_real= 0.515, d_loss_fake= 0.098, g_loss 2.344, d_loss 0.306\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 206/390 d_loss_real= 0.176, d_loss_fake= 0.128, g_loss 2.215, d_loss 0.152\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 207/390 d_loss_real= 0.267, d_loss_fake= 0.151, g_loss 2.166, d_loss 0.209\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 19 Batch 208/390 d_loss_real= 0.393, d_loss_fake= 0.153, g_loss 2.047, d_loss 0.273\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 209/390 d_loss_real= 0.254, d_loss_fake= 0.147, g_loss 2.018, d_loss 0.201\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 210/390 d_loss_real= 0.282, d_loss_fake= 0.138, g_loss 2.213, d_loss 0.210\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 211/390 d_loss_real= 0.341, d_loss_fake= 0.159, g_loss 2.129, d_loss 0.250\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 19 Batch 212/390 d_loss_real= 0.460, d_loss_fake= 0.132, g_loss 2.239, d_loss 0.296\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 213/390 d_loss_real= 0.235, d_loss_fake= 0.125, g_loss 2.291, d_loss 0.180\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 19 Batch 214/390 d_loss_real= 0.428, d_loss_fake= 0.112, g_loss 2.243, d_loss 0.270\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 19 Batch 215/390 d_loss_real= 0.407, d_loss_fake= 0.138, g_loss 2.129, d_loss 0.273\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 216/390 d_loss_real= 0.469, d_loss_fake= 0.194, g_loss 1.972, d_loss 0.331\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 19 Batch 217/390 d_loss_real= 0.272, d_loss_fake= 0.181, g_loss 1.999, d_loss 0.226\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 218/390 d_loss_real= 0.324, d_loss_fake= 0.157, g_loss 2.181, d_loss 0.240\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 219/390 d_loss_real= 0.284, d_loss_fake= 0.123, g_loss 2.292, d_loss 0.204\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 220/390 d_loss_real= 0.205, d_loss_fake= 0.116, g_loss 2.285, d_loss 0.161\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 221/390 d_loss_real= 0.186, d_loss_fake= 0.116, g_loss 2.269, d_loss 0.151\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 19 Batch 222/390 d_loss_real= 0.242, d_loss_fake= 0.126, g_loss 2.174, d_loss 0.184\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 19 Batch 223/390 d_loss_real= 0.279, d_loss_fake= 0.141, g_loss 2.058, d_loss 0.210\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 224/390 d_loss_real= 0.215, d_loss_fake= 0.156, g_loss 2.023, d_loss 0.186\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 225/390 d_loss_real= 0.222, d_loss_fake= 0.174, g_loss 2.040, d_loss 0.198\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 226/390 d_loss_real= 0.405, d_loss_fake= 0.167, g_loss 2.035, d_loss 0.286\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 19 Batch 227/390 d_loss_real= 0.305, d_loss_fake= 0.162, g_loss 2.095, d_loss 0.233\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 228/390 d_loss_real= 0.334, d_loss_fake= 0.146, g_loss 2.134, d_loss 0.240\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 229/390 d_loss_real= 0.219, d_loss_fake= 0.132, g_loss 2.215, d_loss 0.175\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 230/390 d_loss_real= 0.270, d_loss_fake= 0.146, g_loss 2.143, d_loss 0.208\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 231/390 d_loss_real= 0.301, d_loss_fake= 0.165, g_loss 2.103, d_loss 0.233\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 19 Batch 232/390 d_loss_real= 0.159, d_loss_fake= 0.137, g_loss 2.157, d_loss 0.148\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 19 Batch 233/390 d_loss_real= 0.278, d_loss_fake= 0.141, g_loss 2.170, d_loss 0.210\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 19 Batch 234/390 d_loss_real= 0.257, d_loss_fake= 0.127, g_loss 2.153, d_loss 0.192\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 235/390 d_loss_real= 0.273, d_loss_fake= 0.130, g_loss 2.102, d_loss 0.201\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 19 Batch 236/390 d_loss_real= 0.186, d_loss_fake= 0.144, g_loss 2.112, d_loss 0.165\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 19 Batch 237/390 d_loss_real= 0.259, d_loss_fake= 0.135, g_loss 2.157, d_loss 0.197\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 19 Batch 238/390 d_loss_real= 0.282, d_loss_fake= 0.139, g_loss 2.138, d_loss 0.210\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 19 Batch 239/390 d_loss_real= 0.337, d_loss_fake= 0.127, g_loss 2.217, d_loss 0.232\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 240/390 d_loss_real= 0.240, d_loss_fake= 0.128, g_loss 2.289, d_loss 0.184\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 19 Batch 241/390 d_loss_real= 0.487, d_loss_fake= 0.127, g_loss 2.280, d_loss 0.307\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 19 Batch 242/390 d_loss_real= 0.319, d_loss_fake= 0.140, g_loss 2.167, d_loss 0.229\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 19 Batch 243/390 d_loss_real= 0.332, d_loss_fake= 0.151, g_loss 1.958, d_loss 0.242\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 244/390 d_loss_real= 0.421, d_loss_fake= 0.178, g_loss 2.003, d_loss 0.299\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 245/390 d_loss_real= 0.162, d_loss_fake= 0.163, g_loss 2.178, d_loss 0.163\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 19 Batch 246/390 d_loss_real= 0.287, d_loss_fake= 0.125, g_loss 2.314, d_loss 0.206\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 19 Batch 247/390 d_loss_real= 0.432, d_loss_fake= 0.109, g_loss 2.316, d_loss 0.270\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 248/390 d_loss_real= 0.268, d_loss_fake= 0.120, g_loss 2.180, d_loss 0.194\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 249/390 d_loss_real= 0.392, d_loss_fake= 0.137, g_loss 2.046, d_loss 0.264\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 250/390 d_loss_real= 0.330, d_loss_fake= 0.170, g_loss 1.872, d_loss 0.250\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 19 Batch 251/390 d_loss_real= 0.222, d_loss_fake= 0.195, g_loss 1.794, d_loss 0.208\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 252/390 d_loss_real= 0.293, d_loss_fake= 0.186, g_loss 1.936, d_loss 0.240\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 253/390 d_loss_real= 0.177, d_loss_fake= 0.171, g_loss 2.160, d_loss 0.174\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 254/390 d_loss_real= 0.204, d_loss_fake= 0.116, g_loss 2.358, d_loss 0.160\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 255/390 d_loss_real= 0.233, d_loss_fake= 0.117, g_loss 2.263, d_loss 0.175\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 256/390 d_loss_real= 0.346, d_loss_fake= 0.116, g_loss 2.169, d_loss 0.231\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 257/390 d_loss_real= 0.394, d_loss_fake= 0.144, g_loss 2.008, d_loss 0.269\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 258/390 d_loss_real= 0.308, d_loss_fake= 0.182, g_loss 1.809, d_loss 0.245\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 19 Batch 259/390 d_loss_real= 0.234, d_loss_fake= 0.212, g_loss 1.834, d_loss 0.223\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 260/390 d_loss_real= 0.292, d_loss_fake= 0.172, g_loss 2.081, d_loss 0.232\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 261/390 d_loss_real= 0.241, d_loss_fake= 0.152, g_loss 2.109, d_loss 0.196\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 19 Batch 262/390 d_loss_real= 0.281, d_loss_fake= 0.119, g_loss 2.184, d_loss 0.200\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 19 Batch 263/390 d_loss_real= 0.300, d_loss_fake= 0.134, g_loss 2.127, d_loss 0.217\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 264/390 d_loss_real= 0.450, d_loss_fake= 0.152, g_loss 1.980, d_loss 0.301\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 265/390 d_loss_real= 0.132, d_loss_fake= 0.167, g_loss 1.958, d_loss 0.149\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 19 Batch 266/390 d_loss_real= 0.225, d_loss_fake= 0.158, g_loss 2.077, d_loss 0.192\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 267/390 d_loss_real= 0.356, d_loss_fake= 0.138, g_loss 2.129, d_loss 0.247\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 268/390 d_loss_real= 0.273, d_loss_fake= 0.141, g_loss 2.158, d_loss 0.207\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 269/390 d_loss_real= 0.331, d_loss_fake= 0.131, g_loss 2.184, d_loss 0.231\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 19 Batch 270/390 d_loss_real= 0.423, d_loss_fake= 0.147, g_loss 2.057, d_loss 0.285\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 19 Batch 271/390 d_loss_real= 0.227, d_loss_fake= 0.166, g_loss 1.882, d_loss 0.196\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 272/390 d_loss_real= 0.446, d_loss_fake= 0.180, g_loss 1.839, d_loss 0.313\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 273/390 d_loss_real= 0.184, d_loss_fake= 0.202, g_loss 1.834, d_loss 0.193\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 19 Batch 274/390 d_loss_real= 0.206, d_loss_fake= 0.221, g_loss 1.865, d_loss 0.214\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 275/390 d_loss_real= 0.289, d_loss_fake= 0.195, g_loss 1.896, d_loss 0.242\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 276/390 d_loss_real= 0.271, d_loss_fake= 0.171, g_loss 1.920, d_loss 0.221\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 277/390 d_loss_real= 0.236, d_loss_fake= 0.144, g_loss 2.040, d_loss 0.190\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 278/390 d_loss_real= 0.346, d_loss_fake= 0.151, g_loss 2.027, d_loss 0.248\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 279/390 d_loss_real= 0.304, d_loss_fake= 0.147, g_loss 2.043, d_loss 0.225\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 280/390 d_loss_real= 0.204, d_loss_fake= 0.165, g_loss 1.901, d_loss 0.184\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 281/390 d_loss_real= 0.251, d_loss_fake= 0.169, g_loss 1.922, d_loss 0.210\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 19 Batch 282/390 d_loss_real= 0.388, d_loss_fake= 0.192, g_loss 1.789, d_loss 0.290\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 283/390 d_loss_real= 0.242, d_loss_fake= 0.236, g_loss 1.795, d_loss 0.239\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 284/390 d_loss_real= 0.248, d_loss_fake= 0.177, g_loss 2.002, d_loss 0.212\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 285/390 d_loss_real= 0.454, d_loss_fake= 0.144, g_loss 2.141, d_loss 0.299\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 286/390 d_loss_real= 0.178, d_loss_fake= 0.142, g_loss 2.150, d_loss 0.160\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 19 Batch 287/390 d_loss_real= 0.283, d_loss_fake= 0.131, g_loss 2.146, d_loss 0.207\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 19 Batch 288/390 d_loss_real= 0.324, d_loss_fake= 0.139, g_loss 2.153, d_loss 0.232\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 289/390 d_loss_real= 0.354, d_loss_fake= 0.157, g_loss 1.894, d_loss 0.256\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 290/390 d_loss_real= 0.318, d_loss_fake= 0.190, g_loss 1.835, d_loss 0.254\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 291/390 d_loss_real= 0.306, d_loss_fake= 0.229, g_loss 1.787, d_loss 0.267\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 292/390 d_loss_real= 0.288, d_loss_fake= 0.223, g_loss 1.812, d_loss 0.256\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 293/390 d_loss_real= 0.307, d_loss_fake= 0.188, g_loss 1.919, d_loss 0.247\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 19 Batch 294/390 d_loss_real= 0.526, d_loss_fake= 0.188, g_loss 1.865, d_loss 0.357\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 295/390 d_loss_real= 0.165, d_loss_fake= 0.173, g_loss 1.998, d_loss 0.169\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 19 Batch 296/390 d_loss_real= 0.355, d_loss_fake= 0.159, g_loss 2.028, d_loss 0.257\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 297/390 d_loss_real= 0.346, d_loss_fake= 0.157, g_loss 2.042, d_loss 0.251\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 298/390 d_loss_real= 0.235, d_loss_fake= 0.152, g_loss 1.961, d_loss 0.194\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 299/390 d_loss_real= 0.280, d_loss_fake= 0.174, g_loss 1.919, d_loss 0.227\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 300/390 d_loss_real= 0.316, d_loss_fake= 0.214, g_loss 1.802, d_loss 0.265\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 19 Batch 301/390 d_loss_real= 0.344, d_loss_fake= 0.231, g_loss 1.855, d_loss 0.288\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 19 Batch 302/390 d_loss_real= 0.212, d_loss_fake= 0.173, g_loss 2.052, d_loss 0.193\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 303/390 d_loss_real= 0.283, d_loss_fake= 0.133, g_loss 2.124, d_loss 0.208\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 304/390 d_loss_real= 0.398, d_loss_fake= 0.127, g_loss 2.167, d_loss 0.262\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 305/390 d_loss_real= 0.232, d_loss_fake= 0.135, g_loss 2.132, d_loss 0.184\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 19 Batch 306/390 d_loss_real= 0.392, d_loss_fake= 0.142, g_loss 2.127, d_loss 0.267\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 307/390 d_loss_real= 0.250, d_loss_fake= 0.154, g_loss 2.088, d_loss 0.202\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 19 Batch 308/390 d_loss_real= 0.326, d_loss_fake= 0.145, g_loss 2.136, d_loss 0.235\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 19 Batch 309/390 d_loss_real= 0.234, d_loss_fake= 0.161, g_loss 2.076, d_loss 0.198\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 19 Batch 310/390 d_loss_real= 0.303, d_loss_fake= 0.171, g_loss 2.120, d_loss 0.237\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 311/390 d_loss_real= 0.373, d_loss_fake= 0.189, g_loss 2.085, d_loss 0.281\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 312/390 d_loss_real= 0.206, d_loss_fake= 0.141, g_loss 2.197, d_loss 0.174\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 19 Batch 313/390 d_loss_real= 0.281, d_loss_fake= 0.169, g_loss 2.155, d_loss 0.225\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 19 Batch 314/390 d_loss_real= 0.341, d_loss_fake= 0.160, g_loss 2.194, d_loss 0.251\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 315/390 d_loss_real= 0.253, d_loss_fake= 0.141, g_loss 2.137, d_loss 0.197\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 316/390 d_loss_real= 0.363, d_loss_fake= 0.156, g_loss 2.067, d_loss 0.260\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 19 Batch 317/390 d_loss_real= 0.379, d_loss_fake= 0.191, g_loss 1.939, d_loss 0.285\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 318/390 d_loss_real= 0.220, d_loss_fake= 0.177, g_loss 2.160, d_loss 0.199\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 319/390 d_loss_real= 0.234, d_loss_fake= 0.111, g_loss 2.440, d_loss 0.172\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 320/390 d_loss_real= 0.361, d_loss_fake= 0.088, g_loss 2.537, d_loss 0.224\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 321/390 d_loss_real= 0.311, d_loss_fake= 0.105, g_loss 2.419, d_loss 0.208\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 19 Batch 322/390 d_loss_real= 0.224, d_loss_fake= 0.111, g_loss 2.293, d_loss 0.167\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 19 Batch 323/390 d_loss_real= 0.360, d_loss_fake= 0.129, g_loss 2.106, d_loss 0.245\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 19 Batch 324/390 d_loss_real= 0.376, d_loss_fake= 0.192, g_loss 1.881, d_loss 0.284\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 325/390 d_loss_real= 0.217, d_loss_fake= 0.177, g_loss 2.070, d_loss 0.197\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 326/390 d_loss_real= 0.351, d_loss_fake= 0.124, g_loss 2.242, d_loss 0.238\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 19 Batch 327/390 d_loss_real= 0.235, d_loss_fake= 0.118, g_loss 2.359, d_loss 0.176\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 328/390 d_loss_real= 0.248, d_loss_fake= 0.109, g_loss 2.361, d_loss 0.179\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 329/390 d_loss_real= 0.308, d_loss_fake= 0.126, g_loss 2.182, d_loss 0.217\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 330/390 d_loss_real= 0.239, d_loss_fake= 0.150, g_loss 2.000, d_loss 0.195\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 331/390 d_loss_real= 0.203, d_loss_fake= 0.169, g_loss 2.041, d_loss 0.186\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 19 Batch 332/390 d_loss_real= 0.266, d_loss_fake= 0.135, g_loss 2.180, d_loss 0.200\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 19 Batch 333/390 d_loss_real= 0.384, d_loss_fake= 0.152, g_loss 2.149, d_loss 0.268\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 334/390 d_loss_real= 0.401, d_loss_fake= 0.133, g_loss 2.182, d_loss 0.267\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 335/390 d_loss_real= 0.434, d_loss_fake= 0.142, g_loss 2.171, d_loss 0.288\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 336/390 d_loss_real= 0.397, d_loss_fake= 0.164, g_loss 1.974, d_loss 0.281\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 337/390 d_loss_real= 0.368, d_loss_fake= 0.175, g_loss 1.943, d_loss 0.272\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 338/390 d_loss_real= 0.529, d_loss_fake= 0.189, g_loss 1.890, d_loss 0.359\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 19 Batch 339/390 d_loss_real= 0.336, d_loss_fake= 0.178, g_loss 1.876, d_loss 0.257\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 340/390 d_loss_real= 0.261, d_loss_fake= 0.177, g_loss 1.887, d_loss 0.219\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 341/390 d_loss_real= 0.253, d_loss_fake= 0.178, g_loss 1.964, d_loss 0.216\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 19 Batch 342/390 d_loss_real= 0.369, d_loss_fake= 0.162, g_loss 2.010, d_loss 0.266\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 343/390 d_loss_real= 0.259, d_loss_fake= 0.164, g_loss 2.043, d_loss 0.212\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 344/390 d_loss_real= 0.256, d_loss_fake= 0.151, g_loss 1.986, d_loss 0.204\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 19 Batch 345/390 d_loss_real= 0.335, d_loss_fake= 0.169, g_loss 1.990, d_loss 0.252\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 19 Batch 346/390 d_loss_real= 0.240, d_loss_fake= 0.161, g_loss 1.986, d_loss 0.200\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 347/390 d_loss_real= 0.321, d_loss_fake= 0.168, g_loss 1.901, d_loss 0.245\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 348/390 d_loss_real= 0.361, d_loss_fake= 0.192, g_loss 1.860, d_loss 0.277\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 349/390 d_loss_real= 0.223, d_loss_fake= 0.196, g_loss 1.810, d_loss 0.210\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 350/390 d_loss_real= 0.320, d_loss_fake= 0.218, g_loss 1.813, d_loss 0.269\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 351/390 d_loss_real= 0.212, d_loss_fake= 0.194, g_loss 1.932, d_loss 0.203\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 352/390 d_loss_real= 0.348, d_loss_fake= 0.162, g_loss 1.999, d_loss 0.255\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 19 Batch 353/390 d_loss_real= 0.331, d_loss_fake= 0.153, g_loss 2.055, d_loss 0.242\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 354/390 d_loss_real= 0.208, d_loss_fake= 0.147, g_loss 2.058, d_loss 0.178\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 355/390 d_loss_real= 0.223, d_loss_fake= 0.143, g_loss 2.041, d_loss 0.183\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 356/390 d_loss_real= 0.221, d_loss_fake= 0.155, g_loss 2.057, d_loss 0.188\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 357/390 d_loss_real= 0.410, d_loss_fake= 0.156, g_loss 2.080, d_loss 0.283\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 19 Batch 358/390 d_loss_real= 0.199, d_loss_fake= 0.152, g_loss 2.055, d_loss 0.176\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 359/390 d_loss_real= 0.273, d_loss_fake= 0.145, g_loss 2.052, d_loss 0.209\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 360/390 d_loss_real= 0.259, d_loss_fake= 0.152, g_loss 2.074, d_loss 0.206\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 361/390 d_loss_real= 0.210, d_loss_fake= 0.152, g_loss 2.104, d_loss 0.181\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 362/390 d_loss_real= 0.309, d_loss_fake= 0.133, g_loss 2.211, d_loss 0.221\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 19 Batch 363/390 d_loss_real= 0.087, d_loss_fake= 0.126, g_loss 2.330, d_loss 0.106\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 364/390 d_loss_real= 0.392, d_loss_fake= 0.121, g_loss 2.275, d_loss 0.257\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 365/390 d_loss_real= 0.244, d_loss_fake= 0.115, g_loss 2.349, d_loss 0.179\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 366/390 d_loss_real= 0.267, d_loss_fake= 0.117, g_loss 2.289, d_loss 0.192\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 19 Batch 367/390 d_loss_real= 0.253, d_loss_fake= 0.124, g_loss 2.300, d_loss 0.189\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 368/390 d_loss_real= 0.307, d_loss_fake= 0.122, g_loss 2.189, d_loss 0.214\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 369/390 d_loss_real= 0.254, d_loss_fake= 0.132, g_loss 2.195, d_loss 0.193\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 370/390 d_loss_real= 0.411, d_loss_fake= 0.140, g_loss 2.170, d_loss 0.275\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 19 Batch 371/390 d_loss_real= 0.428, d_loss_fake= 0.140, g_loss 2.110, d_loss 0.284\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 372/390 d_loss_real= 0.187, d_loss_fake= 0.147, g_loss 2.131, d_loss 0.167\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 19 Batch 373/390 d_loss_real= 0.276, d_loss_fake= 0.135, g_loss 2.197, d_loss 0.205\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 374/390 d_loss_real= 0.253, d_loss_fake= 0.127, g_loss 2.192, d_loss 0.190\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 19 Batch 375/390 d_loss_real= 0.334, d_loss_fake= 0.135, g_loss 2.148, d_loss 0.234\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 376/390 d_loss_real= 0.233, d_loss_fake= 0.145, g_loss 2.150, d_loss 0.189\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 19 Batch 377/390 d_loss_real= 0.259, d_loss_fake= 0.138, g_loss 2.009, d_loss 0.199\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 378/390 d_loss_real= 0.316, d_loss_fake= 0.169, g_loss 1.970, d_loss 0.242\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 19 Batch 379/390 d_loss_real= 0.193, d_loss_fake= 0.174, g_loss 2.036, d_loss 0.183\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 19 Batch 380/390 d_loss_real= 0.255, d_loss_fake= 0.151, g_loss 2.246, d_loss 0.203\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 381/390 d_loss_real= 0.322, d_loss_fake= 0.122, g_loss 2.296, d_loss 0.222\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 19 Batch 382/390 d_loss_real= 0.414, d_loss_fake= 0.120, g_loss 2.222, d_loss 0.267\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 19 Batch 383/390 d_loss_real= 0.331, d_loss_fake= 0.136, g_loss 2.071, d_loss 0.233\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19 Batch 384/390 d_loss_real= 0.272, d_loss_fake= 0.161, g_loss 1.967, d_loss 0.216\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 385/390 d_loss_real= 0.232, d_loss_fake= 0.174, g_loss 1.948, d_loss 0.203\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 386/390 d_loss_real= 0.237, d_loss_fake= 0.165, g_loss 2.064, d_loss 0.201\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 387/390 d_loss_real= 0.332, d_loss_fake= 0.161, g_loss 2.097, d_loss 0.247\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19 Batch 388/390 d_loss_real= 0.296, d_loss_fake= 0.149, g_loss 2.205, d_loss 0.222\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 19 Batch 389/390 d_loss_real= 0.420, d_loss_fake= 0.143, g_loss 2.186, d_loss 0.282\n",
            "2/2 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19 Batch 390/390 d_loss_real= 0.238, d_loss_fake= 0.142, g_loss 2.101, d_loss 0.190\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 20 Batch 1/390 d_loss_real= 0.311, d_loss_fake= 0.165, g_loss 2.073, d_loss 0.238\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 2/390 d_loss_real= 0.353, d_loss_fake= 0.155, g_loss 1.976, d_loss 0.254\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 3/390 d_loss_real= 0.276, d_loss_fake= 0.161, g_loss 1.927, d_loss 0.218\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 4/390 d_loss_real= 0.229, d_loss_fake= 0.196, g_loss 2.001, d_loss 0.212\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 5/390 d_loss_real= 0.290, d_loss_fake= 0.166, g_loss 2.004, d_loss 0.228\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 20 Batch 6/390 d_loss_real= 0.233, d_loss_fake= 0.154, g_loss 2.031, d_loss 0.193\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 7/390 d_loss_real= 0.207, d_loss_fake= 0.153, g_loss 2.021, d_loss 0.180\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 8/390 d_loss_real= 0.223, d_loss_fake= 0.160, g_loss 2.059, d_loss 0.191\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 9/390 d_loss_real= 0.454, d_loss_fake= 0.169, g_loss 1.896, d_loss 0.312\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 10/390 d_loss_real= 0.222, d_loss_fake= 0.201, g_loss 1.769, d_loss 0.212\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 11/390 d_loss_real= 0.250, d_loss_fake= 0.213, g_loss 1.740, d_loss 0.232\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 12/390 d_loss_real= 0.206, d_loss_fake= 0.214, g_loss 1.788, d_loss 0.210\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 13/390 d_loss_real= 0.268, d_loss_fake= 0.181, g_loss 1.867, d_loss 0.224\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 14/390 d_loss_real= 0.334, d_loss_fake= 0.169, g_loss 1.956, d_loss 0.251\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 20 Batch 15/390 d_loss_real= 0.366, d_loss_fake= 0.165, g_loss 1.931, d_loss 0.266\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 20 Batch 16/390 d_loss_real= 0.215, d_loss_fake= 0.174, g_loss 1.906, d_loss 0.194\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 20 Batch 17/390 d_loss_real= 0.180, d_loss_fake= 0.178, g_loss 1.824, d_loss 0.179\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 18/390 d_loss_real= 0.208, d_loss_fake= 0.191, g_loss 1.855, d_loss 0.200\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 19/390 d_loss_real= 0.181, d_loss_fake= 0.181, g_loss 1.860, d_loss 0.181\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 20/390 d_loss_real= 0.176, d_loss_fake= 0.188, g_loss 1.924, d_loss 0.182\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 21/390 d_loss_real= 0.243, d_loss_fake= 0.162, g_loss 2.091, d_loss 0.202\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 20 Batch 22/390 d_loss_real= 0.378, d_loss_fake= 0.143, g_loss 2.122, d_loss 0.261\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 20 Batch 23/390 d_loss_real= 0.341, d_loss_fake= 0.136, g_loss 2.131, d_loss 0.239\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 24/390 d_loss_real= 0.205, d_loss_fake= 0.142, g_loss 2.128, d_loss 0.173\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 25/390 d_loss_real= 0.285, d_loss_fake= 0.145, g_loss 2.169, d_loss 0.215\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 20 Batch 26/390 d_loss_real= 0.501, d_loss_fake= 0.132, g_loss 2.115, d_loss 0.316\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 20 Batch 27/390 d_loss_real= 0.180, d_loss_fake= 0.164, g_loss 2.130, d_loss 0.172\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 20 Batch 28/390 d_loss_real= 0.225, d_loss_fake= 0.135, g_loss 2.212, d_loss 0.180\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 20 Batch 29/390 d_loss_real= 0.317, d_loss_fake= 0.118, g_loss 2.350, d_loss 0.218\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 20 Batch 30/390 d_loss_real= 0.349, d_loss_fake= 0.108, g_loss 2.395, d_loss 0.229\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 20 Batch 31/390 d_loss_real= 0.499, d_loss_fake= 0.106, g_loss 2.295, d_loss 0.302\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 32/390 d_loss_real= 0.304, d_loss_fake= 0.117, g_loss 2.156, d_loss 0.210\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 33/390 d_loss_real= 0.322, d_loss_fake= 0.156, g_loss 1.974, d_loss 0.239\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 34/390 d_loss_real= 0.343, d_loss_fake= 0.178, g_loss 1.845, d_loss 0.261\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 35/390 d_loss_real= 0.213, d_loss_fake= 0.218, g_loss 2.021, d_loss 0.215\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 36/390 d_loss_real= 0.173, d_loss_fake= 0.137, g_loss 2.310, d_loss 0.155\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 37/390 d_loss_real= 0.259, d_loss_fake= 0.106, g_loss 2.423, d_loss 0.182\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 38/390 d_loss_real= 0.314, d_loss_fake= 0.102, g_loss 2.368, d_loss 0.208\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 20 Batch 39/390 d_loss_real= 0.311, d_loss_fake= 0.108, g_loss 2.323, d_loss 0.209\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 40/390 d_loss_real= 0.335, d_loss_fake= 0.119, g_loss 2.243, d_loss 0.227\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 20 Batch 41/390 d_loss_real= 0.292, d_loss_fake= 0.132, g_loss 2.096, d_loss 0.212\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 42/390 d_loss_real= 0.118, d_loss_fake= 0.153, g_loss 2.114, d_loss 0.136\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 43/390 d_loss_real= 0.122, d_loss_fake= 0.123, g_loss 2.289, d_loss 0.122\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 20 Batch 44/390 d_loss_real= 0.359, d_loss_fake= 0.120, g_loss 2.268, d_loss 0.239\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 20 Batch 45/390 d_loss_real= 0.246, d_loss_fake= 0.115, g_loss 2.337, d_loss 0.181\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 46/390 d_loss_real= 0.196, d_loss_fake= 0.105, g_loss 2.369, d_loss 0.151\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 20 Batch 47/390 d_loss_real= 0.269, d_loss_fake= 0.102, g_loss 2.383, d_loss 0.186\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 48/390 d_loss_real= 0.411, d_loss_fake= 0.114, g_loss 2.193, d_loss 0.263\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 49/390 d_loss_real= 0.286, d_loss_fake= 0.136, g_loss 2.031, d_loss 0.211\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 20 Batch 50/390 d_loss_real= 0.139, d_loss_fake= 0.162, g_loss 2.043, d_loss 0.150\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 51/390 d_loss_real= 0.205, d_loss_fake= 0.180, g_loss 2.135, d_loss 0.193\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 20 Batch 52/390 d_loss_real= 0.178, d_loss_fake= 0.124, g_loss 2.317, d_loss 0.151\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 20 Batch 53/390 d_loss_real= 0.293, d_loss_fake= 0.101, g_loss 2.480, d_loss 0.197\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 54/390 d_loss_real= 0.297, d_loss_fake= 0.100, g_loss 2.446, d_loss 0.199\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 55/390 d_loss_real= 0.345, d_loss_fake= 0.102, g_loss 2.384, d_loss 0.223\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 56/390 d_loss_real= 0.281, d_loss_fake= 0.115, g_loss 2.286, d_loss 0.198\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 57/390 d_loss_real= 0.358, d_loss_fake= 0.135, g_loss 2.108, d_loss 0.246\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 58/390 d_loss_real= 0.458, d_loss_fake= 0.154, g_loss 2.016, d_loss 0.306\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 59/390 d_loss_real= 0.293, d_loss_fake= 0.192, g_loss 1.950, d_loss 0.242\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 20 Batch 60/390 d_loss_real= 0.293, d_loss_fake= 0.165, g_loss 2.008, d_loss 0.229\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 61/390 d_loss_real= 0.363, d_loss_fake= 0.146, g_loss 2.128, d_loss 0.255\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 62/390 d_loss_real= 0.217, d_loss_fake= 0.137, g_loss 2.216, d_loss 0.177\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 63/390 d_loss_real= 0.433, d_loss_fake= 0.124, g_loss 2.199, d_loss 0.279\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 64/390 d_loss_real= 0.205, d_loss_fake= 0.123, g_loss 2.203, d_loss 0.164\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 65/390 d_loss_real= 0.318, d_loss_fake= 0.131, g_loss 2.076, d_loss 0.225\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 66/390 d_loss_real= 0.347, d_loss_fake= 0.168, g_loss 1.864, d_loss 0.258\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 67/390 d_loss_real= 0.251, d_loss_fake= 0.196, g_loss 1.826, d_loss 0.223\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 20 Batch 68/390 d_loss_real= 0.205, d_loss_fake= 0.221, g_loss 1.897, d_loss 0.213\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 20 Batch 69/390 d_loss_real= 0.397, d_loss_fake= 0.168, g_loss 2.048, d_loss 0.282\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 70/390 d_loss_real= 0.215, d_loss_fake= 0.142, g_loss 2.201, d_loss 0.179\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 71/390 d_loss_real= 0.371, d_loss_fake= 0.125, g_loss 2.269, d_loss 0.248\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 20 Batch 72/390 d_loss_real= 0.365, d_loss_fake= 0.124, g_loss 2.210, d_loss 0.245\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 20 Batch 73/390 d_loss_real= 0.345, d_loss_fake= 0.120, g_loss 2.219, d_loss 0.233\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 74/390 d_loss_real= 0.344, d_loss_fake= 0.137, g_loss 2.059, d_loss 0.241\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 20 Batch 75/390 d_loss_real= 0.304, d_loss_fake= 0.167, g_loss 1.885, d_loss 0.235\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 20 Batch 76/390 d_loss_real= 0.354, d_loss_fake= 0.183, g_loss 1.911, d_loss 0.269\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 77/390 d_loss_real= 0.175, d_loss_fake= 0.169, g_loss 2.064, d_loss 0.172\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 78/390 d_loss_real= 0.253, d_loss_fake= 0.149, g_loss 2.186, d_loss 0.201\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 79/390 d_loss_real= 0.128, d_loss_fake= 0.113, g_loss 2.350, d_loss 0.121\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 80/390 d_loss_real= 0.322, d_loss_fake= 0.108, g_loss 2.349, d_loss 0.215\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 81/390 d_loss_real= 0.445, d_loss_fake= 0.114, g_loss 2.233, d_loss 0.280\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 20 Batch 82/390 d_loss_real= 0.357, d_loss_fake= 0.130, g_loss 2.112, d_loss 0.244\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 83/390 d_loss_real= 0.344, d_loss_fake= 0.159, g_loss 2.041, d_loss 0.252\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 20 Batch 84/390 d_loss_real= 0.406, d_loss_fake= 0.170, g_loss 1.923, d_loss 0.288\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 85/390 d_loss_real= 0.300, d_loss_fake= 0.192, g_loss 1.921, d_loss 0.246\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 20 Batch 86/390 d_loss_real= 0.149, d_loss_fake= 0.160, g_loss 2.061, d_loss 0.154\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 20 Batch 87/390 d_loss_real= 0.359, d_loss_fake= 0.144, g_loss 2.175, d_loss 0.251\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 20 Batch 88/390 d_loss_real= 0.430, d_loss_fake= 0.141, g_loss 2.082, d_loss 0.286\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 20 Batch 89/390 d_loss_real= 0.416, d_loss_fake= 0.162, g_loss 2.041, d_loss 0.289\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 20 Batch 90/390 d_loss_real= 0.336, d_loss_fake= 0.166, g_loss 1.919, d_loss 0.251\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 20 Batch 91/390 d_loss_real= 0.367, d_loss_fake= 0.168, g_loss 1.975, d_loss 0.268\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 20 Batch 92/390 d_loss_real= 0.288, d_loss_fake= 0.150, g_loss 2.080, d_loss 0.219\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 93/390 d_loss_real= 0.515, d_loss_fake= 0.153, g_loss 2.086, d_loss 0.334\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 94/390 d_loss_real= 0.358, d_loss_fake= 0.162, g_loss 2.047, d_loss 0.260\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 95/390 d_loss_real= 0.227, d_loss_fake= 0.151, g_loss 2.088, d_loss 0.189\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 96/390 d_loss_real= 0.342, d_loss_fake= 0.149, g_loss 2.081, d_loss 0.246\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 97/390 d_loss_real= 0.187, d_loss_fake= 0.151, g_loss 2.125, d_loss 0.169\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 98/390 d_loss_real= 0.393, d_loss_fake= 0.134, g_loss 2.157, d_loss 0.264\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 99/390 d_loss_real= 0.334, d_loss_fake= 0.143, g_loss 2.130, d_loss 0.239\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 100/390 d_loss_real= 0.250, d_loss_fake= 0.138, g_loss 2.127, d_loss 0.194\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 20 Batch 101/390 d_loss_real= 0.316, d_loss_fake= 0.141, g_loss 2.063, d_loss 0.228\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 20 Batch 102/390 d_loss_real= 0.319, d_loss_fake= 0.165, g_loss 2.013, d_loss 0.242\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 20 Batch 103/390 d_loss_real= 0.320, d_loss_fake= 0.159, g_loss 2.037, d_loss 0.240\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 20 Batch 104/390 d_loss_real= 0.238, d_loss_fake= 0.152, g_loss 2.087, d_loss 0.195\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 105/390 d_loss_real= 0.317, d_loss_fake= 0.140, g_loss 2.156, d_loss 0.228\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 106/390 d_loss_real= 0.291, d_loss_fake= 0.137, g_loss 2.145, d_loss 0.214\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 107/390 d_loss_real= 0.364, d_loss_fake= 0.134, g_loss 2.187, d_loss 0.249\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 20 Batch 108/390 d_loss_real= 0.175, d_loss_fake= 0.123, g_loss 2.248, d_loss 0.149\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 109/390 d_loss_real= 0.265, d_loss_fake= 0.106, g_loss 2.383, d_loss 0.186\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 110/390 d_loss_real= 0.375, d_loss_fake= 0.112, g_loss 2.284, d_loss 0.244\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 111/390 d_loss_real= 0.219, d_loss_fake= 0.125, g_loss 2.130, d_loss 0.172\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 112/390 d_loss_real= 0.356, d_loss_fake= 0.144, g_loss 2.146, d_loss 0.250\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 20 Batch 113/390 d_loss_real= 0.391, d_loss_fake= 0.139, g_loss 2.115, d_loss 0.265\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 20 Batch 114/390 d_loss_real= 0.146, d_loss_fake= 0.146, g_loss 2.167, d_loss 0.146\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 20 Batch 115/390 d_loss_real= 0.392, d_loss_fake= 0.144, g_loss 2.193, d_loss 0.268\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 116/390 d_loss_real= 0.287, d_loss_fake= 0.127, g_loss 2.246, d_loss 0.207\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 117/390 d_loss_real= 0.331, d_loss_fake= 0.117, g_loss 2.284, d_loss 0.224\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 118/390 d_loss_real= 0.149, d_loss_fake= 0.125, g_loss 2.298, d_loss 0.137\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 119/390 d_loss_real= 0.254, d_loss_fake= 0.119, g_loss 2.318, d_loss 0.186\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 120/390 d_loss_real= 0.165, d_loss_fake= 0.105, g_loss 2.425, d_loss 0.135\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 20 Batch 121/390 d_loss_real= 0.169, d_loss_fake= 0.099, g_loss 2.403, d_loss 0.134\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 20 Batch 122/390 d_loss_real= 0.444, d_loss_fake= 0.112, g_loss 2.276, d_loss 0.278\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 123/390 d_loss_real= 0.241, d_loss_fake= 0.131, g_loss 2.208, d_loss 0.186\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 20 Batch 124/390 d_loss_real= 0.159, d_loss_fake= 0.140, g_loss 2.176, d_loss 0.149\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 125/390 d_loss_real= 0.141, d_loss_fake= 0.127, g_loss 2.266, d_loss 0.134\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 126/390 d_loss_real= 0.251, d_loss_fake= 0.113, g_loss 2.360, d_loss 0.182\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 20 Batch 127/390 d_loss_real= 0.241, d_loss_fake= 0.107, g_loss 2.468, d_loss 0.174\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 128/390 d_loss_real= 0.371, d_loss_fake= 0.095, g_loss 2.430, d_loss 0.233\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 129/390 d_loss_real= 0.240, d_loss_fake= 0.109, g_loss 2.339, d_loss 0.174\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 130/390 d_loss_real= 0.172, d_loss_fake= 0.126, g_loss 2.226, d_loss 0.149\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 20 Batch 131/390 d_loss_real= 0.183, d_loss_fake= 0.126, g_loss 2.230, d_loss 0.154\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 132/390 d_loss_real= 0.216, d_loss_fake= 0.138, g_loss 2.257, d_loss 0.177\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 133/390 d_loss_real= 0.253, d_loss_fake= 0.112, g_loss 2.355, d_loss 0.182\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 134/390 d_loss_real= 0.191, d_loss_fake= 0.104, g_loss 2.495, d_loss 0.147\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 135/390 d_loss_real= 0.275, d_loss_fake= 0.095, g_loss 2.468, d_loss 0.185\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 136/390 d_loss_real= 0.513, d_loss_fake= 0.106, g_loss 2.374, d_loss 0.310\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 20 Batch 137/390 d_loss_real= 0.311, d_loss_fake= 0.120, g_loss 2.251, d_loss 0.215\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 138/390 d_loss_real= 0.205, d_loss_fake= 0.126, g_loss 2.268, d_loss 0.166\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 20 Batch 139/390 d_loss_real= 0.435, d_loss_fake= 0.123, g_loss 2.256, d_loss 0.279\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 140/390 d_loss_real= 0.445, d_loss_fake= 0.123, g_loss 2.267, d_loss 0.284\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 141/390 d_loss_real= 0.240, d_loss_fake= 0.123, g_loss 2.243, d_loss 0.181\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 20 Batch 142/390 d_loss_real= 0.341, d_loss_fake= 0.120, g_loss 2.270, d_loss 0.230\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 143/390 d_loss_real= 0.173, d_loss_fake= 0.118, g_loss 2.314, d_loss 0.146\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 20 Batch 144/390 d_loss_real= 0.302, d_loss_fake= 0.124, g_loss 2.199, d_loss 0.213\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 145/390 d_loss_real= 0.136, d_loss_fake= 0.139, g_loss 2.088, d_loss 0.138\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 146/390 d_loss_real= 0.338, d_loss_fake= 0.144, g_loss 2.155, d_loss 0.241\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 147/390 d_loss_real= 0.293, d_loss_fake= 0.140, g_loss 2.192, d_loss 0.217\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 20 Batch 148/390 d_loss_real= 0.194, d_loss_fake= 0.118, g_loss 2.390, d_loss 0.156\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 20 Batch 149/390 d_loss_real= 0.246, d_loss_fake= 0.110, g_loss 2.409, d_loss 0.178\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 150/390 d_loss_real= 0.387, d_loss_fake= 0.106, g_loss 2.280, d_loss 0.246\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 151/390 d_loss_real= 0.196, d_loss_fake= 0.136, g_loss 2.149, d_loss 0.166\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 20 Batch 152/390 d_loss_real= 0.241, d_loss_fake= 0.137, g_loss 2.099, d_loss 0.189\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 20 Batch 153/390 d_loss_real= 0.153, d_loss_fake= 0.139, g_loss 2.055, d_loss 0.146\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 154/390 d_loss_real= 0.124, d_loss_fake= 0.144, g_loss 2.243, d_loss 0.134\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 155/390 d_loss_real= 0.233, d_loss_fake= 0.124, g_loss 2.257, d_loss 0.179\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 156/390 d_loss_real= 0.272, d_loss_fake= 0.117, g_loss 2.255, d_loss 0.195\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 157/390 d_loss_real= 0.317, d_loss_fake= 0.113, g_loss 2.308, d_loss 0.215\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 20 Batch 158/390 d_loss_real= 0.287, d_loss_fake= 0.124, g_loss 2.351, d_loss 0.205\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 159/390 d_loss_real= 0.198, d_loss_fake= 0.110, g_loss 2.393, d_loss 0.154\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 20 Batch 160/390 d_loss_real= 0.535, d_loss_fake= 0.106, g_loss 2.303, d_loss 0.321\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 161/390 d_loss_real= 0.103, d_loss_fake= 0.112, g_loss 2.259, d_loss 0.107\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 162/390 d_loss_real= 0.503, d_loss_fake= 0.144, g_loss 2.069, d_loss 0.324\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 163/390 d_loss_real= 0.270, d_loss_fake= 0.151, g_loss 2.078, d_loss 0.211\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 164/390 d_loss_real= 0.340, d_loss_fake= 0.159, g_loss 2.130, d_loss 0.250\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 165/390 d_loss_real= 0.311, d_loss_fake= 0.136, g_loss 2.211, d_loss 0.224\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 20 Batch 166/390 d_loss_real= 0.238, d_loss_fake= 0.128, g_loss 2.258, d_loss 0.183\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 167/390 d_loss_real= 0.091, d_loss_fake= 0.119, g_loss 2.334, d_loss 0.105\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 168/390 d_loss_real= 0.380, d_loss_fake= 0.114, g_loss 2.309, d_loss 0.247\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 20 Batch 169/390 d_loss_real= 0.249, d_loss_fake= 0.127, g_loss 2.185, d_loss 0.188\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 170/390 d_loss_real= 0.241, d_loss_fake= 0.136, g_loss 2.108, d_loss 0.188\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 171/390 d_loss_real= 0.252, d_loss_fake= 0.174, g_loss 2.116, d_loss 0.213\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 172/390 d_loss_real= 0.198, d_loss_fake= 0.124, g_loss 2.176, d_loss 0.161\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 173/390 d_loss_real= 0.222, d_loss_fake= 0.114, g_loss 2.287, d_loss 0.168\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 174/390 d_loss_real= 0.082, d_loss_fake= 0.123, g_loss 2.256, d_loss 0.103\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 175/390 d_loss_real= 0.315, d_loss_fake= 0.108, g_loss 2.329, d_loss 0.212\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 20 Batch 176/390 d_loss_real= 0.157, d_loss_fake= 0.107, g_loss 2.388, d_loss 0.132\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 20 Batch 177/390 d_loss_real= 0.283, d_loss_fake= 0.121, g_loss 2.260, d_loss 0.202\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 178/390 d_loss_real= 0.274, d_loss_fake= 0.117, g_loss 2.358, d_loss 0.196\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 20 Batch 179/390 d_loss_real= 0.225, d_loss_fake= 0.105, g_loss 2.421, d_loss 0.165\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 180/390 d_loss_real= 0.308, d_loss_fake= 0.108, g_loss 2.420, d_loss 0.208\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 181/390 d_loss_real= 0.249, d_loss_fake= 0.108, g_loss 2.345, d_loss 0.178\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 182/390 d_loss_real= 0.236, d_loss_fake= 0.118, g_loss 2.313, d_loss 0.177\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 20 Batch 183/390 d_loss_real= 0.128, d_loss_fake= 0.129, g_loss 2.279, d_loss 0.129\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 20 Batch 184/390 d_loss_real= 0.174, d_loss_fake= 0.117, g_loss 2.366, d_loss 0.146\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 185/390 d_loss_real= 0.249, d_loss_fake= 0.106, g_loss 2.449, d_loss 0.178\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 186/390 d_loss_real= 0.298, d_loss_fake= 0.098, g_loss 2.327, d_loss 0.198\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 187/390 d_loss_real= 0.289, d_loss_fake= 0.106, g_loss 2.228, d_loss 0.198\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 188/390 d_loss_real= 0.265, d_loss_fake= 0.138, g_loss 2.212, d_loss 0.201\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 189/390 d_loss_real= 0.266, d_loss_fake= 0.121, g_loss 2.279, d_loss 0.194\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 20 Batch 190/390 d_loss_real= 0.348, d_loss_fake= 0.143, g_loss 2.266, d_loss 0.245\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 20 Batch 191/390 d_loss_real= 0.116, d_loss_fake= 0.107, g_loss 2.405, d_loss 0.112\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 192/390 d_loss_real= 0.335, d_loss_fake= 0.098, g_loss 2.480, d_loss 0.217\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 20 Batch 193/390 d_loss_real= 0.258, d_loss_fake= 0.098, g_loss 2.352, d_loss 0.178\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 20 Batch 194/390 d_loss_real= 0.533, d_loss_fake= 0.116, g_loss 2.241, d_loss 0.325\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 20 Batch 195/390 d_loss_real= 0.289, d_loss_fake= 0.140, g_loss 2.196, d_loss 0.214\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 20 Batch 196/390 d_loss_real= 0.210, d_loss_fake= 0.130, g_loss 2.150, d_loss 0.170\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 197/390 d_loss_real= 0.231, d_loss_fake= 0.134, g_loss 2.226, d_loss 0.182\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 198/390 d_loss_real= 0.139, d_loss_fake= 0.124, g_loss 2.275, d_loss 0.132\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 20 Batch 199/390 d_loss_real= 0.126, d_loss_fake= 0.105, g_loss 2.430, d_loss 0.116\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 20 Batch 200/390 d_loss_real= 0.171, d_loss_fake= 0.092, g_loss 2.518, d_loss 0.132\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 201/390 d_loss_real= 0.373, d_loss_fake= 0.092, g_loss 2.455, d_loss 0.233\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 202/390 d_loss_real= 0.143, d_loss_fake= 0.102, g_loss 2.362, d_loss 0.123\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 20 Batch 203/390 d_loss_real= 0.369, d_loss_fake= 0.128, g_loss 2.110, d_loss 0.249\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 20 Batch 204/390 d_loss_real= 0.230, d_loss_fake= 0.167, g_loss 2.005, d_loss 0.198\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 205/390 d_loss_real= 0.173, d_loss_fake= 0.149, g_loss 2.148, d_loss 0.161\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 20 Batch 206/390 d_loss_real= 0.384, d_loss_fake= 0.132, g_loss 2.310, d_loss 0.258\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 207/390 d_loss_real= 0.330, d_loss_fake= 0.102, g_loss 2.422, d_loss 0.216\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 208/390 d_loss_real= 0.402, d_loss_fake= 0.095, g_loss 2.458, d_loss 0.248\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 209/390 d_loss_real= 0.250, d_loss_fake= 0.095, g_loss 2.391, d_loss 0.172\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 210/390 d_loss_real= 0.228, d_loss_fake= 0.114, g_loss 2.273, d_loss 0.171\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 211/390 d_loss_real= 0.385, d_loss_fake= 0.128, g_loss 2.155, d_loss 0.256\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 212/390 d_loss_real= 0.114, d_loss_fake= 0.140, g_loss 2.105, d_loss 0.127\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 213/390 d_loss_real= 0.244, d_loss_fake= 0.148, g_loss 2.060, d_loss 0.196\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 20 Batch 214/390 d_loss_real= 0.325, d_loss_fake= 0.151, g_loss 2.183, d_loss 0.238\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 20 Batch 215/390 d_loss_real= 0.432, d_loss_fake= 0.127, g_loss 2.250, d_loss 0.279\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 216/390 d_loss_real= 0.412, d_loss_fake= 0.117, g_loss 2.290, d_loss 0.265\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 217/390 d_loss_real= 0.139, d_loss_fake= 0.113, g_loss 2.283, d_loss 0.126\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 20 Batch 218/390 d_loss_real= 0.197, d_loss_fake= 0.109, g_loss 2.325, d_loss 0.153\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 219/390 d_loss_real= 0.177, d_loss_fake= 0.106, g_loss 2.301, d_loss 0.141\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 220/390 d_loss_real= 0.276, d_loss_fake= 0.113, g_loss 2.254, d_loss 0.195\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 221/390 d_loss_real= 0.108, d_loss_fake= 0.118, g_loss 2.218, d_loss 0.113\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 222/390 d_loss_real= 0.200, d_loss_fake= 0.134, g_loss 2.198, d_loss 0.167\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 223/390 d_loss_real= 0.146, d_loss_fake= 0.137, g_loss 2.232, d_loss 0.142\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 20 Batch 224/390 d_loss_real= 0.225, d_loss_fake= 0.119, g_loss 2.283, d_loss 0.172\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 225/390 d_loss_real= 0.356, d_loss_fake= 0.116, g_loss 2.322, d_loss 0.236\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 20 Batch 226/390 d_loss_real= 0.208, d_loss_fake= 0.105, g_loss 2.352, d_loss 0.157\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 227/390 d_loss_real= 0.287, d_loss_fake= 0.116, g_loss 2.246, d_loss 0.202\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 228/390 d_loss_real= 0.135, d_loss_fake= 0.129, g_loss 2.253, d_loss 0.132\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 20 Batch 229/390 d_loss_real= 0.242, d_loss_fake= 0.118, g_loss 2.319, d_loss 0.180\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 230/390 d_loss_real= 0.359, d_loss_fake= 0.122, g_loss 2.278, d_loss 0.240\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 231/390 d_loss_real= 0.363, d_loss_fake= 0.122, g_loss 2.201, d_loss 0.242\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 20 Batch 232/390 d_loss_real= 0.407, d_loss_fake= 0.134, g_loss 2.150, d_loss 0.270\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 233/390 d_loss_real= 0.307, d_loss_fake= 0.145, g_loss 2.072, d_loss 0.226\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 234/390 d_loss_real= 0.316, d_loss_fake= 0.136, g_loss 2.205, d_loss 0.226\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 20 Batch 235/390 d_loss_real= 0.168, d_loss_fake= 0.136, g_loss 2.174, d_loss 0.152\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 20 Batch 236/390 d_loss_real= 0.239, d_loss_fake= 0.139, g_loss 2.100, d_loss 0.189\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 237/390 d_loss_real= 0.156, d_loss_fake= 0.131, g_loss 2.162, d_loss 0.144\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 238/390 d_loss_real= 0.283, d_loss_fake= 0.132, g_loss 2.114, d_loss 0.207\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 239/390 d_loss_real= 0.281, d_loss_fake= 0.157, g_loss 2.069, d_loss 0.219\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 240/390 d_loss_real= 0.226, d_loss_fake= 0.146, g_loss 2.075, d_loss 0.186\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 20 Batch 241/390 d_loss_real= 0.210, d_loss_fake= 0.141, g_loss 2.120, d_loss 0.176\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 242/390 d_loss_real= 0.414, d_loss_fake= 0.138, g_loss 2.066, d_loss 0.276\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 20 Batch 243/390 d_loss_real= 0.188, d_loss_fake= 0.140, g_loss 2.136, d_loss 0.164\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 20 Batch 244/390 d_loss_real= 0.211, d_loss_fake= 0.143, g_loss 2.078, d_loss 0.177\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 20 Batch 245/390 d_loss_real= 0.379, d_loss_fake= 0.154, g_loss 1.967, d_loss 0.267\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 246/390 d_loss_real= 0.280, d_loss_fake= 0.182, g_loss 1.899, d_loss 0.231\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 20 Batch 247/390 d_loss_real= 0.188, d_loss_fake= 0.182, g_loss 1.971, d_loss 0.185\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 20 Batch 248/390 d_loss_real= 0.254, d_loss_fake= 0.167, g_loss 2.050, d_loss 0.211\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 249/390 d_loss_real= 0.257, d_loss_fake= 0.137, g_loss 2.219, d_loss 0.197\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 20 Batch 250/390 d_loss_real= 0.269, d_loss_fake= 0.120, g_loss 2.254, d_loss 0.194\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 251/390 d_loss_real= 0.376, d_loss_fake= 0.115, g_loss 2.232, d_loss 0.246\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 252/390 d_loss_real= 0.324, d_loss_fake= 0.115, g_loss 2.215, d_loss 0.220\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 20 Batch 253/390 d_loss_real= 0.179, d_loss_fake= 0.128, g_loss 2.170, d_loss 0.154\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 254/390 d_loss_real= 0.289, d_loss_fake= 0.134, g_loss 2.074, d_loss 0.211\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 20 Batch 255/390 d_loss_real= 0.326, d_loss_fake= 0.166, g_loss 1.913, d_loss 0.246\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 20 Batch 256/390 d_loss_real= 0.233, d_loss_fake= 0.181, g_loss 1.914, d_loss 0.207\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 257/390 d_loss_real= 0.161, d_loss_fake= 0.197, g_loss 1.985, d_loss 0.179\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 258/390 d_loss_real= 0.225, d_loss_fake= 0.161, g_loss 2.109, d_loss 0.193\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 259/390 d_loss_real= 0.205, d_loss_fake= 0.127, g_loss 2.274, d_loss 0.166\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 260/390 d_loss_real= 0.177, d_loss_fake= 0.110, g_loss 2.376, d_loss 0.143\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 261/390 d_loss_real= 0.435, d_loss_fake= 0.102, g_loss 2.375, d_loss 0.268\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 262/390 d_loss_real= 0.452, d_loss_fake= 0.114, g_loss 2.308, d_loss 0.283\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 20 Batch 263/390 d_loss_real= 0.240, d_loss_fake= 0.138, g_loss 2.106, d_loss 0.189\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 264/390 d_loss_real= 0.243, d_loss_fake= 0.153, g_loss 2.017, d_loss 0.198\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 20 Batch 265/390 d_loss_real= 0.283, d_loss_fake= 0.176, g_loss 2.055, d_loss 0.229\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 20 Batch 266/390 d_loss_real= 0.245, d_loss_fake= 0.169, g_loss 2.156, d_loss 0.207\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 267/390 d_loss_real= 0.185, d_loss_fake= 0.137, g_loss 2.262, d_loss 0.161\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 20 Batch 268/390 d_loss_real= 0.170, d_loss_fake= 0.120, g_loss 2.447, d_loss 0.145\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 20 Batch 269/390 d_loss_real= 0.169, d_loss_fake= 0.129, g_loss 2.389, d_loss 0.149\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 270/390 d_loss_real= 0.333, d_loss_fake= 0.111, g_loss 2.339, d_loss 0.222\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 20 Batch 271/390 d_loss_real= 0.163, d_loss_fake= 0.116, g_loss 2.280, d_loss 0.139\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 272/390 d_loss_real= 0.392, d_loss_fake= 0.131, g_loss 2.160, d_loss 0.261\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 20 Batch 273/390 d_loss_real= 0.347, d_loss_fake= 0.162, g_loss 2.083, d_loss 0.255\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 20 Batch 274/390 d_loss_real= 0.317, d_loss_fake= 0.184, g_loss 2.099, d_loss 0.251\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 20 Batch 275/390 d_loss_real= 0.151, d_loss_fake= 0.167, g_loss 2.189, d_loss 0.159\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 276/390 d_loss_real= 0.115, d_loss_fake= 0.106, g_loss 2.540, d_loss 0.110\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 277/390 d_loss_real= 0.322, d_loss_fake= 0.082, g_loss 2.731, d_loss 0.202\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 278/390 d_loss_real= 0.451, d_loss_fake= 0.082, g_loss 2.578, d_loss 0.266\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 279/390 d_loss_real= 0.433, d_loss_fake= 0.095, g_loss 2.407, d_loss 0.264\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 20 Batch 280/390 d_loss_real= 0.331, d_loss_fake= 0.119, g_loss 2.224, d_loss 0.225\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 281/390 d_loss_real= 0.311, d_loss_fake= 0.148, g_loss 1.952, d_loss 0.230\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 282/390 d_loss_real= 0.088, d_loss_fake= 0.166, g_loss 2.026, d_loss 0.127\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 283/390 d_loss_real= 0.328, d_loss_fake= 0.182, g_loss 2.065, d_loss 0.255\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 284/390 d_loss_real= 0.139, d_loss_fake= 0.136, g_loss 2.333, d_loss 0.137\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 285/390 d_loss_real= 0.207, d_loss_fake= 0.108, g_loss 2.497, d_loss 0.157\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 286/390 d_loss_real= 0.234, d_loss_fake= 0.097, g_loss 2.498, d_loss 0.165\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 20 Batch 287/390 d_loss_real= 0.324, d_loss_fake= 0.092, g_loss 2.428, d_loss 0.208\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 288/390 d_loss_real= 0.286, d_loss_fake= 0.107, g_loss 2.274, d_loss 0.197\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 289/390 d_loss_real= 0.351, d_loss_fake= 0.135, g_loss 2.084, d_loss 0.243\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 290/390 d_loss_real= 0.355, d_loss_fake= 0.173, g_loss 1.944, d_loss 0.264\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 20 Batch 291/390 d_loss_real= 0.324, d_loss_fake= 0.136, g_loss 2.157, d_loss 0.230\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 292/390 d_loss_real= 0.219, d_loss_fake= 0.194, g_loss 2.138, d_loss 0.207\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 20 Batch 293/390 d_loss_real= 0.234, d_loss_fake= 0.124, g_loss 2.358, d_loss 0.179\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 294/390 d_loss_real= 0.452, d_loss_fake= 0.108, g_loss 2.468, d_loss 0.280\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 295/390 d_loss_real= 0.345, d_loss_fake= 0.095, g_loss 2.500, d_loss 0.220\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 296/390 d_loss_real= 0.320, d_loss_fake= 0.094, g_loss 2.435, d_loss 0.207\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 297/390 d_loss_real= 0.245, d_loss_fake= 0.115, g_loss 2.303, d_loss 0.180\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 298/390 d_loss_real= 0.324, d_loss_fake= 0.133, g_loss 2.137, d_loss 0.228\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 20 Batch 299/390 d_loss_real= 0.263, d_loss_fake= 0.171, g_loss 1.989, d_loss 0.217\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 300/390 d_loss_real= 0.207, d_loss_fake= 0.177, g_loss 2.061, d_loss 0.192\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 301/390 d_loss_real= 0.163, d_loss_fake= 0.135, g_loss 2.306, d_loss 0.149\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 20 Batch 302/390 d_loss_real= 0.220, d_loss_fake= 0.108, g_loss 2.447, d_loss 0.164\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 303/390 d_loss_real= 0.350, d_loss_fake= 0.106, g_loss 2.459, d_loss 0.228\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 304/390 d_loss_real= 0.134, d_loss_fake= 0.094, g_loss 2.500, d_loss 0.114\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 305/390 d_loss_real= 0.199, d_loss_fake= 0.091, g_loss 2.535, d_loss 0.145\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 20 Batch 306/390 d_loss_real= 0.261, d_loss_fake= 0.093, g_loss 2.538, d_loss 0.177\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 307/390 d_loss_real= 0.229, d_loss_fake= 0.108, g_loss 2.377, d_loss 0.168\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 20 Batch 308/390 d_loss_real= 0.356, d_loss_fake= 0.119, g_loss 2.244, d_loss 0.237\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 20 Batch 309/390 d_loss_real= 0.324, d_loss_fake= 0.130, g_loss 2.289, d_loss 0.227\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 310/390 d_loss_real= 0.347, d_loss_fake= 0.117, g_loss 2.320, d_loss 0.232\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 311/390 d_loss_real= 0.257, d_loss_fake= 0.115, g_loss 2.366, d_loss 0.186\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 312/390 d_loss_real= 0.320, d_loss_fake= 0.107, g_loss 2.435, d_loss 0.214\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 20 Batch 313/390 d_loss_real= 0.397, d_loss_fake= 0.104, g_loss 2.400, d_loss 0.250\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 314/390 d_loss_real= 0.298, d_loss_fake= 0.113, g_loss 2.340, d_loss 0.206\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 315/390 d_loss_real= 0.338, d_loss_fake= 0.127, g_loss 2.173, d_loss 0.232\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 20 Batch 316/390 d_loss_real= 0.183, d_loss_fake= 0.141, g_loss 2.157, d_loss 0.162\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 20 Batch 317/390 d_loss_real= 0.110, d_loss_fake= 0.138, g_loss 2.240, d_loss 0.124\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 318/390 d_loss_real= 0.348, d_loss_fake= 0.128, g_loss 2.221, d_loss 0.238\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 319/390 d_loss_real= 0.393, d_loss_fake= 0.131, g_loss 2.179, d_loss 0.262\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 320/390 d_loss_real= 0.312, d_loss_fake= 0.133, g_loss 2.112, d_loss 0.222\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 20 Batch 321/390 d_loss_real= 0.220, d_loss_fake= 0.140, g_loss 2.121, d_loss 0.180\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 20 Batch 322/390 d_loss_real= 0.181, d_loss_fake= 0.132, g_loss 2.184, d_loss 0.157\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 20 Batch 323/390 d_loss_real= 0.221, d_loss_fake= 0.122, g_loss 2.317, d_loss 0.172\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 324/390 d_loss_real= 0.189, d_loss_fake= 0.109, g_loss 2.391, d_loss 0.149\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 20 Batch 325/390 d_loss_real= 0.113, d_loss_fake= 0.098, g_loss 2.460, d_loss 0.105\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 326/390 d_loss_real= 0.117, d_loss_fake= 0.095, g_loss 2.513, d_loss 0.106\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 327/390 d_loss_real= 0.435, d_loss_fake= 0.095, g_loss 2.422, d_loss 0.265\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 20 Batch 328/390 d_loss_real= 0.178, d_loss_fake= 0.108, g_loss 2.252, d_loss 0.143\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 20 Batch 329/390 d_loss_real= 0.350, d_loss_fake= 0.140, g_loss 1.991, d_loss 0.245\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 330/390 d_loss_real= 0.329, d_loss_fake= 0.186, g_loss 2.035, d_loss 0.258\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 331/390 d_loss_real= 0.115, d_loss_fake= 0.147, g_loss 2.186, d_loss 0.131\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 332/390 d_loss_real= 0.161, d_loss_fake= 0.129, g_loss 2.268, d_loss 0.145\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 333/390 d_loss_real= 0.231, d_loss_fake= 0.105, g_loss 2.480, d_loss 0.168\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 20 Batch 334/390 d_loss_real= 0.293, d_loss_fake= 0.095, g_loss 2.430, d_loss 0.194\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 335/390 d_loss_real= 0.182, d_loss_fake= 0.102, g_loss 2.362, d_loss 0.142\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 20 Batch 336/390 d_loss_real= 0.302, d_loss_fake= 0.115, g_loss 2.299, d_loss 0.208\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 337/390 d_loss_real= 0.274, d_loss_fake= 0.138, g_loss 2.245, d_loss 0.206\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 338/390 d_loss_real= 0.243, d_loss_fake= 0.142, g_loss 2.111, d_loss 0.193\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 20 Batch 339/390 d_loss_real= 0.207, d_loss_fake= 0.133, g_loss 2.193, d_loss 0.170\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 340/390 d_loss_real= 0.423, d_loss_fake= 0.145, g_loss 2.201, d_loss 0.284\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 20 Batch 341/390 d_loss_real= 0.191, d_loss_fake= 0.138, g_loss 2.214, d_loss 0.164\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 20 Batch 342/390 d_loss_real= 0.290, d_loss_fake= 0.125, g_loss 2.258, d_loss 0.208\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 20 Batch 343/390 d_loss_real= 0.334, d_loss_fake= 0.118, g_loss 2.314, d_loss 0.226\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 344/390 d_loss_real= 0.307, d_loss_fake= 0.120, g_loss 2.186, d_loss 0.214\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 20 Batch 345/390 d_loss_real= 0.139, d_loss_fake= 0.142, g_loss 2.074, d_loss 0.140\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 346/390 d_loss_real= 0.166, d_loss_fake= 0.164, g_loss 2.080, d_loss 0.165\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 20 Batch 347/390 d_loss_real= 0.247, d_loss_fake= 0.138, g_loss 2.196, d_loss 0.193\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 20 Batch 348/390 d_loss_real= 0.426, d_loss_fake= 0.121, g_loss 2.213, d_loss 0.273\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 349/390 d_loss_real= 0.130, d_loss_fake= 0.122, g_loss 2.204, d_loss 0.126\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 20 Batch 350/390 d_loss_real= 0.087, d_loss_fake= 0.131, g_loss 2.187, d_loss 0.109\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 351/390 d_loss_real= 0.366, d_loss_fake= 0.144, g_loss 2.179, d_loss 0.255\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 352/390 d_loss_real= 0.230, d_loss_fake= 0.125, g_loss 2.157, d_loss 0.178\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 20 Batch 353/390 d_loss_real= 0.178, d_loss_fake= 0.136, g_loss 2.157, d_loss 0.157\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 354/390 d_loss_real= 0.323, d_loss_fake= 0.129, g_loss 2.179, d_loss 0.226\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 355/390 d_loss_real= 0.416, d_loss_fake= 0.136, g_loss 2.128, d_loss 0.276\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 356/390 d_loss_real= 0.362, d_loss_fake= 0.150, g_loss 2.159, d_loss 0.256\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 20 Batch 357/390 d_loss_real= 0.158, d_loss_fake= 0.134, g_loss 2.189, d_loss 0.146\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 358/390 d_loss_real= 0.193, d_loss_fake= 0.118, g_loss 2.291, d_loss 0.156\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 359/390 d_loss_real= 0.485, d_loss_fake= 0.117, g_loss 2.182, d_loss 0.301\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 20 Batch 360/390 d_loss_real= 0.337, d_loss_fake= 0.154, g_loss 2.074, d_loss 0.245\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 361/390 d_loss_real= 0.290, d_loss_fake= 0.144, g_loss 1.969, d_loss 0.217\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 362/390 d_loss_real= 0.251, d_loss_fake= 0.189, g_loss 1.968, d_loss 0.220\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 20 Batch 363/390 d_loss_real= 0.276, d_loss_fake= 0.172, g_loss 1.967, d_loss 0.224\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 364/390 d_loss_real= 0.198, d_loss_fake= 0.153, g_loss 2.043, d_loss 0.176\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 20 Batch 365/390 d_loss_real= 0.152, d_loss_fake= 0.138, g_loss 2.159, d_loss 0.145\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 366/390 d_loss_real= 0.283, d_loss_fake= 0.131, g_loss 2.189, d_loss 0.207\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 20 Batch 367/390 d_loss_real= 0.353, d_loss_fake= 0.126, g_loss 2.200, d_loss 0.240\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 368/390 d_loss_real= 0.201, d_loss_fake= 0.133, g_loss 2.174, d_loss 0.167\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 369/390 d_loss_real= 0.236, d_loss_fake= 0.150, g_loss 2.138, d_loss 0.193\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 20 Batch 370/390 d_loss_real= 0.247, d_loss_fake= 0.137, g_loss 2.052, d_loss 0.192\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 20 Batch 371/390 d_loss_real= 0.244, d_loss_fake= 0.154, g_loss 2.035, d_loss 0.199\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 372/390 d_loss_real= 0.194, d_loss_fake= 0.163, g_loss 1.983, d_loss 0.179\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 373/390 d_loss_real= 0.310, d_loss_fake= 0.169, g_loss 1.986, d_loss 0.239\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 20 Batch 374/390 d_loss_real= 0.220, d_loss_fake= 0.166, g_loss 2.034, d_loss 0.193\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 375/390 d_loss_real= 0.167, d_loss_fake= 0.144, g_loss 2.217, d_loss 0.155\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 376/390 d_loss_real= 0.129, d_loss_fake= 0.114, g_loss 2.411, d_loss 0.121\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 377/390 d_loss_real= 0.360, d_loss_fake= 0.099, g_loss 2.508, d_loss 0.230\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 378/390 d_loss_real= 0.424, d_loss_fake= 0.087, g_loss 2.566, d_loss 0.256\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 379/390 d_loss_real= 0.256, d_loss_fake= 0.099, g_loss 2.439, d_loss 0.177\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 380/390 d_loss_real= 0.361, d_loss_fake= 0.121, g_loss 2.205, d_loss 0.241\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 381/390 d_loss_real= 0.200, d_loss_fake= 0.156, g_loss 2.151, d_loss 0.178\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 382/390 d_loss_real= 0.338, d_loss_fake= 0.129, g_loss 2.433, d_loss 0.233\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20 Batch 383/390 d_loss_real= 0.381, d_loss_fake= 0.109, g_loss 2.489, d_loss 0.245\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 20 Batch 384/390 d_loss_real= 0.192, d_loss_fake= 0.098, g_loss 2.585, d_loss 0.145\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20 Batch 385/390 d_loss_real= 0.403, d_loss_fake= 0.095, g_loss 2.570, d_loss 0.249\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20 Batch 386/390 d_loss_real= 0.284, d_loss_fake= 0.096, g_loss 2.533, d_loss 0.190\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 20 Batch 387/390 d_loss_real= 0.243, d_loss_fake= 0.110, g_loss 2.618, d_loss 0.176\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 388/390 d_loss_real= 0.175, d_loss_fake= 0.091, g_loss 2.485, d_loss 0.133\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20 Batch 389/390 d_loss_real= 0.291, d_loss_fake= 0.129, g_loss 2.405, d_loss 0.210\n",
            "2/2 [==============================] - 0s 13ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20 Batch 390/390 d_loss_real= 0.188, d_loss_fake= 0.126, g_loss 2.219, d_loss 0.157\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 21 Batch 1/390 d_loss_real= 0.231, d_loss_fake= 0.143, g_loss 2.440, d_loss 0.187\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 21 Batch 2/390 d_loss_real= 0.224, d_loss_fake= 0.100, g_loss 2.564, d_loss 0.162\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 21 Batch 3/390 d_loss_real= 0.400, d_loss_fake= 0.090, g_loss 2.649, d_loss 0.245\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 4/390 d_loss_real= 0.143, d_loss_fake= 0.086, g_loss 2.664, d_loss 0.115\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 21 Batch 5/390 d_loss_real= 0.436, d_loss_fake= 0.085, g_loss 2.558, d_loss 0.261\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 6/390 d_loss_real= 0.228, d_loss_fake= 0.102, g_loss 2.403, d_loss 0.165\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 7/390 d_loss_real= 0.421, d_loss_fake= 0.119, g_loss 2.284, d_loss 0.270\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 8/390 d_loss_real= 0.062, d_loss_fake= 0.119, g_loss 2.348, d_loss 0.091\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 9/390 d_loss_real= 0.304, d_loss_fake= 0.119, g_loss 2.284, d_loss 0.211\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 21 Batch 10/390 d_loss_real= 0.341, d_loss_fake= 0.129, g_loss 2.246, d_loss 0.235\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 11/390 d_loss_real= 0.218, d_loss_fake= 0.129, g_loss 2.258, d_loss 0.173\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 12/390 d_loss_real= 0.200, d_loss_fake= 0.113, g_loss 2.341, d_loss 0.156\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 13/390 d_loss_real= 0.306, d_loss_fake= 0.114, g_loss 2.342, d_loss 0.210\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 14/390 d_loss_real= 0.328, d_loss_fake= 0.115, g_loss 2.260, d_loss 0.221\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 15/390 d_loss_real= 0.353, d_loss_fake= 0.124, g_loss 2.183, d_loss 0.239\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 16/390 d_loss_real= 0.232, d_loss_fake= 0.126, g_loss 2.164, d_loss 0.179\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 17/390 d_loss_real= 0.261, d_loss_fake= 0.136, g_loss 2.139, d_loss 0.198\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 18/390 d_loss_real= 0.190, d_loss_fake= 0.158, g_loss 2.094, d_loss 0.174\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 21 Batch 19/390 d_loss_real= 0.302, d_loss_fake= 0.155, g_loss 2.099, d_loss 0.228\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 20/390 d_loss_real= 0.352, d_loss_fake= 0.143, g_loss 2.117, d_loss 0.248\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 21 Batch 21/390 d_loss_real= 0.337, d_loss_fake= 0.140, g_loss 2.091, d_loss 0.239\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 21 Batch 22/390 d_loss_real= 0.221, d_loss_fake= 0.144, g_loss 2.111, d_loss 0.182\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 23/390 d_loss_real= 0.128, d_loss_fake= 0.136, g_loss 2.160, d_loss 0.132\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 24/390 d_loss_real= 0.243, d_loss_fake= 0.129, g_loss 2.192, d_loss 0.186\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 25/390 d_loss_real= 0.214, d_loss_fake= 0.118, g_loss 2.216, d_loss 0.166\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 26/390 d_loss_real= 0.323, d_loss_fake= 0.138, g_loss 2.160, d_loss 0.230\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 27/390 d_loss_real= 0.145, d_loss_fake= 0.146, g_loss 2.158, d_loss 0.146\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 28/390 d_loss_real= 0.310, d_loss_fake= 0.130, g_loss 2.118, d_loss 0.220\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 21 Batch 29/390 d_loss_real= 0.195, d_loss_fake= 0.159, g_loss 2.160, d_loss 0.177\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 21 Batch 30/390 d_loss_real= 0.210, d_loss_fake= 0.149, g_loss 2.126, d_loss 0.179\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 21 Batch 31/390 d_loss_real= 0.272, d_loss_fake= 0.111, g_loss 2.394, d_loss 0.192\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 32/390 d_loss_real= 0.349, d_loss_fake= 0.100, g_loss 2.358, d_loss 0.225\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 21 Batch 33/390 d_loss_real= 0.338, d_loss_fake= 0.125, g_loss 2.219, d_loss 0.232\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 34/390 d_loss_real= 0.152, d_loss_fake= 0.135, g_loss 2.148, d_loss 0.143\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 35/390 d_loss_real= 0.193, d_loss_fake= 0.142, g_loss 2.213, d_loss 0.167\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 21 Batch 36/390 d_loss_real= 0.235, d_loss_fake= 0.141, g_loss 2.215, d_loss 0.188\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 37/390 d_loss_real= 0.260, d_loss_fake= 0.125, g_loss 2.235, d_loss 0.192\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 21 Batch 38/390 d_loss_real= 0.246, d_loss_fake= 0.123, g_loss 2.269, d_loss 0.184\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 39/390 d_loss_real= 0.207, d_loss_fake= 0.122, g_loss 2.264, d_loss 0.164\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 40/390 d_loss_real= 0.355, d_loss_fake= 0.126, g_loss 2.222, d_loss 0.241\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 21 Batch 41/390 d_loss_real= 0.210, d_loss_fake= 0.120, g_loss 2.260, d_loss 0.165\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 42/390 d_loss_real= 0.196, d_loss_fake= 0.136, g_loss 2.153, d_loss 0.166\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 43/390 d_loss_real= 0.263, d_loss_fake= 0.151, g_loss 2.154, d_loss 0.207\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 44/390 d_loss_real= 0.300, d_loss_fake= 0.135, g_loss 2.230, d_loss 0.218\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 21 Batch 45/390 d_loss_real= 0.283, d_loss_fake= 0.136, g_loss 2.237, d_loss 0.209\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 46/390 d_loss_real= 0.397, d_loss_fake= 0.121, g_loss 2.318, d_loss 0.259\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 47/390 d_loss_real= 0.344, d_loss_fake= 0.124, g_loss 2.273, d_loss 0.234\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 21 Batch 48/390 d_loss_real= 0.207, d_loss_fake= 0.122, g_loss 2.284, d_loss 0.165\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 21 Batch 49/390 d_loss_real= 0.113, d_loss_fake= 0.108, g_loss 2.422, d_loss 0.111\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 21 Batch 50/390 d_loss_real= 0.444, d_loss_fake= 0.099, g_loss 2.419, d_loss 0.272\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 51/390 d_loss_real= 0.337, d_loss_fake= 0.104, g_loss 2.362, d_loss 0.220\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 52/390 d_loss_real= 0.298, d_loss_fake= 0.114, g_loss 2.303, d_loss 0.206\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 53/390 d_loss_real= 0.300, d_loss_fake= 0.122, g_loss 2.262, d_loss 0.211\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 54/390 d_loss_real= 0.292, d_loss_fake= 0.119, g_loss 2.275, d_loss 0.205\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 21 Batch 55/390 d_loss_real= 0.321, d_loss_fake= 0.134, g_loss 2.260, d_loss 0.227\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 56/390 d_loss_real= 0.235, d_loss_fake= 0.126, g_loss 2.296, d_loss 0.180\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 57/390 d_loss_real= 0.277, d_loss_fake= 0.108, g_loss 2.393, d_loss 0.193\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 58/390 d_loss_real= 0.286, d_loss_fake= 0.110, g_loss 2.386, d_loss 0.198\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 59/390 d_loss_real= 0.343, d_loss_fake= 0.110, g_loss 2.384, d_loss 0.226\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 60/390 d_loss_real= 0.082, d_loss_fake= 0.105, g_loss 2.461, d_loss 0.094\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 21 Batch 61/390 d_loss_real= 0.256, d_loss_fake= 0.100, g_loss 2.405, d_loss 0.178\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 21 Batch 62/390 d_loss_real= 0.149, d_loss_fake= 0.102, g_loss 2.378, d_loss 0.125\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 21 Batch 63/390 d_loss_real= 0.241, d_loss_fake= 0.110, g_loss 2.256, d_loss 0.175\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 21 Batch 64/390 d_loss_real= 0.253, d_loss_fake= 0.132, g_loss 2.163, d_loss 0.193\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 21 Batch 65/390 d_loss_real= 0.215, d_loss_fake= 0.163, g_loss 2.192, d_loss 0.189\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 21 Batch 66/390 d_loss_real= 0.330, d_loss_fake= 0.142, g_loss 2.333, d_loss 0.236\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 21 Batch 67/390 d_loss_real= 0.266, d_loss_fake= 0.107, g_loss 2.422, d_loss 0.187\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 68/390 d_loss_real= 0.375, d_loss_fake= 0.102, g_loss 2.392, d_loss 0.238\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 69/390 d_loss_real= 0.237, d_loss_fake= 0.117, g_loss 2.216, d_loss 0.177\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 21 Batch 70/390 d_loss_real= 0.287, d_loss_fake= 0.162, g_loss 2.060, d_loss 0.224\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 21 Batch 71/390 d_loss_real= 0.164, d_loss_fake= 0.151, g_loss 2.004, d_loss 0.158\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 72/390 d_loss_real= 0.323, d_loss_fake= 0.184, g_loss 1.910, d_loss 0.253\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 21 Batch 73/390 d_loss_real= 0.173, d_loss_fake= 0.178, g_loss 1.983, d_loss 0.176\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 21 Batch 74/390 d_loss_real= 0.193, d_loss_fake= 0.158, g_loss 2.133, d_loss 0.175\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 21 Batch 75/390 d_loss_real= 0.247, d_loss_fake= 0.139, g_loss 2.205, d_loss 0.193\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 76/390 d_loss_real= 0.340, d_loss_fake= 0.126, g_loss 2.209, d_loss 0.233\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 21 Batch 77/390 d_loss_real= 0.422, d_loss_fake= 0.140, g_loss 2.058, d_loss 0.281\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 78/390 d_loss_real= 0.231, d_loss_fake= 0.145, g_loss 2.042, d_loss 0.188\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 79/390 d_loss_real= 0.188, d_loss_fake= 0.155, g_loss 2.134, d_loss 0.171\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 80/390 d_loss_real= 0.375, d_loss_fake= 0.139, g_loss 2.156, d_loss 0.257\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 81/390 d_loss_real= 0.268, d_loss_fake= 0.142, g_loss 2.226, d_loss 0.205\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 21 Batch 82/390 d_loss_real= 0.143, d_loss_fake= 0.140, g_loss 2.206, d_loss 0.141\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 83/390 d_loss_real= 0.116, d_loss_fake= 0.117, g_loss 2.358, d_loss 0.117\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 21 Batch 84/390 d_loss_real= 0.059, d_loss_fake= 0.107, g_loss 2.418, d_loss 0.083\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 85/390 d_loss_real= 0.289, d_loss_fake= 0.096, g_loss 2.407, d_loss 0.193\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 21 Batch 86/390 d_loss_real= 0.474, d_loss_fake= 0.107, g_loss 2.282, d_loss 0.290\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 87/390 d_loss_real= 0.159, d_loss_fake= 0.128, g_loss 2.130, d_loss 0.143\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 88/390 d_loss_real= 0.184, d_loss_fake= 0.150, g_loss 2.156, d_loss 0.167\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 89/390 d_loss_real= 0.306, d_loss_fake= 0.146, g_loss 2.211, d_loss 0.226\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 90/390 d_loss_real= 0.221, d_loss_fake= 0.115, g_loss 2.320, d_loss 0.168\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 21 Batch 91/390 d_loss_real= 0.214, d_loss_fake= 0.106, g_loss 2.438, d_loss 0.160\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 21 Batch 92/390 d_loss_real= 0.328, d_loss_fake= 0.097, g_loss 2.478, d_loss 0.213\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 93/390 d_loss_real= 0.196, d_loss_fake= 0.093, g_loss 2.465, d_loss 0.144\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 21 Batch 94/390 d_loss_real= 0.340, d_loss_fake= 0.104, g_loss 2.296, d_loss 0.222\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 95/390 d_loss_real= 0.096, d_loss_fake= 0.122, g_loss 2.276, d_loss 0.109\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 96/390 d_loss_real= 0.194, d_loss_fake= 0.127, g_loss 2.255, d_loss 0.160\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 97/390 d_loss_real= 0.091, d_loss_fake= 0.119, g_loss 2.300, d_loss 0.105\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 98/390 d_loss_real= 0.155, d_loss_fake= 0.111, g_loss 2.348, d_loss 0.133\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 21 Batch 99/390 d_loss_real= 0.313, d_loss_fake= 0.106, g_loss 2.294, d_loss 0.210\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 100/390 d_loss_real= 0.449, d_loss_fake= 0.118, g_loss 2.256, d_loss 0.284\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 101/390 d_loss_real= 0.308, d_loss_fake= 0.152, g_loss 2.199, d_loss 0.230\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 102/390 d_loss_real= 0.262, d_loss_fake= 0.135, g_loss 2.198, d_loss 0.199\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 103/390 d_loss_real= 0.197, d_loss_fake= 0.134, g_loss 2.214, d_loss 0.166\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 21 Batch 104/390 d_loss_real= 0.430, d_loss_fake= 0.124, g_loss 2.275, d_loss 0.277\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 105/390 d_loss_real= 0.179, d_loss_fake= 0.118, g_loss 2.322, d_loss 0.148\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 21 Batch 106/390 d_loss_real= 0.138, d_loss_fake= 0.106, g_loss 2.436, d_loss 0.122\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 21 Batch 107/390 d_loss_real= 0.205, d_loss_fake= 0.094, g_loss 2.487, d_loss 0.149\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 21 Batch 108/390 d_loss_real= 0.252, d_loss_fake= 0.095, g_loss 2.554, d_loss 0.174\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 109/390 d_loss_real= 0.370, d_loss_fake= 0.098, g_loss 2.300, d_loss 0.234\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 21 Batch 110/390 d_loss_real= 0.237, d_loss_fake= 0.131, g_loss 2.216, d_loss 0.184\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 111/390 d_loss_real= 0.102, d_loss_fake= 0.132, g_loss 2.301, d_loss 0.117\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 112/390 d_loss_real= 0.324, d_loss_fake= 0.106, g_loss 2.453, d_loss 0.215\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 113/390 d_loss_real= 0.354, d_loss_fake= 0.095, g_loss 2.448, d_loss 0.225\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 114/390 d_loss_real= 0.208, d_loss_fake= 0.102, g_loss 2.423, d_loss 0.155\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 115/390 d_loss_real= 0.359, d_loss_fake= 0.116, g_loss 2.166, d_loss 0.238\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 116/390 d_loss_real= 0.105, d_loss_fake= 0.167, g_loss 2.106, d_loss 0.136\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 117/390 d_loss_real= 0.256, d_loss_fake= 0.148, g_loss 2.271, d_loss 0.202\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 21 Batch 118/390 d_loss_real= 0.201, d_loss_fake= 0.112, g_loss 2.477, d_loss 0.157\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 21 Batch 119/390 d_loss_real= 0.174, d_loss_fake= 0.087, g_loss 2.616, d_loss 0.131\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 120/390 d_loss_real= 0.211, d_loss_fake= 0.083, g_loss 2.615, d_loss 0.147\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 21 Batch 121/390 d_loss_real= 0.236, d_loss_fake= 0.088, g_loss 2.535, d_loss 0.162\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 122/390 d_loss_real= 0.415, d_loss_fake= 0.096, g_loss 2.461, d_loss 0.255\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 123/390 d_loss_real= 0.369, d_loss_fake= 0.124, g_loss 2.264, d_loss 0.246\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 124/390 d_loss_real= 0.136, d_loss_fake= 0.129, g_loss 2.200, d_loss 0.133\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 125/390 d_loss_real= 0.173, d_loss_fake= 0.153, g_loss 2.138, d_loss 0.163\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 21 Batch 126/390 d_loss_real= 0.129, d_loss_fake= 0.142, g_loss 2.130, d_loss 0.135\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 127/390 d_loss_real= 0.372, d_loss_fake= 0.153, g_loss 2.212, d_loss 0.263\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 128/390 d_loss_real= 0.328, d_loss_fake= 0.122, g_loss 2.329, d_loss 0.225\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 129/390 d_loss_real= 0.445, d_loss_fake= 0.117, g_loss 2.287, d_loss 0.281\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 21 Batch 130/390 d_loss_real= 0.147, d_loss_fake= 0.115, g_loss 2.322, d_loss 0.131\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 131/390 d_loss_real= 0.175, d_loss_fake= 0.108, g_loss 2.327, d_loss 0.142\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 132/390 d_loss_real= 0.364, d_loss_fake= 0.112, g_loss 2.302, d_loss 0.238\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 133/390 d_loss_real= 0.156, d_loss_fake= 0.116, g_loss 2.265, d_loss 0.136\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 134/390 d_loss_real= 0.252, d_loss_fake= 0.124, g_loss 2.175, d_loss 0.188\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 135/390 d_loss_real= 0.280, d_loss_fake= 0.135, g_loss 2.058, d_loss 0.208\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 136/390 d_loss_real= 0.170, d_loss_fake= 0.180, g_loss 1.891, d_loss 0.175\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 137/390 d_loss_real= 0.251, d_loss_fake= 0.163, g_loss 2.176, d_loss 0.207\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 138/390 d_loss_real= 0.160, d_loss_fake= 0.132, g_loss 2.306, d_loss 0.146\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 21 Batch 139/390 d_loss_real= 0.409, d_loss_fake= 0.107, g_loss 2.377, d_loss 0.258\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 140/390 d_loss_real= 0.207, d_loss_fake= 0.110, g_loss 2.342, d_loss 0.158\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 141/390 d_loss_real= 0.217, d_loss_fake= 0.112, g_loss 2.236, d_loss 0.165\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 142/390 d_loss_real= 0.120, d_loss_fake= 0.127, g_loss 2.223, d_loss 0.123\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 143/390 d_loss_real= 0.284, d_loss_fake= 0.139, g_loss 2.261, d_loss 0.212\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 144/390 d_loss_real= 0.129, d_loss_fake= 0.117, g_loss 2.373, d_loss 0.123\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 145/390 d_loss_real= 0.152, d_loss_fake= 0.100, g_loss 2.490, d_loss 0.126\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 146/390 d_loss_real= 0.311, d_loss_fake= 0.101, g_loss 2.423, d_loss 0.206\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 147/390 d_loss_real= 0.197, d_loss_fake= 0.101, g_loss 2.398, d_loss 0.149\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 148/390 d_loss_real= 0.247, d_loss_fake= 0.110, g_loss 2.288, d_loss 0.179\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 149/390 d_loss_real= 0.295, d_loss_fake= 0.123, g_loss 2.129, d_loss 0.209\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 150/390 d_loss_real= 0.175, d_loss_fake= 0.149, g_loss 2.091, d_loss 0.162\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 151/390 d_loss_real= 0.349, d_loss_fake= 0.146, g_loss 2.084, d_loss 0.248\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 21 Batch 152/390 d_loss_real= 0.268, d_loss_fake= 0.152, g_loss 2.217, d_loss 0.210\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 153/390 d_loss_real= 0.347, d_loss_fake= 0.119, g_loss 2.308, d_loss 0.233\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 21 Batch 154/390 d_loss_real= 0.311, d_loss_fake= 0.109, g_loss 2.275, d_loss 0.210\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 21 Batch 155/390 d_loss_real= 0.205, d_loss_fake= 0.116, g_loss 2.208, d_loss 0.160\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 156/390 d_loss_real= 0.146, d_loss_fake= 0.133, g_loss 2.070, d_loss 0.140\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 157/390 d_loss_real= 0.193, d_loss_fake= 0.158, g_loss 2.054, d_loss 0.176\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 21 Batch 158/390 d_loss_real= 0.147, d_loss_fake= 0.142, g_loss 2.160, d_loss 0.145\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 21 Batch 159/390 d_loss_real= 0.244, d_loss_fake= 0.131, g_loss 2.242, d_loss 0.187\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 21 Batch 160/390 d_loss_real= 0.368, d_loss_fake= 0.113, g_loss 2.297, d_loss 0.240\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 21 Batch 161/390 d_loss_real= 0.266, d_loss_fake= 0.113, g_loss 2.239, d_loss 0.190\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 21 Batch 162/390 d_loss_real= 0.215, d_loss_fake= 0.134, g_loss 2.222, d_loss 0.174\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 163/390 d_loss_real= 0.127, d_loss_fake= 0.124, g_loss 2.301, d_loss 0.126\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 164/390 d_loss_real= 0.221, d_loss_fake= 0.109, g_loss 2.400, d_loss 0.165\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 165/390 d_loss_real= 0.181, d_loss_fake= 0.100, g_loss 2.424, d_loss 0.141\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 21 Batch 166/390 d_loss_real= 0.249, d_loss_fake= 0.097, g_loss 2.444, d_loss 0.173\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 167/390 d_loss_real= 0.265, d_loss_fake= 0.105, g_loss 2.347, d_loss 0.185\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 168/390 d_loss_real= 0.239, d_loss_fake= 0.109, g_loss 2.311, d_loss 0.174\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 169/390 d_loss_real= 0.143, d_loss_fake= 0.109, g_loss 2.329, d_loss 0.126\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 21 Batch 170/390 d_loss_real= 0.275, d_loss_fake= 0.116, g_loss 2.181, d_loss 0.196\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 171/390 d_loss_real= 0.191, d_loss_fake= 0.130, g_loss 2.240, d_loss 0.160\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 172/390 d_loss_real= 0.332, d_loss_fake= 0.128, g_loss 2.175, d_loss 0.230\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 21 Batch 173/390 d_loss_real= 0.143, d_loss_fake= 0.135, g_loss 2.299, d_loss 0.139\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 174/390 d_loss_real= 0.336, d_loss_fake= 0.112, g_loss 2.314, d_loss 0.224\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 21 Batch 175/390 d_loss_real= 0.135, d_loss_fake= 0.105, g_loss 2.431, d_loss 0.120\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 176/390 d_loss_real= 0.330, d_loss_fake= 0.097, g_loss 2.445, d_loss 0.213\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 177/390 d_loss_real= 0.178, d_loss_fake= 0.104, g_loss 2.423, d_loss 0.141\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 178/390 d_loss_real= 0.129, d_loss_fake= 0.101, g_loss 2.491, d_loss 0.115\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 21 Batch 179/390 d_loss_real= 0.236, d_loss_fake= 0.100, g_loss 2.405, d_loss 0.168\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 21 Batch 180/390 d_loss_real= 0.285, d_loss_fake= 0.112, g_loss 2.340, d_loss 0.198\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 21 Batch 181/390 d_loss_real= 0.320, d_loss_fake= 0.113, g_loss 2.253, d_loss 0.217\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 182/390 d_loss_real= 0.187, d_loss_fake= 0.111, g_loss 2.274, d_loss 0.149\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 183/390 d_loss_real= 0.188, d_loss_fake= 0.120, g_loss 2.292, d_loss 0.154\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 184/390 d_loss_real= 0.416, d_loss_fake= 0.132, g_loss 2.215, d_loss 0.274\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 185/390 d_loss_real= 0.184, d_loss_fake= 0.131, g_loss 2.338, d_loss 0.157\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 186/390 d_loss_real= 0.208, d_loss_fake= 0.111, g_loss 2.394, d_loss 0.159\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 21 Batch 187/390 d_loss_real= 0.289, d_loss_fake= 0.101, g_loss 2.470, d_loss 0.195\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 21 Batch 188/390 d_loss_real= 0.155, d_loss_fake= 0.093, g_loss 2.518, d_loss 0.124\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 189/390 d_loss_real= 0.371, d_loss_fake= 0.094, g_loss 2.437, d_loss 0.232\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 190/390 d_loss_real= 0.300, d_loss_fake= 0.098, g_loss 2.335, d_loss 0.199\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 191/390 d_loss_real= 0.208, d_loss_fake= 0.121, g_loss 2.162, d_loss 0.164\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 21 Batch 192/390 d_loss_real= 0.092, d_loss_fake= 0.125, g_loss 2.156, d_loss 0.108\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 193/390 d_loss_real= 0.267, d_loss_fake= 0.137, g_loss 2.189, d_loss 0.202\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 194/390 d_loss_real= 0.159, d_loss_fake= 0.123, g_loss 2.230, d_loss 0.141\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 195/390 d_loss_real= 0.243, d_loss_fake= 0.122, g_loss 2.300, d_loss 0.183\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 21 Batch 196/390 d_loss_real= 0.111, d_loss_fake= 0.108, g_loss 2.430, d_loss 0.109\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 197/390 d_loss_real= 0.375, d_loss_fake= 0.102, g_loss 2.391, d_loss 0.238\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 198/390 d_loss_real= 0.343, d_loss_fake= 0.115, g_loss 2.243, d_loss 0.229\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 199/390 d_loss_real= 0.219, d_loss_fake= 0.148, g_loss 2.126, d_loss 0.184\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 200/390 d_loss_real= 0.169, d_loss_fake= 0.154, g_loss 2.104, d_loss 0.161\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 21 Batch 201/390 d_loss_real= 0.219, d_loss_fake= 0.133, g_loss 2.303, d_loss 0.176\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 202/390 d_loss_real= 0.206, d_loss_fake= 0.110, g_loss 2.413, d_loss 0.158\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 21 Batch 203/390 d_loss_real= 0.260, d_loss_fake= 0.099, g_loss 2.428, d_loss 0.180\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 204/390 d_loss_real= 0.178, d_loss_fake= 0.104, g_loss 2.408, d_loss 0.141\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 205/390 d_loss_real= 0.056, d_loss_fake= 0.097, g_loss 2.499, d_loss 0.076\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 21 Batch 206/390 d_loss_real= 0.118, d_loss_fake= 0.088, g_loss 2.569, d_loss 0.103\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 207/390 d_loss_real= 0.319, d_loss_fake= 0.085, g_loss 2.541, d_loss 0.202\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 208/390 d_loss_real= 0.398, d_loss_fake= 0.092, g_loss 2.461, d_loss 0.245\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 209/390 d_loss_real= 0.285, d_loss_fake= 0.108, g_loss 2.277, d_loss 0.196\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 210/390 d_loss_real= 0.181, d_loss_fake= 0.134, g_loss 2.178, d_loss 0.157\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 21 Batch 211/390 d_loss_real= 0.147, d_loss_fake= 0.133, g_loss 2.324, d_loss 0.140\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 212/390 d_loss_real= 0.178, d_loss_fake= 0.107, g_loss 2.427, d_loss 0.142\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 21 Batch 213/390 d_loss_real= 0.251, d_loss_fake= 0.094, g_loss 2.508, d_loss 0.173\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 21 Batch 214/390 d_loss_real= 0.281, d_loss_fake= 0.095, g_loss 2.514, d_loss 0.188\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 21 Batch 215/390 d_loss_real= 0.209, d_loss_fake= 0.090, g_loss 2.466, d_loss 0.149\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 21 Batch 216/390 d_loss_real= 0.395, d_loss_fake= 0.098, g_loss 2.460, d_loss 0.247\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 21 Batch 217/390 d_loss_real= 0.287, d_loss_fake= 0.104, g_loss 2.324, d_loss 0.196\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 21 Batch 218/390 d_loss_real= 0.194, d_loss_fake= 0.116, g_loss 2.260, d_loss 0.155\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "Epoch 21 Batch 219/390 d_loss_real= 0.211, d_loss_fake= 0.114, g_loss 2.338, d_loss 0.162\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 21 Batch 220/390 d_loss_real= 0.094, d_loss_fake= 0.111, g_loss 2.398, d_loss 0.102\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 21 Batch 221/390 d_loss_real= 0.344, d_loss_fake= 0.101, g_loss 2.379, d_loss 0.223\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 222/390 d_loss_real= 0.300, d_loss_fake= 0.108, g_loss 2.400, d_loss 0.204\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 21 Batch 223/390 d_loss_real= 0.179, d_loss_fake= 0.110, g_loss 2.354, d_loss 0.144\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 224/390 d_loss_real= 0.250, d_loss_fake= 0.107, g_loss 2.301, d_loss 0.179\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 21 Batch 225/390 d_loss_real= 0.322, d_loss_fake= 0.121, g_loss 2.241, d_loss 0.221\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 226/390 d_loss_real= 0.243, d_loss_fake= 0.124, g_loss 2.225, d_loss 0.184\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 227/390 d_loss_real= 0.108, d_loss_fake= 0.118, g_loss 2.309, d_loss 0.113\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 228/390 d_loss_real= 0.393, d_loss_fake= 0.113, g_loss 2.283, d_loss 0.253\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 229/390 d_loss_real= 0.114, d_loss_fake= 0.108, g_loss 2.396, d_loss 0.111\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 230/390 d_loss_real= 0.402, d_loss_fake= 0.108, g_loss 2.272, d_loss 0.255\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 231/390 d_loss_real= 0.222, d_loss_fake= 0.127, g_loss 2.224, d_loss 0.174\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 232/390 d_loss_real= 0.078, d_loss_fake= 0.117, g_loss 2.307, d_loss 0.097\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 233/390 d_loss_real= 0.197, d_loss_fake= 0.111, g_loss 2.353, d_loss 0.154\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 21 Batch 234/390 d_loss_real= 0.240, d_loss_fake= 0.106, g_loss 2.420, d_loss 0.173\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 235/390 d_loss_real= 0.154, d_loss_fake= 0.093, g_loss 2.491, d_loss 0.124\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 236/390 d_loss_real= 0.327, d_loss_fake= 0.099, g_loss 2.421, d_loss 0.213\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 21 Batch 237/390 d_loss_real= 0.161, d_loss_fake= 0.106, g_loss 2.354, d_loss 0.133\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 21 Batch 238/390 d_loss_real= 0.190, d_loss_fake= 0.111, g_loss 2.381, d_loss 0.151\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 239/390 d_loss_real= 0.270, d_loss_fake= 0.114, g_loss 2.328, d_loss 0.192\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 240/390 d_loss_real= 0.178, d_loss_fake= 0.104, g_loss 2.367, d_loss 0.141\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 241/390 d_loss_real= 0.169, d_loss_fake= 0.106, g_loss 2.451, d_loss 0.137\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 242/390 d_loss_real= 0.292, d_loss_fake= 0.103, g_loss 2.408, d_loss 0.198\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 243/390 d_loss_real= 0.225, d_loss_fake= 0.103, g_loss 2.351, d_loss 0.164\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 21 Batch 244/390 d_loss_real= 0.179, d_loss_fake= 0.115, g_loss 2.240, d_loss 0.147\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 21 Batch 245/390 d_loss_real= 0.524, d_loss_fake= 0.147, g_loss 2.102, d_loss 0.335\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 21 Batch 246/390 d_loss_real= 0.142, d_loss_fake= 0.153, g_loss 2.207, d_loss 0.148\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 247/390 d_loss_real= 0.206, d_loss_fake= 0.121, g_loss 2.403, d_loss 0.163\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 248/390 d_loss_real= 0.125, d_loss_fake= 0.099, g_loss 2.525, d_loss 0.112\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 249/390 d_loss_real= 0.253, d_loss_fake= 0.091, g_loss 2.557, d_loss 0.172\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 250/390 d_loss_real= 0.294, d_loss_fake= 0.093, g_loss 2.530, d_loss 0.193\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 21 Batch 251/390 d_loss_real= 0.161, d_loss_fake= 0.092, g_loss 2.502, d_loss 0.127\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 252/390 d_loss_real= 0.237, d_loss_fake= 0.090, g_loss 2.483, d_loss 0.163\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 253/390 d_loss_real= 0.116, d_loss_fake= 0.097, g_loss 2.471, d_loss 0.106\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 254/390 d_loss_real= 0.201, d_loss_fake= 0.095, g_loss 2.406, d_loss 0.148\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 255/390 d_loss_real= 0.262, d_loss_fake= 0.102, g_loss 2.285, d_loss 0.182\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 256/390 d_loss_real= 0.078, d_loss_fake= 0.128, g_loss 2.252, d_loss 0.103\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 21 Batch 257/390 d_loss_real= 0.217, d_loss_fake= 0.119, g_loss 2.349, d_loss 0.168\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 258/390 d_loss_real= 0.201, d_loss_fake= 0.117, g_loss 2.397, d_loss 0.159\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 259/390 d_loss_real= 0.316, d_loss_fake= 0.106, g_loss 2.373, d_loss 0.211\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 260/390 d_loss_real= 0.187, d_loss_fake= 0.106, g_loss 2.401, d_loss 0.147\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 261/390 d_loss_real= 0.110, d_loss_fake= 0.095, g_loss 2.546, d_loss 0.103\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 262/390 d_loss_real= 0.228, d_loss_fake= 0.092, g_loss 2.443, d_loss 0.160\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 21 Batch 263/390 d_loss_real= 0.198, d_loss_fake= 0.099, g_loss 2.435, d_loss 0.148\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 21 Batch 264/390 d_loss_real= 0.253, d_loss_fake= 0.113, g_loss 2.308, d_loss 0.183\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 265/390 d_loss_real= 0.363, d_loss_fake= 0.109, g_loss 2.290, d_loss 0.236\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 266/390 d_loss_real= 0.341, d_loss_fake= 0.110, g_loss 2.374, d_loss 0.225\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 21 Batch 267/390 d_loss_real= 0.242, d_loss_fake= 0.115, g_loss 2.389, d_loss 0.178\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 21 Batch 268/390 d_loss_real= 0.303, d_loss_fake= 0.094, g_loss 2.443, d_loss 0.198\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 21 Batch 269/390 d_loss_real= 0.308, d_loss_fake= 0.114, g_loss 2.357, d_loss 0.211\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 270/390 d_loss_real= 0.221, d_loss_fake= 0.115, g_loss 2.359, d_loss 0.168\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 271/390 d_loss_real= 0.305, d_loss_fake= 0.113, g_loss 2.322, d_loss 0.209\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 272/390 d_loss_real= 0.314, d_loss_fake= 0.111, g_loss 2.359, d_loss 0.212\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 273/390 d_loss_real= 0.216, d_loss_fake= 0.120, g_loss 2.242, d_loss 0.168\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 21 Batch 274/390 d_loss_real= 0.253, d_loss_fake= 0.136, g_loss 2.275, d_loss 0.194\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 21 Batch 275/390 d_loss_real= 0.215, d_loss_fake= 0.115, g_loss 2.322, d_loss 0.165\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 21 Batch 276/390 d_loss_real= 0.221, d_loss_fake= 0.106, g_loss 2.326, d_loss 0.163\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 21 Batch 277/390 d_loss_real= 0.155, d_loss_fake= 0.108, g_loss 2.362, d_loss 0.131\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 21 Batch 278/390 d_loss_real= 0.111, d_loss_fake= 0.114, g_loss 2.288, d_loss 0.112\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 21 Batch 279/390 d_loss_real= 0.124, d_loss_fake= 0.109, g_loss 2.281, d_loss 0.117\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 280/390 d_loss_real= 0.162, d_loss_fake= 0.122, g_loss 2.268, d_loss 0.142\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 21 Batch 281/390 d_loss_real= 0.170, d_loss_fake= 0.121, g_loss 2.261, d_loss 0.145\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 21 Batch 282/390 d_loss_real= 0.205, d_loss_fake= 0.115, g_loss 2.325, d_loss 0.160\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 283/390 d_loss_real= 0.073, d_loss_fake= 0.100, g_loss 2.490, d_loss 0.086\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 21 Batch 284/390 d_loss_real= 0.242, d_loss_fake= 0.097, g_loss 2.501, d_loss 0.170\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 21 Batch 285/390 d_loss_real= 0.331, d_loss_fake= 0.097, g_loss 2.473, d_loss 0.214\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 21 Batch 286/390 d_loss_real= 0.253, d_loss_fake= 0.100, g_loss 2.451, d_loss 0.176\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 287/390 d_loss_real= 0.309, d_loss_fake= 0.108, g_loss 2.331, d_loss 0.209\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 288/390 d_loss_real= 0.290, d_loss_fake= 0.105, g_loss 2.247, d_loss 0.198\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 289/390 d_loss_real= 0.388, d_loss_fake= 0.120, g_loss 2.271, d_loss 0.254\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 21 Batch 290/390 d_loss_real= 0.183, d_loss_fake= 0.115, g_loss 2.281, d_loss 0.149\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 291/390 d_loss_real= 0.286, d_loss_fake= 0.126, g_loss 2.369, d_loss 0.206\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 292/390 d_loss_real= 0.185, d_loss_fake= 0.117, g_loss 2.407, d_loss 0.151\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 21 Batch 293/390 d_loss_real= 0.296, d_loss_fake= 0.107, g_loss 2.458, d_loss 0.202\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 294/390 d_loss_real= 0.186, d_loss_fake= 0.099, g_loss 2.457, d_loss 0.143\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 21 Batch 295/390 d_loss_real= 0.400, d_loss_fake= 0.098, g_loss 2.456, d_loss 0.249\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 296/390 d_loss_real= 0.142, d_loss_fake= 0.096, g_loss 2.480, d_loss 0.119\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 297/390 d_loss_real= 0.150, d_loss_fake= 0.086, g_loss 2.523, d_loss 0.118\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 21 Batch 298/390 d_loss_real= 0.303, d_loss_fake= 0.095, g_loss 2.432, d_loss 0.199\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 299/390 d_loss_real= 0.158, d_loss_fake= 0.107, g_loss 2.351, d_loss 0.133\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 300/390 d_loss_real= 0.217, d_loss_fake= 0.107, g_loss 2.399, d_loss 0.162\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 21 Batch 301/390 d_loss_real= 0.236, d_loss_fake= 0.116, g_loss 2.286, d_loss 0.176\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 302/390 d_loss_real= 0.190, d_loss_fake= 0.127, g_loss 2.358, d_loss 0.159\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 303/390 d_loss_real= 0.183, d_loss_fake= 0.116, g_loss 2.346, d_loss 0.150\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 21 Batch 304/390 d_loss_real= 0.139, d_loss_fake= 0.109, g_loss 2.502, d_loss 0.124\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 21 Batch 305/390 d_loss_real= 0.199, d_loss_fake= 0.092, g_loss 2.585, d_loss 0.145\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 306/390 d_loss_real= 0.310, d_loss_fake= 0.090, g_loss 2.642, d_loss 0.200\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 21 Batch 307/390 d_loss_real= 0.198, d_loss_fake= 0.079, g_loss 2.735, d_loss 0.139\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 308/390 d_loss_real= 0.215, d_loss_fake= 0.082, g_loss 2.633, d_loss 0.149\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 309/390 d_loss_real= 0.127, d_loss_fake= 0.093, g_loss 2.590, d_loss 0.110\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 310/390 d_loss_real= 0.349, d_loss_fake= 0.096, g_loss 2.524, d_loss 0.222\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 311/390 d_loss_real= 0.281, d_loss_fake= 0.106, g_loss 2.372, d_loss 0.193\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 312/390 d_loss_real= 0.290, d_loss_fake= 0.111, g_loss 2.359, d_loss 0.201\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 313/390 d_loss_real= 0.329, d_loss_fake= 0.128, g_loss 2.380, d_loss 0.229\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 21 Batch 314/390 d_loss_real= 0.149, d_loss_fake= 0.120, g_loss 2.387, d_loss 0.134\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 315/390 d_loss_real= 0.125, d_loss_fake= 0.111, g_loss 2.527, d_loss 0.118\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 21 Batch 316/390 d_loss_real= 0.303, d_loss_fake= 0.094, g_loss 2.672, d_loss 0.198\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 317/390 d_loss_real= 0.268, d_loss_fake= 0.081, g_loss 2.704, d_loss 0.174\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 318/390 d_loss_real= 0.260, d_loss_fake= 0.084, g_loss 2.578, d_loss 0.172\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 319/390 d_loss_real= 0.316, d_loss_fake= 0.098, g_loss 2.197, d_loss 0.207\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 320/390 d_loss_real= 0.182, d_loss_fake= 0.182, g_loss 2.188, d_loss 0.182\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 321/390 d_loss_real= 0.205, d_loss_fake= 0.123, g_loss 2.578, d_loss 0.164\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 322/390 d_loss_real= 0.345, d_loss_fake= 0.086, g_loss 2.682, d_loss 0.215\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 323/390 d_loss_real= 0.171, d_loss_fake= 0.073, g_loss 2.717, d_loss 0.122\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 21 Batch 324/390 d_loss_real= 0.255, d_loss_fake= 0.078, g_loss 2.654, d_loss 0.166\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 325/390 d_loss_real= 0.238, d_loss_fake= 0.082, g_loss 2.509, d_loss 0.160\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 326/390 d_loss_real= 0.319, d_loss_fake= 0.096, g_loss 2.391, d_loss 0.208\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 327/390 d_loss_real= 0.192, d_loss_fake= 0.104, g_loss 2.381, d_loss 0.148\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 21 Batch 328/390 d_loss_real= 0.191, d_loss_fake= 0.103, g_loss 2.368, d_loss 0.147\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 329/390 d_loss_real= 0.348, d_loss_fake= 0.113, g_loss 2.224, d_loss 0.231\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 21 Batch 330/390 d_loss_real= 0.184, d_loss_fake= 0.122, g_loss 2.331, d_loss 0.153\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 331/390 d_loss_real= 0.150, d_loss_fake= 0.116, g_loss 2.380, d_loss 0.133\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 21 Batch 332/390 d_loss_real= 0.364, d_loss_fake= 0.116, g_loss 2.381, d_loss 0.240\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 333/390 d_loss_real= 0.311, d_loss_fake= 0.115, g_loss 2.334, d_loss 0.213\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 334/390 d_loss_real= 0.403, d_loss_fake= 0.129, g_loss 2.172, d_loss 0.266\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 335/390 d_loss_real= 0.280, d_loss_fake= 0.133, g_loss 2.152, d_loss 0.207\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 21 Batch 336/390 d_loss_real= 0.215, d_loss_fake= 0.151, g_loss 2.081, d_loss 0.183\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 337/390 d_loss_real= 0.422, d_loss_fake= 0.171, g_loss 2.057, d_loss 0.296\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 21 Batch 338/390 d_loss_real= 0.172, d_loss_fake= 0.146, g_loss 2.165, d_loss 0.159\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 339/390 d_loss_real= 0.335, d_loss_fake= 0.147, g_loss 2.033, d_loss 0.241\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 340/390 d_loss_real= 0.194, d_loss_fake= 0.155, g_loss 2.104, d_loss 0.175\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 341/390 d_loss_real= 0.206, d_loss_fake= 0.140, g_loss 2.211, d_loss 0.173\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 342/390 d_loss_real= 0.057, d_loss_fake= 0.117, g_loss 2.408, d_loss 0.087\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 21 Batch 343/390 d_loss_real= 0.467, d_loss_fake= 0.092, g_loss 2.492, d_loss 0.279\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 21 Batch 344/390 d_loss_real= 0.175, d_loss_fake= 0.087, g_loss 2.553, d_loss 0.131\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 345/390 d_loss_real= 0.227, d_loss_fake= 0.088, g_loss 2.515, d_loss 0.158\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 346/390 d_loss_real= 0.324, d_loss_fake= 0.098, g_loss 2.360, d_loss 0.211\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 347/390 d_loss_real= 0.296, d_loss_fake= 0.114, g_loss 2.261, d_loss 0.205\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 348/390 d_loss_real= 0.215, d_loss_fake= 0.130, g_loss 2.129, d_loss 0.172\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 349/390 d_loss_real= 0.095, d_loss_fake= 0.155, g_loss 2.229, d_loss 0.125\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 21 Batch 350/390 d_loss_real= 0.079, d_loss_fake= 0.109, g_loss 2.479, d_loss 0.094\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 351/390 d_loss_real= 0.129, d_loss_fake= 0.084, g_loss 2.595, d_loss 0.106\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 21 Batch 352/390 d_loss_real= 0.221, d_loss_fake= 0.074, g_loss 2.691, d_loss 0.148\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 21 Batch 353/390 d_loss_real= 0.269, d_loss_fake= 0.075, g_loss 2.670, d_loss 0.172\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 354/390 d_loss_real= 0.290, d_loss_fake= 0.081, g_loss 2.582, d_loss 0.185\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 21 Batch 355/390 d_loss_real= 0.260, d_loss_fake= 0.094, g_loss 2.423, d_loss 0.177\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 21 Batch 356/390 d_loss_real= 0.116, d_loss_fake= 0.110, g_loss 2.317, d_loss 0.113\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 357/390 d_loss_real= 0.143, d_loss_fake= 0.128, g_loss 2.216, d_loss 0.136\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 358/390 d_loss_real= 0.224, d_loss_fake= 0.166, g_loss 2.305, d_loss 0.195\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 359/390 d_loss_real= 0.202, d_loss_fake= 0.104, g_loss 2.594, d_loss 0.153\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 360/390 d_loss_real= 0.213, d_loss_fake= 0.076, g_loss 2.784, d_loss 0.144\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 21 Batch 361/390 d_loss_real= 0.279, d_loss_fake= 0.066, g_loss 2.904, d_loss 0.173\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21 Batch 362/390 d_loss_real= 0.200, d_loss_fake= 0.062, g_loss 2.767, d_loss 0.131\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 363/390 d_loss_real= 0.355, d_loss_fake= 0.080, g_loss 2.547, d_loss 0.217\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 21 Batch 364/390 d_loss_real= 0.258, d_loss_fake= 0.125, g_loss 2.306, d_loss 0.191\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 365/390 d_loss_real= 0.148, d_loss_fake= 0.183, g_loss 2.227, d_loss 0.166\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 21 Batch 366/390 d_loss_real= 0.052, d_loss_fake= 0.107, g_loss 2.583, d_loss 0.080\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 21 Batch 367/390 d_loss_real= 0.260, d_loss_fake= 0.073, g_loss 2.859, d_loss 0.167\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 368/390 d_loss_real= 0.353, d_loss_fake= 0.063, g_loss 2.906, d_loss 0.208\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 369/390 d_loss_real= 0.454, d_loss_fake= 0.067, g_loss 2.736, d_loss 0.261\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 21 Batch 370/390 d_loss_real= 0.374, d_loss_fake= 0.081, g_loss 2.458, d_loss 0.227\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 21 Batch 371/390 d_loss_real= 0.110, d_loss_fake= 0.119, g_loss 2.136, d_loss 0.115\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 372/390 d_loss_real= 0.184, d_loss_fake= 0.173, g_loss 2.103, d_loss 0.178\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 373/390 d_loss_real= 0.277, d_loss_fake= 0.202, g_loss 2.153, d_loss 0.240\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 374/390 d_loss_real= 0.285, d_loss_fake= 0.121, g_loss 2.321, d_loss 0.203\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 21 Batch 375/390 d_loss_real= 0.278, d_loss_fake= 0.100, g_loss 2.495, d_loss 0.189\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 376/390 d_loss_real= 0.189, d_loss_fake= 0.095, g_loss 2.495, d_loss 0.142\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 377/390 d_loss_real= 0.197, d_loss_fake= 0.094, g_loss 2.506, d_loss 0.145\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 378/390 d_loss_real= 0.357, d_loss_fake= 0.102, g_loss 2.405, d_loss 0.229\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 379/390 d_loss_real= 0.158, d_loss_fake= 0.104, g_loss 2.363, d_loss 0.131\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 21 Batch 380/390 d_loss_real= 0.338, d_loss_fake= 0.116, g_loss 2.277, d_loss 0.227\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 21 Batch 381/390 d_loss_real= 0.282, d_loss_fake= 0.125, g_loss 2.265, d_loss 0.204\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 382/390 d_loss_real= 0.207, d_loss_fake= 0.140, g_loss 2.149, d_loss 0.174\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 383/390 d_loss_real= 0.170, d_loss_fake= 0.129, g_loss 2.163, d_loss 0.150\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 21 Batch 384/390 d_loss_real= 0.159, d_loss_fake= 0.123, g_loss 2.279, d_loss 0.141\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 385/390 d_loss_real= 0.027, d_loss_fake= 0.112, g_loss 2.434, d_loss 0.069\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 21 Batch 386/390 d_loss_real= 0.226, d_loss_fake= 0.099, g_loss 2.475, d_loss 0.162\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 387/390 d_loss_real= 0.275, d_loss_fake= 0.095, g_loss 2.438, d_loss 0.185\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21 Batch 388/390 d_loss_real= 0.189, d_loss_fake= 0.105, g_loss 2.367, d_loss 0.147\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21 Batch 389/390 d_loss_real= 0.025, d_loss_fake= 0.105, g_loss 2.391, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21 Batch 390/390 d_loss_real= 0.250, d_loss_fake= 0.109, g_loss 2.409, d_loss 0.179\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 22 Batch 1/390 d_loss_real= 0.148, d_loss_fake= 0.103, g_loss 2.482, d_loss 0.125\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 22 Batch 2/390 d_loss_real= 0.113, d_loss_fake= 0.094, g_loss 2.528, d_loss 0.103\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22 Batch 3/390 d_loss_real= 0.227, d_loss_fake= 0.093, g_loss 2.563, d_loss 0.160\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 22 Batch 4/390 d_loss_real= 0.101, d_loss_fake= 0.095, g_loss 2.556, d_loss 0.098\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 22 Batch 5/390 d_loss_real= 0.091, d_loss_fake= 0.093, g_loss 2.601, d_loss 0.092\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 22 Batch 6/390 d_loss_real= 0.271, d_loss_fake= 0.073, g_loss 2.693, d_loss 0.172\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 22 Batch 7/390 d_loss_real= 0.334, d_loss_fake= 0.085, g_loss 2.556, d_loss 0.209\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 8/390 d_loss_real= 0.140, d_loss_fake= 0.096, g_loss 2.511, d_loss 0.118\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 22 Batch 9/390 d_loss_real= 0.339, d_loss_fake= 0.103, g_loss 2.448, d_loss 0.221\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 10/390 d_loss_real= 0.277, d_loss_fake= 0.112, g_loss 2.474, d_loss 0.194\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 11/390 d_loss_real= 0.277, d_loss_fake= 0.097, g_loss 2.397, d_loss 0.187\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 12/390 d_loss_real= 0.218, d_loss_fake= 0.098, g_loss 2.493, d_loss 0.158\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 22 Batch 13/390 d_loss_real= 0.170, d_loss_fake= 0.094, g_loss 2.558, d_loss 0.132\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 22 Batch 14/390 d_loss_real= 0.032, d_loss_fake= 0.082, g_loss 2.718, d_loss 0.057\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 22 Batch 15/390 d_loss_real= 0.373, d_loss_fake= 0.072, g_loss 2.719, d_loss 0.222\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22 Batch 16/390 d_loss_real= 0.324, d_loss_fake= 0.070, g_loss 2.760, d_loss 0.197\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 17/390 d_loss_real= 0.460, d_loss_fake= 0.081, g_loss 2.574, d_loss 0.270\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 18/390 d_loss_real= 0.128, d_loss_fake= 0.097, g_loss 2.398, d_loss 0.112\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 22 Batch 19/390 d_loss_real= 0.206, d_loss_fake= 0.111, g_loss 2.340, d_loss 0.159\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 20/390 d_loss_real= 0.081, d_loss_fake= 0.102, g_loss 2.408, d_loss 0.091\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 21/390 d_loss_real= 0.255, d_loss_fake= 0.096, g_loss 2.458, d_loss 0.175\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 22 Batch 22/390 d_loss_real= 0.172, d_loss_fake= 0.103, g_loss 2.485, d_loss 0.138\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 23/390 d_loss_real= 0.319, d_loss_fake= 0.101, g_loss 2.405, d_loss 0.210\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 24/390 d_loss_real= 0.150, d_loss_fake= 0.102, g_loss 2.334, d_loss 0.126\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 22 Batch 25/390 d_loss_real= 0.174, d_loss_fake= 0.111, g_loss 2.303, d_loss 0.143\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 26/390 d_loss_real= 0.202, d_loss_fake= 0.119, g_loss 2.266, d_loss 0.161\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 27/390 d_loss_real= 0.290, d_loss_fake= 0.133, g_loss 2.294, d_loss 0.212\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 28/390 d_loss_real= 0.230, d_loss_fake= 0.119, g_loss 2.372, d_loss 0.175\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 22 Batch 29/390 d_loss_real= 0.196, d_loss_fake= 0.100, g_loss 2.472, d_loss 0.148\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 22 Batch 30/390 d_loss_real= 0.290, d_loss_fake= 0.103, g_loss 2.444, d_loss 0.197\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 22 Batch 31/390 d_loss_real= 0.206, d_loss_fake= 0.102, g_loss 2.458, d_loss 0.154\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 32/390 d_loss_real= 0.055, d_loss_fake= 0.101, g_loss 2.395, d_loss 0.078\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 22 Batch 33/390 d_loss_real= 0.351, d_loss_fake= 0.095, g_loss 2.438, d_loss 0.223\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 34/390 d_loss_real= 0.180, d_loss_fake= 0.097, g_loss 2.513, d_loss 0.138\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 35/390 d_loss_real= 0.146, d_loss_fake= 0.084, g_loss 2.625, d_loss 0.115\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 36/390 d_loss_real= 0.306, d_loss_fake= 0.083, g_loss 2.612, d_loss 0.195\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 37/390 d_loss_real= 0.256, d_loss_fake= 0.085, g_loss 2.562, d_loss 0.171\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 22 Batch 38/390 d_loss_real= 0.229, d_loss_fake= 0.099, g_loss 2.399, d_loss 0.164\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 39/390 d_loss_real= 0.041, d_loss_fake= 0.112, g_loss 2.392, d_loss 0.077\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 40/390 d_loss_real= 0.213, d_loss_fake= 0.105, g_loss 2.524, d_loss 0.159\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22 Batch 41/390 d_loss_real= 0.202, d_loss_fake= 0.078, g_loss 2.697, d_loss 0.140\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 42/390 d_loss_real= 0.127, d_loss_fake= 0.080, g_loss 2.760, d_loss 0.103\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 43/390 d_loss_real= 0.284, d_loss_fake= 0.080, g_loss 2.652, d_loss 0.182\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 44/390 d_loss_real= 0.286, d_loss_fake= 0.087, g_loss 2.619, d_loss 0.186\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 45/390 d_loss_real= 0.279, d_loss_fake= 0.101, g_loss 2.436, d_loss 0.190\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22 Batch 46/390 d_loss_real= 0.352, d_loss_fake= 0.120, g_loss 2.197, d_loss 0.236\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 47/390 d_loss_real= 0.389, d_loss_fake= 0.157, g_loss 2.376, d_loss 0.273\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 48/390 d_loss_real= 0.135, d_loss_fake= 0.101, g_loss 2.677, d_loss 0.118\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22 Batch 49/390 d_loss_real= 0.295, d_loss_fake= 0.072, g_loss 2.844, d_loss 0.184\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 50/390 d_loss_real= 0.248, d_loss_fake= 0.063, g_loss 2.903, d_loss 0.155\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 51/390 d_loss_real= 0.360, d_loss_fake= 0.070, g_loss 2.678, d_loss 0.215\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 22 Batch 52/390 d_loss_real= 0.306, d_loss_fake= 0.090, g_loss 2.343, d_loss 0.198\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 53/390 d_loss_real= 0.060, d_loss_fake= 0.120, g_loss 2.101, d_loss 0.090\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 22 Batch 54/390 d_loss_real= 0.137, d_loss_fake= 0.154, g_loss 2.077, d_loss 0.145\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 55/390 d_loss_real= 0.292, d_loss_fake= 0.194, g_loss 2.289, d_loss 0.243\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 56/390 d_loss_real= 0.230, d_loss_fake= 0.098, g_loss 2.682, d_loss 0.164\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 57/390 d_loss_real= 0.183, d_loss_fake= 0.069, g_loss 2.843, d_loss 0.126\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 22 Batch 58/390 d_loss_real= 0.216, d_loss_fake= 0.063, g_loss 2.858, d_loss 0.140\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22 Batch 59/390 d_loss_real= 0.508, d_loss_fake= 0.063, g_loss 2.786, d_loss 0.286\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 22 Batch 60/390 d_loss_real= 0.325, d_loss_fake= 0.081, g_loss 2.479, d_loss 0.203\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 61/390 d_loss_real= 0.070, d_loss_fake= 0.111, g_loss 2.238, d_loss 0.090\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 22 Batch 62/390 d_loss_real= 0.187, d_loss_fake= 0.153, g_loss 2.074, d_loss 0.170\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 22 Batch 63/390 d_loss_real= 0.230, d_loss_fake= 0.135, g_loss 2.258, d_loss 0.182\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 64/390 d_loss_real= 0.164, d_loss_fake= 0.109, g_loss 2.489, d_loss 0.136\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 22 Batch 65/390 d_loss_real= 0.238, d_loss_fake= 0.088, g_loss 2.644, d_loss 0.163\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 22 Batch 66/390 d_loss_real= 0.129, d_loss_fake= 0.078, g_loss 2.744, d_loss 0.103\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 22 Batch 67/390 d_loss_real= 0.256, d_loss_fake= 0.072, g_loss 2.665, d_loss 0.164\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 22 Batch 68/390 d_loss_real= 0.364, d_loss_fake= 0.083, g_loss 2.510, d_loss 0.224\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 22 Batch 69/390 d_loss_real= 0.220, d_loss_fake= 0.112, g_loss 2.282, d_loss 0.166\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 70/390 d_loss_real= 0.346, d_loss_fake= 0.141, g_loss 2.131, d_loss 0.243\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 71/390 d_loss_real= 0.196, d_loss_fake= 0.200, g_loss 2.186, d_loss 0.198\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 72/390 d_loss_real= 0.173, d_loss_fake= 0.105, g_loss 2.550, d_loss 0.139\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22 Batch 73/390 d_loss_real= 0.244, d_loss_fake= 0.084, g_loss 2.644, d_loss 0.164\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 22 Batch 74/390 d_loss_real= 0.114, d_loss_fake= 0.077, g_loss 2.710, d_loss 0.095\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 75/390 d_loss_real= 0.302, d_loss_fake= 0.079, g_loss 2.598, d_loss 0.191\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 22 Batch 76/390 d_loss_real= 0.271, d_loss_fake= 0.103, g_loss 2.367, d_loss 0.187\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 77/390 d_loss_real= 0.237, d_loss_fake= 0.154, g_loss 2.180, d_loss 0.196\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 78/390 d_loss_real= 0.182, d_loss_fake= 0.142, g_loss 2.366, d_loss 0.162\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 79/390 d_loss_real= 0.119, d_loss_fake= 0.097, g_loss 2.573, d_loss 0.108\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22 Batch 80/390 d_loss_real= 0.290, d_loss_fake= 0.076, g_loss 2.715, d_loss 0.183\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 81/390 d_loss_real= 0.171, d_loss_fake= 0.074, g_loss 2.778, d_loss 0.122\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22 Batch 82/390 d_loss_real= 0.313, d_loss_fake= 0.079, g_loss 2.655, d_loss 0.196\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 22 Batch 83/390 d_loss_real= 0.248, d_loss_fake= 0.077, g_loss 2.595, d_loss 0.162\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 84/390 d_loss_real= 0.113, d_loss_fake= 0.096, g_loss 2.570, d_loss 0.104\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 85/390 d_loss_real= 0.424, d_loss_fake= 0.091, g_loss 2.460, d_loss 0.257\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 86/390 d_loss_real= 0.218, d_loss_fake= 0.101, g_loss 2.345, d_loss 0.160\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22 Batch 87/390 d_loss_real= 0.137, d_loss_fake= 0.132, g_loss 2.365, d_loss 0.134\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 88/390 d_loss_real= 0.149, d_loss_fake= 0.110, g_loss 2.508, d_loss 0.129\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 22 Batch 89/390 d_loss_real= 0.228, d_loss_fake= 0.082, g_loss 2.636, d_loss 0.155\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 90/390 d_loss_real= 0.165, d_loss_fake= 0.091, g_loss 2.561, d_loss 0.128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 91/390 d_loss_real= 0.381, d_loss_fake= 0.094, g_loss 2.502, d_loss 0.237\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 22 Batch 92/390 d_loss_real= 0.288, d_loss_fake= 0.106, g_loss 2.367, d_loss 0.197\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 93/390 d_loss_real= 0.186, d_loss_fake= 0.122, g_loss 2.351, d_loss 0.154\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 22 Batch 94/390 d_loss_real= 0.161, d_loss_fake= 0.107, g_loss 2.467, d_loss 0.134\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 22 Batch 95/390 d_loss_real= 0.346, d_loss_fake= 0.095, g_loss 2.547, d_loss 0.220\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 96/390 d_loss_real= 0.247, d_loss_fake= 0.090, g_loss 2.590, d_loss 0.169\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22 Batch 97/390 d_loss_real= 0.293, d_loss_fake= 0.090, g_loss 2.516, d_loss 0.192\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 98/390 d_loss_real= 0.349, d_loss_fake= 0.095, g_loss 2.463, d_loss 0.222\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 99/390 d_loss_real= 0.205, d_loss_fake= 0.117, g_loss 2.326, d_loss 0.161\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 22 Batch 100/390 d_loss_real= 0.245, d_loss_fake= 0.130, g_loss 2.317, d_loss 0.188\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 22 Batch 101/390 d_loss_real= 0.261, d_loss_fake= 0.126, g_loss 2.337, d_loss 0.194\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 22 Batch 102/390 d_loss_real= 0.294, d_loss_fake= 0.111, g_loss 2.383, d_loss 0.202\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 22 Batch 103/390 d_loss_real= 0.366, d_loss_fake= 0.102, g_loss 2.373, d_loss 0.234\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 104/390 d_loss_real= 0.261, d_loss_fake= 0.108, g_loss 2.356, d_loss 0.184\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 105/390 d_loss_real= 0.063, d_loss_fake= 0.105, g_loss 2.415, d_loss 0.084\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 106/390 d_loss_real= 0.185, d_loss_fake= 0.111, g_loss 2.281, d_loss 0.148\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 22 Batch 107/390 d_loss_real= 0.238, d_loss_fake= 0.134, g_loss 2.256, d_loss 0.186\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 22 Batch 108/390 d_loss_real= 0.133, d_loss_fake= 0.122, g_loss 2.389, d_loss 0.127\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 109/390 d_loss_real= 0.180, d_loss_fake= 0.112, g_loss 2.449, d_loss 0.146\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 110/390 d_loss_real= 0.312, d_loss_fake= 0.091, g_loss 2.608, d_loss 0.201\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22 Batch 111/390 d_loss_real= 0.377, d_loss_fake= 0.083, g_loss 2.575, d_loss 0.230\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22 Batch 112/390 d_loss_real= 0.235, d_loss_fake= 0.083, g_loss 2.655, d_loss 0.159\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 113/390 d_loss_real= 0.296, d_loss_fake= 0.080, g_loss 2.569, d_loss 0.188\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 114/390 d_loss_real= 0.215, d_loss_fake= 0.087, g_loss 2.498, d_loss 0.151\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 115/390 d_loss_real= 0.306, d_loss_fake= 0.096, g_loss 2.427, d_loss 0.201\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22 Batch 116/390 d_loss_real= 0.238, d_loss_fake= 0.103, g_loss 2.330, d_loss 0.170\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 22 Batch 117/390 d_loss_real= 0.110, d_loss_fake= 0.135, g_loss 2.215, d_loss 0.122\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22 Batch 118/390 d_loss_real= 0.221, d_loss_fake= 0.128, g_loss 2.323, d_loss 0.175\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 119/390 d_loss_real= 0.350, d_loss_fake= 0.097, g_loss 2.455, d_loss 0.224\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 120/390 d_loss_real= 0.282, d_loss_fake= 0.094, g_loss 2.449, d_loss 0.188\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 121/390 d_loss_real= 0.190, d_loss_fake= 0.099, g_loss 2.352, d_loss 0.145\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 22 Batch 122/390 d_loss_real= 0.227, d_loss_fake= 0.121, g_loss 2.255, d_loss 0.174\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 22 Batch 123/390 d_loss_real= 0.214, d_loss_fake= 0.133, g_loss 2.193, d_loss 0.173\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 22 Batch 124/390 d_loss_real= 0.267, d_loss_fake= 0.158, g_loss 2.193, d_loss 0.213\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 125/390 d_loss_real= 0.214, d_loss_fake= 0.134, g_loss 2.192, d_loss 0.174\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 22 Batch 126/390 d_loss_real= 0.158, d_loss_fake= 0.136, g_loss 2.303, d_loss 0.147\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 127/390 d_loss_real= 0.091, d_loss_fake= 0.101, g_loss 2.500, d_loss 0.096\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 128/390 d_loss_real= 0.102, d_loss_fake= 0.090, g_loss 2.636, d_loss 0.096\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 22 Batch 129/390 d_loss_real= 0.324, d_loss_fake= 0.080, g_loss 2.637, d_loss 0.202\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 130/390 d_loss_real= 0.026, d_loss_fake= 0.077, g_loss 2.645, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 131/390 d_loss_real= 0.127, d_loss_fake= 0.082, g_loss 2.634, d_loss 0.104\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22 Batch 132/390 d_loss_real= 0.333, d_loss_fake= 0.090, g_loss 2.479, d_loss 0.211\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 22 Batch 133/390 d_loss_real= 0.255, d_loss_fake= 0.114, g_loss 2.230, d_loss 0.185\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 22 Batch 134/390 d_loss_real= 0.204, d_loss_fake= 0.107, g_loss 2.272, d_loss 0.156\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 135/390 d_loss_real= 0.143, d_loss_fake= 0.108, g_loss 2.386, d_loss 0.126\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22 Batch 136/390 d_loss_real= 0.074, d_loss_fake= 0.112, g_loss 2.561, d_loss 0.093\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 22 Batch 137/390 d_loss_real= 0.136, d_loss_fake= 0.079, g_loss 2.760, d_loss 0.108\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 22 Batch 138/390 d_loss_real= 0.198, d_loss_fake= 0.070, g_loss 2.911, d_loss 0.134\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 22 Batch 139/390 d_loss_real= 0.156, d_loss_fake= 0.060, g_loss 3.089, d_loss 0.108\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 140/390 d_loss_real= 0.233, d_loss_fake= 0.060, g_loss 2.970, d_loss 0.147\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 22 Batch 141/390 d_loss_real= 0.149, d_loss_fake= 0.062, g_loss 2.800, d_loss 0.105\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 142/390 d_loss_real= 0.253, d_loss_fake= 0.075, g_loss 2.618, d_loss 0.164\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 22 Batch 143/390 d_loss_real= 0.168, d_loss_fake= 0.082, g_loss 2.629, d_loss 0.125\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 22 Batch 144/390 d_loss_real= 0.210, d_loss_fake= 0.077, g_loss 2.644, d_loss 0.144\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 22 Batch 145/390 d_loss_real= 0.170, d_loss_fake= 0.109, g_loss 2.459, d_loss 0.139\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 22 Batch 146/390 d_loss_real= 0.351, d_loss_fake= 0.124, g_loss 2.403, d_loss 0.237\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 147/390 d_loss_real= 0.249, d_loss_fake= 0.104, g_loss 2.552, d_loss 0.177\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 148/390 d_loss_real= 0.270, d_loss_fake= 0.091, g_loss 2.666, d_loss 0.180\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22 Batch 149/390 d_loss_real= 0.289, d_loss_fake= 0.072, g_loss 2.839, d_loss 0.181\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 22 Batch 150/390 d_loss_real= 0.319, d_loss_fake= 0.067, g_loss 2.733, d_loss 0.193\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 151/390 d_loss_real= 0.222, d_loss_fake= 0.084, g_loss 2.548, d_loss 0.153\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 152/390 d_loss_real= 0.278, d_loss_fake= 0.110, g_loss 2.295, d_loss 0.194\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 22 Batch 153/390 d_loss_real= 0.162, d_loss_fake= 0.127, g_loss 2.281, d_loss 0.145\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22 Batch 154/390 d_loss_real= 0.219, d_loss_fake= 0.105, g_loss 2.446, d_loss 0.162\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 155/390 d_loss_real= 0.104, d_loss_fake= 0.094, g_loss 2.604, d_loss 0.099\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 156/390 d_loss_real= 0.192, d_loss_fake= 0.089, g_loss 2.625, d_loss 0.141\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 22 Batch 157/390 d_loss_real= 0.155, d_loss_fake= 0.088, g_loss 2.586, d_loss 0.121\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 158/390 d_loss_real= 0.306, d_loss_fake= 0.095, g_loss 2.507, d_loss 0.200\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 159/390 d_loss_real= 0.229, d_loss_fake= 0.106, g_loss 2.429, d_loss 0.167\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 160/390 d_loss_real= 0.153, d_loss_fake= 0.101, g_loss 2.445, d_loss 0.127\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 161/390 d_loss_real= 0.274, d_loss_fake= 0.107, g_loss 2.393, d_loss 0.191\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 22 Batch 162/390 d_loss_real= 0.080, d_loss_fake= 0.108, g_loss 2.478, d_loss 0.094\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22 Batch 163/390 d_loss_real= 0.358, d_loss_fake= 0.094, g_loss 2.513, d_loss 0.226\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 164/390 d_loss_real= 0.255, d_loss_fake= 0.094, g_loss 2.518, d_loss 0.174\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 165/390 d_loss_real= 0.221, d_loss_fake= 0.093, g_loss 2.507, d_loss 0.157\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 166/390 d_loss_real= 0.113, d_loss_fake= 0.092, g_loss 2.563, d_loss 0.103\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 22 Batch 167/390 d_loss_real= 0.292, d_loss_fake= 0.089, g_loss 2.584, d_loss 0.190\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22 Batch 168/390 d_loss_real= 0.250, d_loss_fake= 0.087, g_loss 2.581, d_loss 0.169\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 169/390 d_loss_real= 0.273, d_loss_fake= 0.099, g_loss 2.543, d_loss 0.186\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 170/390 d_loss_real= 0.328, d_loss_fake= 0.103, g_loss 2.381, d_loss 0.215\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 171/390 d_loss_real= 0.224, d_loss_fake= 0.122, g_loss 2.241, d_loss 0.173\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 172/390 d_loss_real= 0.261, d_loss_fake= 0.146, g_loss 2.175, d_loss 0.204\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 22 Batch 173/390 d_loss_real= 0.360, d_loss_fake= 0.161, g_loss 2.104, d_loss 0.261\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 174/390 d_loss_real= 0.127, d_loss_fake= 0.138, g_loss 2.406, d_loss 0.132\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 22 Batch 175/390 d_loss_real= 0.243, d_loss_fake= 0.098, g_loss 2.553, d_loss 0.170\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 176/390 d_loss_real= 0.213, d_loss_fake= 0.091, g_loss 2.575, d_loss 0.152\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22 Batch 177/390 d_loss_real= 0.245, d_loss_fake= 0.089, g_loss 2.508, d_loss 0.167\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 178/390 d_loss_real= 0.254, d_loss_fake= 0.098, g_loss 2.388, d_loss 0.176\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 179/390 d_loss_real= 0.259, d_loss_fake= 0.111, g_loss 2.244, d_loss 0.185\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 180/390 d_loss_real= 0.229, d_loss_fake= 0.131, g_loss 2.157, d_loss 0.180\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 22 Batch 181/390 d_loss_real= 0.108, d_loss_fake= 0.142, g_loss 2.216, d_loss 0.125\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 182/390 d_loss_real= 0.103, d_loss_fake= 0.115, g_loss 2.365, d_loss 0.109\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 183/390 d_loss_real= 0.154, d_loss_fake= 0.096, g_loss 2.533, d_loss 0.125\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 184/390 d_loss_real= 0.116, d_loss_fake= 0.083, g_loss 2.627, d_loss 0.099\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 22 Batch 185/390 d_loss_real= 0.286, d_loss_fake= 0.084, g_loss 2.619, d_loss 0.185\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 186/390 d_loss_real= 0.093, d_loss_fake= 0.087, g_loss 2.559, d_loss 0.090\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 187/390 d_loss_real= 0.374, d_loss_fake= 0.094, g_loss 2.431, d_loss 0.234\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 188/390 d_loss_real= 0.292, d_loss_fake= 0.110, g_loss 2.199, d_loss 0.201\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 22 Batch 189/390 d_loss_real= 0.245, d_loss_fake= 0.159, g_loss 1.978, d_loss 0.202\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 190/390 d_loss_real= 0.174, d_loss_fake= 0.185, g_loss 1.952, d_loss 0.180\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22 Batch 191/390 d_loss_real= 0.260, d_loss_fake= 0.149, g_loss 2.157, d_loss 0.204\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 192/390 d_loss_real= 0.118, d_loss_fake= 0.109, g_loss 2.491, d_loss 0.113\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 193/390 d_loss_real= 0.261, d_loss_fake= 0.094, g_loss 2.588, d_loss 0.177\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 22 Batch 194/390 d_loss_real= 0.163, d_loss_fake= 0.079, g_loss 2.676, d_loss 0.121\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 195/390 d_loss_real= 0.168, d_loss_fake= 0.078, g_loss 2.683, d_loss 0.123\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 22 Batch 196/390 d_loss_real= 0.176, d_loss_fake= 0.076, g_loss 2.665, d_loss 0.126\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 197/390 d_loss_real= 0.197, d_loss_fake= 0.078, g_loss 2.597, d_loss 0.138\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 198/390 d_loss_real= 0.395, d_loss_fake= 0.097, g_loss 2.321, d_loss 0.246\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22 Batch 199/390 d_loss_real= 0.241, d_loss_fake= 0.137, g_loss 1.917, d_loss 0.189\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 200/390 d_loss_real= 0.370, d_loss_fake= 0.300, g_loss 2.061, d_loss 0.335\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 201/390 d_loss_real= 0.332, d_loss_fake= 0.121, g_loss 2.609, d_loss 0.226\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 202/390 d_loss_real= 0.173, d_loss_fake= 0.068, g_loss 2.908, d_loss 0.120\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 203/390 d_loss_real= 0.377, d_loss_fake= 0.062, g_loss 2.849, d_loss 0.219\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 204/390 d_loss_real= 0.328, d_loss_fake= 0.068, g_loss 2.659, d_loss 0.198\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 22 Batch 205/390 d_loss_real= 0.187, d_loss_fake= 0.088, g_loss 2.405, d_loss 0.138\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 206/390 d_loss_real= 0.127, d_loss_fake= 0.124, g_loss 2.241, d_loss 0.126\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 22 Batch 207/390 d_loss_real= 0.140, d_loss_fake= 0.132, g_loss 2.286, d_loss 0.136\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 22 Batch 208/390 d_loss_real= 0.262, d_loss_fake= 0.111, g_loss 2.448, d_loss 0.187\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 22 Batch 209/390 d_loss_real= 0.144, d_loss_fake= 0.088, g_loss 2.621, d_loss 0.116\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 22 Batch 210/390 d_loss_real= 0.242, d_loss_fake= 0.084, g_loss 2.663, d_loss 0.163\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 22 Batch 211/390 d_loss_real= 0.359, d_loss_fake= 0.086, g_loss 2.600, d_loss 0.222\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 22 Batch 212/390 d_loss_real= 0.153, d_loss_fake= 0.098, g_loss 2.567, d_loss 0.125\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 22 Batch 213/390 d_loss_real= 0.198, d_loss_fake= 0.085, g_loss 2.502, d_loss 0.141\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "Epoch 22 Batch 214/390 d_loss_real= 0.201, d_loss_fake= 0.096, g_loss 2.487, d_loss 0.148\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 22 Batch 215/390 d_loss_real= 0.316, d_loss_fake= 0.096, g_loss 2.566, d_loss 0.206\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 22 Batch 216/390 d_loss_real= 0.224, d_loss_fake= 0.082, g_loss 2.715, d_loss 0.153\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 22 Batch 217/390 d_loss_real= 0.215, d_loss_fake= 0.076, g_loss 2.658, d_loss 0.146\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 22 Batch 218/390 d_loss_real= 0.138, d_loss_fake= 0.087, g_loss 2.593, d_loss 0.112\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 22 Batch 219/390 d_loss_real= 0.215, d_loss_fake= 0.081, g_loss 2.696, d_loss 0.148\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 220/390 d_loss_real= 0.490, d_loss_fake= 0.093, g_loss 2.540, d_loss 0.291\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 22 Batch 221/390 d_loss_real= 0.123, d_loss_fake= 0.093, g_loss 2.464, d_loss 0.108\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 22 Batch 222/390 d_loss_real= 0.132, d_loss_fake= 0.103, g_loss 2.518, d_loss 0.118\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 22 Batch 223/390 d_loss_real= 0.110, d_loss_fake= 0.092, g_loss 2.541, d_loss 0.101\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 224/390 d_loss_real= 0.405, d_loss_fake= 0.083, g_loss 2.618, d_loss 0.244\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 22 Batch 225/390 d_loss_real= 0.164, d_loss_fake= 0.091, g_loss 2.544, d_loss 0.128\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 22 Batch 226/390 d_loss_real= 0.118, d_loss_fake= 0.087, g_loss 2.577, d_loss 0.102\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 22 Batch 227/390 d_loss_real= 0.158, d_loss_fake= 0.106, g_loss 2.450, d_loss 0.132\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 22 Batch 228/390 d_loss_real= 0.239, d_loss_fake= 0.097, g_loss 2.489, d_loss 0.168\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 22 Batch 229/390 d_loss_real= 0.297, d_loss_fake= 0.101, g_loss 2.532, d_loss 0.199\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 22 Batch 230/390 d_loss_real= 0.084, d_loss_fake= 0.096, g_loss 2.535, d_loss 0.090\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 231/390 d_loss_real= 0.377, d_loss_fake= 0.093, g_loss 2.521, d_loss 0.235\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 22 Batch 232/390 d_loss_real= 0.344, d_loss_fake= 0.085, g_loss 2.591, d_loss 0.215\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22 Batch 233/390 d_loss_real= 0.177, d_loss_fake= 0.105, g_loss 2.468, d_loss 0.141\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 22 Batch 234/390 d_loss_real= 0.245, d_loss_fake= 0.096, g_loss 2.452, d_loss 0.171\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 235/390 d_loss_real= 0.173, d_loss_fake= 0.118, g_loss 2.421, d_loss 0.146\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 236/390 d_loss_real= 0.174, d_loss_fake= 0.106, g_loss 2.491, d_loss 0.140\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 237/390 d_loss_real= 0.282, d_loss_fake= 0.092, g_loss 2.509, d_loss 0.187\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 238/390 d_loss_real= 0.206, d_loss_fake= 0.094, g_loss 2.466, d_loss 0.150\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 22 Batch 239/390 d_loss_real= 0.168, d_loss_fake= 0.091, g_loss 2.493, d_loss 0.130\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 240/390 d_loss_real= 0.242, d_loss_fake= 0.101, g_loss 2.529, d_loss 0.171\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 22 Batch 241/390 d_loss_real= 0.197, d_loss_fake= 0.094, g_loss 2.553, d_loss 0.145\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 22 Batch 242/390 d_loss_real= 0.240, d_loss_fake= 0.084, g_loss 2.585, d_loss 0.162\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 243/390 d_loss_real= 0.121, d_loss_fake= 0.087, g_loss 2.584, d_loss 0.104\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 244/390 d_loss_real= 0.325, d_loss_fake= 0.089, g_loss 2.612, d_loss 0.207\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 22 Batch 245/390 d_loss_real= 0.157, d_loss_fake= 0.082, g_loss 2.619, d_loss 0.119\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22 Batch 246/390 d_loss_real= 0.238, d_loss_fake= 0.085, g_loss 2.576, d_loss 0.161\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 247/390 d_loss_real= 0.169, d_loss_fake= 0.085, g_loss 2.577, d_loss 0.127\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 248/390 d_loss_real= 0.293, d_loss_fake= 0.087, g_loss 2.419, d_loss 0.190\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 22 Batch 249/390 d_loss_real= 0.191, d_loss_fake= 0.121, g_loss 2.401, d_loss 0.156\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "Epoch 22 Batch 250/390 d_loss_real= 0.308, d_loss_fake= 0.101, g_loss 2.376, d_loss 0.204\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 22 Batch 251/390 d_loss_real= 0.118, d_loss_fake= 0.121, g_loss 2.372, d_loss 0.119\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 22 Batch 252/390 d_loss_real= 0.364, d_loss_fake= 0.102, g_loss 2.449, d_loss 0.233\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 22 Batch 253/390 d_loss_real= 0.124, d_loss_fake= 0.095, g_loss 2.560, d_loss 0.109\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 22 Batch 254/390 d_loss_real= 0.040, d_loss_fake= 0.084, g_loss 2.606, d_loss 0.062\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 22 Batch 255/390 d_loss_real= 0.295, d_loss_fake= 0.085, g_loss 2.613, d_loss 0.190\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 22 Batch 256/390 d_loss_real= 0.269, d_loss_fake= 0.087, g_loss 2.419, d_loss 0.178\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 22 Batch 257/390 d_loss_real= 0.093, d_loss_fake= 0.111, g_loss 2.335, d_loss 0.102\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 22 Batch 258/390 d_loss_real= 0.390, d_loss_fake= 0.129, g_loss 2.260, d_loss 0.259\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "Epoch 22 Batch 259/390 d_loss_real= 0.164, d_loss_fake= 0.101, g_loss 2.478, d_loss 0.133\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 22 Batch 260/390 d_loss_real= 0.218, d_loss_fake= 0.094, g_loss 2.582, d_loss 0.156\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 22 Batch 261/390 d_loss_real= 0.198, d_loss_fake= 0.081, g_loss 2.688, d_loss 0.139\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 22 Batch 262/390 d_loss_real= 0.160, d_loss_fake= 0.073, g_loss 2.715, d_loss 0.117\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 22 Batch 263/390 d_loss_real= 0.199, d_loss_fake= 0.078, g_loss 2.659, d_loss 0.138\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 22 Batch 264/390 d_loss_real= 0.166, d_loss_fake= 0.090, g_loss 2.473, d_loss 0.128\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 265/390 d_loss_real= 0.160, d_loss_fake= 0.109, g_loss 2.323, d_loss 0.134\n",
            "2/2 [==============================] - 0s 28ms/step\n",
            "Epoch 22 Batch 266/390 d_loss_real= 0.208, d_loss_fake= 0.126, g_loss 2.372, d_loss 0.167\n",
            "2/2 [==============================] - 0s 28ms/step\n",
            "Epoch 22 Batch 267/390 d_loss_real= 0.180, d_loss_fake= 0.103, g_loss 2.466, d_loss 0.141\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 22 Batch 268/390 d_loss_real= 0.058, d_loss_fake= 0.084, g_loss 2.616, d_loss 0.071\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 22 Batch 269/390 d_loss_real= 0.260, d_loss_fake= 0.079, g_loss 2.668, d_loss 0.169\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Epoch 22 Batch 270/390 d_loss_real= 0.088, d_loss_fake= 0.084, g_loss 2.614, d_loss 0.086\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 22 Batch 271/390 d_loss_real= 0.285, d_loss_fake= 0.079, g_loss 2.566, d_loss 0.182\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 22 Batch 272/390 d_loss_real= 0.117, d_loss_fake= 0.088, g_loss 2.475, d_loss 0.102\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 22 Batch 273/390 d_loss_real= 0.170, d_loss_fake= 0.095, g_loss 2.576, d_loss 0.132\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 22 Batch 274/390 d_loss_real= 0.275, d_loss_fake= 0.078, g_loss 2.619, d_loss 0.177\n",
            "2/2 [==============================] - 0s 26ms/step\n",
            "Epoch 22 Batch 275/390 d_loss_real= 0.052, d_loss_fake= 0.081, g_loss 2.753, d_loss 0.067\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 22 Batch 276/390 d_loss_real= 0.382, d_loss_fake= 0.073, g_loss 2.666, d_loss 0.228\n",
            "2/2 [==============================] - 0s 27ms/step\n",
            "Epoch 22 Batch 277/390 d_loss_real= 0.275, d_loss_fake= 0.080, g_loss 2.668, d_loss 0.178\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 22 Batch 278/390 d_loss_real= 0.154, d_loss_fake= 0.087, g_loss 2.559, d_loss 0.120\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 22 Batch 279/390 d_loss_real= 0.199, d_loss_fake= 0.094, g_loss 2.393, d_loss 0.146\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 22 Batch 280/390 d_loss_real= 0.270, d_loss_fake= 0.122, g_loss 2.380, d_loss 0.196\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 281/390 d_loss_real= 0.359, d_loss_fake= 0.116, g_loss 2.465, d_loss 0.237\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 282/390 d_loss_real= 0.193, d_loss_fake= 0.099, g_loss 2.518, d_loss 0.146\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 22 Batch 283/390 d_loss_real= 0.228, d_loss_fake= 0.087, g_loss 2.648, d_loss 0.158\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 22 Batch 284/390 d_loss_real= 0.149, d_loss_fake= 0.075, g_loss 2.724, d_loss 0.112\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 285/390 d_loss_real= 0.357, d_loss_fake= 0.072, g_loss 2.708, d_loss 0.214\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 22 Batch 286/390 d_loss_real= 0.294, d_loss_fake= 0.081, g_loss 2.572, d_loss 0.188\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 287/390 d_loss_real= 0.225, d_loss_fake= 0.099, g_loss 2.271, d_loss 0.162\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 22 Batch 288/390 d_loss_real= 0.106, d_loss_fake= 0.132, g_loss 2.235, d_loss 0.119\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 22 Batch 289/390 d_loss_real= 0.169, d_loss_fake= 0.131, g_loss 2.298, d_loss 0.150\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 22 Batch 290/390 d_loss_real= 0.251, d_loss_fake= 0.101, g_loss 2.429, d_loss 0.176\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 22 Batch 291/390 d_loss_real= 0.141, d_loss_fake= 0.090, g_loss 2.499, d_loss 0.116\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 292/390 d_loss_real= 0.085, d_loss_fake= 0.091, g_loss 2.560, d_loss 0.088\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 22 Batch 293/390 d_loss_real= 0.269, d_loss_fake= 0.095, g_loss 2.512, d_loss 0.182\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 22 Batch 294/390 d_loss_real= 0.216, d_loss_fake= 0.100, g_loss 2.520, d_loss 0.158\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 295/390 d_loss_real= 0.174, d_loss_fake= 0.097, g_loss 2.447, d_loss 0.136\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 296/390 d_loss_real= 0.196, d_loss_fake= 0.111, g_loss 2.372, d_loss 0.153\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 22 Batch 297/390 d_loss_real= 0.357, d_loss_fake= 0.115, g_loss 2.325, d_loss 0.236\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 298/390 d_loss_real= 0.104, d_loss_fake= 0.115, g_loss 2.357, d_loss 0.109\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 299/390 d_loss_real= 0.234, d_loss_fake= 0.107, g_loss 2.523, d_loss 0.170\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 22 Batch 300/390 d_loss_real= 0.230, d_loss_fake= 0.090, g_loss 2.592, d_loss 0.160\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 22 Batch 301/390 d_loss_real= 0.314, d_loss_fake= 0.098, g_loss 2.555, d_loss 0.206\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 22 Batch 302/390 d_loss_real= 0.242, d_loss_fake= 0.094, g_loss 2.540, d_loss 0.168\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 303/390 d_loss_real= 0.182, d_loss_fake= 0.096, g_loss 2.485, d_loss 0.139\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 304/390 d_loss_real= 0.260, d_loss_fake= 0.097, g_loss 2.534, d_loss 0.179\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 305/390 d_loss_real= 0.298, d_loss_fake= 0.088, g_loss 2.464, d_loss 0.193\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 306/390 d_loss_real= 0.206, d_loss_fake= 0.098, g_loss 2.419, d_loss 0.152\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 307/390 d_loss_real= 0.323, d_loss_fake= 0.099, g_loss 2.413, d_loss 0.211\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 22 Batch 308/390 d_loss_real= 0.175, d_loss_fake= 0.097, g_loss 2.483, d_loss 0.136\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 309/390 d_loss_real= 0.230, d_loss_fake= 0.099, g_loss 2.477, d_loss 0.165\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 310/390 d_loss_real= 0.245, d_loss_fake= 0.095, g_loss 2.365, d_loss 0.170\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 311/390 d_loss_real= 0.363, d_loss_fake= 0.115, g_loss 2.317, d_loss 0.239\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22 Batch 312/390 d_loss_real= 0.143, d_loss_fake= 0.124, g_loss 2.258, d_loss 0.134\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 22 Batch 313/390 d_loss_real= 0.323, d_loss_fake= 0.119, g_loss 2.297, d_loss 0.221\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 22 Batch 314/390 d_loss_real= 0.129, d_loss_fake= 0.140, g_loss 2.353, d_loss 0.134\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 315/390 d_loss_real= 0.267, d_loss_fake= 0.104, g_loss 2.444, d_loss 0.186\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 316/390 d_loss_real= 0.364, d_loss_fake= 0.100, g_loss 2.535, d_loss 0.232\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 317/390 d_loss_real= 0.190, d_loss_fake= 0.084, g_loss 2.647, d_loss 0.137\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 318/390 d_loss_real= 0.400, d_loss_fake= 0.079, g_loss 2.652, d_loss 0.240\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 319/390 d_loss_real= 0.140, d_loss_fake= 0.088, g_loss 2.618, d_loss 0.114\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 320/390 d_loss_real= 0.270, d_loss_fake= 0.093, g_loss 2.499, d_loss 0.181\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 22 Batch 321/390 d_loss_real= 0.360, d_loss_fake= 0.117, g_loss 2.422, d_loss 0.238\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 22 Batch 322/390 d_loss_real= 0.094, d_loss_fake= 0.104, g_loss 2.547, d_loss 0.099\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 323/390 d_loss_real= 0.255, d_loss_fake= 0.078, g_loss 2.786, d_loss 0.166\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 22 Batch 324/390 d_loss_real= 0.106, d_loss_fake= 0.070, g_loss 2.837, d_loss 0.088\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22 Batch 325/390 d_loss_real= 0.141, d_loss_fake= 0.061, g_loss 2.894, d_loss 0.101\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 22 Batch 326/390 d_loss_real= 0.184, d_loss_fake= 0.064, g_loss 2.834, d_loss 0.124\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 22 Batch 327/390 d_loss_real= 0.249, d_loss_fake= 0.070, g_loss 2.724, d_loss 0.159\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 22 Batch 328/390 d_loss_real= 0.102, d_loss_fake= 0.081, g_loss 2.726, d_loss 0.091\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 329/390 d_loss_real= 0.180, d_loss_fake= 0.069, g_loss 2.785, d_loss 0.125\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 22 Batch 330/390 d_loss_real= 0.105, d_loss_fake= 0.127, g_loss 2.842, d_loss 0.116\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 331/390 d_loss_real= 0.215, d_loss_fake= 0.090, g_loss 3.118, d_loss 0.152\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 332/390 d_loss_real= 0.218, d_loss_fake= 0.061, g_loss 3.223, d_loss 0.139\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 333/390 d_loss_real= 0.507, d_loss_fake= 0.083, g_loss 2.728, d_loss 0.295\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 334/390 d_loss_real= 0.385, d_loss_fake= 0.102, g_loss 2.418, d_loss 0.243\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 335/390 d_loss_real= 0.304, d_loss_fake= 0.119, g_loss 2.256, d_loss 0.211\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 336/390 d_loss_real= 0.209, d_loss_fake= 0.138, g_loss 2.153, d_loss 0.174\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 337/390 d_loss_real= 0.365, d_loss_fake= 0.164, g_loss 2.022, d_loss 0.264\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 338/390 d_loss_real= 0.087, d_loss_fake= 0.252, g_loss 2.042, d_loss 0.169\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 339/390 d_loss_real= 0.105, d_loss_fake= 0.181, g_loss 2.547, d_loss 0.143\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 340/390 d_loss_real= 0.309, d_loss_fake= 0.101, g_loss 3.008, d_loss 0.205\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 341/390 d_loss_real= 0.370, d_loss_fake= 0.059, g_loss 3.121, d_loss 0.215\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 342/390 d_loss_real= 0.268, d_loss_fake= 0.049, g_loss 3.088, d_loss 0.159\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 22 Batch 343/390 d_loss_real= 0.291, d_loss_fake= 0.060, g_loss 3.065, d_loss 0.175\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 344/390 d_loss_real= 0.405, d_loss_fake= 0.073, g_loss 2.718, d_loss 0.239\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 22 Batch 345/390 d_loss_real= 0.478, d_loss_fake= 0.243, g_loss 2.605, d_loss 0.360\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22 Batch 346/390 d_loss_real= 0.251, d_loss_fake= 0.146, g_loss 2.751, d_loss 0.198\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 347/390 d_loss_real= 0.109, d_loss_fake= 0.065, g_loss 2.966, d_loss 0.087\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 348/390 d_loss_real= 0.340, d_loss_fake= 0.059, g_loss 2.945, d_loss 0.200\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 22 Batch 349/390 d_loss_real= 0.483, d_loss_fake= 0.063, g_loss 2.745, d_loss 0.273\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 22 Batch 350/390 d_loss_real= 0.312, d_loss_fake= 0.080, g_loss 2.509, d_loss 0.196\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 351/390 d_loss_real= 0.432, d_loss_fake= 0.122, g_loss 1.994, d_loss 0.277\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 352/390 d_loss_real= 0.173, d_loss_fake= 0.360, g_loss 1.789, d_loss 0.266\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 353/390 d_loss_real= 0.023, d_loss_fake= 0.177, g_loss 2.253, d_loss 0.100\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 22 Batch 354/390 d_loss_real= 0.114, d_loss_fake= 0.099, g_loss 2.575, d_loss 0.107\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 22 Batch 355/390 d_loss_real= 0.256, d_loss_fake= 0.073, g_loss 2.811, d_loss 0.164\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 356/390 d_loss_real= 0.227, d_loss_fake= 0.068, g_loss 2.889, d_loss 0.147\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 22 Batch 357/390 d_loss_real= 0.297, d_loss_fake= 0.064, g_loss 2.858, d_loss 0.180\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 358/390 d_loss_real= 0.209, d_loss_fake= 0.067, g_loss 2.781, d_loss 0.138\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 359/390 d_loss_real= 0.283, d_loss_fake= 0.075, g_loss 2.552, d_loss 0.179\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 22 Batch 360/390 d_loss_real= 0.253, d_loss_fake= 0.213, g_loss 2.541, d_loss 0.233\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 361/390 d_loss_real= 0.157, d_loss_fake= 0.093, g_loss 3.092, d_loss 0.125\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 22 Batch 362/390 d_loss_real= 0.281, d_loss_fake= 0.046, g_loss 3.322, d_loss 0.164\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 363/390 d_loss_real= 0.225, d_loss_fake= 0.044, g_loss 3.370, d_loss 0.134\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 22 Batch 364/390 d_loss_real= 0.246, d_loss_fake= 0.043, g_loss 3.290, d_loss 0.144\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 22 Batch 365/390 d_loss_real= 0.164, d_loss_fake= 0.049, g_loss 2.976, d_loss 0.107\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 366/390 d_loss_real= 0.138, d_loss_fake= 0.082, g_loss 2.669, d_loss 0.110\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 367/390 d_loss_real= 0.155, d_loss_fake= 0.133, g_loss 2.750, d_loss 0.144\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 22 Batch 368/390 d_loss_real= 0.085, d_loss_fake= 0.054, g_loss 3.221, d_loss 0.070\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 369/390 d_loss_real= 0.111, d_loss_fake= 0.042, g_loss 3.381, d_loss 0.077\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 370/390 d_loss_real= 0.335, d_loss_fake= 0.042, g_loss 3.177, d_loss 0.189\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 22 Batch 371/390 d_loss_real= 0.306, d_loss_fake= 0.063, g_loss 2.725, d_loss 0.185\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22 Batch 372/390 d_loss_real= 0.089, d_loss_fake= 0.137, g_loss 2.563, d_loss 0.113\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 373/390 d_loss_real= 0.119, d_loss_fake= 0.118, g_loss 2.908, d_loss 0.118\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 22 Batch 374/390 d_loss_real= 0.305, d_loss_fake= 0.068, g_loss 3.113, d_loss 0.186\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 22 Batch 375/390 d_loss_real= 0.269, d_loss_fake= 0.060, g_loss 3.056, d_loss 0.165\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 22 Batch 376/390 d_loss_real= 0.344, d_loss_fake= 0.060, g_loss 2.849, d_loss 0.202\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 377/390 d_loss_real= 0.205, d_loss_fake= 0.077, g_loss 2.654, d_loss 0.141\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 22 Batch 378/390 d_loss_real= 0.239, d_loss_fake= 0.112, g_loss 2.380, d_loss 0.175\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 22 Batch 379/390 d_loss_real= 0.166, d_loss_fake= 0.142, g_loss 2.229, d_loss 0.154\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 22 Batch 380/390 d_loss_real= 0.122, d_loss_fake= 0.114, g_loss 2.332, d_loss 0.118\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 381/390 d_loss_real= 0.092, d_loss_fake= 0.092, g_loss 2.592, d_loss 0.092\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 22 Batch 382/390 d_loss_real= 0.189, d_loss_fake= 0.081, g_loss 2.598, d_loss 0.135\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 22 Batch 383/390 d_loss_real= 0.178, d_loss_fake= 0.089, g_loss 2.632, d_loss 0.133\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22 Batch 384/390 d_loss_real= 0.547, d_loss_fake= 0.098, g_loss 2.517, d_loss 0.322\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 22 Batch 385/390 d_loss_real= 0.317, d_loss_fake= 0.108, g_loss 2.348, d_loss 0.213\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 386/390 d_loss_real= 0.403, d_loss_fake= 0.155, g_loss 2.144, d_loss 0.279\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 387/390 d_loss_real= 0.228, d_loss_fake= 0.152, g_loss 2.208, d_loss 0.190\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22 Batch 388/390 d_loss_real= 0.199, d_loss_fake= 0.124, g_loss 2.279, d_loss 0.162\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22 Batch 389/390 d_loss_real= 0.272, d_loss_fake= 0.110, g_loss 2.392, d_loss 0.191\n",
            "2/2 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22 Batch 390/390 d_loss_real= 0.127, d_loss_fake= 0.124, g_loss 2.304, d_loss 0.125\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 23 Batch 1/390 d_loss_real= 0.102, d_loss_fake= 0.107, g_loss 2.490, d_loss 0.105\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 2/390 d_loss_real= 0.121, d_loss_fake= 0.090, g_loss 2.588, d_loss 0.105\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 3/390 d_loss_real= 0.352, d_loss_fake= 0.090, g_loss 2.539, d_loss 0.221\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 4/390 d_loss_real= 0.315, d_loss_fake= 0.083, g_loss 2.612, d_loss 0.199\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 23 Batch 5/390 d_loss_real= 0.216, d_loss_fake= 0.092, g_loss 2.443, d_loss 0.154\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 23 Batch 6/390 d_loss_real= 0.180, d_loss_fake= 0.108, g_loss 2.283, d_loss 0.144\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 7/390 d_loss_real= 0.124, d_loss_fake= 0.116, g_loss 2.248, d_loss 0.120\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 8/390 d_loss_real= 0.134, d_loss_fake= 0.134, g_loss 2.320, d_loss 0.134\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 23 Batch 9/390 d_loss_real= 0.054, d_loss_fake= 0.105, g_loss 2.537, d_loss 0.079\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 23 Batch 10/390 d_loss_real= 0.237, d_loss_fake= 0.091, g_loss 2.688, d_loss 0.164\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 11/390 d_loss_real= 0.228, d_loss_fake= 0.080, g_loss 2.615, d_loss 0.154\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 12/390 d_loss_real= 0.300, d_loss_fake= 0.092, g_loss 2.502, d_loss 0.196\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 13/390 d_loss_real= 0.233, d_loss_fake= 0.097, g_loss 2.400, d_loss 0.165\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 14/390 d_loss_real= 0.104, d_loss_fake= 0.120, g_loss 2.430, d_loss 0.112\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 23 Batch 15/390 d_loss_real= 0.293, d_loss_fake= 0.110, g_loss 2.419, d_loss 0.202\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 16/390 d_loss_real= 0.345, d_loss_fake= 0.102, g_loss 2.434, d_loss 0.223\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 23 Batch 17/390 d_loss_real= 0.135, d_loss_fake= 0.100, g_loss 2.432, d_loss 0.118\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 18/390 d_loss_real= 0.177, d_loss_fake= 0.099, g_loss 2.519, d_loss 0.138\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 19/390 d_loss_real= 0.158, d_loss_fake= 0.095, g_loss 2.621, d_loss 0.127\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 20/390 d_loss_real= 0.155, d_loss_fake= 0.085, g_loss 2.713, d_loss 0.120\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 21/390 d_loss_real= 0.289, d_loss_fake= 0.078, g_loss 2.757, d_loss 0.183\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 22/390 d_loss_real= 0.308, d_loss_fake= 0.075, g_loss 2.710, d_loss 0.191\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 23/390 d_loss_real= 0.190, d_loss_fake= 0.077, g_loss 2.605, d_loss 0.134\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 24/390 d_loss_real= 0.106, d_loss_fake= 0.088, g_loss 2.509, d_loss 0.097\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 25/390 d_loss_real= 0.189, d_loss_fake= 0.105, g_loss 2.344, d_loss 0.147\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 23 Batch 26/390 d_loss_real= 0.307, d_loss_fake= 0.141, g_loss 2.220, d_loss 0.224\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 27/390 d_loss_real= 0.216, d_loss_fake= 0.136, g_loss 2.393, d_loss 0.176\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 28/390 d_loss_real= 0.154, d_loss_fake= 0.097, g_loss 2.559, d_loss 0.126\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 29/390 d_loss_real= 0.123, d_loss_fake= 0.081, g_loss 2.633, d_loss 0.102\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 23 Batch 30/390 d_loss_real= 0.452, d_loss_fake= 0.081, g_loss 2.653, d_loss 0.266\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 31/390 d_loss_real= 0.192, d_loss_fake= 0.082, g_loss 2.562, d_loss 0.137\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 23 Batch 32/390 d_loss_real= 0.243, d_loss_fake= 0.095, g_loss 2.434, d_loss 0.169\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 23 Batch 33/390 d_loss_real= 0.276, d_loss_fake= 0.110, g_loss 2.364, d_loss 0.193\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 23 Batch 34/390 d_loss_real= 0.160, d_loss_fake= 0.110, g_loss 2.423, d_loss 0.135\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 35/390 d_loss_real= 0.088, d_loss_fake= 0.094, g_loss 2.634, d_loss 0.091\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 23 Batch 36/390 d_loss_real= 0.171, d_loss_fake= 0.067, g_loss 2.871, d_loss 0.119\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 23 Batch 37/390 d_loss_real= 0.332, d_loss_fake= 0.060, g_loss 2.824, d_loss 0.196\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 38/390 d_loss_real= 0.306, d_loss_fake= 0.065, g_loss 2.814, d_loss 0.186\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 39/390 d_loss_real= 0.212, d_loss_fake= 0.073, g_loss 2.591, d_loss 0.142\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 23 Batch 40/390 d_loss_real= 0.275, d_loss_fake= 0.100, g_loss 2.239, d_loss 0.188\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 41/390 d_loss_real= 0.147, d_loss_fake= 0.158, g_loss 2.208, d_loss 0.153\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 23 Batch 42/390 d_loss_real= 0.072, d_loss_fake= 0.115, g_loss 2.666, d_loss 0.094\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 43/390 d_loss_real= 0.134, d_loss_fake= 0.060, g_loss 3.086, d_loss 0.097\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 23 Batch 44/390 d_loss_real= 0.022, d_loss_fake= 0.047, g_loss 3.264, d_loss 0.034\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 23 Batch 45/390 d_loss_real= 0.371, d_loss_fake= 0.045, g_loss 3.250, d_loss 0.208\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 23 Batch 46/390 d_loss_real= 0.139, d_loss_fake= 0.045, g_loss 3.144, d_loss 0.092\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 47/390 d_loss_real= 0.168, d_loss_fake= 0.049, g_loss 2.996, d_loss 0.109\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 48/390 d_loss_real= 0.211, d_loss_fake= 0.062, g_loss 2.708, d_loss 0.136\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 49/390 d_loss_real= 0.259, d_loss_fake= 0.091, g_loss 2.435, d_loss 0.175\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 50/390 d_loss_real= 0.186, d_loss_fake= 0.202, g_loss 2.141, d_loss 0.194\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 23 Batch 51/390 d_loss_real= 0.088, d_loss_fake= 0.175, g_loss 2.374, d_loss 0.131\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 52/390 d_loss_real= 0.119, d_loss_fake= 0.090, g_loss 2.873, d_loss 0.104\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 23 Batch 53/390 d_loss_real= 0.259, d_loss_fake= 0.061, g_loss 2.985, d_loss 0.160\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 54/390 d_loss_real= 0.301, d_loss_fake= 0.054, g_loss 3.004, d_loss 0.178\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 55/390 d_loss_real= 0.408, d_loss_fake= 0.054, g_loss 2.957, d_loss 0.231\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 56/390 d_loss_real= 0.368, d_loss_fake= 0.067, g_loss 2.785, d_loss 0.217\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 57/390 d_loss_real= 0.182, d_loss_fake= 0.085, g_loss 2.499, d_loss 0.133\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 58/390 d_loss_real= 0.213, d_loss_fake= 0.105, g_loss 2.301, d_loss 0.159\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 59/390 d_loss_real= 0.280, d_loss_fake= 0.132, g_loss 2.191, d_loss 0.206\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 23 Batch 60/390 d_loss_real= 0.181, d_loss_fake= 0.230, g_loss 2.069, d_loss 0.206\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 23 Batch 61/390 d_loss_real= 0.100, d_loss_fake= 0.121, g_loss 2.487, d_loss 0.110\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 62/390 d_loss_real= 0.181, d_loss_fake= 0.085, g_loss 2.686, d_loss 0.133\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 63/390 d_loss_real= 0.076, d_loss_fake= 0.070, g_loss 2.866, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 64/390 d_loss_real= 0.213, d_loss_fake= 0.058, g_loss 2.886, d_loss 0.135\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 23 Batch 65/390 d_loss_real= 0.389, d_loss_fake= 0.067, g_loss 2.766, d_loss 0.228\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 23 Batch 66/390 d_loss_real= 0.076, d_loss_fake= 0.073, g_loss 2.638, d_loss 0.075\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 67/390 d_loss_real= 0.301, d_loss_fake= 0.099, g_loss 2.417, d_loss 0.200\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 23 Batch 68/390 d_loss_real= 0.171, d_loss_fake= 0.116, g_loss 2.252, d_loss 0.144\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 69/390 d_loss_real= 0.146, d_loss_fake= 0.149, g_loss 2.177, d_loss 0.148\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 70/390 d_loss_real= 0.176, d_loss_fake= 0.135, g_loss 2.322, d_loss 0.156\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 71/390 d_loss_real= 0.088, d_loss_fake= 0.099, g_loss 2.538, d_loss 0.094\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 23 Batch 72/390 d_loss_real= 0.200, d_loss_fake= 0.088, g_loss 2.664, d_loss 0.144\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 73/390 d_loss_real= 0.063, d_loss_fake= 0.078, g_loss 2.762, d_loss 0.071\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 74/390 d_loss_real= 0.099, d_loss_fake= 0.065, g_loss 2.838, d_loss 0.082\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 75/390 d_loss_real= 0.298, d_loss_fake= 0.067, g_loss 2.730, d_loss 0.182\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 76/390 d_loss_real= 0.275, d_loss_fake= 0.081, g_loss 2.484, d_loss 0.178\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 77/390 d_loss_real= 0.234, d_loss_fake= 0.103, g_loss 2.338, d_loss 0.168\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 23 Batch 78/390 d_loss_real= 0.201, d_loss_fake= 0.091, g_loss 2.474, d_loss 0.146\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 23 Batch 79/390 d_loss_real= 0.348, d_loss_fake= 0.167, g_loss 2.323, d_loss 0.258\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 23 Batch 80/390 d_loss_real= 0.196, d_loss_fake= 0.080, g_loss 2.866, d_loss 0.138\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 81/390 d_loss_real= 0.105, d_loss_fake= 0.055, g_loss 3.113, d_loss 0.080\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 23 Batch 82/390 d_loss_real= 0.488, d_loss_fake= 0.049, g_loss 3.016, d_loss 0.268\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 23 Batch 83/390 d_loss_real= 0.201, d_loss_fake= 0.055, g_loss 2.887, d_loss 0.128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 84/390 d_loss_real= 0.211, d_loss_fake= 0.065, g_loss 2.767, d_loss 0.138\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 85/390 d_loss_real= 0.125, d_loss_fake= 0.073, g_loss 2.620, d_loss 0.099\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 86/390 d_loss_real= 0.121, d_loss_fake= 0.086, g_loss 2.562, d_loss 0.104\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 87/390 d_loss_real= 0.205, d_loss_fake= 0.096, g_loss 2.482, d_loss 0.150\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 88/390 d_loss_real= 0.134, d_loss_fake= 0.093, g_loss 2.633, d_loss 0.113\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 89/390 d_loss_real= 0.133, d_loss_fake= 0.077, g_loss 2.704, d_loss 0.105\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 90/390 d_loss_real= 0.293, d_loss_fake= 0.070, g_loss 2.773, d_loss 0.181\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 91/390 d_loss_real= 0.210, d_loss_fake= 0.073, g_loss 2.720, d_loss 0.142\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 23 Batch 92/390 d_loss_real= 0.273, d_loss_fake= 0.081, g_loss 2.655, d_loss 0.177\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 93/390 d_loss_real= 0.222, d_loss_fake= 0.096, g_loss 2.441, d_loss 0.159\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 94/390 d_loss_real= 0.160, d_loss_fake= 0.111, g_loss 2.478, d_loss 0.136\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 95/390 d_loss_real= 0.349, d_loss_fake= 0.103, g_loss 2.463, d_loss 0.226\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 96/390 d_loss_real= 0.145, d_loss_fake= 0.091, g_loss 2.558, d_loss 0.118\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 97/390 d_loss_real= 0.261, d_loss_fake= 0.086, g_loss 2.676, d_loss 0.173\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 98/390 d_loss_real= 0.092, d_loss_fake= 0.075, g_loss 2.772, d_loss 0.084\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 99/390 d_loss_real= 0.281, d_loss_fake= 0.072, g_loss 2.665, d_loss 0.177\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 100/390 d_loss_real= 0.181, d_loss_fake= 0.081, g_loss 2.541, d_loss 0.131\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 23 Batch 101/390 d_loss_real= 0.210, d_loss_fake= 0.099, g_loss 2.382, d_loss 0.155\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 102/390 d_loss_real= 0.269, d_loss_fake= 0.127, g_loss 2.274, d_loss 0.198\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 103/390 d_loss_real= 0.201, d_loss_fake= 0.136, g_loss 2.301, d_loss 0.169\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 23 Batch 104/390 d_loss_real= 0.099, d_loss_fake= 0.108, g_loss 2.545, d_loss 0.103\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 105/390 d_loss_real= 0.065, d_loss_fake= 0.078, g_loss 2.767, d_loss 0.071\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 106/390 d_loss_real= 0.190, d_loss_fake= 0.070, g_loss 2.836, d_loss 0.130\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 23 Batch 107/390 d_loss_real= 0.126, d_loss_fake= 0.062, g_loss 2.794, d_loss 0.094\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 23 Batch 108/390 d_loss_real= 0.180, d_loss_fake= 0.067, g_loss 2.724, d_loss 0.123\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 23 Batch 109/390 d_loss_real= 0.245, d_loss_fake= 0.080, g_loss 2.559, d_loss 0.162\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 110/390 d_loss_real= 0.166, d_loss_fake= 0.097, g_loss 2.429, d_loss 0.131\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 111/390 d_loss_real= 0.271, d_loss_fake= 0.124, g_loss 2.187, d_loss 0.197\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 112/390 d_loss_real= 0.145, d_loss_fake= 0.138, g_loss 2.326, d_loss 0.141\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 113/390 d_loss_real= 0.180, d_loss_fake= 0.096, g_loss 2.612, d_loss 0.138\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 114/390 d_loss_real= 0.122, d_loss_fake= 0.077, g_loss 2.752, d_loss 0.100\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 115/390 d_loss_real= 0.195, d_loss_fake= 0.067, g_loss 2.865, d_loss 0.131\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 116/390 d_loss_real= 0.227, d_loss_fake= 0.066, g_loss 2.807, d_loss 0.147\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 117/390 d_loss_real= 0.106, d_loss_fake= 0.069, g_loss 2.751, d_loss 0.088\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 118/390 d_loss_real= 0.207, d_loss_fake= 0.072, g_loss 2.628, d_loss 0.139\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 119/390 d_loss_real= 0.285, d_loss_fake= 0.083, g_loss 2.529, d_loss 0.184\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 23 Batch 120/390 d_loss_real= 0.143, d_loss_fake= 0.102, g_loss 2.355, d_loss 0.122\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 121/390 d_loss_real= 0.117, d_loss_fake= 0.106, g_loss 2.418, d_loss 0.111\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 122/390 d_loss_real= 0.142, d_loss_fake= 0.113, g_loss 2.384, d_loss 0.128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 123/390 d_loss_real= 0.108, d_loss_fake= 0.094, g_loss 2.604, d_loss 0.101\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 124/390 d_loss_real= 0.264, d_loss_fake= 0.072, g_loss 2.758, d_loss 0.168\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 23 Batch 125/390 d_loss_real= 0.382, d_loss_fake= 0.081, g_loss 2.556, d_loss 0.232\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 126/390 d_loss_real= 0.176, d_loss_fake= 0.108, g_loss 2.445, d_loss 0.142\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 23 Batch 127/390 d_loss_real= 0.096, d_loss_fake= 0.099, g_loss 2.543, d_loss 0.098\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 23 Batch 128/390 d_loss_real= 0.192, d_loss_fake= 0.096, g_loss 2.572, d_loss 0.144\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 129/390 d_loss_real= 0.340, d_loss_fake= 0.083, g_loss 2.623, d_loss 0.212\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 23 Batch 130/390 d_loss_real= 0.172, d_loss_fake= 0.079, g_loss 2.729, d_loss 0.126\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 23 Batch 131/390 d_loss_real= 0.232, d_loss_fake= 0.076, g_loss 2.691, d_loss 0.154\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 23 Batch 132/390 d_loss_real= 0.164, d_loss_fake= 0.072, g_loss 2.729, d_loss 0.118\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 133/390 d_loss_real= 0.202, d_loss_fake= 0.075, g_loss 2.661, d_loss 0.138\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 134/390 d_loss_real= 0.062, d_loss_fake= 0.079, g_loss 2.662, d_loss 0.070\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 135/390 d_loss_real= 0.383, d_loss_fake= 0.096, g_loss 2.378, d_loss 0.240\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 23 Batch 136/390 d_loss_real= 0.260, d_loss_fake= 0.121, g_loss 2.234, d_loss 0.191\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 23 Batch 137/390 d_loss_real= 0.189, d_loss_fake= 0.133, g_loss 2.392, d_loss 0.161\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 138/390 d_loss_real= 0.133, d_loss_fake= 0.092, g_loss 2.627, d_loss 0.112\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 139/390 d_loss_real= 0.237, d_loss_fake= 0.082, g_loss 2.697, d_loss 0.160\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 23 Batch 140/390 d_loss_real= 0.118, d_loss_fake= 0.072, g_loss 2.807, d_loss 0.095\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 141/390 d_loss_real= 0.185, d_loss_fake= 0.063, g_loss 2.849, d_loss 0.124\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 142/390 d_loss_real= 0.241, d_loss_fake= 0.065, g_loss 2.769, d_loss 0.153\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 143/390 d_loss_real= 0.214, d_loss_fake= 0.076, g_loss 2.709, d_loss 0.145\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 144/390 d_loss_real= 0.223, d_loss_fake= 0.075, g_loss 2.659, d_loss 0.149\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 145/390 d_loss_real= 0.170, d_loss_fake= 0.080, g_loss 2.632, d_loss 0.125\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 23 Batch 146/390 d_loss_real= 0.147, d_loss_fake= 0.087, g_loss 2.541, d_loss 0.117\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 147/390 d_loss_real= 0.125, d_loss_fake= 0.094, g_loss 2.496, d_loss 0.110\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 23 Batch 148/390 d_loss_real= 0.226, d_loss_fake= 0.098, g_loss 2.481, d_loss 0.162\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 23 Batch 149/390 d_loss_real= 0.181, d_loss_fake= 0.087, g_loss 2.541, d_loss 0.134\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 23 Batch 150/390 d_loss_real= 0.190, d_loss_fake= 0.086, g_loss 2.539, d_loss 0.138\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 151/390 d_loss_real= 0.250, d_loss_fake= 0.087, g_loss 2.552, d_loss 0.169\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 152/390 d_loss_real= 0.315, d_loss_fake= 0.094, g_loss 2.510, d_loss 0.205\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 153/390 d_loss_real= 0.175, d_loss_fake= 0.093, g_loss 2.550, d_loss 0.134\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 154/390 d_loss_real= 0.132, d_loss_fake= 0.084, g_loss 2.553, d_loss 0.108\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 155/390 d_loss_real= 0.191, d_loss_fake= 0.083, g_loss 2.593, d_loss 0.137\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 156/390 d_loss_real= 0.217, d_loss_fake= 0.082, g_loss 2.622, d_loss 0.149\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 157/390 d_loss_real= 0.141, d_loss_fake= 0.084, g_loss 2.612, d_loss 0.113\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 23 Batch 158/390 d_loss_real= 0.152, d_loss_fake= 0.083, g_loss 2.598, d_loss 0.118\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 159/390 d_loss_real= 0.190, d_loss_fake= 0.084, g_loss 2.638, d_loss 0.137\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 160/390 d_loss_real= 0.122, d_loss_fake= 0.080, g_loss 2.655, d_loss 0.101\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 161/390 d_loss_real= 0.196, d_loss_fake= 0.079, g_loss 2.720, d_loss 0.138\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 162/390 d_loss_real= 0.157, d_loss_fake= 0.081, g_loss 2.677, d_loss 0.119\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 163/390 d_loss_real= 0.162, d_loss_fake= 0.082, g_loss 2.655, d_loss 0.122\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 164/390 d_loss_real= 0.182, d_loss_fake= 0.077, g_loss 2.690, d_loss 0.129\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 165/390 d_loss_real= 0.308, d_loss_fake= 0.069, g_loss 2.742, d_loss 0.188\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 166/390 d_loss_real= 0.214, d_loss_fake= 0.089, g_loss 2.576, d_loss 0.151\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 23 Batch 167/390 d_loss_real= 0.302, d_loss_fake= 0.098, g_loss 2.570, d_loss 0.200\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 168/390 d_loss_real= 0.206, d_loss_fake= 0.082, g_loss 2.620, d_loss 0.144\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 169/390 d_loss_real= 0.223, d_loss_fake= 0.081, g_loss 2.589, d_loss 0.152\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 170/390 d_loss_real= 0.302, d_loss_fake= 0.086, g_loss 2.427, d_loss 0.194\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 171/390 d_loss_real= 0.336, d_loss_fake= 0.136, g_loss 2.215, d_loss 0.236\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 172/390 d_loss_real= 0.367, d_loss_fake= 0.130, g_loss 2.314, d_loss 0.248\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 173/390 d_loss_real= 0.143, d_loss_fake= 0.096, g_loss 2.588, d_loss 0.119\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 174/390 d_loss_real= 0.223, d_loss_fake= 0.079, g_loss 2.657, d_loss 0.151\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 175/390 d_loss_real= 0.091, d_loss_fake= 0.074, g_loss 2.743, d_loss 0.082\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 176/390 d_loss_real= 0.293, d_loss_fake= 0.073, g_loss 2.736, d_loss 0.183\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 23 Batch 177/390 d_loss_real= 0.165, d_loss_fake= 0.072, g_loss 2.676, d_loss 0.119\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 178/390 d_loss_real= 0.284, d_loss_fake= 0.088, g_loss 2.494, d_loss 0.186\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 179/390 d_loss_real= 0.198, d_loss_fake= 0.109, g_loss 2.382, d_loss 0.153\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 180/390 d_loss_real= 0.071, d_loss_fake= 0.105, g_loss 2.369, d_loss 0.088\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 181/390 d_loss_real= 0.194, d_loss_fake= 0.096, g_loss 2.432, d_loss 0.145\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 182/390 d_loss_real= 0.105, d_loss_fake= 0.093, g_loss 2.465, d_loss 0.099\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 183/390 d_loss_real= 0.193, d_loss_fake= 0.088, g_loss 2.599, d_loss 0.140\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 184/390 d_loss_real= 0.233, d_loss_fake= 0.089, g_loss 2.583, d_loss 0.161\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 185/390 d_loss_real= 0.082, d_loss_fake= 0.086, g_loss 2.567, d_loss 0.084\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 186/390 d_loss_real= 0.087, d_loss_fake= 0.085, g_loss 2.567, d_loss 0.086\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 187/390 d_loss_real= 0.146, d_loss_fake= 0.090, g_loss 2.547, d_loss 0.118\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 188/390 d_loss_real= 0.085, d_loss_fake= 0.083, g_loss 2.661, d_loss 0.084\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 189/390 d_loss_real= 0.214, d_loss_fake= 0.077, g_loss 2.709, d_loss 0.145\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 190/390 d_loss_real= 0.125, d_loss_fake= 0.072, g_loss 2.736, d_loss 0.099\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 191/390 d_loss_real= 0.170, d_loss_fake= 0.072, g_loss 2.737, d_loss 0.121\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 192/390 d_loss_real= 0.162, d_loss_fake= 0.067, g_loss 2.745, d_loss 0.115\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 193/390 d_loss_real= 0.128, d_loss_fake= 0.067, g_loss 2.732, d_loss 0.097\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 23 Batch 194/390 d_loss_real= 0.185, d_loss_fake= 0.090, g_loss 2.526, d_loss 0.137\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 195/390 d_loss_real= 0.175, d_loss_fake= 0.124, g_loss 2.520, d_loss 0.149\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 196/390 d_loss_real= 0.137, d_loss_fake= 0.092, g_loss 2.689, d_loss 0.114\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 23 Batch 197/390 d_loss_real= 0.163, d_loss_fake= 0.068, g_loss 2.923, d_loss 0.116\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 198/390 d_loss_real= 0.119, d_loss_fake= 0.057, g_loss 2.989, d_loss 0.088\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 23 Batch 199/390 d_loss_real= 0.368, d_loss_fake= 0.059, g_loss 2.874, d_loss 0.213\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 23 Batch 200/390 d_loss_real= 0.339, d_loss_fake= 0.067, g_loss 2.753, d_loss 0.203\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 201/390 d_loss_real= 0.284, d_loss_fake= 0.097, g_loss 2.498, d_loss 0.191\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 23 Batch 202/390 d_loss_real= 0.199, d_loss_fake= 0.123, g_loss 2.484, d_loss 0.161\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 203/390 d_loss_real= 0.096, d_loss_fake= 0.088, g_loss 2.683, d_loss 0.092\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 204/390 d_loss_real= 0.196, d_loss_fake= 0.072, g_loss 2.770, d_loss 0.134\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 23 Batch 205/390 d_loss_real= 0.263, d_loss_fake= 0.073, g_loss 2.783, d_loss 0.168\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 23 Batch 206/390 d_loss_real= 0.266, d_loss_fake= 0.072, g_loss 2.649, d_loss 0.169\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 207/390 d_loss_real= 0.226, d_loss_fake= 0.089, g_loss 2.417, d_loss 0.157\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 208/390 d_loss_real= 0.207, d_loss_fake= 0.113, g_loss 2.333, d_loss 0.160\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 209/390 d_loss_real= 0.206, d_loss_fake= 0.124, g_loss 2.330, d_loss 0.165\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 210/390 d_loss_real= 0.162, d_loss_fake= 0.109, g_loss 2.483, d_loss 0.136\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 23 Batch 211/390 d_loss_real= 0.199, d_loss_fake= 0.096, g_loss 2.590, d_loss 0.148\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 212/390 d_loss_real= 0.145, d_loss_fake= 0.084, g_loss 2.646, d_loss 0.114\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 213/390 d_loss_real= 0.165, d_loss_fake= 0.081, g_loss 2.634, d_loss 0.123\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 214/390 d_loss_real= 0.153, d_loss_fake= 0.079, g_loss 2.619, d_loss 0.116\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 215/390 d_loss_real= 0.154, d_loss_fake= 0.081, g_loss 2.601, d_loss 0.117\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 216/390 d_loss_real= 0.086, d_loss_fake= 0.087, g_loss 2.585, d_loss 0.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 217/390 d_loss_real= 0.176, d_loss_fake= 0.089, g_loss 2.507, d_loss 0.133\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 23 Batch 218/390 d_loss_real= 0.184, d_loss_fake= 0.101, g_loss 2.496, d_loss 0.143\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 23 Batch 219/390 d_loss_real= 0.235, d_loss_fake= 0.099, g_loss 2.447, d_loss 0.167\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 220/390 d_loss_real= 0.156, d_loss_fake= 0.102, g_loss 2.540, d_loss 0.129\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 221/390 d_loss_real= 0.108, d_loss_fake= 0.091, g_loss 2.677, d_loss 0.099\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 222/390 d_loss_real= 0.272, d_loss_fake= 0.074, g_loss 2.742, d_loss 0.173\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 23 Batch 223/390 d_loss_real= 0.292, d_loss_fake= 0.074, g_loss 2.708, d_loss 0.183\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 224/390 d_loss_real= 0.228, d_loss_fake= 0.074, g_loss 2.706, d_loss 0.151\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 23 Batch 225/390 d_loss_real= 0.237, d_loss_fake= 0.082, g_loss 2.566, d_loss 0.160\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 226/390 d_loss_real= 0.223, d_loss_fake= 0.083, g_loss 2.583, d_loss 0.153\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 23 Batch 227/390 d_loss_real= 0.181, d_loss_fake= 0.094, g_loss 2.640, d_loss 0.138\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 228/390 d_loss_real= 0.102, d_loss_fake= 0.083, g_loss 2.705, d_loss 0.092\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 229/390 d_loss_real= 0.126, d_loss_fake= 0.070, g_loss 2.785, d_loss 0.098\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 230/390 d_loss_real= 0.230, d_loss_fake= 0.064, g_loss 2.792, d_loss 0.147\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 23 Batch 231/390 d_loss_real= 0.364, d_loss_fake= 0.075, g_loss 2.539, d_loss 0.220\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 23 Batch 232/390 d_loss_real= 0.175, d_loss_fake= 0.122, g_loss 2.370, d_loss 0.149\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 233/390 d_loss_real= 0.085, d_loss_fake= 0.093, g_loss 2.563, d_loss 0.089\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 234/390 d_loss_real= 0.135, d_loss_fake= 0.089, g_loss 2.766, d_loss 0.112\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 23 Batch 235/390 d_loss_real= 0.086, d_loss_fake= 0.071, g_loss 2.836, d_loss 0.078\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 23 Batch 236/390 d_loss_real= 0.302, d_loss_fake= 0.064, g_loss 2.903, d_loss 0.183\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 23 Batch 237/390 d_loss_real= 0.162, d_loss_fake= 0.063, g_loss 2.904, d_loss 0.112\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 238/390 d_loss_real= 0.060, d_loss_fake= 0.061, g_loss 2.868, d_loss 0.060\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 23 Batch 239/390 d_loss_real= 0.382, d_loss_fake= 0.075, g_loss 2.611, d_loss 0.228\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 240/390 d_loss_real= 0.065, d_loss_fake= 0.097, g_loss 2.445, d_loss 0.081\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 23 Batch 241/390 d_loss_real= 0.342, d_loss_fake= 0.101, g_loss 2.488, d_loss 0.221\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 242/390 d_loss_real= 0.173, d_loss_fake= 0.108, g_loss 2.649, d_loss 0.141\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 23 Batch 243/390 d_loss_real= 0.312, d_loss_fake= 0.071, g_loss 2.772, d_loss 0.192\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 244/390 d_loss_real= 0.317, d_loss_fake= 0.069, g_loss 2.793, d_loss 0.193\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 23 Batch 245/390 d_loss_real= 0.150, d_loss_fake= 0.074, g_loss 2.782, d_loss 0.112\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 23 Batch 246/390 d_loss_real= 0.241, d_loss_fake= 0.073, g_loss 2.652, d_loss 0.157\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 247/390 d_loss_real= 0.231, d_loss_fake= 0.082, g_loss 2.575, d_loss 0.157\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 248/390 d_loss_real= 0.231, d_loss_fake= 0.093, g_loss 2.555, d_loss 0.162\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 249/390 d_loss_real= 0.158, d_loss_fake= 0.099, g_loss 2.428, d_loss 0.129\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 250/390 d_loss_real= 0.210, d_loss_fake= 0.102, g_loss 2.461, d_loss 0.156\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 251/390 d_loss_real= 0.189, d_loss_fake= 0.102, g_loss 2.487, d_loss 0.146\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 252/390 d_loss_real= 0.330, d_loss_fake= 0.092, g_loss 2.478, d_loss 0.211\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 23 Batch 253/390 d_loss_real= 0.094, d_loss_fake= 0.097, g_loss 2.474, d_loss 0.095\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 254/390 d_loss_real= 0.235, d_loss_fake= 0.098, g_loss 2.459, d_loss 0.166\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 23 Batch 255/390 d_loss_real= 0.164, d_loss_fake= 0.103, g_loss 2.354, d_loss 0.133\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 256/390 d_loss_real= 0.125, d_loss_fake= 0.121, g_loss 2.471, d_loss 0.123\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 257/390 d_loss_real= 0.150, d_loss_fake= 0.088, g_loss 2.652, d_loss 0.119\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 23 Batch 258/390 d_loss_real= 0.124, d_loss_fake= 0.074, g_loss 2.796, d_loss 0.099\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 23 Batch 259/390 d_loss_real= 0.193, d_loss_fake= 0.067, g_loss 2.818, d_loss 0.130\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 260/390 d_loss_real= 0.216, d_loss_fake= 0.071, g_loss 2.712, d_loss 0.144\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 261/390 d_loss_real= 0.277, d_loss_fake= 0.086, g_loss 2.479, d_loss 0.181\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 262/390 d_loss_real= 0.176, d_loss_fake= 0.114, g_loss 2.385, d_loss 0.145\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 263/390 d_loss_real= 0.099, d_loss_fake= 0.110, g_loss 2.574, d_loss 0.105\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 23 Batch 264/390 d_loss_real= 0.092, d_loss_fake= 0.090, g_loss 2.607, d_loss 0.091\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 265/390 d_loss_real= 0.135, d_loss_fake= 0.085, g_loss 2.650, d_loss 0.110\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 266/390 d_loss_real= 0.132, d_loss_fake= 0.079, g_loss 2.694, d_loss 0.105\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 267/390 d_loss_real= 0.180, d_loss_fake= 0.077, g_loss 2.639, d_loss 0.128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 268/390 d_loss_real= 0.278, d_loss_fake= 0.091, g_loss 2.452, d_loss 0.184\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 269/390 d_loss_real= 0.213, d_loss_fake= 0.133, g_loss 2.341, d_loss 0.173\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 23 Batch 270/390 d_loss_real= 0.283, d_loss_fake= 0.123, g_loss 2.458, d_loss 0.203\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 271/390 d_loss_real= 0.180, d_loss_fake= 0.084, g_loss 2.723, d_loss 0.132\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 272/390 d_loss_real= 0.224, d_loss_fake= 0.073, g_loss 2.803, d_loss 0.148\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 273/390 d_loss_real= 0.174, d_loss_fake= 0.068, g_loss 2.744, d_loss 0.121\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 274/390 d_loss_real= 0.206, d_loss_fake= 0.072, g_loss 2.752, d_loss 0.139\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 275/390 d_loss_real= 0.235, d_loss_fake= 0.067, g_loss 2.789, d_loss 0.151\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 276/390 d_loss_real= 0.301, d_loss_fake= 0.079, g_loss 2.503, d_loss 0.190\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 277/390 d_loss_real= 0.140, d_loss_fake= 0.099, g_loss 2.295, d_loss 0.119\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 278/390 d_loss_real= 0.271, d_loss_fake= 0.167, g_loss 2.261, d_loss 0.219\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 23 Batch 279/390 d_loss_real= 0.118, d_loss_fake= 0.117, g_loss 2.466, d_loss 0.117\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 280/390 d_loss_real= 0.239, d_loss_fake= 0.090, g_loss 2.671, d_loss 0.164\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 281/390 d_loss_real= 0.206, d_loss_fake= 0.074, g_loss 2.718, d_loss 0.140\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 282/390 d_loss_real= 0.195, d_loss_fake= 0.072, g_loss 2.715, d_loss 0.134\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 23 Batch 283/390 d_loss_real= 0.136, d_loss_fake= 0.070, g_loss 2.733, d_loss 0.103\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 23 Batch 284/390 d_loss_real= 0.149, d_loss_fake= 0.070, g_loss 2.722, d_loss 0.109\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 285/390 d_loss_real= 0.289, d_loss_fake= 0.072, g_loss 2.712, d_loss 0.181\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 23 Batch 286/390 d_loss_real= 0.263, d_loss_fake= 0.080, g_loss 2.536, d_loss 0.172\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 287/390 d_loss_real= 0.308, d_loss_fake= 0.116, g_loss 2.237, d_loss 0.212\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 23 Batch 288/390 d_loss_real= 0.122, d_loss_fake= 0.134, g_loss 2.136, d_loss 0.128\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 289/390 d_loss_real= 0.050, d_loss_fake= 0.124, g_loss 2.359, d_loss 0.087\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 23 Batch 290/390 d_loss_real= 0.123, d_loss_fake= 0.097, g_loss 2.529, d_loss 0.110\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 291/390 d_loss_real= 0.306, d_loss_fake= 0.081, g_loss 2.623, d_loss 0.194\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 23 Batch 292/390 d_loss_real= 0.147, d_loss_fake= 0.078, g_loss 2.671, d_loss 0.113\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 293/390 d_loss_real= 0.077, d_loss_fake= 0.076, g_loss 2.687, d_loss 0.076\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 294/390 d_loss_real= 0.227, d_loss_fake= 0.080, g_loss 2.588, d_loss 0.153\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 295/390 d_loss_real= 0.050, d_loss_fake= 0.087, g_loss 2.600, d_loss 0.068\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 23 Batch 296/390 d_loss_real= 0.156, d_loss_fake= 0.081, g_loss 2.561, d_loss 0.119\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 297/390 d_loss_real= 0.156, d_loss_fake= 0.092, g_loss 2.477, d_loss 0.124\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 298/390 d_loss_real= 0.215, d_loss_fake= 0.105, g_loss 2.451, d_loss 0.160\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 23 Batch 299/390 d_loss_real= 0.194, d_loss_fake= 0.104, g_loss 2.442, d_loss 0.149\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 300/390 d_loss_real= 0.099, d_loss_fake= 0.098, g_loss 2.558, d_loss 0.098\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 301/390 d_loss_real= 0.229, d_loss_fake= 0.090, g_loss 2.600, d_loss 0.159\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 302/390 d_loss_real= 0.214, d_loss_fake= 0.082, g_loss 2.685, d_loss 0.148\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 303/390 d_loss_real= 0.324, d_loss_fake= 0.086, g_loss 2.622, d_loss 0.205\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 23 Batch 304/390 d_loss_real= 0.083, d_loss_fake= 0.083, g_loss 2.681, d_loss 0.083\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 305/390 d_loss_real= 0.404, d_loss_fake= 0.081, g_loss 2.601, d_loss 0.243\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 306/390 d_loss_real= 0.069, d_loss_fake= 0.071, g_loss 2.841, d_loss 0.070\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 307/390 d_loss_real= 0.108, d_loss_fake= 0.063, g_loss 3.030, d_loss 0.086\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 308/390 d_loss_real= 0.045, d_loss_fake= 0.057, g_loss 3.037, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 309/390 d_loss_real= 0.551, d_loss_fake= 0.056, g_loss 2.996, d_loss 0.303\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 23 Batch 310/390 d_loss_real= 0.172, d_loss_fake= 0.064, g_loss 2.774, d_loss 0.118\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 311/390 d_loss_real= 0.257, d_loss_fake= 0.088, g_loss 2.506, d_loss 0.172\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 23 Batch 312/390 d_loss_real= 0.281, d_loss_fake= 0.108, g_loss 2.484, d_loss 0.195\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 313/390 d_loss_real= 0.127, d_loss_fake= 0.087, g_loss 2.789, d_loss 0.107\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 314/390 d_loss_real= 0.196, d_loss_fake= 0.066, g_loss 2.878, d_loss 0.131\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 23 Batch 315/390 d_loss_real= 0.237, d_loss_fake= 0.067, g_loss 2.805, d_loss 0.152\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 23 Batch 316/390 d_loss_real= 0.273, d_loss_fake= 0.075, g_loss 2.675, d_loss 0.174\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 23 Batch 317/390 d_loss_real= 0.313, d_loss_fake= 0.087, g_loss 2.588, d_loss 0.200\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 318/390 d_loss_real= 0.223, d_loss_fake= 0.089, g_loss 2.504, d_loss 0.156\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 319/390 d_loss_real= 0.331, d_loss_fake= 0.102, g_loss 2.445, d_loss 0.216\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 23 Batch 320/390 d_loss_real= 0.184, d_loss_fake= 0.097, g_loss 2.534, d_loss 0.140\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 321/390 d_loss_real= 0.017, d_loss_fake= 0.082, g_loss 2.677, d_loss 0.049\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 322/390 d_loss_real= 0.335, d_loss_fake= 0.083, g_loss 2.531, d_loss 0.209\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 323/390 d_loss_real= 0.164, d_loss_fake= 0.085, g_loss 2.561, d_loss 0.125\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 324/390 d_loss_real= 0.225, d_loss_fake= 0.092, g_loss 2.507, d_loss 0.158\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 325/390 d_loss_real= 0.188, d_loss_fake= 0.093, g_loss 2.451, d_loss 0.141\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 326/390 d_loss_real= 0.151, d_loss_fake= 0.092, g_loss 2.505, d_loss 0.121\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 23 Batch 327/390 d_loss_real= 0.086, d_loss_fake= 0.090, g_loss 2.524, d_loss 0.088\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 328/390 d_loss_real= 0.233, d_loss_fake= 0.091, g_loss 2.480, d_loss 0.162\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 329/390 d_loss_real= 0.184, d_loss_fake= 0.106, g_loss 2.365, d_loss 0.145\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 330/390 d_loss_real= 0.168, d_loss_fake= 0.111, g_loss 2.364, d_loss 0.139\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 23 Batch 331/390 d_loss_real= 0.339, d_loss_fake= 0.114, g_loss 2.333, d_loss 0.226\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 23 Batch 332/390 d_loss_real= 0.016, d_loss_fake= 0.090, g_loss 2.569, d_loss 0.053\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 333/390 d_loss_real= 0.114, d_loss_fake= 0.076, g_loss 2.799, d_loss 0.095\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 23 Batch 334/390 d_loss_real= 0.181, d_loss_fake= 0.068, g_loss 2.816, d_loss 0.124\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Epoch 23 Batch 335/390 d_loss_real= 0.135, d_loss_fake= 0.069, g_loss 2.751, d_loss 0.102\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 336/390 d_loss_real= 0.058, d_loss_fake= 0.071, g_loss 2.755, d_loss 0.065\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 337/390 d_loss_real= 0.168, d_loss_fake= 0.073, g_loss 2.704, d_loss 0.120\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 338/390 d_loss_real= 0.210, d_loss_fake= 0.078, g_loss 2.684, d_loss 0.144\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 339/390 d_loss_real= 0.124, d_loss_fake= 0.078, g_loss 2.647, d_loss 0.101\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 340/390 d_loss_real= 0.194, d_loss_fake= 0.080, g_loss 2.732, d_loss 0.137\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 23 Batch 341/390 d_loss_real= 0.115, d_loss_fake= 0.068, g_loss 2.848, d_loss 0.092\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 342/390 d_loss_real= 0.270, d_loss_fake= 0.068, g_loss 2.821, d_loss 0.169\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 343/390 d_loss_real= 0.290, d_loss_fake= 0.069, g_loss 2.846, d_loss 0.180\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 344/390 d_loss_real= 0.134, d_loss_fake= 0.069, g_loss 2.841, d_loss 0.101\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 345/390 d_loss_real= 0.170, d_loss_fake= 0.074, g_loss 2.753, d_loss 0.122\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 23 Batch 346/390 d_loss_real= 0.382, d_loss_fake= 0.072, g_loss 2.761, d_loss 0.227\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 347/390 d_loss_real= 0.269, d_loss_fake= 0.070, g_loss 2.811, d_loss 0.170\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 348/390 d_loss_real= 0.144, d_loss_fake= 0.067, g_loss 2.779, d_loss 0.106\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 23 Batch 349/390 d_loss_real= 0.167, d_loss_fake= 0.081, g_loss 2.652, d_loss 0.124\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 350/390 d_loss_real= 0.197, d_loss_fake= 0.082, g_loss 2.670, d_loss 0.139\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 351/390 d_loss_real= 0.308, d_loss_fake= 0.095, g_loss 2.576, d_loss 0.201\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 23 Batch 352/390 d_loss_real= 0.110, d_loss_fake= 0.088, g_loss 2.711, d_loss 0.099\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 353/390 d_loss_real= 0.238, d_loss_fake= 0.074, g_loss 2.810, d_loss 0.156\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 354/390 d_loss_real= 0.069, d_loss_fake= 0.064, g_loss 2.863, d_loss 0.066\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 355/390 d_loss_real= 0.359, d_loss_fake= 0.065, g_loss 2.856, d_loss 0.212\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 356/390 d_loss_real= 0.161, d_loss_fake= 0.070, g_loss 2.790, d_loss 0.115\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 357/390 d_loss_real= 0.242, d_loss_fake= 0.081, g_loss 2.616, d_loss 0.162\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 358/390 d_loss_real= 0.245, d_loss_fake= 0.096, g_loss 2.489, d_loss 0.171\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 359/390 d_loss_real= 0.260, d_loss_fake= 0.113, g_loss 2.443, d_loss 0.187\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 360/390 d_loss_real= 0.095, d_loss_fake= 0.095, g_loss 2.601, d_loss 0.095\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 23 Batch 361/390 d_loss_real= 0.263, d_loss_fake= 0.085, g_loss 2.587, d_loss 0.174\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 362/390 d_loss_real= 0.199, d_loss_fake= 0.082, g_loss 2.631, d_loss 0.141\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 363/390 d_loss_real= 0.264, d_loss_fake= 0.088, g_loss 2.575, d_loss 0.176\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 364/390 d_loss_real= 0.130, d_loss_fake= 0.093, g_loss 2.599, d_loss 0.111\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 365/390 d_loss_real= 0.221, d_loss_fake= 0.082, g_loss 2.588, d_loss 0.152\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 366/390 d_loss_real= 0.195, d_loss_fake= 0.086, g_loss 2.544, d_loss 0.140\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 367/390 d_loss_real= 0.185, d_loss_fake= 0.088, g_loss 2.580, d_loss 0.137\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 368/390 d_loss_real= 0.298, d_loss_fake= 0.091, g_loss 2.547, d_loss 0.195\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 23 Batch 369/390 d_loss_real= 0.106, d_loss_fake= 0.088, g_loss 2.555, d_loss 0.097\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 23 Batch 370/390 d_loss_real= 0.178, d_loss_fake= 0.091, g_loss 2.566, d_loss 0.134\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 23 Batch 371/390 d_loss_real= 0.141, d_loss_fake= 0.081, g_loss 2.669, d_loss 0.111\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 372/390 d_loss_real= 0.081, d_loss_fake= 0.071, g_loss 2.793, d_loss 0.076\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 23 Batch 373/390 d_loss_real= 0.381, d_loss_fake= 0.073, g_loss 2.672, d_loss 0.227\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 374/390 d_loss_real= 0.218, d_loss_fake= 0.084, g_loss 2.508, d_loss 0.151\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 375/390 d_loss_real= 0.233, d_loss_fake= 0.105, g_loss 2.388, d_loss 0.169\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 376/390 d_loss_real= 0.273, d_loss_fake= 0.135, g_loss 2.302, d_loss 0.204\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 23 Batch 377/390 d_loss_real= 0.242, d_loss_fake= 0.128, g_loss 2.492, d_loss 0.185\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 23 Batch 378/390 d_loss_real= 0.147, d_loss_fake= 0.081, g_loss 2.740, d_loss 0.114\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 379/390 d_loss_real= 0.097, d_loss_fake= 0.063, g_loss 2.889, d_loss 0.080\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 23 Batch 380/390 d_loss_real= 0.146, d_loss_fake= 0.058, g_loss 2.971, d_loss 0.102\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 23 Batch 381/390 d_loss_real= 0.212, d_loss_fake= 0.058, g_loss 2.899, d_loss 0.135\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 382/390 d_loss_real= 0.157, d_loss_fake= 0.064, g_loss 2.770, d_loss 0.110\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 383/390 d_loss_real= 0.202, d_loss_fake= 0.079, g_loss 2.544, d_loss 0.140\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 23 Batch 384/390 d_loss_real= 0.210, d_loss_fake= 0.114, g_loss 2.311, d_loss 0.162\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23 Batch 385/390 d_loss_real= 0.163, d_loss_fake= 0.145, g_loss 2.462, d_loss 0.154\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 23 Batch 386/390 d_loss_real= 0.196, d_loss_fake= 0.091, g_loss 2.666, d_loss 0.144\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 23 Batch 387/390 d_loss_real= 0.199, d_loss_fake= 0.072, g_loss 2.818, d_loss 0.135\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 23 Batch 388/390 d_loss_real= 0.108, d_loss_fake= 0.059, g_loss 2.927, d_loss 0.084\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23 Batch 389/390 d_loss_real= 0.071, d_loss_fake= 0.057, g_loss 3.004, d_loss 0.064\n",
            "2/2 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23 Batch 390/390 d_loss_real= 0.103, d_loss_fake= 0.054, g_loss 3.023, d_loss 0.078\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 24 Batch 1/390 d_loss_real= 0.216, d_loss_fake= 0.055, g_loss 2.926, d_loss 0.135\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 2/390 d_loss_real= 0.090, d_loss_fake= 0.060, g_loss 2.846, d_loss 0.075\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 24 Batch 3/390 d_loss_real= 0.164, d_loss_fake= 0.075, g_loss 2.599, d_loss 0.119\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 4/390 d_loss_real= 0.203, d_loss_fake= 0.099, g_loss 2.377, d_loss 0.151\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 24 Batch 5/390 d_loss_real= 0.098, d_loss_fake= 0.163, g_loss 2.554, d_loss 0.130\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 6/390 d_loss_real= 0.149, d_loss_fake= 0.057, g_loss 3.255, d_loss 0.103\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 7/390 d_loss_real= 0.182, d_loss_fake= 0.040, g_loss 3.393, d_loss 0.111\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 24 Batch 8/390 d_loss_real= 0.243, d_loss_fake= 0.037, g_loss 3.437, d_loss 0.140\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 9/390 d_loss_real= 0.203, d_loss_fake= 0.036, g_loss 3.437, d_loss 0.120\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 10/390 d_loss_real= 0.265, d_loss_fake= 0.040, g_loss 3.207, d_loss 0.152\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 11/390 d_loss_real= 0.086, d_loss_fake= 0.044, g_loss 3.048, d_loss 0.065\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 24 Batch 12/390 d_loss_real= 0.244, d_loss_fake= 0.060, g_loss 2.676, d_loss 0.152\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 13/390 d_loss_real= 0.210, d_loss_fake= 0.118, g_loss 2.324, d_loss 0.164\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 24 Batch 14/390 d_loss_real= 0.123, d_loss_fake= 0.224, g_loss 2.539, d_loss 0.173\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 15/390 d_loss_real= 0.168, d_loss_fake= 0.064, g_loss 3.186, d_loss 0.116\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 16/390 d_loss_real= 0.390, d_loss_fake= 0.042, g_loss 3.297, d_loss 0.216\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 24 Batch 17/390 d_loss_real= 0.328, d_loss_fake= 0.045, g_loss 3.212, d_loss 0.187\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 18/390 d_loss_real= 0.289, d_loss_fake= 0.047, g_loss 3.014, d_loss 0.168\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 24 Batch 19/390 d_loss_real= 0.442, d_loss_fake= 0.064, g_loss 2.727, d_loss 0.253\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 24 Batch 20/390 d_loss_real= 0.193, d_loss_fake= 0.090, g_loss 2.383, d_loss 0.141\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 21/390 d_loss_real= 0.118, d_loss_fake= 0.120, g_loss 2.184, d_loss 0.119\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 22/390 d_loss_real= 0.085, d_loss_fake= 0.119, g_loss 2.275, d_loss 0.102\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 23/390 d_loss_real= 0.038, d_loss_fake= 0.114, g_loss 2.491, d_loss 0.076\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 24/390 d_loss_real= 0.115, d_loss_fake= 0.084, g_loss 2.691, d_loss 0.100\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 25/390 d_loss_real= 0.083, d_loss_fake= 0.066, g_loss 2.880, d_loss 0.074\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 26/390 d_loss_real= 0.160, d_loss_fake= 0.061, g_loss 2.944, d_loss 0.111\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 27/390 d_loss_real= 0.215, d_loss_fake= 0.058, g_loss 2.841, d_loss 0.136\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24 Batch 28/390 d_loss_real= 0.325, d_loss_fake= 0.073, g_loss 2.579, d_loss 0.199\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 29/390 d_loss_real= 0.249, d_loss_fake= 0.106, g_loss 2.185, d_loss 0.178\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 30/390 d_loss_real= 0.033, d_loss_fake= 0.183, g_loss 2.233, d_loss 0.108\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24 Batch 31/390 d_loss_real= 0.086, d_loss_fake= 0.128, g_loss 2.439, d_loss 0.107\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 32/390 d_loss_real= 0.320, d_loss_fake= 0.077, g_loss 2.815, d_loss 0.199\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 33/390 d_loss_real= 0.245, d_loss_fake= 0.063, g_loss 2.910, d_loss 0.154\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 24 Batch 34/390 d_loss_real= 0.306, d_loss_fake= 0.061, g_loss 2.904, d_loss 0.184\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 35/390 d_loss_real= 0.255, d_loss_fake= 0.063, g_loss 2.810, d_loss 0.159\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 36/390 d_loss_real= 0.319, d_loss_fake= 0.072, g_loss 2.618, d_loss 0.195\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 37/390 d_loss_real= 0.131, d_loss_fake= 0.091, g_loss 2.442, d_loss 0.111\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24 Batch 38/390 d_loss_real= 0.135, d_loss_fake= 0.130, g_loss 2.351, d_loss 0.133\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 24 Batch 39/390 d_loss_real= 0.153, d_loss_fake= 0.116, g_loss 2.391, d_loss 0.135\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 40/390 d_loss_real= 0.180, d_loss_fake= 0.122, g_loss 2.465, d_loss 0.151\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 41/390 d_loss_real= 0.128, d_loss_fake= 0.090, g_loss 2.687, d_loss 0.109\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 24 Batch 42/390 d_loss_real= 0.182, d_loss_fake= 0.078, g_loss 2.770, d_loss 0.130\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24 Batch 43/390 d_loss_real= 0.042, d_loss_fake= 0.063, g_loss 2.929, d_loss 0.052\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 44/390 d_loss_real= 0.152, d_loss_fake= 0.057, g_loss 2.982, d_loss 0.105\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 24 Batch 45/390 d_loss_real= 0.235, d_loss_fake= 0.055, g_loss 2.955, d_loss 0.145\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 24 Batch 46/390 d_loss_real= 0.404, d_loss_fake= 0.057, g_loss 2.831, d_loss 0.231\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 47/390 d_loss_real= 0.305, d_loss_fake= 0.067, g_loss 2.725, d_loss 0.186\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 24 Batch 48/390 d_loss_real= 0.430, d_loss_fake= 0.091, g_loss 2.504, d_loss 0.261\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24 Batch 49/390 d_loss_real= 0.196, d_loss_fake= 0.109, g_loss 2.338, d_loss 0.153\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "Epoch 24 Batch 50/390 d_loss_real= 0.177, d_loss_fake= 0.123, g_loss 2.368, d_loss 0.150\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 24 Batch 51/390 d_loss_real= 0.042, d_loss_fake= 0.108, g_loss 2.588, d_loss 0.075\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 24 Batch 52/390 d_loss_real= 0.197, d_loss_fake= 0.075, g_loss 2.790, d_loss 0.136\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 24 Batch 53/390 d_loss_real= 0.405, d_loss_fake= 0.070, g_loss 2.727, d_loss 0.238\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 54/390 d_loss_real= 0.383, d_loss_fake= 0.075, g_loss 2.600, d_loss 0.229\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 24 Batch 55/390 d_loss_real= 0.133, d_loss_fake= 0.089, g_loss 2.487, d_loss 0.111\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 24 Batch 56/390 d_loss_real= 0.293, d_loss_fake= 0.112, g_loss 2.319, d_loss 0.203\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 57/390 d_loss_real= 0.242, d_loss_fake= 0.131, g_loss 2.277, d_loss 0.186\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 24 Batch 58/390 d_loss_real= 0.258, d_loss_fake= 0.122, g_loss 2.380, d_loss 0.190\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 24 Batch 59/390 d_loss_real= 0.177, d_loss_fake= 0.102, g_loss 2.520, d_loss 0.140\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 24 Batch 60/390 d_loss_real= 0.022, d_loss_fake= 0.085, g_loss 2.710, d_loss 0.054\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 24 Batch 61/390 d_loss_real= 0.171, d_loss_fake= 0.073, g_loss 2.717, d_loss 0.122\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 62/390 d_loss_real= 0.105, d_loss_fake= 0.069, g_loss 2.733, d_loss 0.087\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 24 Batch 63/390 d_loss_real= 0.166, d_loss_fake= 0.076, g_loss 2.596, d_loss 0.121\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 64/390 d_loss_real= 0.203, d_loss_fake= 0.090, g_loss 2.470, d_loss 0.146\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 65/390 d_loss_real= 0.118, d_loss_fake= 0.107, g_loss 2.643, d_loss 0.112\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 66/390 d_loss_real= 0.092, d_loss_fake= 0.070, g_loss 2.913, d_loss 0.081\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 24 Batch 67/390 d_loss_real= 0.160, d_loss_fake= 0.057, g_loss 3.068, d_loss 0.109\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 68/390 d_loss_real= 0.186, d_loss_fake= 0.050, g_loss 3.048, d_loss 0.118\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 69/390 d_loss_real= 0.199, d_loss_fake= 0.056, g_loss 2.941, d_loss 0.128\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 24 Batch 70/390 d_loss_real= 0.253, d_loss_fake= 0.074, g_loss 2.768, d_loss 0.163\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 71/390 d_loss_real= 0.169, d_loss_fake= 0.080, g_loss 2.675, d_loss 0.124\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 24 Batch 72/390 d_loss_real= 0.088, d_loss_fake= 0.090, g_loss 2.645, d_loss 0.089\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 24 Batch 73/390 d_loss_real= 0.054, d_loss_fake= 0.082, g_loss 2.992, d_loss 0.068\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 74/390 d_loss_real= 0.176, d_loss_fake= 0.068, g_loss 2.933, d_loss 0.122\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 24 Batch 75/390 d_loss_real= 0.179, d_loss_fake= 0.061, g_loss 3.047, d_loss 0.120\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24 Batch 76/390 d_loss_real= 0.285, d_loss_fake= 0.067, g_loss 2.782, d_loss 0.176\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 77/390 d_loss_real= 0.214, d_loss_fake= 0.084, g_loss 2.677, d_loss 0.149\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 78/390 d_loss_real= 0.198, d_loss_fake= 0.093, g_loss 2.681, d_loss 0.145\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 24 Batch 79/390 d_loss_real= 0.158, d_loss_fake= 0.078, g_loss 2.782, d_loss 0.118\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 80/390 d_loss_real= 0.191, d_loss_fake= 0.086, g_loss 2.707, d_loss 0.139\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 81/390 d_loss_real= 0.245, d_loss_fake= 0.086, g_loss 2.670, d_loss 0.166\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 82/390 d_loss_real= 0.153, d_loss_fake= 0.089, g_loss 2.692, d_loss 0.121\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 83/390 d_loss_real= 0.244, d_loss_fake= 0.077, g_loss 2.778, d_loss 0.160\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24 Batch 84/390 d_loss_real= 0.193, d_loss_fake= 0.069, g_loss 2.804, d_loss 0.131\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 85/390 d_loss_real= 0.244, d_loss_fake= 0.074, g_loss 2.753, d_loss 0.159\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24 Batch 86/390 d_loss_real= 0.175, d_loss_fake= 0.077, g_loss 2.658, d_loss 0.126\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 87/390 d_loss_real= 0.094, d_loss_fake= 0.085, g_loss 2.696, d_loss 0.090\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 88/390 d_loss_real= 0.253, d_loss_fake= 0.085, g_loss 2.627, d_loss 0.169\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 89/390 d_loss_real= 0.219, d_loss_fake= 0.093, g_loss 2.459, d_loss 0.156\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 90/390 d_loss_real= 0.194, d_loss_fake= 0.101, g_loss 2.487, d_loss 0.147\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 24 Batch 91/390 d_loss_real= 0.221, d_loss_fake= 0.092, g_loss 2.636, d_loss 0.157\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 92/390 d_loss_real= 0.243, d_loss_fake= 0.084, g_loss 2.727, d_loss 0.164\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 24 Batch 93/390 d_loss_real= 0.202, d_loss_fake= 0.069, g_loss 2.804, d_loss 0.136\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 24 Batch 94/390 d_loss_real= 0.225, d_loss_fake= 0.069, g_loss 2.765, d_loss 0.147\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 24 Batch 95/390 d_loss_real= 0.307, d_loss_fake= 0.083, g_loss 2.591, d_loss 0.195\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 96/390 d_loss_real= 0.180, d_loss_fake= 0.095, g_loss 2.424, d_loss 0.138\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 97/390 d_loss_real= 0.332, d_loss_fake= 0.121, g_loss 2.353, d_loss 0.227\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 24 Batch 98/390 d_loss_real= 0.167, d_loss_fake= 0.140, g_loss 2.360, d_loss 0.154\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 99/390 d_loss_real= 0.173, d_loss_fake= 0.100, g_loss 2.500, d_loss 0.137\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 100/390 d_loss_real= 0.182, d_loss_fake= 0.084, g_loss 2.623, d_loss 0.133\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 101/390 d_loss_real= 0.248, d_loss_fake= 0.081, g_loss 2.605, d_loss 0.165\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 24 Batch 102/390 d_loss_real= 0.347, d_loss_fake= 0.091, g_loss 2.538, d_loss 0.219\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 103/390 d_loss_real= 0.076, d_loss_fake= 0.096, g_loss 2.496, d_loss 0.086\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 24 Batch 104/390 d_loss_real= 0.260, d_loss_fake= 0.098, g_loss 2.532, d_loss 0.179\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 24 Batch 105/390 d_loss_real= 0.188, d_loss_fake= 0.087, g_loss 2.585, d_loss 0.137\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 106/390 d_loss_real= 0.264, d_loss_fake= 0.082, g_loss 2.608, d_loss 0.173\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 107/390 d_loss_real= 0.108, d_loss_fake= 0.082, g_loss 2.577, d_loss 0.095\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 108/390 d_loss_real= 0.184, d_loss_fake= 0.079, g_loss 2.577, d_loss 0.132\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 109/390 d_loss_real= 0.295, d_loss_fake= 0.092, g_loss 2.480, d_loss 0.194\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 110/390 d_loss_real= 0.217, d_loss_fake= 0.105, g_loss 2.377, d_loss 0.161\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 111/390 d_loss_real= 0.164, d_loss_fake= 0.113, g_loss 2.348, d_loss 0.139\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 24 Batch 112/390 d_loss_real= 0.163, d_loss_fake= 0.106, g_loss 2.464, d_loss 0.135\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 113/390 d_loss_real= 0.282, d_loss_fake= 0.100, g_loss 2.530, d_loss 0.191\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 114/390 d_loss_real= 0.065, d_loss_fake= 0.089, g_loss 2.605, d_loss 0.077\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 115/390 d_loss_real= 0.144, d_loss_fake= 0.077, g_loss 2.673, d_loss 0.110\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 24 Batch 116/390 d_loss_real= 0.241, d_loss_fake= 0.077, g_loss 2.722, d_loss 0.159\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 24 Batch 117/390 d_loss_real= 0.094, d_loss_fake= 0.077, g_loss 2.703, d_loss 0.085\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 118/390 d_loss_real= 0.203, d_loss_fake= 0.078, g_loss 2.621, d_loss 0.140\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24 Batch 119/390 d_loss_real= 0.182, d_loss_fake= 0.100, g_loss 2.402, d_loss 0.141\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 24 Batch 120/390 d_loss_real= 0.060, d_loss_fake= 0.114, g_loss 2.493, d_loss 0.087\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 121/390 d_loss_real= 0.078, d_loss_fake= 0.087, g_loss 2.684, d_loss 0.082\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 24 Batch 122/390 d_loss_real= 0.177, d_loss_fake= 0.069, g_loss 2.976, d_loss 0.123\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 24 Batch 123/390 d_loss_real= 0.365, d_loss_fake= 0.063, g_loss 2.849, d_loss 0.214\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 124/390 d_loss_real= 0.142, d_loss_fake= 0.076, g_loss 2.819, d_loss 0.109\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 125/390 d_loss_real= 0.184, d_loss_fake= 0.074, g_loss 2.780, d_loss 0.129\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 126/390 d_loss_real= 0.306, d_loss_fake= 0.075, g_loss 2.649, d_loss 0.191\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 24 Batch 127/390 d_loss_real= 0.195, d_loss_fake= 0.101, g_loss 2.492, d_loss 0.148\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 24 Batch 128/390 d_loss_real= 0.128, d_loss_fake= 0.116, g_loss 2.520, d_loss 0.122\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24 Batch 129/390 d_loss_real= 0.156, d_loss_fake= 0.090, g_loss 2.753, d_loss 0.123\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 130/390 d_loss_real= 0.290, d_loss_fake= 0.063, g_loss 3.007, d_loss 0.177\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 131/390 d_loss_real= 0.071, d_loss_fake= 0.053, g_loss 3.240, d_loss 0.062\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24 Batch 132/390 d_loss_real= 0.104, d_loss_fake= 0.047, g_loss 3.178, d_loss 0.075\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24 Batch 133/390 d_loss_real= 0.165, d_loss_fake= 0.056, g_loss 2.960, d_loss 0.110\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 134/390 d_loss_real= 0.225, d_loss_fake= 0.063, g_loss 2.860, d_loss 0.144\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 135/390 d_loss_real= 0.225, d_loss_fake= 0.090, g_loss 2.762, d_loss 0.157\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 136/390 d_loss_real= 0.090, d_loss_fake= 0.065, g_loss 2.878, d_loss 0.077\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 137/390 d_loss_real= 0.040, d_loss_fake= 0.064, g_loss 3.100, d_loss 0.052\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 24 Batch 138/390 d_loss_real= 0.222, d_loss_fake= 0.058, g_loss 3.004, d_loss 0.140\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 139/390 d_loss_real= 0.166, d_loss_fake= 0.062, g_loss 2.964, d_loss 0.114\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24 Batch 140/390 d_loss_real= 0.186, d_loss_fake= 0.058, g_loss 2.950, d_loss 0.122\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 24 Batch 141/390 d_loss_real= 0.286, d_loss_fake= 0.072, g_loss 2.878, d_loss 0.179\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 24 Batch 142/390 d_loss_real= 0.096, d_loss_fake= 0.085, g_loss 2.917, d_loss 0.090\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 24 Batch 143/390 d_loss_real= 0.235, d_loss_fake= 0.068, g_loss 2.842, d_loss 0.152\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 24 Batch 144/390 d_loss_real= 0.010, d_loss_fake= 0.066, g_loss 3.025, d_loss 0.038\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 24 Batch 145/390 d_loss_real= 0.317, d_loss_fake= 0.055, g_loss 3.023, d_loss 0.186\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 146/390 d_loss_real= 0.277, d_loss_fake= 0.053, g_loss 3.089, d_loss 0.165\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 147/390 d_loss_real= 0.216, d_loss_fake= 0.052, g_loss 3.153, d_loss 0.134\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 148/390 d_loss_real= 0.072, d_loss_fake= 0.051, g_loss 3.004, d_loss 0.062\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 24 Batch 149/390 d_loss_real= 0.211, d_loss_fake= 0.058, g_loss 2.935, d_loss 0.135\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 150/390 d_loss_real= 0.124, d_loss_fake= 0.065, g_loss 2.815, d_loss 0.094\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 24 Batch 151/390 d_loss_real= 0.261, d_loss_fake= 0.080, g_loss 2.669, d_loss 0.171\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 152/390 d_loss_real= 0.306, d_loss_fake= 0.106, g_loss 2.554, d_loss 0.206\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 153/390 d_loss_real= 0.176, d_loss_fake= 0.099, g_loss 2.669, d_loss 0.138\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 154/390 d_loss_real= 0.148, d_loss_fake= 0.072, g_loss 2.875, d_loss 0.110\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 155/390 d_loss_real= 0.233, d_loss_fake= 0.063, g_loss 2.917, d_loss 0.148\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 24 Batch 156/390 d_loss_real= 0.224, d_loss_fake= 0.062, g_loss 2.932, d_loss 0.143\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 157/390 d_loss_real= 0.194, d_loss_fake= 0.059, g_loss 2.884, d_loss 0.127\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 158/390 d_loss_real= 0.276, d_loss_fake= 0.065, g_loss 2.859, d_loss 0.170\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24 Batch 159/390 d_loss_real= 0.264, d_loss_fake= 0.070, g_loss 2.818, d_loss 0.167\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 24 Batch 160/390 d_loss_real= 0.081, d_loss_fake= 0.071, g_loss 2.817, d_loss 0.076\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 161/390 d_loss_real= 0.290, d_loss_fake= 0.068, g_loss 2.903, d_loss 0.179\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24 Batch 162/390 d_loss_real= 0.244, d_loss_fake= 0.061, g_loss 2.927, d_loss 0.152\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24 Batch 163/390 d_loss_real= 0.329, d_loss_fake= 0.062, g_loss 2.874, d_loss 0.196\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24 Batch 164/390 d_loss_real= 0.225, d_loss_fake= 0.071, g_loss 2.802, d_loss 0.148\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 24 Batch 165/390 d_loss_real= 0.245, d_loss_fake= 0.079, g_loss 2.725, d_loss 0.162\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 166/390 d_loss_real= 0.078, d_loss_fake= 0.088, g_loss 2.647, d_loss 0.083\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 167/390 d_loss_real= 0.412, d_loss_fake= 0.088, g_loss 2.629, d_loss 0.250\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 168/390 d_loss_real= 0.152, d_loss_fake= 0.084, g_loss 2.740, d_loss 0.118\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 24 Batch 169/390 d_loss_real= 0.072, d_loss_fake= 0.068, g_loss 2.904, d_loss 0.070\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 24 Batch 170/390 d_loss_real= 0.085, d_loss_fake= 0.060, g_loss 3.016, d_loss 0.072\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 24 Batch 171/390 d_loss_real= 0.162, d_loss_fake= 0.052, g_loss 3.083, d_loss 0.107\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 172/390 d_loss_real= 0.269, d_loss_fake= 0.055, g_loss 2.940, d_loss 0.162\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24 Batch 173/390 d_loss_real= 0.065, d_loss_fake= 0.073, g_loss 2.738, d_loss 0.069\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 24 Batch 174/390 d_loss_real= 0.123, d_loss_fake= 0.093, g_loss 2.678, d_loss 0.108\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 175/390 d_loss_real= 0.059, d_loss_fake= 0.091, g_loss 2.764, d_loss 0.075\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 176/390 d_loss_real= 0.171, d_loss_fake= 0.076, g_loss 2.853, d_loss 0.124\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 177/390 d_loss_real= 0.343, d_loss_fake= 0.073, g_loss 2.793, d_loss 0.208\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 178/390 d_loss_real= 0.208, d_loss_fake= 0.074, g_loss 2.709, d_loss 0.141\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 179/390 d_loss_real= 0.042, d_loss_fake= 0.087, g_loss 2.594, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 180/390 d_loss_real= 0.140, d_loss_fake= 0.097, g_loss 2.633, d_loss 0.119\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 24 Batch 181/390 d_loss_real= 0.019, d_loss_fake= 0.093, g_loss 2.807, d_loss 0.056\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 182/390 d_loss_real= 0.285, d_loss_fake= 0.062, g_loss 3.009, d_loss 0.173\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 183/390 d_loss_real= 0.271, d_loss_fake= 0.060, g_loss 2.882, d_loss 0.165\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 24 Batch 184/390 d_loss_real= 0.131, d_loss_fake= 0.062, g_loss 2.876, d_loss 0.097\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 24 Batch 185/390 d_loss_real= 0.297, d_loss_fake= 0.075, g_loss 2.663, d_loss 0.186\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 186/390 d_loss_real= 0.307, d_loss_fake= 0.100, g_loss 2.489, d_loss 0.203\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 187/390 d_loss_real= 0.121, d_loss_fake= 0.100, g_loss 2.528, d_loss 0.111\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 188/390 d_loss_real= 0.095, d_loss_fake= 0.060, g_loss 2.968, d_loss 0.078\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 189/390 d_loss_real= 0.131, d_loss_fake= 0.067, g_loss 2.947, d_loss 0.099\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 24 Batch 190/390 d_loss_real= 0.220, d_loss_fake= 0.058, g_loss 2.996, d_loss 0.139\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 191/390 d_loss_real= 0.189, d_loss_fake= 0.058, g_loss 2.946, d_loss 0.123\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 192/390 d_loss_real= 0.104, d_loss_fake= 0.060, g_loss 3.022, d_loss 0.082\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 24 Batch 193/390 d_loss_real= 0.159, d_loss_fake= 0.054, g_loss 2.940, d_loss 0.106\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 194/390 d_loss_real= 0.293, d_loss_fake= 0.065, g_loss 2.885, d_loss 0.179\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 24 Batch 195/390 d_loss_real= 0.170, d_loss_fake= 0.074, g_loss 2.773, d_loss 0.122\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 196/390 d_loss_real= 0.141, d_loss_fake= 0.076, g_loss 2.773, d_loss 0.108\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 24 Batch 197/390 d_loss_real= 0.249, d_loss_fake= 0.073, g_loss 2.754, d_loss 0.161\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 24 Batch 198/390 d_loss_real= 0.165, d_loss_fake= 0.070, g_loss 2.713, d_loss 0.117\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 199/390 d_loss_real= 0.151, d_loss_fake= 0.090, g_loss 2.677, d_loss 0.121\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 200/390 d_loss_real= 0.108, d_loss_fake= 0.078, g_loss 2.710, d_loss 0.093\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 24 Batch 201/390 d_loss_real= 0.076, d_loss_fake= 0.074, g_loss 2.788, d_loss 0.075\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 24 Batch 202/390 d_loss_real= 0.086, d_loss_fake= 0.065, g_loss 2.911, d_loss 0.076\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 24 Batch 203/390 d_loss_real= 0.188, d_loss_fake= 0.060, g_loss 2.934, d_loss 0.124\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 204/390 d_loss_real= 0.169, d_loss_fake= 0.058, g_loss 2.918, d_loss 0.113\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24 Batch 205/390 d_loss_real= 0.291, d_loss_fake= 0.060, g_loss 2.833, d_loss 0.175\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 206/390 d_loss_real= 0.282, d_loss_fake= 0.076, g_loss 2.699, d_loss 0.179\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24 Batch 207/390 d_loss_real= 0.272, d_loss_fake= 0.092, g_loss 2.441, d_loss 0.182\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 208/390 d_loss_real= 0.103, d_loss_fake= 0.103, g_loss 2.470, d_loss 0.103\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 209/390 d_loss_real= 0.156, d_loss_fake= 0.096, g_loss 2.597, d_loss 0.126\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 24 Batch 210/390 d_loss_real= 0.092, d_loss_fake= 0.086, g_loss 2.697, d_loss 0.089\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 24 Batch 211/390 d_loss_real= 0.146, d_loss_fake= 0.068, g_loss 2.897, d_loss 0.107\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 24 Batch 212/390 d_loss_real= 0.135, d_loss_fake= 0.058, g_loss 2.968, d_loss 0.097\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 24 Batch 213/390 d_loss_real= 0.175, d_loss_fake= 0.056, g_loss 2.980, d_loss 0.116\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 214/390 d_loss_real= 0.333, d_loss_fake= 0.061, g_loss 2.872, d_loss 0.197\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 215/390 d_loss_real= 0.201, d_loss_fake= 0.070, g_loss 2.588, d_loss 0.136\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 216/390 d_loss_real= 0.210, d_loss_fake= 0.115, g_loss 2.316, d_loss 0.163\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 24 Batch 217/390 d_loss_real= 0.222, d_loss_fake= 0.132, g_loss 2.394, d_loss 0.177\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 218/390 d_loss_real= 0.275, d_loss_fake= 0.101, g_loss 2.595, d_loss 0.188\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 24 Batch 219/390 d_loss_real= 0.240, d_loss_fake= 0.080, g_loss 2.748, d_loss 0.160\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 24 Batch 220/390 d_loss_real= 0.182, d_loss_fake= 0.070, g_loss 2.815, d_loss 0.126\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 24 Batch 221/390 d_loss_real= 0.237, d_loss_fake= 0.066, g_loss 2.782, d_loss 0.151\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 222/390 d_loss_real= 0.192, d_loss_fake= 0.071, g_loss 2.768, d_loss 0.132\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 223/390 d_loss_real= 0.344, d_loss_fake= 0.077, g_loss 2.666, d_loss 0.211\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 24 Batch 224/390 d_loss_real= 0.219, d_loss_fake= 0.089, g_loss 2.439, d_loss 0.154\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 24 Batch 225/390 d_loss_real= 0.124, d_loss_fake= 0.115, g_loss 2.275, d_loss 0.119\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 226/390 d_loss_real= 0.022, d_loss_fake= 0.130, g_loss 2.398, d_loss 0.076\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 227/390 d_loss_real= 0.074, d_loss_fake= 0.099, g_loss 2.647, d_loss 0.086\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 24 Batch 228/390 d_loss_real= 0.119, d_loss_fake= 0.075, g_loss 2.855, d_loss 0.097\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24 Batch 229/390 d_loss_real= 0.078, d_loss_fake= 0.061, g_loss 2.934, d_loss 0.070\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24 Batch 230/390 d_loss_real= 0.288, d_loss_fake= 0.060, g_loss 2.857, d_loss 0.174\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 24 Batch 231/390 d_loss_real= 0.106, d_loss_fake= 0.072, g_loss 2.749, d_loss 0.089\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 232/390 d_loss_real= 0.158, d_loss_fake= 0.080, g_loss 2.513, d_loss 0.119\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 24 Batch 233/390 d_loss_real= 0.179, d_loss_fake= 0.121, g_loss 2.381, d_loss 0.150\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 234/390 d_loss_real= 0.194, d_loss_fake= 0.149, g_loss 2.463, d_loss 0.172\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 24 Batch 235/390 d_loss_real= 0.131, d_loss_fake= 0.080, g_loss 2.773, d_loss 0.106\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 236/390 d_loss_real= 0.145, d_loss_fake= 0.057, g_loss 3.011, d_loss 0.101\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 237/390 d_loss_real= 0.071, d_loss_fake= 0.051, g_loss 3.151, d_loss 0.061\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 238/390 d_loss_real= 0.331, d_loss_fake= 0.053, g_loss 2.956, d_loss 0.192\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 239/390 d_loss_real= 0.174, d_loss_fake= 0.064, g_loss 2.795, d_loss 0.119\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 240/390 d_loss_real= 0.169, d_loss_fake= 0.073, g_loss 2.620, d_loss 0.121\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 241/390 d_loss_real= 0.259, d_loss_fake= 0.098, g_loss 2.412, d_loss 0.178\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 24 Batch 242/390 d_loss_real= 0.129, d_loss_fake= 0.114, g_loss 2.519, d_loss 0.122\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 24 Batch 243/390 d_loss_real= 0.211, d_loss_fake= 0.083, g_loss 2.684, d_loss 0.147\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 244/390 d_loss_real= 0.184, d_loss_fake= 0.071, g_loss 2.807, d_loss 0.127\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 245/390 d_loss_real= 0.219, d_loss_fake= 0.073, g_loss 2.753, d_loss 0.146\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 246/390 d_loss_real= 0.154, d_loss_fake= 0.069, g_loss 2.718, d_loss 0.111\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 24 Batch 247/390 d_loss_real= 0.189, d_loss_fake= 0.075, g_loss 2.728, d_loss 0.132\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 248/390 d_loss_real= 0.068, d_loss_fake= 0.073, g_loss 2.798, d_loss 0.071\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24 Batch 249/390 d_loss_real= 0.064, d_loss_fake= 0.065, g_loss 2.900, d_loss 0.064\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 24 Batch 250/390 d_loss_real= 0.153, d_loss_fake= 0.063, g_loss 2.975, d_loss 0.108\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 251/390 d_loss_real= 0.076, d_loss_fake= 0.057, g_loss 2.948, d_loss 0.066\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 24 Batch 252/390 d_loss_real= 0.146, d_loss_fake= 0.057, g_loss 2.877, d_loss 0.101\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 253/390 d_loss_real= 0.195, d_loss_fake= 0.063, g_loss 2.739, d_loss 0.129\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 254/390 d_loss_real= 0.118, d_loss_fake= 0.078, g_loss 2.675, d_loss 0.098\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24 Batch 255/390 d_loss_real= 0.150, d_loss_fake= 0.087, g_loss 2.614, d_loss 0.119\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 256/390 d_loss_real= 0.208, d_loss_fake= 0.092, g_loss 2.613, d_loss 0.150\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 24 Batch 257/390 d_loss_real= 0.170, d_loss_fake= 0.083, g_loss 2.830, d_loss 0.126\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 258/390 d_loss_real= 0.154, d_loss_fake= 0.067, g_loss 2.925, d_loss 0.110\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 259/390 d_loss_real= 0.048, d_loss_fake= 0.053, g_loss 3.113, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 260/390 d_loss_real= 0.181, d_loss_fake= 0.048, g_loss 3.092, d_loss 0.114\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 261/390 d_loss_real= 0.415, d_loss_fake= 0.055, g_loss 2.868, d_loss 0.235\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 24 Batch 262/390 d_loss_real= 0.048, d_loss_fake= 0.073, g_loss 2.705, d_loss 0.060\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 24 Batch 263/390 d_loss_real= 0.199, d_loss_fake= 0.090, g_loss 2.329, d_loss 0.145\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 264/390 d_loss_real= 0.204, d_loss_fake= 0.152, g_loss 2.452, d_loss 0.178\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 24 Batch 265/390 d_loss_real= 0.274, d_loss_fake= 0.083, g_loss 2.882, d_loss 0.179\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 24 Batch 266/390 d_loss_real= 0.227, d_loss_fake= 0.057, g_loss 3.064, d_loss 0.142\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 24 Batch 267/390 d_loss_real= 0.174, d_loss_fake= 0.048, g_loss 3.146, d_loss 0.111\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 24 Batch 268/390 d_loss_real= 0.287, d_loss_fake= 0.047, g_loss 3.114, d_loss 0.167\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 269/390 d_loss_real= 0.291, d_loss_fake= 0.057, g_loss 2.817, d_loss 0.174\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24 Batch 270/390 d_loss_real= 0.130, d_loss_fake= 0.081, g_loss 2.511, d_loss 0.106\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 24 Batch 271/390 d_loss_real= 0.066, d_loss_fake= 0.114, g_loss 2.490, d_loss 0.090\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 272/390 d_loss_real= 0.181, d_loss_fake= 0.116, g_loss 2.532, d_loss 0.149\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 24 Batch 273/390 d_loss_real= 0.213, d_loss_fake= 0.090, g_loss 2.775, d_loss 0.152\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 24 Batch 274/390 d_loss_real= 0.274, d_loss_fake= 0.068, g_loss 2.831, d_loss 0.171\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 24 Batch 275/390 d_loss_real= 0.249, d_loss_fake= 0.068, g_loss 2.822, d_loss 0.158\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 276/390 d_loss_real= 0.190, d_loss_fake= 0.072, g_loss 2.741, d_loss 0.131\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 277/390 d_loss_real= 0.187, d_loss_fake= 0.077, g_loss 2.628, d_loss 0.132\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 24 Batch 278/390 d_loss_real= 0.244, d_loss_fake= 0.096, g_loss 2.410, d_loss 0.170\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 24 Batch 279/390 d_loss_real= 0.111, d_loss_fake= 0.104, g_loss 2.392, d_loss 0.108\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 24 Batch 280/390 d_loss_real= 0.123, d_loss_fake= 0.109, g_loss 2.444, d_loss 0.116\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 24 Batch 281/390 d_loss_real= 0.073, d_loss_fake= 0.085, g_loss 2.655, d_loss 0.079\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 24 Batch 282/390 d_loss_real= 0.088, d_loss_fake= 0.075, g_loss 2.758, d_loss 0.082\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 283/390 d_loss_real= 0.176, d_loss_fake= 0.068, g_loss 2.808, d_loss 0.122\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 24 Batch 284/390 d_loss_real= 0.201, d_loss_fake= 0.067, g_loss 2.816, d_loss 0.134\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 285/390 d_loss_real= 0.193, d_loss_fake= 0.065, g_loss 2.767, d_loss 0.129\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 286/390 d_loss_real= 0.141, d_loss_fake= 0.072, g_loss 2.606, d_loss 0.107\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 287/390 d_loss_real= 0.224, d_loss_fake= 0.100, g_loss 2.507, d_loss 0.162\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 24 Batch 288/390 d_loss_real= 0.076, d_loss_fake= 0.118, g_loss 2.436, d_loss 0.097\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 24 Batch 289/390 d_loss_real= 0.093, d_loss_fake= 0.110, g_loss 2.597, d_loss 0.102\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 290/390 d_loss_real= 0.119, d_loss_fake= 0.074, g_loss 2.892, d_loss 0.096\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 24 Batch 291/390 d_loss_real= 0.209, d_loss_fake= 0.064, g_loss 2.959, d_loss 0.137\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 292/390 d_loss_real= 0.336, d_loss_fake= 0.065, g_loss 2.854, d_loss 0.201\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 293/390 d_loss_real= 0.306, d_loss_fake= 0.066, g_loss 2.777, d_loss 0.186\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 294/390 d_loss_real= 0.158, d_loss_fake= 0.074, g_loss 2.743, d_loss 0.116\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 295/390 d_loss_real= 0.217, d_loss_fake= 0.077, g_loss 2.725, d_loss 0.147\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 296/390 d_loss_real= 0.205, d_loss_fake= 0.083, g_loss 2.742, d_loss 0.144\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 24 Batch 297/390 d_loss_real= 0.088, d_loss_fake= 0.071, g_loss 2.827, d_loss 0.079\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 298/390 d_loss_real= 0.208, d_loss_fake= 0.068, g_loss 2.832, d_loss 0.138\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 299/390 d_loss_real= 0.161, d_loss_fake= 0.077, g_loss 2.799, d_loss 0.119\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 24 Batch 300/390 d_loss_real= 0.121, d_loss_fake= 0.071, g_loss 2.721, d_loss 0.096\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 301/390 d_loss_real= 0.264, d_loss_fake= 0.081, g_loss 2.703, d_loss 0.173\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 302/390 d_loss_real= 0.231, d_loss_fake= 0.081, g_loss 2.664, d_loss 0.156\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 303/390 d_loss_real= 0.276, d_loss_fake= 0.077, g_loss 2.715, d_loss 0.177\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 304/390 d_loss_real= 0.132, d_loss_fake= 0.071, g_loss 2.730, d_loss 0.102\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 24 Batch 305/390 d_loss_real= 0.204, d_loss_fake= 0.088, g_loss 2.667, d_loss 0.146\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 24 Batch 306/390 d_loss_real= 0.303, d_loss_fake= 0.081, g_loss 2.729, d_loss 0.192\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 307/390 d_loss_real= 0.249, d_loss_fake= 0.078, g_loss 2.661, d_loss 0.163\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 308/390 d_loss_real= 0.206, d_loss_fake= 0.085, g_loss 2.539, d_loss 0.145\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 309/390 d_loss_real= 0.082, d_loss_fake= 0.082, g_loss 2.651, d_loss 0.082\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 310/390 d_loss_real= 0.156, d_loss_fake= 0.080, g_loss 2.642, d_loss 0.118\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 24 Batch 311/390 d_loss_real= 0.207, d_loss_fake= 0.074, g_loss 2.680, d_loss 0.141\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 312/390 d_loss_real= 0.125, d_loss_fake= 0.076, g_loss 2.795, d_loss 0.100\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 313/390 d_loss_real= 0.251, d_loss_fake= 0.072, g_loss 2.724, d_loss 0.162\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 314/390 d_loss_real= 0.078, d_loss_fake= 0.072, g_loss 2.772, d_loss 0.075\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24 Batch 315/390 d_loss_real= 0.151, d_loss_fake= 0.066, g_loss 2.914, d_loss 0.109\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 24 Batch 316/390 d_loss_real= 0.101, d_loss_fake= 0.058, g_loss 2.976, d_loss 0.079\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 317/390 d_loss_real= 0.387, d_loss_fake= 0.059, g_loss 2.800, d_loss 0.223\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 318/390 d_loss_real= 0.161, d_loss_fake= 0.081, g_loss 2.677, d_loss 0.121\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 319/390 d_loss_real= 0.088, d_loss_fake= 0.082, g_loss 2.719, d_loss 0.085\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 24 Batch 320/390 d_loss_real= 0.297, d_loss_fake= 0.080, g_loss 2.738, d_loss 0.189\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 24 Batch 321/390 d_loss_real= 0.140, d_loss_fake= 0.070, g_loss 2.839, d_loss 0.105\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 24 Batch 322/390 d_loss_real= 0.297, d_loss_fake= 0.066, g_loss 2.828, d_loss 0.181\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 24 Batch 323/390 d_loss_real= 0.270, d_loss_fake= 0.076, g_loss 2.704, d_loss 0.173\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 324/390 d_loss_real= 0.267, d_loss_fake= 0.096, g_loss 2.644, d_loss 0.182\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 325/390 d_loss_real= 0.157, d_loss_fake= 0.093, g_loss 2.581, d_loss 0.125\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 24 Batch 326/390 d_loss_real= 0.101, d_loss_fake= 0.076, g_loss 2.773, d_loss 0.088\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 327/390 d_loss_real= 0.212, d_loss_fake= 0.063, g_loss 2.996, d_loss 0.138\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 24 Batch 328/390 d_loss_real= 0.303, d_loss_fake= 0.057, g_loss 3.063, d_loss 0.180\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 24 Batch 329/390 d_loss_real= 0.275, d_loss_fake= 0.056, g_loss 3.070, d_loss 0.165\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 24 Batch 330/390 d_loss_real= 0.289, d_loss_fake= 0.058, g_loss 2.766, d_loss 0.173\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 331/390 d_loss_real= 0.234, d_loss_fake= 0.081, g_loss 2.487, d_loss 0.158\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 24 Batch 332/390 d_loss_real= 0.166, d_loss_fake= 0.121, g_loss 2.397, d_loss 0.144\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 24 Batch 333/390 d_loss_real= 0.246, d_loss_fake= 0.130, g_loss 2.474, d_loss 0.188\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 334/390 d_loss_real= 0.212, d_loss_fake= 0.083, g_loss 2.733, d_loss 0.148\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 335/390 d_loss_real= 0.110, d_loss_fake= 0.071, g_loss 2.829, d_loss 0.090\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 24 Batch 336/390 d_loss_real= 0.258, d_loss_fake= 0.070, g_loss 2.777, d_loss 0.164\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 24 Batch 337/390 d_loss_real= 0.360, d_loss_fake= 0.081, g_loss 2.513, d_loss 0.220\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 24 Batch 338/390 d_loss_real= 0.157, d_loss_fake= 0.104, g_loss 2.360, d_loss 0.131\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 24 Batch 339/390 d_loss_real= 0.038, d_loss_fake= 0.106, g_loss 2.463, d_loss 0.072\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 340/390 d_loss_real= 0.157, d_loss_fake= 0.087, g_loss 2.627, d_loss 0.122\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 341/390 d_loss_real= 0.148, d_loss_fake= 0.079, g_loss 2.730, d_loss 0.113\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 342/390 d_loss_real= 0.254, d_loss_fake= 0.074, g_loss 2.715, d_loss 0.164\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 24 Batch 343/390 d_loss_real= 0.209, d_loss_fake= 0.076, g_loss 2.673, d_loss 0.142\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 344/390 d_loss_real= 0.133, d_loss_fake= 0.076, g_loss 2.713, d_loss 0.105\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 345/390 d_loss_real= 0.266, d_loss_fake= 0.073, g_loss 2.679, d_loss 0.169\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 346/390 d_loss_real= 0.141, d_loss_fake= 0.079, g_loss 2.695, d_loss 0.110\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 24 Batch 347/390 d_loss_real= 0.139, d_loss_fake= 0.073, g_loss 2.733, d_loss 0.106\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 348/390 d_loss_real= 0.260, d_loss_fake= 0.084, g_loss 2.637, d_loss 0.172\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 24 Batch 349/390 d_loss_real= 0.226, d_loss_fake= 0.073, g_loss 2.741, d_loss 0.149\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 24 Batch 350/390 d_loss_real= 0.203, d_loss_fake= 0.080, g_loss 2.653, d_loss 0.142\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 351/390 d_loss_real= 0.205, d_loss_fake= 0.098, g_loss 2.610, d_loss 0.152\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 352/390 d_loss_real= 0.055, d_loss_fake= 0.073, g_loss 2.879, d_loss 0.064\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 24 Batch 353/390 d_loss_real= 0.072, d_loss_fake= 0.059, g_loss 2.985, d_loss 0.066\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 24 Batch 354/390 d_loss_real= 0.148, d_loss_fake= 0.057, g_loss 2.961, d_loss 0.103\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 355/390 d_loss_real= 0.066, d_loss_fake= 0.057, g_loss 2.952, d_loss 0.062\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 24 Batch 356/390 d_loss_real= 0.232, d_loss_fake= 0.061, g_loss 2.867, d_loss 0.146\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 24 Batch 357/390 d_loss_real= 0.234, d_loss_fake= 0.074, g_loss 2.557, d_loss 0.154\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24 Batch 358/390 d_loss_real= 0.264, d_loss_fake= 0.134, g_loss 2.650, d_loss 0.199\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 24 Batch 359/390 d_loss_real= 0.171, d_loss_fake= 0.064, g_loss 2.998, d_loss 0.117\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 360/390 d_loss_real= 0.302, d_loss_fake= 0.059, g_loss 2.949, d_loss 0.180\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 361/390 d_loss_real= 0.266, d_loss_fake= 0.065, g_loss 2.745, d_loss 0.166\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 362/390 d_loss_real= 0.096, d_loss_fake= 0.073, g_loss 2.671, d_loss 0.084\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 24 Batch 363/390 d_loss_real= 0.256, d_loss_fake= 0.112, g_loss 2.521, d_loss 0.184\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 24 Batch 364/390 d_loss_real= 0.215, d_loss_fake= 0.103, g_loss 2.726, d_loss 0.159\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24 Batch 365/390 d_loss_real= 0.118, d_loss_fake= 0.063, g_loss 2.935, d_loss 0.091\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 24 Batch 366/390 d_loss_real= 0.319, d_loss_fake= 0.061, g_loss 2.878, d_loss 0.190\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 24 Batch 367/390 d_loss_real= 0.224, d_loss_fake= 0.066, g_loss 2.799, d_loss 0.145\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 24 Batch 368/390 d_loss_real= 0.268, d_loss_fake= 0.081, g_loss 2.580, d_loss 0.175\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 24 Batch 369/390 d_loss_real= 0.184, d_loss_fake= 0.107, g_loss 2.407, d_loss 0.146\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 370/390 d_loss_real= 0.224, d_loss_fake= 0.113, g_loss 2.489, d_loss 0.169\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 371/390 d_loss_real= 0.182, d_loss_fake= 0.086, g_loss 2.668, d_loss 0.134\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 372/390 d_loss_real= 0.132, d_loss_fake= 0.076, g_loss 2.690, d_loss 0.104\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24 Batch 373/390 d_loss_real= 0.123, d_loss_fake= 0.076, g_loss 2.747, d_loss 0.100\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 24 Batch 374/390 d_loss_real= 0.172, d_loss_fake= 0.074, g_loss 2.742, d_loss 0.123\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 24 Batch 375/390 d_loss_real= 0.141, d_loss_fake= 0.067, g_loss 2.822, d_loss 0.104\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 24 Batch 376/390 d_loss_real= 0.338, d_loss_fake= 0.070, g_loss 2.764, d_loss 0.204\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 377/390 d_loss_real= 0.103, d_loss_fake= 0.072, g_loss 2.784, d_loss 0.088\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 24 Batch 378/390 d_loss_real= 0.106, d_loss_fake= 0.065, g_loss 2.852, d_loss 0.086\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24 Batch 379/390 d_loss_real= 0.126, d_loss_fake= 0.062, g_loss 2.873, d_loss 0.094\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 380/390 d_loss_real= 0.064, d_loss_fake= 0.065, g_loss 2.885, d_loss 0.064\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 24 Batch 381/390 d_loss_real= 0.221, d_loss_fake= 0.066, g_loss 2.848, d_loss 0.143\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 24 Batch 382/390 d_loss_real= 0.081, d_loss_fake= 0.064, g_loss 2.899, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 383/390 d_loss_real= 0.116, d_loss_fake= 0.066, g_loss 2.863, d_loss 0.091\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 24 Batch 384/390 d_loss_real= 0.218, d_loss_fake= 0.065, g_loss 2.854, d_loss 0.142\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 24 Batch 385/390 d_loss_real= 0.251, d_loss_fake= 0.068, g_loss 2.879, d_loss 0.159\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 386/390 d_loss_real= 0.159, d_loss_fake= 0.066, g_loss 2.906, d_loss 0.112\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24 Batch 387/390 d_loss_real= 0.154, d_loss_fake= 0.064, g_loss 2.887, d_loss 0.109\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 24 Batch 388/390 d_loss_real= 0.219, d_loss_fake= 0.059, g_loss 2.809, d_loss 0.139\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24 Batch 389/390 d_loss_real= 0.320, d_loss_fake= 0.068, g_loss 2.743, d_loss 0.194\n",
            "2/2 [==============================] - 0s 10ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24 Batch 390/390 d_loss_real= 0.271, d_loss_fake= 0.081, g_loss 2.656, d_loss 0.176\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 1/390 d_loss_real= 0.250, d_loss_fake= 0.088, g_loss 2.468, d_loss 0.169\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 2/390 d_loss_real= 0.166, d_loss_fake= 0.100, g_loss 2.367, d_loss 0.133\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 25 Batch 3/390 d_loss_real= 0.236, d_loss_fake= 0.120, g_loss 2.335, d_loss 0.178\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 4/390 d_loss_real= 0.089, d_loss_fake= 0.104, g_loss 2.537, d_loss 0.097\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 5/390 d_loss_real= 0.158, d_loss_fake= 0.091, g_loss 2.606, d_loss 0.124\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 25 Batch 6/390 d_loss_real= 0.187, d_loss_fake= 0.082, g_loss 2.638, d_loss 0.135\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 25 Batch 7/390 d_loss_real= 0.097, d_loss_fake= 0.083, g_loss 2.617, d_loss 0.090\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 8/390 d_loss_real= 0.236, d_loss_fake= 0.080, g_loss 2.661, d_loss 0.158\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 9/390 d_loss_real= 0.278, d_loss_fake= 0.078, g_loss 2.654, d_loss 0.178\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 10/390 d_loss_real= 0.066, d_loss_fake= 0.076, g_loss 2.678, d_loss 0.071\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 11/390 d_loss_real= 0.116, d_loss_fake= 0.081, g_loss 2.692, d_loss 0.098\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 25 Batch 12/390 d_loss_real= 0.085, d_loss_fake= 0.080, g_loss 2.735, d_loss 0.082\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 13/390 d_loss_real= 0.189, d_loss_fake= 0.077, g_loss 2.732, d_loss 0.133\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 14/390 d_loss_real= 0.240, d_loss_fake= 0.074, g_loss 2.726, d_loss 0.157\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 15/390 d_loss_real= 0.206, d_loss_fake= 0.073, g_loss 2.630, d_loss 0.140\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25 Batch 16/390 d_loss_real= 0.123, d_loss_fake= 0.091, g_loss 2.618, d_loss 0.107\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 17/390 d_loss_real= 0.212, d_loss_fake= 0.084, g_loss 2.625, d_loss 0.148\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 18/390 d_loss_real= 0.096, d_loss_fake= 0.084, g_loss 2.766, d_loss 0.090\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 19/390 d_loss_real= 0.197, d_loss_fake= 0.070, g_loss 2.856, d_loss 0.134\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 20/390 d_loss_real= 0.197, d_loss_fake= 0.061, g_loss 2.908, d_loss 0.129\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 21/390 d_loss_real= 0.179, d_loss_fake= 0.059, g_loss 2.881, d_loss 0.119\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 25 Batch 22/390 d_loss_real= 0.118, d_loss_fake= 0.066, g_loss 2.703, d_loss 0.092\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 25 Batch 23/390 d_loss_real= 0.315, d_loss_fake= 0.090, g_loss 2.506, d_loss 0.203\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 25 Batch 24/390 d_loss_real= 0.218, d_loss_fake= 0.117, g_loss 2.515, d_loss 0.167\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 25 Batch 25/390 d_loss_real= 0.169, d_loss_fake= 0.097, g_loss 2.912, d_loss 0.133\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 26/390 d_loss_real= 0.184, d_loss_fake= 0.053, g_loss 3.123, d_loss 0.118\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 25 Batch 27/390 d_loss_real= 0.196, d_loss_fake= 0.042, g_loss 3.265, d_loss 0.119\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 25 Batch 28/390 d_loss_real= 0.254, d_loss_fake= 0.042, g_loss 3.281, d_loss 0.148\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 29/390 d_loss_real= 0.163, d_loss_fake= 0.044, g_loss 3.154, d_loss 0.104\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 30/390 d_loss_real= 0.171, d_loss_fake= 0.051, g_loss 2.971, d_loss 0.111\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 25 Batch 31/390 d_loss_real= 0.023, d_loss_fake= 0.064, g_loss 2.833, d_loss 0.044\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 32/390 d_loss_real= 0.205, d_loss_fake= 0.074, g_loss 2.632, d_loss 0.139\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 25 Batch 33/390 d_loss_real= 0.162, d_loss_fake= 0.086, g_loss 2.559, d_loss 0.124\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 25 Batch 34/390 d_loss_real= 0.081, d_loss_fake= 0.113, g_loss 2.686, d_loss 0.097\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 35/390 d_loss_real= 0.258, d_loss_fake= 0.062, g_loss 3.076, d_loss 0.160\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 36/390 d_loss_real= 0.218, d_loss_fake= 0.048, g_loss 3.183, d_loss 0.133\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 37/390 d_loss_real= 0.338, d_loss_fake= 0.048, g_loss 3.059, d_loss 0.193\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 38/390 d_loss_real= 0.197, d_loss_fake= 0.058, g_loss 2.831, d_loss 0.127\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 25 Batch 39/390 d_loss_real= 0.252, d_loss_fake= 0.078, g_loss 2.529, d_loss 0.165\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 25 Batch 40/390 d_loss_real= 0.184, d_loss_fake= 0.120, g_loss 2.153, d_loss 0.152\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 41/390 d_loss_real= 0.106, d_loss_fake= 0.198, g_loss 2.548, d_loss 0.152\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 25 Batch 42/390 d_loss_real= 0.210, d_loss_fake= 0.074, g_loss 2.896, d_loss 0.142\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 43/390 d_loss_real= 0.155, d_loss_fake= 0.058, g_loss 2.990, d_loss 0.106\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 44/390 d_loss_real= 0.166, d_loss_fake= 0.059, g_loss 2.924, d_loss 0.112\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 45/390 d_loss_real= 0.293, d_loss_fake= 0.063, g_loss 2.836, d_loss 0.178\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 46/390 d_loss_real= 0.120, d_loss_fake= 0.066, g_loss 2.750, d_loss 0.093\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 47/390 d_loss_real= 0.234, d_loss_fake= 0.074, g_loss 2.700, d_loss 0.154\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25 Batch 48/390 d_loss_real= 0.225, d_loss_fake= 0.083, g_loss 2.569, d_loss 0.154\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 49/390 d_loss_real= 0.212, d_loss_fake= 0.090, g_loss 2.459, d_loss 0.151\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 50/390 d_loss_real= 0.215, d_loss_fake= 0.099, g_loss 2.422, d_loss 0.157\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25 Batch 51/390 d_loss_real= 0.052, d_loss_fake= 0.115, g_loss 2.498, d_loss 0.084\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 25 Batch 52/390 d_loss_real= 0.160, d_loss_fake= 0.104, g_loss 2.627, d_loss 0.132\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 25 Batch 53/390 d_loss_real= 0.217, d_loss_fake= 0.075, g_loss 2.741, d_loss 0.146\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 25 Batch 54/390 d_loss_real= 0.314, d_loss_fake= 0.074, g_loss 2.672, d_loss 0.194\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 55/390 d_loss_real= 0.051, d_loss_fake= 0.078, g_loss 2.642, d_loss 0.064\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 25 Batch 56/390 d_loss_real= 0.134, d_loss_fake= 0.086, g_loss 2.668, d_loss 0.110\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 57/390 d_loss_real= 0.139, d_loss_fake= 0.077, g_loss 2.653, d_loss 0.108\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25 Batch 58/390 d_loss_real= 0.079, d_loss_fake= 0.090, g_loss 2.673, d_loss 0.085\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 25 Batch 59/390 d_loss_real= 0.195, d_loss_fake= 0.080, g_loss 2.763, d_loss 0.137\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 25 Batch 60/390 d_loss_real= 0.179, d_loss_fake= 0.069, g_loss 2.835, d_loss 0.124\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 61/390 d_loss_real= 0.219, d_loss_fake= 0.065, g_loss 2.839, d_loss 0.142\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 25 Batch 62/390 d_loss_real= 0.191, d_loss_fake= 0.065, g_loss 2.832, d_loss 0.128\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 25 Batch 63/390 d_loss_real= 0.204, d_loss_fake= 0.063, g_loss 2.790, d_loss 0.133\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 25 Batch 64/390 d_loss_real= 0.144, d_loss_fake= 0.074, g_loss 2.711, d_loss 0.109\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 65/390 d_loss_real= 0.136, d_loss_fake= 0.072, g_loss 2.766, d_loss 0.104\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 25 Batch 66/390 d_loss_real= 0.111, d_loss_fake= 0.067, g_loss 2.784, d_loss 0.089\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 67/390 d_loss_real= 0.176, d_loss_fake= 0.072, g_loss 2.814, d_loss 0.124\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 25 Batch 68/390 d_loss_real= 0.133, d_loss_fake= 0.068, g_loss 2.722, d_loss 0.100\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25 Batch 69/390 d_loss_real= 0.317, d_loss_fake= 0.089, g_loss 2.678, d_loss 0.203\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25 Batch 70/390 d_loss_real= 0.018, d_loss_fake= 0.103, g_loss 2.654, d_loss 0.061\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25 Batch 71/390 d_loss_real= 0.176, d_loss_fake= 0.072, g_loss 2.902, d_loss 0.124\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 25 Batch 72/390 d_loss_real= 0.159, d_loss_fake= 0.060, g_loss 2.984, d_loss 0.110\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 73/390 d_loss_real= 0.054, d_loss_fake= 0.051, g_loss 3.139, d_loss 0.053\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 25 Batch 74/390 d_loss_real= 0.343, d_loss_fake= 0.048, g_loss 3.130, d_loss 0.196\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25 Batch 75/390 d_loss_real= 0.186, d_loss_fake= 0.052, g_loss 3.044, d_loss 0.119\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 25 Batch 76/390 d_loss_real= 0.180, d_loss_fake= 0.056, g_loss 2.933, d_loss 0.118\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 25 Batch 77/390 d_loss_real= 0.130, d_loss_fake= 0.064, g_loss 2.865, d_loss 0.097\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 25 Batch 78/390 d_loss_real= 0.157, d_loss_fake= 0.082, g_loss 2.691, d_loss 0.119\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 79/390 d_loss_real= 0.161, d_loss_fake= 0.105, g_loss 2.565, d_loss 0.133\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 25 Batch 80/390 d_loss_real= 0.120, d_loss_fake= 0.081, g_loss 2.699, d_loss 0.101\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 81/390 d_loss_real= 0.218, d_loss_fake= 0.077, g_loss 2.793, d_loss 0.147\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 82/390 d_loss_real= 0.077, d_loss_fake= 0.076, g_loss 2.896, d_loss 0.076\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 83/390 d_loss_real= 0.283, d_loss_fake= 0.064, g_loss 2.969, d_loss 0.173\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 25 Batch 84/390 d_loss_real= 0.167, d_loss_fake= 0.055, g_loss 3.069, d_loss 0.111\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 25 Batch 85/390 d_loss_real= 0.302, d_loss_fake= 0.052, g_loss 3.001, d_loss 0.177\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 86/390 d_loss_real= 0.299, d_loss_fake= 0.059, g_loss 2.851, d_loss 0.179\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 25 Batch 87/390 d_loss_real= 0.129, d_loss_fake= 0.064, g_loss 2.811, d_loss 0.096\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 88/390 d_loss_real= 0.076, d_loss_fake= 0.079, g_loss 2.743, d_loss 0.077\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 89/390 d_loss_real= 0.097, d_loss_fake= 0.069, g_loss 2.788, d_loss 0.083\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 25 Batch 90/390 d_loss_real= 0.140, d_loss_fake= 0.076, g_loss 2.848, d_loss 0.108\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 91/390 d_loss_real= 0.115, d_loss_fake= 0.062, g_loss 2.868, d_loss 0.089\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 92/390 d_loss_real= 0.052, d_loss_fake= 0.060, g_loss 2.947, d_loss 0.056\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 93/390 d_loss_real= 0.054, d_loss_fake= 0.053, g_loss 3.132, d_loss 0.053\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 25 Batch 94/390 d_loss_real= 0.222, d_loss_fake= 0.047, g_loss 3.112, d_loss 0.134\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25 Batch 95/390 d_loss_real= 0.210, d_loss_fake= 0.047, g_loss 3.117, d_loss 0.128\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 96/390 d_loss_real= 0.224, d_loss_fake= 0.056, g_loss 2.894, d_loss 0.140\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 97/390 d_loss_real= 0.128, d_loss_fake= 0.078, g_loss 2.802, d_loss 0.103\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 25 Batch 98/390 d_loss_real= 0.133, d_loss_fake= 0.094, g_loss 2.685, d_loss 0.113\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 25 Batch 99/390 d_loss_real= 0.232, d_loss_fake= 0.080, g_loss 2.827, d_loss 0.156\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 100/390 d_loss_real= 0.218, d_loss_fake= 0.072, g_loss 2.842, d_loss 0.145\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 101/390 d_loss_real= 0.095, d_loss_fake= 0.060, g_loss 3.045, d_loss 0.077\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25 Batch 102/390 d_loss_real= 0.426, d_loss_fake= 0.063, g_loss 2.874, d_loss 0.244\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 25 Batch 103/390 d_loss_real= 0.307, d_loss_fake= 0.089, g_loss 2.824, d_loss 0.198\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 25 Batch 104/390 d_loss_real= 0.139, d_loss_fake= 0.062, g_loss 3.101, d_loss 0.100\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 105/390 d_loss_real= 0.105, d_loss_fake= 0.045, g_loss 3.311, d_loss 0.075\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 106/390 d_loss_real= 0.247, d_loss_fake= 0.043, g_loss 3.188, d_loss 0.145\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 107/390 d_loss_real= 0.210, d_loss_fake= 0.061, g_loss 2.739, d_loss 0.136\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 25 Batch 108/390 d_loss_real= 0.217, d_loss_fake= 0.102, g_loss 2.723, d_loss 0.160\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 109/390 d_loss_real= 0.050, d_loss_fake= 0.065, g_loss 2.979, d_loss 0.057\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 110/390 d_loss_real= 0.102, d_loss_fake= 0.051, g_loss 3.222, d_loss 0.076\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 25 Batch 111/390 d_loss_real= 0.136, d_loss_fake= 0.043, g_loss 3.262, d_loss 0.090\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 112/390 d_loss_real= 0.100, d_loss_fake= 0.042, g_loss 3.316, d_loss 0.071\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 113/390 d_loss_real= 0.124, d_loss_fake= 0.043, g_loss 3.198, d_loss 0.083\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 114/390 d_loss_real= 0.162, d_loss_fake= 0.056, g_loss 3.044, d_loss 0.109\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 25 Batch 115/390 d_loss_real= 0.184, d_loss_fake= 0.069, g_loss 2.913, d_loss 0.126\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 116/390 d_loss_real= 0.131, d_loss_fake= 0.072, g_loss 2.962, d_loss 0.102\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 117/390 d_loss_real= 0.054, d_loss_fake= 0.060, g_loss 3.202, d_loss 0.057\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 118/390 d_loss_real= 0.186, d_loss_fake= 0.043, g_loss 3.253, d_loss 0.114\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 25 Batch 119/390 d_loss_real= 0.172, d_loss_fake= 0.049, g_loss 3.165, d_loss 0.110\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 120/390 d_loss_real= 0.330, d_loss_fake= 0.054, g_loss 2.976, d_loss 0.192\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 25 Batch 121/390 d_loss_real= 0.383, d_loss_fake= 0.066, g_loss 2.741, d_loss 0.224\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 25 Batch 122/390 d_loss_real= 0.073, d_loss_fake= 0.094, g_loss 2.606, d_loss 0.084\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 123/390 d_loss_real= 0.197, d_loss_fake= 0.086, g_loss 2.680, d_loss 0.141\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 124/390 d_loss_real= 0.112, d_loss_fake= 0.078, g_loss 2.686, d_loss 0.095\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 125/390 d_loss_real= 0.087, d_loss_fake= 0.079, g_loss 2.724, d_loss 0.083\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 126/390 d_loss_real= 0.221, d_loss_fake= 0.078, g_loss 2.774, d_loss 0.150\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 25 Batch 127/390 d_loss_real= 0.112, d_loss_fake= 0.073, g_loss 2.841, d_loss 0.092\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 25 Batch 128/390 d_loss_real= 0.149, d_loss_fake= 0.070, g_loss 2.772, d_loss 0.110\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25 Batch 129/390 d_loss_real= 0.147, d_loss_fake= 0.075, g_loss 2.807, d_loss 0.111\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 130/390 d_loss_real= 0.159, d_loss_fake= 0.083, g_loss 2.726, d_loss 0.121\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 25 Batch 131/390 d_loss_real= 0.155, d_loss_fake= 0.081, g_loss 2.848, d_loss 0.118\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 132/390 d_loss_real= 0.278, d_loss_fake= 0.062, g_loss 2.961, d_loss 0.170\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 133/390 d_loss_real= 0.131, d_loss_fake= 0.054, g_loss 3.083, d_loss 0.092\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25 Batch 134/390 d_loss_real= 0.103, d_loss_fake= 0.052, g_loss 3.016, d_loss 0.078\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 135/390 d_loss_real= 0.306, d_loss_fake= 0.062, g_loss 2.843, d_loss 0.184\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 25 Batch 136/390 d_loss_real= 0.325, d_loss_fake= 0.091, g_loss 2.687, d_loss 0.208\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 137/390 d_loss_real= 0.146, d_loss_fake= 0.087, g_loss 2.907, d_loss 0.116\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 25 Batch 138/390 d_loss_real= 0.281, d_loss_fake= 0.060, g_loss 2.941, d_loss 0.171\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 139/390 d_loss_real= 0.296, d_loss_fake= 0.063, g_loss 2.795, d_loss 0.180\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 140/390 d_loss_real= 0.205, d_loss_fake= 0.074, g_loss 2.756, d_loss 0.139\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 25 Batch 141/390 d_loss_real= 0.147, d_loss_fake= 0.081, g_loss 2.664, d_loss 0.114\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 25 Batch 142/390 d_loss_real= 0.104, d_loss_fake= 0.072, g_loss 2.759, d_loss 0.088\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 25 Batch 143/390 d_loss_real= 0.057, d_loss_fake= 0.077, g_loss 2.772, d_loss 0.067\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 144/390 d_loss_real= 0.070, d_loss_fake= 0.068, g_loss 2.947, d_loss 0.069\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 25 Batch 145/390 d_loss_real= 0.089, d_loss_fake= 0.057, g_loss 3.035, d_loss 0.073\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 25 Batch 146/390 d_loss_real= 0.231, d_loss_fake= 0.055, g_loss 3.050, d_loss 0.143\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 25 Batch 147/390 d_loss_real= 0.295, d_loss_fake= 0.055, g_loss 2.925, d_loss 0.175\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 148/390 d_loss_real= 0.079, d_loss_fake= 0.075, g_loss 2.687, d_loss 0.077\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 149/390 d_loss_real= 0.111, d_loss_fake= 0.080, g_loss 2.636, d_loss 0.095\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25 Batch 150/390 d_loss_real= 0.148, d_loss_fake= 0.095, g_loss 2.688, d_loss 0.122\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25 Batch 151/390 d_loss_real= 0.138, d_loss_fake= 0.077, g_loss 2.939, d_loss 0.107\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 152/390 d_loss_real= 0.104, d_loss_fake= 0.059, g_loss 3.174, d_loss 0.081\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 153/390 d_loss_real= 0.218, d_loss_fake= 0.046, g_loss 3.248, d_loss 0.132\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 154/390 d_loss_real= 0.328, d_loss_fake= 0.044, g_loss 3.223, d_loss 0.186\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 155/390 d_loss_real= 0.294, d_loss_fake= 0.046, g_loss 3.072, d_loss 0.170\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 156/390 d_loss_real= 0.167, d_loss_fake= 0.058, g_loss 2.849, d_loss 0.112\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25 Batch 157/390 d_loss_real= 0.156, d_loss_fake= 0.082, g_loss 2.653, d_loss 0.119\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 158/390 d_loss_real= 0.188, d_loss_fake= 0.095, g_loss 2.628, d_loss 0.142\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 25 Batch 159/390 d_loss_real= 0.143, d_loss_fake= 0.084, g_loss 2.803, d_loss 0.114\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 160/390 d_loss_real= 0.250, d_loss_fake= 0.068, g_loss 2.899, d_loss 0.159\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 161/390 d_loss_real= 0.104, d_loss_fake= 0.057, g_loss 3.043, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 162/390 d_loss_real= 0.299, d_loss_fake= 0.054, g_loss 3.046, d_loss 0.176\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 25 Batch 163/390 d_loss_real= 0.221, d_loss_fake= 0.057, g_loss 2.984, d_loss 0.139\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25 Batch 164/390 d_loss_real= 0.127, d_loss_fake= 0.058, g_loss 2.947, d_loss 0.093\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 165/390 d_loss_real= 0.244, d_loss_fake= 0.061, g_loss 2.809, d_loss 0.153\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 25 Batch 166/390 d_loss_real= 0.125, d_loss_fake= 0.073, g_loss 2.777, d_loss 0.099\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 25 Batch 167/390 d_loss_real= 0.137, d_loss_fake= 0.078, g_loss 2.681, d_loss 0.107\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 25 Batch 168/390 d_loss_real= 0.055, d_loss_fake= 0.075, g_loss 2.660, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 169/390 d_loss_real= 0.188, d_loss_fake= 0.082, g_loss 2.689, d_loss 0.135\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 25 Batch 170/390 d_loss_real= 0.230, d_loss_fake= 0.079, g_loss 2.856, d_loss 0.155\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 171/390 d_loss_real= 0.138, d_loss_fake= 0.068, g_loss 2.956, d_loss 0.103\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 25 Batch 172/390 d_loss_real= 0.054, d_loss_fake= 0.053, g_loss 3.066, d_loss 0.053\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 173/390 d_loss_real= 0.227, d_loss_fake= 0.057, g_loss 3.139, d_loss 0.142\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 174/390 d_loss_real= 0.116, d_loss_fake= 0.060, g_loss 2.952, d_loss 0.088\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 175/390 d_loss_real= 0.283, d_loss_fake= 0.071, g_loss 2.601, d_loss 0.177\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 25 Batch 176/390 d_loss_real= 0.176, d_loss_fake= 0.151, g_loss 2.350, d_loss 0.163\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 177/390 d_loss_real= 0.094, d_loss_fake= 0.119, g_loss 2.822, d_loss 0.106\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 25 Batch 178/390 d_loss_real= 0.210, d_loss_fake= 0.056, g_loss 3.171, d_loss 0.133\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 179/390 d_loss_real= 0.241, d_loss_fake= 0.046, g_loss 3.313, d_loss 0.143\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25 Batch 180/390 d_loss_real= 0.481, d_loss_fake= 0.047, g_loss 3.138, d_loss 0.264\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 25 Batch 181/390 d_loss_real= 0.351, d_loss_fake= 0.058, g_loss 2.860, d_loss 0.205\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 25 Batch 182/390 d_loss_real= 0.155, d_loss_fake= 0.076, g_loss 2.605, d_loss 0.116\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 183/390 d_loss_real= 0.104, d_loss_fake= 0.100, g_loss 2.330, d_loss 0.102\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 184/390 d_loss_real= 0.172, d_loss_fake= 0.120, g_loss 2.324, d_loss 0.146\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 185/390 d_loss_real= 0.131, d_loss_fake= 0.109, g_loss 2.469, d_loss 0.120\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 186/390 d_loss_real= 0.150, d_loss_fake= 0.107, g_loss 2.424, d_loss 0.128\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 187/390 d_loss_real= 0.018, d_loss_fake= 0.099, g_loss 2.608, d_loss 0.058\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 25 Batch 188/390 d_loss_real= 0.277, d_loss_fake= 0.076, g_loss 2.724, d_loss 0.177\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 25 Batch 189/390 d_loss_real= 0.212, d_loss_fake= 0.073, g_loss 2.733, d_loss 0.142\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 190/390 d_loss_real= 0.297, d_loss_fake= 0.070, g_loss 2.742, d_loss 0.184\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 25 Batch 191/390 d_loss_real= 0.072, d_loss_fake= 0.075, g_loss 2.739, d_loss 0.073\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 25 Batch 192/390 d_loss_real= 0.130, d_loss_fake= 0.071, g_loss 2.711, d_loss 0.100\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 25 Batch 193/390 d_loss_real= 0.191, d_loss_fake= 0.078, g_loss 2.644, d_loss 0.135\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 194/390 d_loss_real= 0.156, d_loss_fake= 0.083, g_loss 2.588, d_loss 0.120\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 195/390 d_loss_real= 0.111, d_loss_fake= 0.084, g_loss 2.637, d_loss 0.098\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 196/390 d_loss_real= 0.158, d_loss_fake= 0.075, g_loss 2.674, d_loss 0.116\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 197/390 d_loss_real= 0.194, d_loss_fake= 0.074, g_loss 2.666, d_loss 0.134\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 25 Batch 198/390 d_loss_real= 0.088, d_loss_fake= 0.078, g_loss 2.765, d_loss 0.083\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 199/390 d_loss_real= 0.299, d_loss_fake= 0.074, g_loss 2.758, d_loss 0.187\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 25 Batch 200/390 d_loss_real= 0.279, d_loss_fake= 0.076, g_loss 2.676, d_loss 0.178\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 201/390 d_loss_real= 0.091, d_loss_fake= 0.077, g_loss 2.737, d_loss 0.084\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25 Batch 202/390 d_loss_real= 0.112, d_loss_fake= 0.068, g_loss 2.876, d_loss 0.090\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 203/390 d_loss_real= 0.108, d_loss_fake= 0.063, g_loss 2.891, d_loss 0.086\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 204/390 d_loss_real= 0.329, d_loss_fake= 0.063, g_loss 2.873, d_loss 0.196\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 205/390 d_loss_real= 0.154, d_loss_fake= 0.061, g_loss 2.914, d_loss 0.107\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25 Batch 206/390 d_loss_real= 0.224, d_loss_fake= 0.063, g_loss 2.858, d_loss 0.144\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 207/390 d_loss_real= 0.137, d_loss_fake= 0.072, g_loss 2.835, d_loss 0.105\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 25 Batch 208/390 d_loss_real= 0.221, d_loss_fake= 0.068, g_loss 2.807, d_loss 0.145\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 25 Batch 209/390 d_loss_real= 0.177, d_loss_fake= 0.084, g_loss 2.644, d_loss 0.131\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 210/390 d_loss_real= 0.165, d_loss_fake= 0.084, g_loss 2.631, d_loss 0.125\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 211/390 d_loss_real= 0.222, d_loss_fake= 0.085, g_loss 2.706, d_loss 0.153\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 212/390 d_loss_real= 0.097, d_loss_fake= 0.061, g_loss 2.981, d_loss 0.079\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 213/390 d_loss_real= 0.201, d_loss_fake= 0.057, g_loss 3.012, d_loss 0.129\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 25 Batch 214/390 d_loss_real= 0.154, d_loss_fake= 0.055, g_loss 2.972, d_loss 0.105\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 215/390 d_loss_real= 0.224, d_loss_fake= 0.063, g_loss 2.879, d_loss 0.143\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 216/390 d_loss_real= 0.108, d_loss_fake= 0.068, g_loss 2.783, d_loss 0.088\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 217/390 d_loss_real= 0.050, d_loss_fake= 0.074, g_loss 2.745, d_loss 0.062\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 25 Batch 218/390 d_loss_real= 0.378, d_loss_fake= 0.082, g_loss 2.706, d_loss 0.230\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 219/390 d_loss_real= 0.097, d_loss_fake= 0.081, g_loss 2.728, d_loss 0.089\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 220/390 d_loss_real= 0.174, d_loss_fake= 0.072, g_loss 2.837, d_loss 0.123\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 221/390 d_loss_real= 0.257, d_loss_fake= 0.068, g_loss 2.780, d_loss 0.162\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 222/390 d_loss_real= 0.197, d_loss_fake= 0.077, g_loss 2.618, d_loss 0.137\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 25 Batch 223/390 d_loss_real= 0.087, d_loss_fake= 0.079, g_loss 2.682, d_loss 0.083\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 224/390 d_loss_real= 0.118, d_loss_fake= 0.092, g_loss 2.793, d_loss 0.105\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 225/390 d_loss_real= 0.376, d_loss_fake= 0.075, g_loss 2.775, d_loss 0.226\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 226/390 d_loss_real= 0.167, d_loss_fake= 0.067, g_loss 2.920, d_loss 0.117\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 227/390 d_loss_real= 0.101, d_loss_fake= 0.062, g_loss 2.896, d_loss 0.082\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 228/390 d_loss_real= 0.083, d_loss_fake= 0.067, g_loss 2.845, d_loss 0.075\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 25 Batch 229/390 d_loss_real= 0.260, d_loss_fake= 0.073, g_loss 2.677, d_loss 0.166\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25 Batch 230/390 d_loss_real= 0.132, d_loss_fake= 0.086, g_loss 2.683, d_loss 0.109\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 231/390 d_loss_real= 0.205, d_loss_fake= 0.076, g_loss 2.751, d_loss 0.141\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 25 Batch 232/390 d_loss_real= 0.127, d_loss_fake= 0.077, g_loss 2.790, d_loss 0.102\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 233/390 d_loss_real= 0.288, d_loss_fake= 0.074, g_loss 2.747, d_loss 0.181\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 234/390 d_loss_real= 0.185, d_loss_fake= 0.066, g_loss 2.833, d_loss 0.125\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 25 Batch 235/390 d_loss_real= 0.307, d_loss_fake= 0.077, g_loss 2.698, d_loss 0.192\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 236/390 d_loss_real= 0.142, d_loss_fake= 0.076, g_loss 2.691, d_loss 0.109\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 237/390 d_loss_real= 0.018, d_loss_fake= 0.069, g_loss 2.850, d_loss 0.043\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 25 Batch 238/390 d_loss_real= 0.219, d_loss_fake= 0.074, g_loss 2.728, d_loss 0.147\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 239/390 d_loss_real= 0.211, d_loss_fake= 0.072, g_loss 2.685, d_loss 0.141\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25 Batch 240/390 d_loss_real= 0.068, d_loss_fake= 0.077, g_loss 2.713, d_loss 0.072\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 241/390 d_loss_real= 0.120, d_loss_fake= 0.074, g_loss 2.808, d_loss 0.097\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 242/390 d_loss_real= 0.088, d_loss_fake= 0.059, g_loss 2.890, d_loss 0.074\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 25 Batch 243/390 d_loss_real= 0.145, d_loss_fake= 0.059, g_loss 2.932, d_loss 0.102\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 244/390 d_loss_real= 0.165, d_loss_fake= 0.058, g_loss 2.880, d_loss 0.111\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 25 Batch 245/390 d_loss_real= 0.143, d_loss_fake= 0.066, g_loss 2.848, d_loss 0.105\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 25 Batch 246/390 d_loss_real= 0.140, d_loss_fake= 0.070, g_loss 2.873, d_loss 0.105\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 25 Batch 247/390 d_loss_real= 0.036, d_loss_fake= 0.059, g_loss 2.965, d_loss 0.048\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 248/390 d_loss_real= 0.132, d_loss_fake= 0.053, g_loss 3.048, d_loss 0.092\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 25 Batch 249/390 d_loss_real= 0.202, d_loss_fake= 0.052, g_loss 3.045, d_loss 0.127\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 25 Batch 250/390 d_loss_real= 0.106, d_loss_fake= 0.056, g_loss 2.993, d_loss 0.081\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 25 Batch 251/390 d_loss_real= 0.104, d_loss_fake= 0.055, g_loss 3.013, d_loss 0.079\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25 Batch 252/390 d_loss_real= 0.203, d_loss_fake= 0.057, g_loss 2.949, d_loss 0.130\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 253/390 d_loss_real= 0.232, d_loss_fake= 0.057, g_loss 2.912, d_loss 0.145\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 254/390 d_loss_real= 0.213, d_loss_fake= 0.060, g_loss 2.876, d_loss 0.137\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 255/390 d_loss_real= 0.154, d_loss_fake= 0.072, g_loss 2.739, d_loss 0.113\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25 Batch 256/390 d_loss_real= 0.075, d_loss_fake= 0.077, g_loss 2.721, d_loss 0.076\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 257/390 d_loss_real= 0.074, d_loss_fake= 0.080, g_loss 2.786, d_loss 0.077\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 25 Batch 258/390 d_loss_real= 0.162, d_loss_fake= 0.073, g_loss 2.831, d_loss 0.117\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 25 Batch 259/390 d_loss_real= 0.034, d_loss_fake= 0.076, g_loss 2.813, d_loss 0.055\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 25 Batch 260/390 d_loss_real= 0.104, d_loss_fake= 0.068, g_loss 2.907, d_loss 0.086\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 25 Batch 261/390 d_loss_real= 0.313, d_loss_fake= 0.066, g_loss 2.883, d_loss 0.190\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 262/390 d_loss_real= 0.174, d_loss_fake= 0.073, g_loss 2.840, d_loss 0.124\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 263/390 d_loss_real= 0.200, d_loss_fake= 0.072, g_loss 2.650, d_loss 0.136\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 25 Batch 264/390 d_loss_real= 0.199, d_loss_fake= 0.094, g_loss 2.602, d_loss 0.147\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 265/390 d_loss_real= 0.023, d_loss_fake= 0.060, g_loss 3.013, d_loss 0.042\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 266/390 d_loss_real= 0.212, d_loss_fake= 0.064, g_loss 2.961, d_loss 0.138\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 267/390 d_loss_real= 0.280, d_loss_fake= 0.071, g_loss 2.782, d_loss 0.175\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 25 Batch 268/390 d_loss_real= 0.077, d_loss_fake= 0.075, g_loss 2.837, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 269/390 d_loss_real= 0.074, d_loss_fake= 0.064, g_loss 2.943, d_loss 0.069\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 270/390 d_loss_real= 0.309, d_loss_fake= 0.057, g_loss 3.062, d_loss 0.183\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 25 Batch 271/390 d_loss_real= 0.277, d_loss_fake= 0.046, g_loss 3.248, d_loss 0.162\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25 Batch 272/390 d_loss_real= 0.273, d_loss_fake= 0.045, g_loss 3.105, d_loss 0.159\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 25 Batch 273/390 d_loss_real= 0.168, d_loss_fake= 0.054, g_loss 2.911, d_loss 0.111\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 274/390 d_loss_real= 0.143, d_loss_fake= 0.073, g_loss 2.774, d_loss 0.108\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 275/390 d_loss_real= 0.173, d_loss_fake= 0.077, g_loss 2.841, d_loss 0.125\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 276/390 d_loss_real= 0.091, d_loss_fake= 0.060, g_loss 2.998, d_loss 0.076\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 277/390 d_loss_real= 0.218, d_loss_fake= 0.050, g_loss 3.114, d_loss 0.134\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25 Batch 278/390 d_loss_real= 0.361, d_loss_fake= 0.047, g_loss 3.144, d_loss 0.204\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 279/390 d_loss_real= 0.277, d_loss_fake= 0.048, g_loss 3.048, d_loss 0.163\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25 Batch 280/390 d_loss_real= 0.149, d_loss_fake= 0.055, g_loss 2.940, d_loss 0.102\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 281/390 d_loss_real= 0.236, d_loss_fake= 0.069, g_loss 2.611, d_loss 0.153\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 282/390 d_loss_real= 0.078, d_loss_fake= 0.101, g_loss 2.488, d_loss 0.090\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 283/390 d_loss_real= 0.062, d_loss_fake= 0.115, g_loss 2.597, d_loss 0.089\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 284/390 d_loss_real= 0.131, d_loss_fake= 0.065, g_loss 2.989, d_loss 0.098\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 25 Batch 285/390 d_loss_real= 0.263, d_loss_fake= 0.049, g_loss 3.104, d_loss 0.156\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 25 Batch 286/390 d_loss_real= 0.169, d_loss_fake= 0.051, g_loss 3.056, d_loss 0.110\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 287/390 d_loss_real= 0.131, d_loss_fake= 0.057, g_loss 2.911, d_loss 0.094\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 288/390 d_loss_real= 0.139, d_loss_fake= 0.076, g_loss 2.667, d_loss 0.108\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 289/390 d_loss_real= 0.359, d_loss_fake= 0.107, g_loss 2.358, d_loss 0.233\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 25 Batch 290/390 d_loss_real= 0.070, d_loss_fake= 0.089, g_loss 2.642, d_loss 0.079\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 291/390 d_loss_real= 0.185, d_loss_fake= 0.104, g_loss 2.691, d_loss 0.145\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 25 Batch 292/390 d_loss_real= 0.265, d_loss_fake= 0.074, g_loss 2.826, d_loss 0.169\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 25 Batch 293/390 d_loss_real= 0.037, d_loss_fake= 0.058, g_loss 3.081, d_loss 0.047\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 25 Batch 294/390 d_loss_real= 0.243, d_loss_fake= 0.050, g_loss 3.131, d_loss 0.147\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 25 Batch 295/390 d_loss_real= 0.264, d_loss_fake= 0.053, g_loss 3.032, d_loss 0.158\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 25 Batch 296/390 d_loss_real= 0.022, d_loss_fake= 0.057, g_loss 3.012, d_loss 0.039\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 25 Batch 297/390 d_loss_real= 0.194, d_loss_fake= 0.062, g_loss 2.821, d_loss 0.128\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 298/390 d_loss_real= 0.223, d_loss_fake= 0.064, g_loss 2.704, d_loss 0.144\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 299/390 d_loss_real= 0.093, d_loss_fake= 0.086, g_loss 2.718, d_loss 0.090\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 25 Batch 300/390 d_loss_real= 0.262, d_loss_fake= 0.097, g_loss 2.710, d_loss 0.180\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 301/390 d_loss_real= 0.278, d_loss_fake= 0.071, g_loss 2.939, d_loss 0.175\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 302/390 d_loss_real= 0.167, d_loss_fake= 0.054, g_loss 3.014, d_loss 0.111\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 303/390 d_loss_real= 0.211, d_loss_fake= 0.055, g_loss 3.075, d_loss 0.133\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 304/390 d_loss_real= 0.225, d_loss_fake= 0.054, g_loss 2.959, d_loss 0.140\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 25 Batch 305/390 d_loss_real= 0.250, d_loss_fake= 0.062, g_loss 2.738, d_loss 0.156\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 306/390 d_loss_real= 0.356, d_loss_fake= 0.102, g_loss 2.296, d_loss 0.229\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 25 Batch 307/390 d_loss_real= 0.035, d_loss_fake= 0.152, g_loss 2.245, d_loss 0.093\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 308/390 d_loss_real= 0.264, d_loss_fake= 0.096, g_loss 2.692, d_loss 0.180\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 309/390 d_loss_real= 0.094, d_loss_fake= 0.062, g_loss 2.937, d_loss 0.078\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 25 Batch 310/390 d_loss_real= 0.196, d_loss_fake= 0.059, g_loss 2.889, d_loss 0.128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 311/390 d_loss_real= 0.105, d_loss_fake= 0.062, g_loss 2.804, d_loss 0.084\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 25 Batch 312/390 d_loss_real= 0.129, d_loss_fake= 0.076, g_loss 2.640, d_loss 0.103\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 25 Batch 313/390 d_loss_real= 0.103, d_loss_fake= 0.078, g_loss 2.691, d_loss 0.091\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 314/390 d_loss_real= 0.148, d_loss_fake= 0.072, g_loss 2.772, d_loss 0.110\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 25 Batch 315/390 d_loss_real= 0.099, d_loss_fake= 0.067, g_loss 2.870, d_loss 0.083\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 316/390 d_loss_real= 0.189, d_loss_fake= 0.063, g_loss 2.905, d_loss 0.126\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 317/390 d_loss_real= 0.237, d_loss_fake= 0.060, g_loss 2.897, d_loss 0.148\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 318/390 d_loss_real= 0.118, d_loss_fake= 0.063, g_loss 2.909, d_loss 0.090\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 319/390 d_loss_real= 0.175, d_loss_fake= 0.066, g_loss 2.821, d_loss 0.121\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25 Batch 320/390 d_loss_real= 0.127, d_loss_fake= 0.068, g_loss 2.847, d_loss 0.098\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 321/390 d_loss_real= 0.069, d_loss_fake= 0.065, g_loss 2.899, d_loss 0.067\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 322/390 d_loss_real= 0.115, d_loss_fake= 0.063, g_loss 3.006, d_loss 0.089\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 323/390 d_loss_real= 0.210, d_loss_fake= 0.053, g_loss 3.006, d_loss 0.131\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 324/390 d_loss_real= 0.066, d_loss_fake= 0.059, g_loss 2.874, d_loss 0.062\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 325/390 d_loss_real= 0.241, d_loss_fake= 0.080, g_loss 2.801, d_loss 0.161\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 326/390 d_loss_real= 0.105, d_loss_fake= 0.056, g_loss 3.022, d_loss 0.081\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 327/390 d_loss_real= 0.146, d_loss_fake= 0.051, g_loss 3.156, d_loss 0.098\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 328/390 d_loss_real= 0.128, d_loss_fake= 0.047, g_loss 3.169, d_loss 0.087\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 329/390 d_loss_real= 0.116, d_loss_fake= 0.043, g_loss 3.247, d_loss 0.080\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 25 Batch 330/390 d_loss_real= 0.159, d_loss_fake= 0.046, g_loss 3.034, d_loss 0.103\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 25 Batch 331/390 d_loss_real= 0.119, d_loss_fake= 0.067, g_loss 2.791, d_loss 0.093\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 332/390 d_loss_real= 0.285, d_loss_fake= 0.104, g_loss 2.679, d_loss 0.195\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 25 Batch 333/390 d_loss_real= 0.198, d_loss_fake= 0.069, g_loss 2.891, d_loss 0.133\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 334/390 d_loss_real= 0.153, d_loss_fake= 0.058, g_loss 3.016, d_loss 0.105\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 25 Batch 335/390 d_loss_real= 0.106, d_loss_fake= 0.059, g_loss 3.056, d_loss 0.082\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 336/390 d_loss_real= 0.142, d_loss_fake= 0.046, g_loss 3.194, d_loss 0.094\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 337/390 d_loss_real= 0.281, d_loss_fake= 0.051, g_loss 2.998, d_loss 0.166\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 25 Batch 338/390 d_loss_real= 0.196, d_loss_fake= 0.065, g_loss 2.777, d_loss 0.130\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 339/390 d_loss_real= 0.251, d_loss_fake= 0.077, g_loss 2.732, d_loss 0.164\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 340/390 d_loss_real= 0.165, d_loss_fake= 0.088, g_loss 2.688, d_loss 0.126\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 25 Batch 341/390 d_loss_real= 0.068, d_loss_fake= 0.069, g_loss 2.855, d_loss 0.069\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 342/390 d_loss_real= 0.156, d_loss_fake= 0.066, g_loss 2.862, d_loss 0.111\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 343/390 d_loss_real= 0.192, d_loss_fake= 0.066, g_loss 2.843, d_loss 0.129\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 344/390 d_loss_real= 0.163, d_loss_fake= 0.066, g_loss 2.894, d_loss 0.114\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 345/390 d_loss_real= 0.064, d_loss_fake= 0.060, g_loss 2.932, d_loss 0.062\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25 Batch 346/390 d_loss_real= 0.201, d_loss_fake= 0.058, g_loss 2.945, d_loss 0.130\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 347/390 d_loss_real= 0.093, d_loss_fake= 0.062, g_loss 2.827, d_loss 0.078\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 348/390 d_loss_real= 0.068, d_loss_fake= 0.073, g_loss 2.717, d_loss 0.071\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 349/390 d_loss_real= 0.239, d_loss_fake= 0.073, g_loss 2.790, d_loss 0.156\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 25 Batch 350/390 d_loss_real= 0.254, d_loss_fake= 0.070, g_loss 2.741, d_loss 0.162\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 351/390 d_loss_real= 0.049, d_loss_fake= 0.067, g_loss 2.859, d_loss 0.058\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 25 Batch 352/390 d_loss_real= 0.131, d_loss_fake= 0.069, g_loss 2.797, d_loss 0.100\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 353/390 d_loss_real= 0.177, d_loss_fake= 0.067, g_loss 2.859, d_loss 0.122\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 25 Batch 354/390 d_loss_real= 0.392, d_loss_fake= 0.072, g_loss 2.845, d_loss 0.232\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 355/390 d_loss_real= 0.037, d_loss_fake= 0.061, g_loss 2.958, d_loss 0.049\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 356/390 d_loss_real= 0.066, d_loss_fake= 0.054, g_loss 3.029, d_loss 0.060\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 357/390 d_loss_real= 0.262, d_loss_fake= 0.054, g_loss 2.999, d_loss 0.158\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 358/390 d_loss_real= 0.164, d_loss_fake= 0.057, g_loss 2.922, d_loss 0.111\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 359/390 d_loss_real= 0.191, d_loss_fake= 0.065, g_loss 2.776, d_loss 0.128\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 360/390 d_loss_real= 0.167, d_loss_fake= 0.086, g_loss 2.621, d_loss 0.127\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 361/390 d_loss_real= 0.106, d_loss_fake= 0.079, g_loss 2.732, d_loss 0.092\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25 Batch 362/390 d_loss_real= 0.017, d_loss_fake= 0.066, g_loss 2.889, d_loss 0.042\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 25 Batch 363/390 d_loss_real= 0.252, d_loss_fake= 0.060, g_loss 2.977, d_loss 0.156\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 364/390 d_loss_real= 0.246, d_loss_fake= 0.056, g_loss 2.854, d_loss 0.151\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 365/390 d_loss_real= 0.030, d_loss_fake= 0.067, g_loss 2.878, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 366/390 d_loss_real= 0.113, d_loss_fake= 0.070, g_loss 2.855, d_loss 0.092\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 25 Batch 367/390 d_loss_real= 0.098, d_loss_fake= 0.066, g_loss 2.865, d_loss 0.082\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 25 Batch 368/390 d_loss_real= 0.110, d_loss_fake= 0.058, g_loss 3.039, d_loss 0.084\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 369/390 d_loss_real= 0.212, d_loss_fake= 0.052, g_loss 3.003, d_loss 0.132\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 370/390 d_loss_real= 0.030, d_loss_fake= 0.058, g_loss 3.087, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 371/390 d_loss_real= 0.088, d_loss_fake= 0.053, g_loss 3.109, d_loss 0.070\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 25 Batch 372/390 d_loss_real= 0.296, d_loss_fake= 0.053, g_loss 2.965, d_loss 0.174\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 373/390 d_loss_real= 0.019, d_loss_fake= 0.061, g_loss 2.960, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 374/390 d_loss_real= 0.205, d_loss_fake= 0.065, g_loss 2.956, d_loss 0.135\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25 Batch 375/390 d_loss_real= 0.089, d_loss_fake= 0.058, g_loss 3.076, d_loss 0.073\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 25 Batch 376/390 d_loss_real= 0.259, d_loss_fake= 0.054, g_loss 3.136, d_loss 0.156\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 377/390 d_loss_real= 0.048, d_loss_fake= 0.051, g_loss 3.141, d_loss 0.050\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 25 Batch 378/390 d_loss_real= 0.166, d_loss_fake= 0.052, g_loss 3.069, d_loss 0.109\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 379/390 d_loss_real= 0.307, d_loss_fake= 0.064, g_loss 2.873, d_loss 0.185\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 380/390 d_loss_real= 0.144, d_loss_fake= 0.072, g_loss 3.015, d_loss 0.108\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 381/390 d_loss_real= 0.163, d_loss_fake= 0.051, g_loss 3.132, d_loss 0.107\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 25 Batch 382/390 d_loss_real= 0.299, d_loss_fake= 0.050, g_loss 3.198, d_loss 0.174\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25 Batch 383/390 d_loss_real= 0.118, d_loss_fake= 0.044, g_loss 3.258, d_loss 0.081\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 25 Batch 384/390 d_loss_real= 0.115, d_loss_fake= 0.040, g_loss 3.310, d_loss 0.077\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 385/390 d_loss_real= 0.262, d_loss_fake= 0.040, g_loss 3.246, d_loss 0.151\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 386/390 d_loss_real= 0.310, d_loss_fake= 0.051, g_loss 2.921, d_loss 0.180\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 387/390 d_loss_real= 0.180, d_loss_fake= 0.076, g_loss 2.788, d_loss 0.128\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25 Batch 388/390 d_loss_real= 0.146, d_loss_fake= 0.068, g_loss 2.944, d_loss 0.107\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25 Batch 389/390 d_loss_real= 0.130, d_loss_fake= 0.066, g_loss 3.044, d_loss 0.098\n",
            "2/2 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25 Batch 390/390 d_loss_real= 0.188, d_loss_fake= 0.054, g_loss 3.090, d_loss 0.121\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 1/390 d_loss_real= 0.157, d_loss_fake= 0.046, g_loss 3.192, d_loss 0.101\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 26 Batch 2/390 d_loss_real= 0.096, d_loss_fake= 0.045, g_loss 3.195, d_loss 0.070\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 3/390 d_loss_real= 0.197, d_loss_fake= 0.044, g_loss 3.180, d_loss 0.120\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 26 Batch 4/390 d_loss_real= 0.166, d_loss_fake= 0.049, g_loss 3.053, d_loss 0.108\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 26 Batch 5/390 d_loss_real= 0.391, d_loss_fake= 0.055, g_loss 2.813, d_loss 0.223\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 6/390 d_loss_real= 0.193, d_loss_fake= 0.082, g_loss 2.733, d_loss 0.138\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 26 Batch 7/390 d_loss_real= 0.260, d_loss_fake= 0.070, g_loss 2.693, d_loss 0.165\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 26 Batch 8/390 d_loss_real= 0.187, d_loss_fake= 0.079, g_loss 2.681, d_loss 0.133\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 9/390 d_loss_real= 0.176, d_loss_fake= 0.087, g_loss 2.612, d_loss 0.132\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 10/390 d_loss_real= 0.219, d_loss_fake= 0.078, g_loss 2.679, d_loss 0.148\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 26 Batch 11/390 d_loss_real= 0.149, d_loss_fake= 0.079, g_loss 2.626, d_loss 0.114\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 12/390 d_loss_real= 0.165, d_loss_fake= 0.084, g_loss 2.540, d_loss 0.125\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 26 Batch 13/390 d_loss_real= 0.059, d_loss_fake= 0.088, g_loss 2.573, d_loss 0.074\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 26 Batch 14/390 d_loss_real= 0.021, d_loss_fake= 0.091, g_loss 2.542, d_loss 0.056\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 15/390 d_loss_real= 0.079, d_loss_fake= 0.097, g_loss 2.584, d_loss 0.088\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 16/390 d_loss_real= 0.227, d_loss_fake= 0.090, g_loss 2.624, d_loss 0.159\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 17/390 d_loss_real= 0.189, d_loss_fake= 0.086, g_loss 2.627, d_loss 0.138\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 18/390 d_loss_real= 0.195, d_loss_fake= 0.084, g_loss 2.635, d_loss 0.140\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 26 Batch 19/390 d_loss_real= 0.119, d_loss_fake= 0.102, g_loss 2.500, d_loss 0.110\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 20/390 d_loss_real= 0.248, d_loss_fake= 0.225, g_loss 2.718, d_loss 0.237\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 26 Batch 21/390 d_loss_real= 0.001, d_loss_fake= 0.054, g_loss 3.449, d_loss 0.028\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 22/390 d_loss_real= 0.419, d_loss_fake= 0.031, g_loss 3.645, d_loss 0.225\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 23/390 d_loss_real= 0.218, d_loss_fake= 0.030, g_loss 3.627, d_loss 0.124\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 26 Batch 24/390 d_loss_real= 0.160, d_loss_fake= 0.032, g_loss 3.549, d_loss 0.096\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 26 Batch 25/390 d_loss_real= 0.179, d_loss_fake= 0.033, g_loss 3.410, d_loss 0.106\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 26/390 d_loss_real= 0.269, d_loss_fake= 0.040, g_loss 3.224, d_loss 0.154\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 27/390 d_loss_real= 0.264, d_loss_fake= 0.054, g_loss 2.914, d_loss 0.159\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 28/390 d_loss_real= 0.062, d_loss_fake= 0.083, g_loss 2.553, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 29/390 d_loss_real= 0.228, d_loss_fake= 0.133, g_loss 2.703, d_loss 0.181\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 26 Batch 30/390 d_loss_real= 0.130, d_loss_fake= 0.065, g_loss 3.343, d_loss 0.098\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 26 Batch 31/390 d_loss_real= 0.054, d_loss_fake= 0.025, g_loss 4.073, d_loss 0.039\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 26 Batch 32/390 d_loss_real= 0.327, d_loss_fake= 0.016, g_loss 4.257, d_loss 0.172\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 26 Batch 33/390 d_loss_real= 0.179, d_loss_fake= 0.015, g_loss 4.237, d_loss 0.097\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 26 Batch 34/390 d_loss_real= 0.035, d_loss_fake= 0.026, g_loss 3.821, d_loss 0.030\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 26 Batch 35/390 d_loss_real= 0.110, d_loss_fake= 0.038, g_loss 3.998, d_loss 0.074\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 36/390 d_loss_real= 0.222, d_loss_fake= 0.012, g_loss 4.465, d_loss 0.117\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 37/390 d_loss_real= 0.074, d_loss_fake= 0.018, g_loss 4.148, d_loss 0.046\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 26 Batch 38/390 d_loss_real= 0.168, d_loss_fake= 0.036, g_loss 4.266, d_loss 0.102\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 26 Batch 39/390 d_loss_real= 0.000, d_loss_fake= 0.010, g_loss 5.066, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 40/390 d_loss_real= 0.132, d_loss_fake= 0.006, g_loss 5.201, d_loss 0.069\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 41/390 d_loss_real= 0.095, d_loss_fake= 0.006, g_loss 5.151, d_loss 0.051\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 26 Batch 42/390 d_loss_real= 0.070, d_loss_fake= 0.006, g_loss 5.070, d_loss 0.038\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 43/390 d_loss_real= 0.212, d_loss_fake= 0.007, g_loss 4.778, d_loss 0.110\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 44/390 d_loss_real= 0.144, d_loss_fake= 0.011, g_loss 4.395, d_loss 0.077\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 45/390 d_loss_real= 0.100, d_loss_fake= 0.015, g_loss 4.214, d_loss 0.058\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 46/390 d_loss_real= 0.248, d_loss_fake= 0.022, g_loss 3.864, d_loss 0.135\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 47/390 d_loss_real= 0.058, d_loss_fake= 0.024, g_loss 4.022, d_loss 0.041\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 48/390 d_loss_real= 0.069, d_loss_fake= 0.016, g_loss 4.354, d_loss 0.043\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 49/390 d_loss_real= 0.160, d_loss_fake= 0.013, g_loss 4.401, d_loss 0.087\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 26 Batch 50/390 d_loss_real= 0.152, d_loss_fake= 0.013, g_loss 4.328, d_loss 0.083\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 26 Batch 51/390 d_loss_real= 0.171, d_loss_fake= 0.015, g_loss 4.145, d_loss 0.093\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 52/390 d_loss_real= 0.103, d_loss_fake= 0.018, g_loss 3.994, d_loss 0.061\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 26 Batch 53/390 d_loss_real= 0.019, d_loss_fake= 0.021, g_loss 3.927, d_loss 0.020\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 54/390 d_loss_real= 0.063, d_loss_fake= 0.022, g_loss 3.966, d_loss 0.043\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 26 Batch 55/390 d_loss_real= 0.045, d_loss_fake= 0.020, g_loss 4.079, d_loss 0.032\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 26 Batch 56/390 d_loss_real= 0.052, d_loss_fake= 0.017, g_loss 4.150, d_loss 0.035\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 57/390 d_loss_real= 0.084, d_loss_fake= 0.017, g_loss 4.118, d_loss 0.050\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 58/390 d_loss_real= 0.027, d_loss_fake= 0.022, g_loss 4.054, d_loss 0.025\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 59/390 d_loss_real= 0.055, d_loss_fake= 0.038, g_loss 4.313, d_loss 0.046\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 26 Batch 60/390 d_loss_real= 0.076, d_loss_fake= 0.014, g_loss 4.488, d_loss 0.045\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 61/390 d_loss_real= 0.015, d_loss_fake= 0.011, g_loss 4.488, d_loss 0.013\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 26 Batch 62/390 d_loss_real= 0.058, d_loss_fake= 0.012, g_loss 4.384, d_loss 0.035\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 63/390 d_loss_real= 0.065, d_loss_fake= 0.016, g_loss 4.184, d_loss 0.040\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 26 Batch 64/390 d_loss_real= 0.020, d_loss_fake= 0.027, g_loss 3.684, d_loss 0.024\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 26 Batch 65/390 d_loss_real= 0.091, d_loss_fake= 0.045, g_loss 3.227, d_loss 0.068\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 66/390 d_loss_real= 0.155, d_loss_fake= 0.056, g_loss 3.094, d_loss 0.105\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 26 Batch 67/390 d_loss_real= 0.117, d_loss_fake= 0.053, g_loss 3.203, d_loss 0.085\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 26 Batch 68/390 d_loss_real= 0.097, d_loss_fake= 0.044, g_loss 3.448, d_loss 0.071\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 69/390 d_loss_real= 0.036, d_loss_fake= 0.032, g_loss 3.837, d_loss 0.034\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 26 Batch 70/390 d_loss_real= 0.040, d_loss_fake= 0.020, g_loss 4.261, d_loss 0.030\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 26 Batch 71/390 d_loss_real= 0.087, d_loss_fake= 0.013, g_loss 4.628, d_loss 0.050\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 26 Batch 72/390 d_loss_real= 0.000, d_loss_fake= 0.010, g_loss 4.979, d_loss 0.005\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 73/390 d_loss_real= 0.121, d_loss_fake= 0.007, g_loss 5.278, d_loss 0.064\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 74/390 d_loss_real= 0.021, d_loss_fake= 0.005, g_loss 5.590, d_loss 0.013\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 26 Batch 75/390 d_loss_real= 0.000, d_loss_fake= 0.003, g_loss 5.882, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 76/390 d_loss_real= 0.000, d_loss_fake= 0.003, g_loss 6.137, d_loss 0.001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 26 Batch 77/390 d_loss_real= 0.052, d_loss_fake= 0.002, g_loss 6.388, d_loss 0.027\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 78/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.524, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 79/390 d_loss_real= 0.000, d_loss_fake= 0.002, g_loss 6.572, d_loss 0.001\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 80/390 d_loss_real= 0.008, d_loss_fake= 0.002, g_loss 6.598, d_loss 0.005\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 26 Batch 81/390 d_loss_real= 0.042, d_loss_fake= 0.004, g_loss 6.341, d_loss 0.023\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 26 Batch 82/390 d_loss_real= 0.069, d_loss_fake= 0.570, g_loss 6.364, d_loss 0.320\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 83/390 d_loss_real= 0.000, d_loss_fake= 0.003, g_loss 6.691, d_loss 0.002\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 84/390 d_loss_real= 0.041, d_loss_fake= 0.002, g_loss 6.489, d_loss 0.021\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 85/390 d_loss_real= 0.000, d_loss_fake= 0.003, g_loss 5.823, d_loss 0.001\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 26 Batch 86/390 d_loss_real= 0.359, d_loss_fake= 0.006, g_loss 5.091, d_loss 0.182\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 87/390 d_loss_real= 0.299, d_loss_fake= 0.009, g_loss 4.611, d_loss 0.154\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 88/390 d_loss_real= 0.205, d_loss_fake= 0.012, g_loss 4.300, d_loss 0.109\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 89/390 d_loss_real= 0.175, d_loss_fake= 0.016, g_loss 4.026, d_loss 0.096\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 90/390 d_loss_real= 0.109, d_loss_fake= 0.021, g_loss 3.803, d_loss 0.065\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 26 Batch 91/390 d_loss_real= 0.120, d_loss_fake= 0.026, g_loss 3.621, d_loss 0.073\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 92/390 d_loss_real= 0.139, d_loss_fake= 0.032, g_loss 3.413, d_loss 0.085\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 93/390 d_loss_real= 0.053, d_loss_fake= 0.040, g_loss 3.148, d_loss 0.047\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 94/390 d_loss_real= 0.087, d_loss_fake= 0.064, g_loss 2.894, d_loss 0.076\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 95/390 d_loss_real= 0.040, d_loss_fake= 0.110, g_loss 3.177, d_loss 0.075\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 96/390 d_loss_real= 0.037, d_loss_fake= 0.034, g_loss 3.820, d_loss 0.035\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 97/390 d_loss_real= 0.075, d_loss_fake= 0.020, g_loss 4.101, d_loss 0.047\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 26 Batch 98/390 d_loss_real= 0.072, d_loss_fake= 0.016, g_loss 4.263, d_loss 0.044\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 26 Batch 99/390 d_loss_real= 0.081, d_loss_fake= 0.014, g_loss 4.355, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 100/390 d_loss_real= 0.066, d_loss_fake= 0.014, g_loss 4.389, d_loss 0.040\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 101/390 d_loss_real= 0.060, d_loss_fake= 0.014, g_loss 4.354, d_loss 0.037\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 26 Batch 102/390 d_loss_real= 0.100, d_loss_fake= 0.016, g_loss 4.187, d_loss 0.058\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 26 Batch 103/390 d_loss_real= 0.001, d_loss_fake= 0.024, g_loss 3.830, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 104/390 d_loss_real= 0.051, d_loss_fake= 0.050, g_loss 3.253, d_loss 0.050\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 26 Batch 105/390 d_loss_real= 0.088, d_loss_fake= 0.145, g_loss 2.675, d_loss 0.116\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 106/390 d_loss_real= 0.001, d_loss_fake= 0.215, g_loss 2.525, d_loss 0.108\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 26 Batch 107/390 d_loss_real= 0.022, d_loss_fake= 0.132, g_loss 3.024, d_loss 0.077\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 26 Batch 108/390 d_loss_real= 0.082, d_loss_fake= 0.048, g_loss 4.045, d_loss 0.065\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 26 Batch 109/390 d_loss_real= 0.023, d_loss_fake= 0.019, g_loss 4.789, d_loss 0.021\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 26 Batch 110/390 d_loss_real= 0.072, d_loss_fake= 0.014, g_loss 4.941, d_loss 0.043\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 111/390 d_loss_real= 0.078, d_loss_fake= 0.014, g_loss 4.657, d_loss 0.046\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 112/390 d_loss_real= 0.000, d_loss_fake= 0.014, g_loss 4.576, d_loss 0.007\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 113/390 d_loss_real= 0.061, d_loss_fake= 0.015, g_loss 4.328, d_loss 0.038\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 26 Batch 114/390 d_loss_real= 0.000, d_loss_fake= 0.063, g_loss 3.355, d_loss 0.032\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 115/390 d_loss_real= 0.001, d_loss_fake= 17.044, g_loss 2.607, d_loss 8.522\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 116/390 d_loss_real= 0.022, d_loss_fake= 0.008, g_loss 8.730, d_loss 0.015\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 26 Batch 117/390 d_loss_real= 1.182, d_loss_fake= 0.000, g_loss 11.402, d_loss 0.591\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 118/390 d_loss_real= 3.324, d_loss_fake= 0.000, g_loss 13.215, d_loss 1.662\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 119/390 d_loss_real= 3.539, d_loss_fake= 0.000, g_loss 13.465, d_loss 1.770\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 120/390 d_loss_real= 2.106, d_loss_fake= 0.000, g_loss 13.026, d_loss 1.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 121/390 d_loss_real= 0.279, d_loss_fake= 0.000, g_loss 12.215, d_loss 0.140\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 122/390 d_loss_real= 0.260, d_loss_fake= 0.000, g_loss 10.975, d_loss 0.130\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 123/390 d_loss_real= 0.129, d_loss_fake= 0.000, g_loss 9.032, d_loss 0.064\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 124/390 d_loss_real= 0.067, d_loss_fake= 3.466, g_loss 3.136, d_loss 1.766\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 125/390 d_loss_real= 0.117, d_loss_fake= 55.897, g_loss 0.000, d_loss 28.007\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 126/390 d_loss_real= 0.276, d_loss_fake= 0.518, g_loss 5.726, d_loss 0.397\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 26 Batch 127/390 d_loss_real= 1.044, d_loss_fake= 0.002, g_loss 7.098, d_loss 0.523\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 26 Batch 128/390 d_loss_real= 5.926, d_loss_fake= 0.001, g_loss 7.304, d_loss 2.963\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 26 Batch 129/390 d_loss_real= 8.101, d_loss_fake= 0.001, g_loss 6.757, d_loss 4.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 130/390 d_loss_real= 7.118, d_loss_fake= 0.002, g_loss 5.412, d_loss 3.560\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 26 Batch 131/390 d_loss_real= 5.917, d_loss_fake= 0.012, g_loss 3.517, d_loss 2.964\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 26 Batch 132/390 d_loss_real= 4.074, d_loss_fake= 0.098, g_loss 1.483, d_loss 2.086\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 26 Batch 133/390 d_loss_real= 2.081, d_loss_fake= 0.719, g_loss 0.345, d_loss 1.400\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 134/390 d_loss_real= 0.682, d_loss_fake= 1.996, g_loss 0.108, d_loss 1.339\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 26 Batch 135/390 d_loss_real= 0.274, d_loss_fake= 2.643, g_loss 0.086, d_loss 1.458\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 136/390 d_loss_real= 0.178, d_loss_fake= 2.427, g_loss 0.145, d_loss 1.302\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 26 Batch 137/390 d_loss_real= 0.210, d_loss_fake= 1.713, g_loss 0.347, d_loss 0.961\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 138/390 d_loss_real= 0.517, d_loss_fake= 0.949, g_loss 0.774, d_loss 0.733\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 26 Batch 139/390 d_loss_real= 0.814, d_loss_fake= 0.469, g_loss 1.296, d_loss 0.641\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 26 Batch 140/390 d_loss_real= 1.152, d_loss_fake= 0.274, g_loss 1.620, d_loss 0.713\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 141/390 d_loss_real= 1.446, d_loss_fake= 0.223, g_loss 1.655, d_loss 0.835\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 142/390 d_loss_real= 1.478, d_loss_fake= 0.249, g_loss 1.444, d_loss 0.864\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 143/390 d_loss_real= 1.152, d_loss_fake= 0.343, g_loss 1.135, d_loss 0.747\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 144/390 d_loss_real= 0.895, d_loss_fake= 0.496, g_loss 0.859, d_loss 0.696\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 145/390 d_loss_real= 0.696, d_loss_fake= 0.674, g_loss 0.680, d_loss 0.685\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 146/390 d_loss_real= 0.572, d_loss_fake= 0.803, g_loss 0.609, d_loss 0.687\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 147/390 d_loss_real= 0.468, d_loss_fake= 0.827, g_loss 0.631, d_loss 0.647\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 26 Batch 148/390 d_loss_real= 0.457, d_loss_fake= 0.755, g_loss 0.726, d_loss 0.606\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 149/390 d_loss_real= 0.547, d_loss_fake= 0.639, g_loss 0.861, d_loss 0.593\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 150/390 d_loss_real= 0.515, d_loss_fake= 0.522, g_loss 1.018, d_loss 0.519\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 151/390 d_loss_real= 0.650, d_loss_fake= 0.434, g_loss 1.142, d_loss 0.542\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 26 Batch 152/390 d_loss_real= 0.681, d_loss_fake= 0.384, g_loss 1.216, d_loss 0.532\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 153/390 d_loss_real= 0.732, d_loss_fake= 0.367, g_loss 1.214, d_loss 0.550\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 26 Batch 154/390 d_loss_real= 0.710, d_loss_fake= 0.384, g_loss 1.152, d_loss 0.547\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 26 Batch 155/390 d_loss_real= 0.521, d_loss_fake= 0.415, g_loss 1.092, d_loss 0.468\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 26 Batch 156/390 d_loss_real= 0.595, d_loss_fake= 0.450, g_loss 1.028, d_loss 0.522\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 157/390 d_loss_real= 0.585, d_loss_fake= 0.480, g_loss 0.987, d_loss 0.532\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 26 Batch 158/390 d_loss_real= 0.430, d_loss_fake= 0.491, g_loss 0.991, d_loss 0.460\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 26 Batch 159/390 d_loss_real= 0.509, d_loss_fake= 0.482, g_loss 1.011, d_loss 0.496\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 26 Batch 160/390 d_loss_real= 0.413, d_loss_fake= 0.461, g_loss 1.059, d_loss 0.437\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 26 Batch 161/390 d_loss_real= 0.508, d_loss_fake= 0.435, g_loss 1.101, d_loss 0.471\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 162/390 d_loss_real= 0.484, d_loss_fake= 0.413, g_loss 1.144, d_loss 0.448\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 163/390 d_loss_real= 0.469, d_loss_fake= 0.390, g_loss 1.188, d_loss 0.429\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 164/390 d_loss_real= 0.479, d_loss_fake= 0.371, g_loss 1.223, d_loss 0.425\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 26 Batch 165/390 d_loss_real= 0.554, d_loss_fake= 0.364, g_loss 1.224, d_loss 0.459\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 26 Batch 166/390 d_loss_real= 0.477, d_loss_fake= 0.367, g_loss 1.213, d_loss 0.422\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 26 Batch 167/390 d_loss_real= 0.468, d_loss_fake= 0.374, g_loss 1.195, d_loss 0.421\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 168/390 d_loss_real= 0.481, d_loss_fake= 0.382, g_loss 1.180, d_loss 0.432\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 26 Batch 169/390 d_loss_real= 0.422, d_loss_fake= 0.385, g_loss 1.182, d_loss 0.403\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 26 Batch 170/390 d_loss_real= 0.371, d_loss_fake= 0.378, g_loss 1.208, d_loss 0.374\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 171/390 d_loss_real= 0.445, d_loss_fake= 0.364, g_loss 1.240, d_loss 0.404\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 172/390 d_loss_real= 0.365, d_loss_fake= 0.346, g_loss 1.283, d_loss 0.356\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 26 Batch 173/390 d_loss_real= 0.375, d_loss_fake= 0.330, g_loss 1.322, d_loss 0.353\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 174/390 d_loss_real= 0.335, d_loss_fake= 0.313, g_loss 1.368, d_loss 0.324\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 175/390 d_loss_real= 0.354, d_loss_fake= 0.299, g_loss 1.403, d_loss 0.327\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 26 Batch 176/390 d_loss_real= 0.417, d_loss_fake= 0.293, g_loss 1.413, d_loss 0.355\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 177/390 d_loss_real= 0.361, d_loss_fake= 0.293, g_loss 1.409, d_loss 0.327\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 178/390 d_loss_real= 0.398, d_loss_fake= 0.296, g_loss 1.399, d_loss 0.347\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 179/390 d_loss_real= 0.301, d_loss_fake= 0.293, g_loss 1.413, d_loss 0.297\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 26 Batch 180/390 d_loss_real= 0.285, d_loss_fake= 0.285, g_loss 1.443, d_loss 0.285\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 181/390 d_loss_real= 0.367, d_loss_fake= 0.280, g_loss 1.450, d_loss 0.324\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 26 Batch 182/390 d_loss_real= 0.335, d_loss_fake= 0.277, g_loss 1.464, d_loss 0.306\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 183/390 d_loss_real= 0.352, d_loss_fake= 0.275, g_loss 1.469, d_loss 0.314\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 184/390 d_loss_real= 0.285, d_loss_fake= 0.269, g_loss 1.484, d_loss 0.277\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 26 Batch 185/390 d_loss_real= 0.349, d_loss_fake= 0.265, g_loss 1.503, d_loss 0.307\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 26 Batch 186/390 d_loss_real= 0.305, d_loss_fake= 0.261, g_loss 1.521, d_loss 0.283\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 187/390 d_loss_real= 0.261, d_loss_fake= 0.253, g_loss 1.545, d_loss 0.257\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 188/390 d_loss_real= 0.281, d_loss_fake= 0.244, g_loss 1.576, d_loss 0.263\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 189/390 d_loss_real= 0.255, d_loss_fake= 0.236, g_loss 1.617, d_loss 0.246\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 190/390 d_loss_real= 0.266, d_loss_fake= 0.229, g_loss 1.648, d_loss 0.247\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 26 Batch 191/390 d_loss_real= 0.281, d_loss_fake= 0.222, g_loss 1.663, d_loss 0.251\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 192/390 d_loss_real= 0.220, d_loss_fake= 0.219, g_loss 1.673, d_loss 0.219\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 193/390 d_loss_real= 0.255, d_loss_fake= 0.208, g_loss 1.703, d_loss 0.232\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 26 Batch 194/390 d_loss_real= 0.230, d_loss_fake= 0.205, g_loss 1.723, d_loss 0.217\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 26 Batch 195/390 d_loss_real= 0.241, d_loss_fake= 0.206, g_loss 1.748, d_loss 0.224\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 26 Batch 196/390 d_loss_real= 0.261, d_loss_fake= 0.195, g_loss 1.778, d_loss 0.228\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 197/390 d_loss_real= 0.234, d_loss_fake= 0.196, g_loss 1.788, d_loss 0.215\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 198/390 d_loss_real= 0.195, d_loss_fake= 0.187, g_loss 1.818, d_loss 0.191\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 199/390 d_loss_real= 0.184, d_loss_fake= 0.181, g_loss 1.868, d_loss 0.183\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 26 Batch 200/390 d_loss_real= 0.200, d_loss_fake= 0.169, g_loss 1.901, d_loss 0.185\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 201/390 d_loss_real= 0.214, d_loss_fake= 0.166, g_loss 1.915, d_loss 0.190\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 202/390 d_loss_real= 0.193, d_loss_fake= 0.163, g_loss 1.932, d_loss 0.178\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 203/390 d_loss_real= 0.228, d_loss_fake= 0.165, g_loss 1.943, d_loss 0.196\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 26 Batch 204/390 d_loss_real= 0.169, d_loss_fake= 0.168, g_loss 1.975, d_loss 0.169\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 205/390 d_loss_real= 0.162, d_loss_fake= 0.148, g_loss 2.007, d_loss 0.155\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 206/390 d_loss_real= 0.144, d_loss_fake= 0.146, g_loss 2.073, d_loss 0.145\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 207/390 d_loss_real= 0.225, d_loss_fake= 0.139, g_loss 2.078, d_loss 0.182\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 26 Batch 208/390 d_loss_real= 0.184, d_loss_fake= 0.139, g_loss 2.062, d_loss 0.161\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 26 Batch 209/390 d_loss_real= 0.198, d_loss_fake= 0.144, g_loss 2.043, d_loss 0.171\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 210/390 d_loss_real= 0.136, d_loss_fake= 0.146, g_loss 2.081, d_loss 0.141\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 26 Batch 211/390 d_loss_real= 0.153, d_loss_fake= 0.135, g_loss 2.104, d_loss 0.144\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 212/390 d_loss_real= 0.103, d_loss_fake= 0.133, g_loss 2.147, d_loss 0.118\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 26 Batch 213/390 d_loss_real= 0.146, d_loss_fake= 0.123, g_loss 2.198, d_loss 0.134\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 214/390 d_loss_real= 0.148, d_loss_fake= 0.120, g_loss 2.201, d_loss 0.134\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 26 Batch 215/390 d_loss_real= 0.140, d_loss_fake= 0.122, g_loss 2.217, d_loss 0.131\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 26 Batch 216/390 d_loss_real= 0.147, d_loss_fake= 0.125, g_loss 2.236, d_loss 0.136\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 217/390 d_loss_real= 0.188, d_loss_fake= 0.126, g_loss 2.210, d_loss 0.157\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 218/390 d_loss_real= 0.089, d_loss_fake= 0.123, g_loss 2.241, d_loss 0.106\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 26 Batch 219/390 d_loss_real= 0.143, d_loss_fake= 0.121, g_loss 2.261, d_loss 0.132\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 26 Batch 220/390 d_loss_real= 0.132, d_loss_fake= 0.117, g_loss 2.273, d_loss 0.124\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 221/390 d_loss_real= 0.169, d_loss_fake= 0.115, g_loss 2.240, d_loss 0.142\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 222/390 d_loss_real= 0.151, d_loss_fake= 0.129, g_loss 2.310, d_loss 0.140\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 26 Batch 223/390 d_loss_real= 0.089, d_loss_fake= 0.142, g_loss 2.359, d_loss 0.116\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 224/390 d_loss_real= 0.166, d_loss_fake= 0.127, g_loss 2.421, d_loss 0.147\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 225/390 d_loss_real= 0.117, d_loss_fake= 0.147, g_loss 2.371, d_loss 0.132\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 226/390 d_loss_real= 0.169, d_loss_fake= 0.142, g_loss 2.427, d_loss 0.155\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 227/390 d_loss_real= 0.183, d_loss_fake= 0.162, g_loss 2.370, d_loss 0.172\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 228/390 d_loss_real= 0.174, d_loss_fake= 0.196, g_loss 2.493, d_loss 0.185\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 26 Batch 229/390 d_loss_real= 0.082, d_loss_fake= 0.242, g_loss 2.393, d_loss 0.162\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 26 Batch 230/390 d_loss_real= 0.162, d_loss_fake= 0.173, g_loss 2.484, d_loss 0.167\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 231/390 d_loss_real= 0.150, d_loss_fake= 0.255, g_loss 2.414, d_loss 0.203\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 26 Batch 232/390 d_loss_real= 0.178, d_loss_fake= 0.259, g_loss 2.315, d_loss 0.218\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 26 Batch 233/390 d_loss_real= 0.204, d_loss_fake= 0.225, g_loss 2.333, d_loss 0.215\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 26 Batch 234/390 d_loss_real= 0.209, d_loss_fake= 0.341, g_loss 1.906, d_loss 0.275\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 235/390 d_loss_real= 0.182, d_loss_fake= 0.727, g_loss 1.981, d_loss 0.455\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 236/390 d_loss_real= 0.245, d_loss_fake= 1.106, g_loss 1.560, d_loss 0.675\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 26 Batch 237/390 d_loss_real= 0.517, d_loss_fake= 1.560, g_loss 1.565, d_loss 1.039\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 26 Batch 238/390 d_loss_real= 0.931, d_loss_fake= 1.732, g_loss 1.348, d_loss 1.331\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 26 Batch 239/390 d_loss_real= 0.919, d_loss_fake= 1.352, g_loss 1.273, d_loss 1.136\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 240/390 d_loss_real= 1.214, d_loss_fake= 1.568, g_loss 1.036, d_loss 1.391\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 26 Batch 241/390 d_loss_real= 1.286, d_loss_fake= 1.252, g_loss 1.072, d_loss 1.269\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 26 Batch 242/390 d_loss_real= 1.124, d_loss_fake= 0.736, g_loss 1.395, d_loss 0.930\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 26 Batch 243/390 d_loss_real= 1.247, d_loss_fake= 0.303, g_loss 2.057, d_loss 0.775\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 26 Batch 244/390 d_loss_real= 1.140, d_loss_fake= 0.199, g_loss 2.517, d_loss 0.670\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 245/390 d_loss_real= 0.889, d_loss_fake= 0.196, g_loss 2.297, d_loss 0.543\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 246/390 d_loss_real= 0.703, d_loss_fake= 0.249, g_loss 1.922, d_loss 0.476\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 247/390 d_loss_real= 0.418, d_loss_fake= 0.465, g_loss 1.505, d_loss 0.442\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 248/390 d_loss_real= 0.335, d_loss_fake= 0.635, g_loss 1.170, d_loss 0.485\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 249/390 d_loss_real= 0.287, d_loss_fake= 0.912, g_loss 1.041, d_loss 0.600\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 250/390 d_loss_real= 0.309, d_loss_fake= 1.348, g_loss 0.822, d_loss 0.829\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 251/390 d_loss_real= 0.435, d_loss_fake= 1.239, g_loss 1.121, d_loss 0.837\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 252/390 d_loss_real= 0.410, d_loss_fake= 0.400, g_loss 2.669, d_loss 0.405\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 253/390 d_loss_real= 0.547, d_loss_fake= 0.088, g_loss 4.199, d_loss 0.318\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 254/390 d_loss_real= 0.981, d_loss_fake= 0.034, g_loss 5.251, d_loss 0.507\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 255/390 d_loss_real= 0.865, d_loss_fake= 0.065, g_loss 4.294, d_loss 0.465\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 26 Batch 256/390 d_loss_real= 1.022, d_loss_fake= 0.197, g_loss 3.295, d_loss 0.610\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 26 Batch 257/390 d_loss_real= 0.701, d_loss_fake= 0.585, g_loss 1.834, d_loss 0.643\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 26 Batch 258/390 d_loss_real= 0.880, d_loss_fake= 1.170, g_loss 1.017, d_loss 1.025\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 26 Batch 259/390 d_loss_real= 0.396, d_loss_fake= 1.600, g_loss 0.877, d_loss 0.998\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 26 Batch 260/390 d_loss_real= 0.574, d_loss_fake= 1.106, g_loss 1.157, d_loss 0.840\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 26 Batch 261/390 d_loss_real= 0.622, d_loss_fake= 0.825, g_loss 1.525, d_loss 0.724\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 26 Batch 262/390 d_loss_real= 0.830, d_loss_fake= 0.572, g_loss 1.391, d_loss 0.701\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 263/390 d_loss_real= 1.041, d_loss_fake= 0.485, g_loss 1.306, d_loss 0.763\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 26 Batch 264/390 d_loss_real= 1.320, d_loss_fake= 0.666, g_loss 1.008, d_loss 0.993\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 26 Batch 265/390 d_loss_real= 1.180, d_loss_fake= 0.701, g_loss 0.910, d_loss 0.940\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 266/390 d_loss_real= 1.232, d_loss_fake= 0.839, g_loss 0.744, d_loss 1.036\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 267/390 d_loss_real= 1.221, d_loss_fake= 0.960, g_loss 0.646, d_loss 1.091\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 268/390 d_loss_real= 1.100, d_loss_fake= 0.905, g_loss 0.619, d_loss 1.002\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 269/390 d_loss_real= 1.108, d_loss_fake= 0.925, g_loss 0.625, d_loss 1.016\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 270/390 d_loss_real= 1.045, d_loss_fake= 0.893, g_loss 0.658, d_loss 0.969\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 26 Batch 271/390 d_loss_real= 0.952, d_loss_fake= 0.787, g_loss 0.738, d_loss 0.869\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 272/390 d_loss_real= 1.083, d_loss_fake= 0.704, g_loss 0.804, d_loss 0.893\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 273/390 d_loss_real= 1.111, d_loss_fake= 0.627, g_loss 0.862, d_loss 0.869\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 274/390 d_loss_real= 1.089, d_loss_fake= 0.616, g_loss 0.873, d_loss 0.852\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 275/390 d_loss_real= 1.056, d_loss_fake= 0.633, g_loss 0.836, d_loss 0.844\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 276/390 d_loss_real= 0.892, d_loss_fake= 0.666, g_loss 0.780, d_loss 0.779\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 26 Batch 277/390 d_loss_real= 0.688, d_loss_fake= 0.696, g_loss 0.763, d_loss 0.692\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 278/390 d_loss_real= 0.780, d_loss_fake= 0.695, g_loss 0.760, d_loss 0.738\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 279/390 d_loss_real= 0.796, d_loss_fake= 0.680, g_loss 0.765, d_loss 0.738\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 280/390 d_loss_real= 0.791, d_loss_fake= 0.673, g_loss 0.791, d_loss 0.732\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 26 Batch 281/390 d_loss_real= 0.769, d_loss_fake= 0.634, g_loss 0.823, d_loss 0.702\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 282/390 d_loss_real= 0.709, d_loss_fake= 0.605, g_loss 0.873, d_loss 0.657\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 26 Batch 283/390 d_loss_real= 0.638, d_loss_fake= 0.553, g_loss 0.928, d_loss 0.596\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 284/390 d_loss_real= 0.728, d_loss_fake= 0.524, g_loss 0.959, d_loss 0.626\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 26 Batch 285/390 d_loss_real= 0.634, d_loss_fake= 0.495, g_loss 1.006, d_loss 0.565\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 26 Batch 286/390 d_loss_real= 0.752, d_loss_fake= 0.480, g_loss 1.018, d_loss 0.616\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 287/390 d_loss_real= 0.776, d_loss_fake= 0.470, g_loss 1.019, d_loss 0.623\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 26 Batch 288/390 d_loss_real= 0.715, d_loss_fake= 0.475, g_loss 1.014, d_loss 0.595\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 289/390 d_loss_real= 0.664, d_loss_fake= 0.483, g_loss 1.007, d_loss 0.573\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 26 Batch 290/390 d_loss_real= 0.505, d_loss_fake= 0.477, g_loss 1.006, d_loss 0.491\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 291/390 d_loss_real= 0.651, d_loss_fake= 0.473, g_loss 1.024, d_loss 0.562\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 292/390 d_loss_real= 0.617, d_loss_fake= 0.481, g_loss 1.031, d_loss 0.549\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 293/390 d_loss_real= 0.547, d_loss_fake= 0.468, g_loss 1.040, d_loss 0.507\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 294/390 d_loss_real= 0.654, d_loss_fake= 0.469, g_loss 1.041, d_loss 0.561\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 26 Batch 295/390 d_loss_real= 0.650, d_loss_fake= 0.488, g_loss 1.020, d_loss 0.569\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 26 Batch 296/390 d_loss_real= 0.557, d_loss_fake= 0.484, g_loss 1.014, d_loss 0.520\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 297/390 d_loss_real= 0.566, d_loss_fake= 0.480, g_loss 1.002, d_loss 0.523\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 298/390 d_loss_real= 0.512, d_loss_fake= 0.502, g_loss 1.017, d_loss 0.507\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 299/390 d_loss_real= 0.533, d_loss_fake= 0.548, g_loss 0.967, d_loss 0.540\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 300/390 d_loss_real= 0.664, d_loss_fake= 0.626, g_loss 0.953, d_loss 0.645\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 26 Batch 301/390 d_loss_real= 0.633, d_loss_fake= 0.706, g_loss 0.900, d_loss 0.670\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 302/390 d_loss_real= 0.809, d_loss_fake= 0.765, g_loss 0.847, d_loss 0.787\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 303/390 d_loss_real= 0.922, d_loss_fake= 1.041, g_loss 0.862, d_loss 0.981\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 304/390 d_loss_real= 0.831, d_loss_fake= 1.235, g_loss 0.764, d_loss 1.033\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 305/390 d_loss_real= 0.916, d_loss_fake= 1.546, g_loss 0.614, d_loss 1.231\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 306/390 d_loss_real= 1.019, d_loss_fake= 1.271, g_loss 0.925, d_loss 1.145\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 26 Batch 307/390 d_loss_real= 1.267, d_loss_fake= 0.619, g_loss 1.644, d_loss 0.943\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 308/390 d_loss_real= 1.364, d_loss_fake= 0.214, g_loss 2.384, d_loss 0.789\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 26 Batch 309/390 d_loss_real= 1.459, d_loss_fake= 0.206, g_loss 1.990, d_loss 0.833\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 310/390 d_loss_real= 1.162, d_loss_fake= 0.335, g_loss 1.365, d_loss 0.749\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 311/390 d_loss_real= 1.109, d_loss_fake= 0.565, g_loss 0.864, d_loss 0.837\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 26 Batch 312/390 d_loss_real= 0.811, d_loss_fake= 0.738, g_loss 0.655, d_loss 0.774\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 313/390 d_loss_real= 0.642, d_loss_fake= 0.875, g_loss 0.577, d_loss 0.759\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 26 Batch 314/390 d_loss_real= 0.482, d_loss_fake= 0.892, g_loss 0.580, d_loss 0.687\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 26 Batch 315/390 d_loss_real= 0.548, d_loss_fake= 0.826, g_loss 0.675, d_loss 0.687\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 316/390 d_loss_real= 0.547, d_loss_fake= 0.699, g_loss 0.808, d_loss 0.623\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 317/390 d_loss_real= 0.748, d_loss_fake= 0.568, g_loss 0.960, d_loss 0.658\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 318/390 d_loss_real= 0.706, d_loss_fake= 0.474, g_loss 1.093, d_loss 0.590\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 26 Batch 319/390 d_loss_real= 0.841, d_loss_fake= 0.414, g_loss 1.178, d_loss 0.627\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 26 Batch 320/390 d_loss_real= 0.781, d_loss_fake= 0.382, g_loss 1.219, d_loss 0.581\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 321/390 d_loss_real= 0.644, d_loss_fake= 0.368, g_loss 1.220, d_loss 0.506\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 26 Batch 322/390 d_loss_real= 0.752, d_loss_fake= 0.375, g_loss 1.215, d_loss 0.563\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 26 Batch 323/390 d_loss_real= 0.666, d_loss_fake= 0.383, g_loss 1.182, d_loss 0.525\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 324/390 d_loss_real= 0.501, d_loss_fake= 0.394, g_loss 1.149, d_loss 0.447\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 26 Batch 325/390 d_loss_real= 0.520, d_loss_fake= 0.406, g_loss 1.120, d_loss 0.463\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 26 Batch 326/390 d_loss_real= 0.494, d_loss_fake= 0.415, g_loss 1.100, d_loss 0.455\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 26 Batch 327/390 d_loss_real= 0.453, d_loss_fake= 0.430, g_loss 1.102, d_loss 0.442\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 328/390 d_loss_real= 0.398, d_loss_fake= 0.437, g_loss 1.098, d_loss 0.417\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 26 Batch 329/390 d_loss_real= 0.507, d_loss_fake= 0.432, g_loss 1.119, d_loss 0.469\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 330/390 d_loss_real= 0.558, d_loss_fake= 0.421, g_loss 1.121, d_loss 0.490\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 331/390 d_loss_real= 0.406, d_loss_fake= 0.402, g_loss 1.171, d_loss 0.404\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 26 Batch 332/390 d_loss_real= 0.445, d_loss_fake= 0.389, g_loss 1.210, d_loss 0.417\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 333/390 d_loss_real= 0.484, d_loss_fake= 0.362, g_loss 1.254, d_loss 0.423\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 26 Batch 334/390 d_loss_real= 0.595, d_loss_fake= 0.344, g_loss 1.282, d_loss 0.470\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 335/390 d_loss_real= 0.569, d_loss_fake= 0.348, g_loss 1.279, d_loss 0.458\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 26 Batch 336/390 d_loss_real= 0.474, d_loss_fake= 0.341, g_loss 1.286, d_loss 0.407\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 26 Batch 337/390 d_loss_real= 0.623, d_loss_fake= 0.345, g_loss 1.272, d_loss 0.484\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 26 Batch 338/390 d_loss_real= 0.601, d_loss_fake= 0.365, g_loss 1.213, d_loss 0.483\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 26 Batch 339/390 d_loss_real= 0.558, d_loss_fake= 0.392, g_loss 1.161, d_loss 0.475\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 340/390 d_loss_real= 0.536, d_loss_fake= 0.418, g_loss 1.111, d_loss 0.477\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 26 Batch 341/390 d_loss_real= 0.538, d_loss_fake= 0.432, g_loss 1.061, d_loss 0.485\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 26 Batch 342/390 d_loss_real= 0.563, d_loss_fake= 0.469, g_loss 1.039, d_loss 0.516\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 343/390 d_loss_real= 0.490, d_loss_fake= 0.499, g_loss 1.032, d_loss 0.495\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 26 Batch 344/390 d_loss_real= 0.544, d_loss_fake= 0.460, g_loss 1.060, d_loss 0.502\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 26 Batch 345/390 d_loss_real= 0.549, d_loss_fake= 0.441, g_loss 1.137, d_loss 0.495\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 346/390 d_loss_real= 0.486, d_loss_fake= 0.409, g_loss 1.201, d_loss 0.448\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 26 Batch 347/390 d_loss_real= 0.466, d_loss_fake= 0.371, g_loss 1.260, d_loss 0.419\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 348/390 d_loss_real= 0.496, d_loss_fake= 0.335, g_loss 1.356, d_loss 0.415\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 349/390 d_loss_real= 0.563, d_loss_fake= 0.320, g_loss 1.369, d_loss 0.442\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 350/390 d_loss_real= 0.473, d_loss_fake= 0.303, g_loss 1.399, d_loss 0.388\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 26 Batch 351/390 d_loss_real= 0.627, d_loss_fake= 0.300, g_loss 1.384, d_loss 0.464\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 26 Batch 352/390 d_loss_real= 0.429, d_loss_fake= 0.301, g_loss 1.369, d_loss 0.365\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 353/390 d_loss_real= 0.499, d_loss_fake= 0.311, g_loss 1.329, d_loss 0.405\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 354/390 d_loss_real= 0.421, d_loss_fake= 0.328, g_loss 1.294, d_loss 0.375\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 355/390 d_loss_real= 0.436, d_loss_fake= 0.341, g_loss 1.279, d_loss 0.388\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 356/390 d_loss_real= 0.311, d_loss_fake= 0.340, g_loss 1.271, d_loss 0.325\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 357/390 d_loss_real= 0.368, d_loss_fake= 0.341, g_loss 1.283, d_loss 0.354\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 26 Batch 358/390 d_loss_real= 0.389, d_loss_fake= 0.335, g_loss 1.299, d_loss 0.362\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 26 Batch 359/390 d_loss_real= 0.399, d_loss_fake= 0.334, g_loss 1.311, d_loss 0.367\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 360/390 d_loss_real= 0.484, d_loss_fake= 0.325, g_loss 1.327, d_loss 0.405\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 26 Batch 361/390 d_loss_real= 0.393, d_loss_fake= 0.319, g_loss 1.343, d_loss 0.356\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 362/390 d_loss_real= 0.413, d_loss_fake= 0.315, g_loss 1.360, d_loss 0.364\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 363/390 d_loss_real= 0.376, d_loss_fake= 0.307, g_loss 1.386, d_loss 0.341\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 364/390 d_loss_real= 0.307, d_loss_fake= 0.298, g_loss 1.409, d_loss 0.303\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 26 Batch 365/390 d_loss_real= 0.436, d_loss_fake= 0.302, g_loss 1.398, d_loss 0.369\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 366/390 d_loss_real= 0.458, d_loss_fake= 0.301, g_loss 1.370, d_loss 0.380\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 367/390 d_loss_real= 0.387, d_loss_fake= 0.319, g_loss 1.297, d_loss 0.353\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 368/390 d_loss_real= 0.314, d_loss_fake= 0.355, g_loss 1.233, d_loss 0.335\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 26 Batch 369/390 d_loss_real= 0.452, d_loss_fake= 0.405, g_loss 1.171, d_loss 0.428\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 370/390 d_loss_real= 0.375, d_loss_fake= 0.397, g_loss 1.234, d_loss 0.386\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 371/390 d_loss_real= 0.379, d_loss_fake= 0.376, g_loss 1.230, d_loss 0.377\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 372/390 d_loss_real= 0.387, d_loss_fake= 0.374, g_loss 1.288, d_loss 0.380\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 373/390 d_loss_real= 0.510, d_loss_fake= 0.353, g_loss 1.288, d_loss 0.432\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 26 Batch 374/390 d_loss_real= 0.346, d_loss_fake= 0.338, g_loss 1.335, d_loss 0.342\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 375/390 d_loss_real= 0.600, d_loss_fake= 0.325, g_loss 1.328, d_loss 0.463\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 376/390 d_loss_real= 0.413, d_loss_fake= 0.322, g_loss 1.362, d_loss 0.368\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 26 Batch 377/390 d_loss_real= 0.409, d_loss_fake= 0.318, g_loss 1.362, d_loss 0.363\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 378/390 d_loss_real= 0.486, d_loss_fake= 0.325, g_loss 1.339, d_loss 0.405\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 26 Batch 379/390 d_loss_real= 0.394, d_loss_fake= 0.319, g_loss 1.331, d_loss 0.357\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 26 Batch 380/390 d_loss_real= 0.347, d_loss_fake= 0.316, g_loss 1.357, d_loss 0.331\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 381/390 d_loss_real= 0.523, d_loss_fake= 0.318, g_loss 1.343, d_loss 0.420\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 382/390 d_loss_real= 0.423, d_loss_fake= 0.324, g_loss 1.321, d_loss 0.374\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 383/390 d_loss_real= 0.408, d_loss_fake= 0.334, g_loss 1.297, d_loss 0.371\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 26 Batch 384/390 d_loss_real= 0.355, d_loss_fake= 0.338, g_loss 1.305, d_loss 0.346\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 26 Batch 385/390 d_loss_real= 0.345, d_loss_fake= 0.341, g_loss 1.309, d_loss 0.343\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26 Batch 386/390 d_loss_real= 0.302, d_loss_fake= 0.330, g_loss 1.318, d_loss 0.316\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 26 Batch 387/390 d_loss_real= 0.408, d_loss_fake= 0.328, g_loss 1.314, d_loss 0.368\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26 Batch 388/390 d_loss_real= 0.451, d_loss_fake= 0.326, g_loss 1.301, d_loss 0.389\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26 Batch 389/390 d_loss_real= 0.354, d_loss_fake= 0.367, g_loss 1.272, d_loss 0.360\n",
            "2/2 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26 Batch 390/390 d_loss_real= 0.488, d_loss_fake= 0.413, g_loss 1.175, d_loss 0.451\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 1/390 d_loss_real= 0.399, d_loss_fake= 0.465, g_loss 1.083, d_loss 0.432\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 2/390 d_loss_real= 0.382, d_loss_fake= 0.545, g_loss 1.029, d_loss 0.464\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 3/390 d_loss_real= 0.445, d_loss_fake= 0.571, g_loss 1.020, d_loss 0.508\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 27 Batch 4/390 d_loss_real= 0.492, d_loss_fake= 0.551, g_loss 1.043, d_loss 0.521\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 27 Batch 5/390 d_loss_real= 0.474, d_loss_fake= 0.504, g_loss 1.139, d_loss 0.489\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 27 Batch 6/390 d_loss_real= 0.619, d_loss_fake= 0.481, g_loss 1.188, d_loss 0.550\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 27 Batch 7/390 d_loss_real= 0.696, d_loss_fake= 0.412, g_loss 1.244, d_loss 0.554\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 8/390 d_loss_real= 0.672, d_loss_fake= 0.397, g_loss 1.287, d_loss 0.534\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 27 Batch 9/390 d_loss_real= 0.607, d_loss_fake= 0.370, g_loss 1.292, d_loss 0.489\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 10/390 d_loss_real= 0.578, d_loss_fake= 0.366, g_loss 1.282, d_loss 0.472\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 27 Batch 11/390 d_loss_real= 0.740, d_loss_fake= 0.374, g_loss 1.226, d_loss 0.557\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 27 Batch 12/390 d_loss_real= 0.662, d_loss_fake= 0.422, g_loss 1.129, d_loss 0.542\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 27 Batch 13/390 d_loss_real= 0.576, d_loss_fake= 0.448, g_loss 1.114, d_loss 0.512\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 14/390 d_loss_real= 0.571, d_loss_fake= 0.454, g_loss 1.076, d_loss 0.512\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 27 Batch 15/390 d_loss_real= 0.528, d_loss_fake= 0.471, g_loss 1.065, d_loss 0.500\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 16/390 d_loss_real= 0.456, d_loss_fake= 0.449, g_loss 1.131, d_loss 0.452\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 17/390 d_loss_real= 0.550, d_loss_fake= 0.418, g_loss 1.187, d_loss 0.484\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 18/390 d_loss_real= 0.708, d_loss_fake= 0.386, g_loss 1.238, d_loss 0.547\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 27 Batch 19/390 d_loss_real= 0.532, d_loss_fake= 0.347, g_loss 1.327, d_loss 0.439\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 20/390 d_loss_real= 0.463, d_loss_fake= 0.317, g_loss 1.393, d_loss 0.390\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 21/390 d_loss_real= 0.537, d_loss_fake= 0.279, g_loss 1.484, d_loss 0.408\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 22/390 d_loss_real= 0.459, d_loss_fake= 0.286, g_loss 1.481, d_loss 0.373\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 23/390 d_loss_real= 0.411, d_loss_fake= 0.269, g_loss 1.489, d_loss 0.340\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 24/390 d_loss_real= 0.395, d_loss_fake= 0.282, g_loss 1.455, d_loss 0.339\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 25/390 d_loss_real= 0.413, d_loss_fake= 0.282, g_loss 1.463, d_loss 0.348\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 26/390 d_loss_real= 0.471, d_loss_fake= 0.277, g_loss 1.440, d_loss 0.374\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 27/390 d_loss_real= 0.364, d_loss_fake= 0.285, g_loss 1.448, d_loss 0.324\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 27 Batch 28/390 d_loss_real= 0.400, d_loss_fake= 0.284, g_loss 1.430, d_loss 0.342\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 29/390 d_loss_real= 0.487, d_loss_fake= 0.289, g_loss 1.436, d_loss 0.388\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 30/390 d_loss_real= 0.424, d_loss_fake= 0.287, g_loss 1.424, d_loss 0.356\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 31/390 d_loss_real= 0.354, d_loss_fake= 0.291, g_loss 1.416, d_loss 0.323\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 27 Batch 32/390 d_loss_real= 0.350, d_loss_fake= 0.285, g_loss 1.422, d_loss 0.318\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 33/390 d_loss_real= 0.262, d_loss_fake= 0.282, g_loss 1.466, d_loss 0.272\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 34/390 d_loss_real= 0.264, d_loss_fake= 0.264, g_loss 1.508, d_loss 0.264\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 27 Batch 35/390 d_loss_real= 0.605, d_loss_fake= 0.249, g_loss 1.549, d_loss 0.427\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 27 Batch 36/390 d_loss_real= 0.408, d_loss_fake= 0.249, g_loss 1.562, d_loss 0.329\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 27 Batch 37/390 d_loss_real= 0.404, d_loss_fake= 0.248, g_loss 1.554, d_loss 0.326\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 27 Batch 38/390 d_loss_real= 0.275, d_loss_fake= 0.248, g_loss 1.557, d_loss 0.262\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 39/390 d_loss_real= 0.434, d_loss_fake= 0.251, g_loss 1.549, d_loss 0.343\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 27 Batch 40/390 d_loss_real= 0.523, d_loss_fake= 0.256, g_loss 1.520, d_loss 0.389\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 41/390 d_loss_real= 0.364, d_loss_fake= 0.264, g_loss 1.486, d_loss 0.314\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 27 Batch 42/390 d_loss_real= 0.395, d_loss_fake= 0.274, g_loss 1.464, d_loss 0.334\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 43/390 d_loss_real= 0.444, d_loss_fake= 0.273, g_loss 1.454, d_loss 0.359\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 44/390 d_loss_real= 0.274, d_loss_fake= 0.280, g_loss 1.458, d_loss 0.277\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 27 Batch 45/390 d_loss_real= 0.385, d_loss_fake= 0.274, g_loss 1.484, d_loss 0.330\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 46/390 d_loss_real= 0.269, d_loss_fake= 0.263, g_loss 1.515, d_loss 0.266\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 27 Batch 47/390 d_loss_real= 0.248, d_loss_fake= 0.251, g_loss 1.584, d_loss 0.250\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 48/390 d_loss_real= 0.371, d_loss_fake= 0.235, g_loss 1.622, d_loss 0.303\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 27 Batch 49/390 d_loss_real= 0.293, d_loss_fake= 0.229, g_loss 1.630, d_loss 0.261\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 50/390 d_loss_real= 0.413, d_loss_fake= 0.225, g_loss 1.649, d_loss 0.319\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 51/390 d_loss_real= 0.405, d_loss_fake= 0.225, g_loss 1.647, d_loss 0.315\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 52/390 d_loss_real= 0.406, d_loss_fake= 0.223, g_loss 1.627, d_loss 0.314\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 53/390 d_loss_real= 0.310, d_loss_fake= 0.229, g_loss 1.623, d_loss 0.270\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 27 Batch 54/390 d_loss_real= 0.326, d_loss_fake= 0.233, g_loss 1.603, d_loss 0.280\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 55/390 d_loss_real= 0.498, d_loss_fake= 0.238, g_loss 1.580, d_loss 0.368\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 56/390 d_loss_real= 0.406, d_loss_fake= 0.243, g_loss 1.525, d_loss 0.325\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 57/390 d_loss_real= 0.230, d_loss_fake= 0.254, g_loss 1.516, d_loss 0.242\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 58/390 d_loss_real= 0.325, d_loss_fake= 0.263, g_loss 1.520, d_loss 0.294\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 59/390 d_loss_real= 0.327, d_loss_fake= 0.257, g_loss 1.543, d_loss 0.292\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 60/390 d_loss_real= 0.365, d_loss_fake= 0.259, g_loss 1.549, d_loss 0.312\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 61/390 d_loss_real= 0.236, d_loss_fake= 0.256, g_loss 1.544, d_loss 0.246\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 62/390 d_loss_real= 0.529, d_loss_fake= 0.254, g_loss 1.538, d_loss 0.392\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 63/390 d_loss_real= 0.388, d_loss_fake= 0.266, g_loss 1.530, d_loss 0.327\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 64/390 d_loss_real= 0.262, d_loss_fake= 0.272, g_loss 1.514, d_loss 0.267\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 65/390 d_loss_real= 0.313, d_loss_fake= 0.272, g_loss 1.511, d_loss 0.292\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 27 Batch 66/390 d_loss_real= 0.394, d_loss_fake= 0.296, g_loss 1.425, d_loss 0.345\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 67/390 d_loss_real= 0.347, d_loss_fake= 0.344, g_loss 1.357, d_loss 0.345\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 27 Batch 68/390 d_loss_real= 0.380, d_loss_fake= 0.358, g_loss 1.254, d_loss 0.369\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 69/390 d_loss_real= 0.540, d_loss_fake= 0.421, g_loss 1.206, d_loss 0.481\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 70/390 d_loss_real= 0.396, d_loss_fake= 0.466, g_loss 1.083, d_loss 0.431\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 71/390 d_loss_real= 0.385, d_loss_fake= 0.538, g_loss 1.056, d_loss 0.462\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 72/390 d_loss_real= 0.261, d_loss_fake= 0.592, g_loss 1.013, d_loss 0.427\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 27 Batch 73/390 d_loss_real= 0.331, d_loss_fake= 0.588, g_loss 0.959, d_loss 0.460\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 27 Batch 74/390 d_loss_real= 0.306, d_loss_fake= 0.616, g_loss 0.950, d_loss 0.461\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 75/390 d_loss_real= 0.491, d_loss_fake= 0.658, g_loss 0.925, d_loss 0.575\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 27 Batch 76/390 d_loss_real= 0.551, d_loss_fake= 0.702, g_loss 0.935, d_loss 0.626\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 27 Batch 77/390 d_loss_real= 0.571, d_loss_fake= 0.763, g_loss 0.881, d_loss 0.667\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 78/390 d_loss_real= 0.723, d_loss_fake= 0.785, g_loss 0.886, d_loss 0.754\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 27 Batch 79/390 d_loss_real= 0.729, d_loss_fake= 0.784, g_loss 0.899, d_loss 0.757\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 27 Batch 80/390 d_loss_real= 0.547, d_loss_fake= 0.727, g_loss 0.987, d_loss 0.637\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 27 Batch 81/390 d_loss_real= 0.672, d_loss_fake= 0.582, g_loss 1.105, d_loss 0.627\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 27 Batch 82/390 d_loss_real= 0.734, d_loss_fake= 0.620, g_loss 1.190, d_loss 0.677\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 83/390 d_loss_real= 0.930, d_loss_fake= 0.583, g_loss 1.216, d_loss 0.757\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 27 Batch 84/390 d_loss_real= 0.717, d_loss_fake= 0.502, g_loss 1.300, d_loss 0.609\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 85/390 d_loss_real= 0.958, d_loss_fake= 0.376, g_loss 1.469, d_loss 0.667\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 27 Batch 86/390 d_loss_real= 0.873, d_loss_fake= 0.319, g_loss 1.484, d_loss 0.596\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 87/390 d_loss_real= 0.481, d_loss_fake= 0.298, g_loss 1.564, d_loss 0.389\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 27 Batch 88/390 d_loss_real= 0.692, d_loss_fake= 0.301, g_loss 1.530, d_loss 0.497\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 89/390 d_loss_real= 0.507, d_loss_fake= 0.304, g_loss 1.552, d_loss 0.406\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 27 Batch 90/390 d_loss_real= 0.624, d_loss_fake= 0.300, g_loss 1.558, d_loss 0.462\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 91/390 d_loss_real= 0.471, d_loss_fake= 0.277, g_loss 1.562, d_loss 0.374\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 92/390 d_loss_real= 0.486, d_loss_fake= 0.282, g_loss 1.599, d_loss 0.384\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 93/390 d_loss_real= 0.346, d_loss_fake= 0.248, g_loss 1.745, d_loss 0.297\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 27 Batch 94/390 d_loss_real= 0.564, d_loss_fake= 0.237, g_loss 1.745, d_loss 0.400\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 95/390 d_loss_real= 0.628, d_loss_fake= 0.229, g_loss 1.738, d_loss 0.428\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 96/390 d_loss_real= 0.569, d_loss_fake= 0.216, g_loss 1.765, d_loss 0.393\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 97/390 d_loss_real= 0.593, d_loss_fake= 0.216, g_loss 1.779, d_loss 0.404\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 98/390 d_loss_real= 0.560, d_loss_fake= 0.213, g_loss 1.816, d_loss 0.386\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 99/390 d_loss_real= 0.278, d_loss_fake= 0.202, g_loss 1.855, d_loss 0.240\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 27 Batch 100/390 d_loss_real= 0.600, d_loss_fake= 0.186, g_loss 1.848, d_loss 0.393\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 27 Batch 101/390 d_loss_real= 0.570, d_loss_fake= 0.195, g_loss 1.856, d_loss 0.383\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 102/390 d_loss_real= 0.358, d_loss_fake= 0.187, g_loss 1.887, d_loss 0.273\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 27 Batch 103/390 d_loss_real= 0.558, d_loss_fake= 0.189, g_loss 1.880, d_loss 0.374\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 27 Batch 104/390 d_loss_real= 0.323, d_loss_fake= 0.182, g_loss 1.883, d_loss 0.253\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 105/390 d_loss_real= 0.386, d_loss_fake= 0.182, g_loss 1.895, d_loss 0.284\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 27 Batch 106/390 d_loss_real= 0.413, d_loss_fake= 0.178, g_loss 1.905, d_loss 0.295\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 27 Batch 107/390 d_loss_real= 0.481, d_loss_fake= 0.176, g_loss 1.891, d_loss 0.329\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 108/390 d_loss_real= 0.353, d_loss_fake= 0.175, g_loss 1.909, d_loss 0.264\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 27 Batch 109/390 d_loss_real= 0.342, d_loss_fake= 0.175, g_loss 1.911, d_loss 0.259\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 110/390 d_loss_real= 0.380, d_loss_fake= 0.181, g_loss 1.859, d_loss 0.281\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 111/390 d_loss_real= 0.555, d_loss_fake= 0.188, g_loss 1.804, d_loss 0.371\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 112/390 d_loss_real= 0.410, d_loss_fake= 0.197, g_loss 1.768, d_loss 0.304\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 113/390 d_loss_real= 0.342, d_loss_fake= 0.202, g_loss 1.779, d_loss 0.272\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 27 Batch 114/390 d_loss_real= 0.502, d_loss_fake= 0.206, g_loss 1.733, d_loss 0.354\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 27 Batch 115/390 d_loss_real= 0.312, d_loss_fake= 0.212, g_loss 1.753, d_loss 0.262\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 27 Batch 116/390 d_loss_real= 0.506, d_loss_fake= 0.214, g_loss 1.732, d_loss 0.360\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 117/390 d_loss_real= 0.483, d_loss_fake= 0.219, g_loss 1.707, d_loss 0.351\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 27 Batch 118/390 d_loss_real= 0.380, d_loss_fake= 0.233, g_loss 1.676, d_loss 0.306\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 27 Batch 119/390 d_loss_real= 0.434, d_loss_fake= 0.253, g_loss 1.665, d_loss 0.343\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 120/390 d_loss_real= 0.316, d_loss_fake= 0.287, g_loss 1.587, d_loss 0.301\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 121/390 d_loss_real= 0.225, d_loss_fake= 0.325, g_loss 1.697, d_loss 0.275\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 27 Batch 122/390 d_loss_real= 0.504, d_loss_fake= 0.202, g_loss 2.031, d_loss 0.353\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 123/390 d_loss_real= 0.550, d_loss_fake= 0.172, g_loss 2.214, d_loss 0.361\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 124/390 d_loss_real= 0.508, d_loss_fake= 0.083, g_loss 2.622, d_loss 0.296\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 27 Batch 125/390 d_loss_real= 0.663, d_loss_fake= 0.099, g_loss 2.404, d_loss 0.381\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 27 Batch 126/390 d_loss_real= 0.552, d_loss_fake= 0.150, g_loss 1.911, d_loss 0.351\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 27 Batch 127/390 d_loss_real= 0.443, d_loss_fake= 0.164, g_loss 1.859, d_loss 0.303\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 27 Batch 128/390 d_loss_real= 0.479, d_loss_fake= 0.216, g_loss 1.659, d_loss 0.348\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 129/390 d_loss_real= 0.264, d_loss_fake= 0.259, g_loss 1.528, d_loss 0.262\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 130/390 d_loss_real= 0.391, d_loss_fake= 0.265, g_loss 1.554, d_loss 0.328\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 27 Batch 131/390 d_loss_real= 0.414, d_loss_fake= 0.257, g_loss 1.652, d_loss 0.335\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 132/390 d_loss_real= 0.350, d_loss_fake= 0.216, g_loss 1.841, d_loss 0.283\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 133/390 d_loss_real= 0.489, d_loss_fake= 0.167, g_loss 2.018, d_loss 0.328\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 134/390 d_loss_real= 0.350, d_loss_fake= 0.145, g_loss 2.118, d_loss 0.248\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 135/390 d_loss_real= 0.468, d_loss_fake= 0.138, g_loss 2.115, d_loss 0.303\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 27 Batch 136/390 d_loss_real= 0.375, d_loss_fake= 0.149, g_loss 2.007, d_loss 0.262\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 137/390 d_loss_real= 0.118, d_loss_fake= 0.177, g_loss 1.882, d_loss 0.148\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 27 Batch 138/390 d_loss_real= 0.273, d_loss_fake= 0.229, g_loss 1.704, d_loss 0.251\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 139/390 d_loss_real= 0.345, d_loss_fake= 0.264, g_loss 1.567, d_loss 0.305\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 140/390 d_loss_real= 0.338, d_loss_fake= 0.301, g_loss 1.505, d_loss 0.319\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 141/390 d_loss_real= 0.393, d_loss_fake= 0.343, g_loss 1.457, d_loss 0.368\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 142/390 d_loss_real= 0.320, d_loss_fake= 0.344, g_loss 1.476, d_loss 0.332\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 143/390 d_loss_real= 0.278, d_loss_fake= 0.321, g_loss 1.618, d_loss 0.300\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 144/390 d_loss_real= 0.478, d_loss_fake= 0.259, g_loss 1.799, d_loss 0.369\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 145/390 d_loss_real= 0.643, d_loss_fake= 0.138, g_loss 2.425, d_loss 0.391\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 27 Batch 146/390 d_loss_real= 0.522, d_loss_fake= 0.046, g_loss 3.207, d_loss 0.284\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 147/390 d_loss_real= 0.428, d_loss_fake= 0.061, g_loss 2.829, d_loss 0.245\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 148/390 d_loss_real= 0.246, d_loss_fake= 0.074, g_loss 2.617, d_loss 0.160\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 149/390 d_loss_real= 0.922, d_loss_fake= 0.110, g_loss 2.239, d_loss 0.516\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 150/390 d_loss_real= 0.504, d_loss_fake= 0.190, g_loss 1.732, d_loss 0.347\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 27 Batch 151/390 d_loss_real= 0.205, d_loss_fake= 0.256, g_loss 1.634, d_loss 0.231\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 27 Batch 152/390 d_loss_real= 0.374, d_loss_fake= 0.290, g_loss 1.600, d_loss 0.332\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 153/390 d_loss_real= 0.260, d_loss_fake= 0.246, g_loss 1.761, d_loss 0.253\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 27 Batch 154/390 d_loss_real= 0.295, d_loss_fake= 0.179, g_loss 2.067, d_loss 0.237\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 27 Batch 155/390 d_loss_real= 0.314, d_loss_fake= 0.118, g_loss 2.367, d_loss 0.216\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 27 Batch 156/390 d_loss_real= 0.227, d_loss_fake= 0.088, g_loss 2.582, d_loss 0.158\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 157/390 d_loss_real= 0.259, d_loss_fake= 0.075, g_loss 2.646, d_loss 0.167\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 27 Batch 158/390 d_loss_real= 0.221, d_loss_fake= 0.079, g_loss 2.591, d_loss 0.150\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 159/390 d_loss_real= 0.544, d_loss_fake= 0.083, g_loss 2.548, d_loss 0.314\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 160/390 d_loss_real= 0.201, d_loss_fake= 0.096, g_loss 2.469, d_loss 0.149\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 161/390 d_loss_real= 0.211, d_loss_fake= 0.106, g_loss 2.348, d_loss 0.159\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 27 Batch 162/390 d_loss_real= 0.297, d_loss_fake= 0.115, g_loss 2.274, d_loss 0.206\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 163/390 d_loss_real= 0.136, d_loss_fake= 0.122, g_loss 2.280, d_loss 0.129\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 164/390 d_loss_real= 0.166, d_loss_fake= 0.127, g_loss 2.336, d_loss 0.147\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 27 Batch 165/390 d_loss_real= 0.245, d_loss_fake= 0.118, g_loss 2.409, d_loss 0.181\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 166/390 d_loss_real= 0.257, d_loss_fake= 0.105, g_loss 2.514, d_loss 0.181\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 27 Batch 167/390 d_loss_real= 0.262, d_loss_fake= 0.128, g_loss 2.504, d_loss 0.195\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 168/390 d_loss_real= 0.099, d_loss_fake= 0.109, g_loss 2.655, d_loss 0.104\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 169/390 d_loss_real= 0.204, d_loss_fake= 0.071, g_loss 3.027, d_loss 0.137\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 170/390 d_loss_real= 0.361, d_loss_fake= 0.048, g_loss 3.261, d_loss 0.204\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 171/390 d_loss_real= 0.387, d_loss_fake= 0.040, g_loss 3.301, d_loss 0.214\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 172/390 d_loss_real= 0.428, d_loss_fake= 0.041, g_loss 3.219, d_loss 0.234\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 27 Batch 173/390 d_loss_real= 0.523, d_loss_fake= 0.050, g_loss 2.966, d_loss 0.287\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 27 Batch 174/390 d_loss_real= 0.493, d_loss_fake= 0.075, g_loss 2.500, d_loss 0.284\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 27 Batch 175/390 d_loss_real= 0.417, d_loss_fake= 0.131, g_loss 2.179, d_loss 0.274\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 176/390 d_loss_real= 0.362, d_loss_fake= 0.147, g_loss 2.313, d_loss 0.255\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 27 Batch 177/390 d_loss_real= 0.180, d_loss_fake= 0.098, g_loss 2.701, d_loss 0.139\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 178/390 d_loss_real= 0.195, d_loss_fake= 0.065, g_loss 3.052, d_loss 0.130\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 27 Batch 179/390 d_loss_real= 0.182, d_loss_fake= 0.045, g_loss 3.277, d_loss 0.113\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 27 Batch 180/390 d_loss_real= 0.201, d_loss_fake= 0.038, g_loss 3.337, d_loss 0.120\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 27 Batch 181/390 d_loss_real= 0.343, d_loss_fake= 0.038, g_loss 3.315, d_loss 0.191\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 182/390 d_loss_real= 0.233, d_loss_fake= 0.040, g_loss 3.196, d_loss 0.137\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 27 Batch 183/390 d_loss_real= 0.415, d_loss_fake= 0.047, g_loss 3.015, d_loss 0.231\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 184/390 d_loss_real= 0.108, d_loss_fake= 0.056, g_loss 2.860, d_loss 0.082\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 27 Batch 185/390 d_loss_real= 0.290, d_loss_fake= 0.068, g_loss 2.676, d_loss 0.179\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 27 Batch 186/390 d_loss_real= 0.193, d_loss_fake= 0.081, g_loss 2.539, d_loss 0.137\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 187/390 d_loss_real= 0.083, d_loss_fake= 0.093, g_loss 2.485, d_loss 0.088\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 27 Batch 188/390 d_loss_real= 0.242, d_loss_fake= 0.092, g_loss 2.533, d_loss 0.167\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 27 Batch 189/390 d_loss_real= 0.160, d_loss_fake= 0.086, g_loss 2.640, d_loss 0.123\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 27 Batch 190/390 d_loss_real= 0.210, d_loss_fake= 0.075, g_loss 2.761, d_loss 0.143\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 27 Batch 191/390 d_loss_real= 0.390, d_loss_fake= 0.070, g_loss 2.760, d_loss 0.230\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 192/390 d_loss_real= 0.126, d_loss_fake= 0.066, g_loss 2.825, d_loss 0.096\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 193/390 d_loss_real= 0.198, d_loss_fake= 0.067, g_loss 2.783, d_loss 0.133\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 194/390 d_loss_real= 0.089, d_loss_fake= 0.068, g_loss 2.794, d_loss 0.079\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 195/390 d_loss_real= 0.132, d_loss_fake= 0.071, g_loss 2.866, d_loss 0.101\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 196/390 d_loss_real= 0.217, d_loss_fake= 0.063, g_loss 2.954, d_loss 0.140\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 197/390 d_loss_real= 0.107, d_loss_fake= 0.058, g_loss 3.039, d_loss 0.082\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 198/390 d_loss_real= 0.231, d_loss_fake= 0.052, g_loss 3.082, d_loss 0.141\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 199/390 d_loss_real= 0.243, d_loss_fake= 0.052, g_loss 3.092, d_loss 0.147\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 200/390 d_loss_real= 0.084, d_loss_fake= 0.048, g_loss 3.156, d_loss 0.066\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 201/390 d_loss_real= 0.153, d_loss_fake= 0.045, g_loss 3.194, d_loss 0.099\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 202/390 d_loss_real= 0.218, d_loss_fake= 0.046, g_loss 3.161, d_loss 0.132\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 203/390 d_loss_real= 0.180, d_loss_fake= 0.048, g_loss 3.140, d_loss 0.114\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 204/390 d_loss_real= 0.307, d_loss_fake= 0.053, g_loss 3.048, d_loss 0.180\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 205/390 d_loss_real= 0.271, d_loss_fake= 0.059, g_loss 2.908, d_loss 0.165\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 27 Batch 206/390 d_loss_real= 0.227, d_loss_fake= 0.066, g_loss 2.839, d_loss 0.146\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 207/390 d_loss_real= 0.175, d_loss_fake= 0.068, g_loss 2.838, d_loss 0.121\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 208/390 d_loss_real= 0.252, d_loss_fake= 0.062, g_loss 2.937, d_loss 0.157\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 209/390 d_loss_real= 0.202, d_loss_fake= 0.054, g_loss 3.050, d_loss 0.128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 210/390 d_loss_real= 0.218, d_loss_fake= 0.049, g_loss 3.112, d_loss 0.134\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 211/390 d_loss_real= 0.318, d_loss_fake= 0.049, g_loss 3.055, d_loss 0.184\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 27 Batch 212/390 d_loss_real= 0.306, d_loss_fake= 0.052, g_loss 2.985, d_loss 0.179\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 213/390 d_loss_real= 0.225, d_loss_fake= 0.057, g_loss 2.933, d_loss 0.141\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 214/390 d_loss_real= 0.221, d_loss_fake= 0.061, g_loss 2.853, d_loss 0.141\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 215/390 d_loss_real= 0.190, d_loss_fake= 0.064, g_loss 2.826, d_loss 0.127\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 27 Batch 216/390 d_loss_real= 0.192, d_loss_fake= 0.066, g_loss 2.831, d_loss 0.129\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 217/390 d_loss_real= 0.224, d_loss_fake= 0.065, g_loss 2.796, d_loss 0.145\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 27 Batch 218/390 d_loss_real= 0.207, d_loss_fake= 0.067, g_loss 2.772, d_loss 0.137\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 219/390 d_loss_real= 0.187, d_loss_fake= 0.069, g_loss 2.742, d_loss 0.128\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 27 Batch 220/390 d_loss_real= 0.191, d_loss_fake= 0.070, g_loss 2.743, d_loss 0.131\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 221/390 d_loss_real= 0.171, d_loss_fake= 0.069, g_loss 2.763, d_loss 0.120\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 222/390 d_loss_real= 0.101, d_loss_fake= 0.067, g_loss 2.787, d_loss 0.084\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 223/390 d_loss_real= 0.066, d_loss_fake= 0.066, g_loss 2.805, d_loss 0.066\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 224/390 d_loss_real= 0.089, d_loss_fake= 0.065, g_loss 2.839, d_loss 0.077\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 225/390 d_loss_real= 0.056, d_loss_fake= 0.064, g_loss 2.844, d_loss 0.060\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 226/390 d_loss_real= 0.188, d_loss_fake= 0.065, g_loss 2.810, d_loss 0.127\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 27 Batch 227/390 d_loss_real= 0.077, d_loss_fake= 0.069, g_loss 2.763, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 228/390 d_loss_real= 0.080, d_loss_fake= 0.076, g_loss 2.675, d_loss 0.078\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 229/390 d_loss_real= 0.106, d_loss_fake= 0.088, g_loss 2.522, d_loss 0.097\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 230/390 d_loss_real= 0.160, d_loss_fake= 0.109, g_loss 2.339, d_loss 0.134\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 231/390 d_loss_real= 0.158, d_loss_fake= 0.129, g_loss 2.173, d_loss 0.143\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 232/390 d_loss_real= 0.099, d_loss_fake= 0.147, g_loss 2.044, d_loss 0.123\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 27 Batch 233/390 d_loss_real= 0.102, d_loss_fake= 0.161, g_loss 1.961, d_loss 0.132\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 27 Batch 234/390 d_loss_real= 0.062, d_loss_fake= 0.150, g_loss 2.024, d_loss 0.106\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 27 Batch 235/390 d_loss_real= 0.236, d_loss_fake= 0.145, g_loss 2.064, d_loss 0.191\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 236/390 d_loss_real= 0.095, d_loss_fake= 0.139, g_loss 2.088, d_loss 0.117\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 27 Batch 237/390 d_loss_real= 0.136, d_loss_fake= 0.132, g_loss 2.170, d_loss 0.134\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 238/390 d_loss_real= 0.206, d_loss_fake= 0.123, g_loss 2.182, d_loss 0.164\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 27 Batch 239/390 d_loss_real= 0.224, d_loss_fake= 0.118, g_loss 2.250, d_loss 0.171\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 240/390 d_loss_real= 0.200, d_loss_fake= 0.112, g_loss 2.280, d_loss 0.156\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 27 Batch 241/390 d_loss_real= 0.171, d_loss_fake= 0.110, g_loss 2.281, d_loss 0.140\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 242/390 d_loss_real= 0.157, d_loss_fake= 0.110, g_loss 2.301, d_loss 0.133\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 243/390 d_loss_real= 0.194, d_loss_fake= 0.110, g_loss 2.304, d_loss 0.152\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 27 Batch 244/390 d_loss_real= 0.057, d_loss_fake= 0.109, g_loss 2.317, d_loss 0.083\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 245/390 d_loss_real= 0.174, d_loss_fake= 0.107, g_loss 2.346, d_loss 0.141\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 246/390 d_loss_real= 0.034, d_loss_fake= 0.104, g_loss 2.357, d_loss 0.069\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 27 Batch 247/390 d_loss_real= 0.072, d_loss_fake= 0.102, g_loss 2.411, d_loss 0.087\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 248/390 d_loss_real= 0.096, d_loss_fake= 0.096, g_loss 2.439, d_loss 0.096\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 249/390 d_loss_real= 0.121, d_loss_fake= 0.094, g_loss 2.469, d_loss 0.107\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 27 Batch 250/390 d_loss_real= 0.045, d_loss_fake= 0.093, g_loss 2.471, d_loss 0.069\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 251/390 d_loss_real= 0.052, d_loss_fake= 0.096, g_loss 2.478, d_loss 0.074\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 252/390 d_loss_real= 0.132, d_loss_fake= 0.103, g_loss 2.459, d_loss 0.118\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 253/390 d_loss_real= 0.098, d_loss_fake= 0.108, g_loss 2.424, d_loss 0.103\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 254/390 d_loss_real= 0.093, d_loss_fake= 0.109, g_loss 2.395, d_loss 0.101\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 27 Batch 255/390 d_loss_real= 0.018, d_loss_fake= 0.100, g_loss 2.412, d_loss 0.059\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 27 Batch 256/390 d_loss_real= 0.058, d_loss_fake= 0.105, g_loss 2.459, d_loss 0.081\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 257/390 d_loss_real= 0.066, d_loss_fake= 0.107, g_loss 2.434, d_loss 0.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 258/390 d_loss_real= 0.136, d_loss_fake= 0.111, g_loss 2.387, d_loss 0.124\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 27 Batch 259/390 d_loss_real= 0.140, d_loss_fake= 0.115, g_loss 2.313, d_loss 0.127\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 27 Batch 260/390 d_loss_real= 0.106, d_loss_fake= 0.155, g_loss 2.141, d_loss 0.131\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 27 Batch 261/390 d_loss_real= 0.223, d_loss_fake= 0.193, g_loss 2.059, d_loss 0.208\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 262/390 d_loss_real= 0.190, d_loss_fake= 0.221, g_loss 1.893, d_loss 0.205\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 263/390 d_loss_real= 0.210, d_loss_fake= 0.300, g_loss 1.725, d_loss 0.255\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 27 Batch 264/390 d_loss_real= 0.226, d_loss_fake= 0.284, g_loss 1.702, d_loss 0.255\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 265/390 d_loss_real= 0.432, d_loss_fake= 0.246, g_loss 1.936, d_loss 0.339\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 27 Batch 266/390 d_loss_real= 0.308, d_loss_fake= 0.070, g_loss 3.142, d_loss 0.189\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 27 Batch 267/390 d_loss_real= 0.288, d_loss_fake= 0.016, g_loss 4.345, d_loss 0.152\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 268/390 d_loss_real= 0.571, d_loss_fake= 0.023, g_loss 3.826, d_loss 0.297\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 27 Batch 269/390 d_loss_real= 0.262, d_loss_fake= 0.053, g_loss 3.030, d_loss 0.157\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 270/390 d_loss_real= 0.449, d_loss_fake= 0.124, g_loss 2.202, d_loss 0.286\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 27 Batch 271/390 d_loss_real= 0.283, d_loss_fake= 0.341, g_loss 1.560, d_loss 0.312\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 27 Batch 272/390 d_loss_real= 0.236, d_loss_fake= 0.296, g_loss 1.655, d_loss 0.266\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 273/390 d_loss_real= 0.375, d_loss_fake= 0.321, g_loss 1.836, d_loss 0.348\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 274/390 d_loss_real= 0.253, d_loss_fake= 0.264, g_loss 1.991, d_loss 0.259\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 275/390 d_loss_real= 0.284, d_loss_fake= 0.143, g_loss 2.409, d_loss 0.214\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 276/390 d_loss_real= 0.071, d_loss_fake= 0.053, g_loss 3.287, d_loss 0.062\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 277/390 d_loss_real= 0.275, d_loss_fake= 0.072, g_loss 2.885, d_loss 0.174\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 278/390 d_loss_real= 0.452, d_loss_fake= 0.087, g_loss 2.727, d_loss 0.270\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 27 Batch 279/390 d_loss_real= 0.287, d_loss_fake= 0.078, g_loss 2.760, d_loss 0.183\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 280/390 d_loss_real= 0.289, d_loss_fake= 0.131, g_loss 2.464, d_loss 0.210\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 281/390 d_loss_real= 0.404, d_loss_fake= 0.118, g_loss 2.329, d_loss 0.261\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 282/390 d_loss_real= 0.350, d_loss_fake= 0.185, g_loss 2.108, d_loss 0.267\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 283/390 d_loss_real= 0.224, d_loss_fake= 0.135, g_loss 2.481, d_loss 0.179\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 284/390 d_loss_real= 0.282, d_loss_fake= 0.253, g_loss 1.923, d_loss 0.267\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 285/390 d_loss_real= 0.083, d_loss_fake= 0.310, g_loss 1.916, d_loss 0.197\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 286/390 d_loss_real= 0.427, d_loss_fake= 0.155, g_loss 2.461, d_loss 0.291\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 287/390 d_loss_real= 0.455, d_loss_fake= 0.080, g_loss 2.981, d_loss 0.267\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 288/390 d_loss_real= 0.339, d_loss_fake= 0.117, g_loss 2.516, d_loss 0.228\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 289/390 d_loss_real= 0.271, d_loss_fake= 0.085, g_loss 2.723, d_loss 0.178\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 290/390 d_loss_real= 0.323, d_loss_fake= 0.054, g_loss 3.024, d_loss 0.188\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 27 Batch 291/390 d_loss_real= 0.437, d_loss_fake= 0.134, g_loss 2.375, d_loss 0.285\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 292/390 d_loss_real= 0.234, d_loss_fake= 0.096, g_loss 2.495, d_loss 0.165\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 293/390 d_loss_real= 0.512, d_loss_fake= 0.083, g_loss 2.679, d_loss 0.298\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 294/390 d_loss_real= 0.494, d_loss_fake= 0.226, g_loss 1.933, d_loss 0.360\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 27 Batch 295/390 d_loss_real= 0.262, d_loss_fake= 0.270, g_loss 1.842, d_loss 0.266\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 296/390 d_loss_real= 0.152, d_loss_fake= 0.335, g_loss 1.867, d_loss 0.243\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 297/390 d_loss_real= 0.273, d_loss_fake= 0.265, g_loss 2.099, d_loss 0.269\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 298/390 d_loss_real= 0.382, d_loss_fake= 0.130, g_loss 2.552, d_loss 0.256\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 299/390 d_loss_real= 0.455, d_loss_fake= 0.074, g_loss 2.895, d_loss 0.265\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 27 Batch 300/390 d_loss_real= 0.583, d_loss_fake= 0.073, g_loss 2.836, d_loss 0.328\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 27 Batch 301/390 d_loss_real= 0.638, d_loss_fake= 0.070, g_loss 2.809, d_loss 0.354\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 27 Batch 302/390 d_loss_real= 0.586, d_loss_fake= 0.079, g_loss 2.587, d_loss 0.332\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 303/390 d_loss_real= 0.194, d_loss_fake= 0.121, g_loss 2.184, d_loss 0.158\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 304/390 d_loss_real= 0.381, d_loss_fake= 0.145, g_loss 2.063, d_loss 0.263\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 305/390 d_loss_real= 0.602, d_loss_fake= 0.156, g_loss 1.890, d_loss 0.379\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 306/390 d_loss_real= 0.200, d_loss_fake= 0.277, g_loss 1.540, d_loss 0.238\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 307/390 d_loss_real= 0.159, d_loss_fake= 0.257, g_loss 1.698, d_loss 0.208\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 308/390 d_loss_real= 0.315, d_loss_fake= 0.206, g_loss 1.937, d_loss 0.260\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 27 Batch 309/390 d_loss_real= 0.423, d_loss_fake= 0.237, g_loss 1.775, d_loss 0.330\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 27 Batch 310/390 d_loss_real= 0.292, d_loss_fake= 0.190, g_loss 1.990, d_loss 0.241\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 311/390 d_loss_real= 0.194, d_loss_fake= 0.176, g_loss 2.062, d_loss 0.185\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 312/390 d_loss_real= 0.430, d_loss_fake= 0.192, g_loss 1.968, d_loss 0.311\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 27 Batch 313/390 d_loss_real= 0.362, d_loss_fake= 0.219, g_loss 1.866, d_loss 0.291\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 314/390 d_loss_real= 0.296, d_loss_fake= 0.258, g_loss 1.818, d_loss 0.277\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 27 Batch 315/390 d_loss_real= 0.607, d_loss_fake= 0.375, g_loss 1.613, d_loss 0.491\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 316/390 d_loss_real= 0.178, d_loss_fake= 0.402, g_loss 1.448, d_loss 0.290\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 27 Batch 317/390 d_loss_real= 0.420, d_loss_fake= 0.379, g_loss 1.547, d_loss 0.399\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 318/390 d_loss_real= 0.508, d_loss_fake= 0.335, g_loss 1.519, d_loss 0.422\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 27 Batch 319/390 d_loss_real= 0.339, d_loss_fake= 0.255, g_loss 1.737, d_loss 0.297\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 320/390 d_loss_real= 0.706, d_loss_fake= 0.200, g_loss 1.891, d_loss 0.453\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 27 Batch 321/390 d_loss_real= 0.397, d_loss_fake= 0.175, g_loss 1.977, d_loss 0.286\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 322/390 d_loss_real= 0.370, d_loss_fake= 0.161, g_loss 2.010, d_loss 0.265\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 323/390 d_loss_real= 0.457, d_loss_fake= 0.158, g_loss 1.988, d_loss 0.308\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 27 Batch 324/390 d_loss_real= 0.592, d_loss_fake= 0.165, g_loss 1.916, d_loss 0.378\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 325/390 d_loss_real= 0.411, d_loss_fake= 0.173, g_loss 1.862, d_loss 0.292\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 326/390 d_loss_real= 0.490, d_loss_fake= 0.185, g_loss 1.795, d_loss 0.338\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 27 Batch 327/390 d_loss_real= 0.457, d_loss_fake= 0.205, g_loss 1.694, d_loss 0.331\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 328/390 d_loss_real= 0.555, d_loss_fake= 0.234, g_loss 1.591, d_loss 0.395\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 329/390 d_loss_real= 0.207, d_loss_fake= 0.248, g_loss 1.627, d_loss 0.228\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 330/390 d_loss_real= 0.307, d_loss_fake= 0.237, g_loss 1.712, d_loss 0.272\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 331/390 d_loss_real= 0.184, d_loss_fake= 0.211, g_loss 1.866, d_loss 0.197\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 27 Batch 332/390 d_loss_real= 0.352, d_loss_fake= 0.169, g_loss 2.046, d_loss 0.261\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 333/390 d_loss_real= 0.318, d_loss_fake= 0.133, g_loss 2.132, d_loss 0.225\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 334/390 d_loss_real= 0.246, d_loss_fake= 0.131, g_loss 2.191, d_loss 0.188\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 335/390 d_loss_real= 0.261, d_loss_fake= 0.124, g_loss 2.150, d_loss 0.193\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 336/390 d_loss_real= 0.258, d_loss_fake= 0.129, g_loss 2.216, d_loss 0.193\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 27 Batch 337/390 d_loss_real= 0.202, d_loss_fake= 0.143, g_loss 2.157, d_loss 0.173\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 338/390 d_loss_real= 0.222, d_loss_fake= 0.139, g_loss 2.051, d_loss 0.181\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 339/390 d_loss_real= 0.243, d_loss_fake= 0.161, g_loss 2.048, d_loss 0.202\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 340/390 d_loss_real= 0.162, d_loss_fake= 0.166, g_loss 1.995, d_loss 0.164\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 27 Batch 341/390 d_loss_real= 0.250, d_loss_fake= 0.154, g_loss 2.087, d_loss 0.202\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 342/390 d_loss_real= 0.619, d_loss_fake= 0.143, g_loss 2.161, d_loss 0.381\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 343/390 d_loss_real= 0.367, d_loss_fake= 0.126, g_loss 2.275, d_loss 0.247\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 344/390 d_loss_real= 0.418, d_loss_fake= 0.123, g_loss 2.336, d_loss 0.270\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 345/390 d_loss_real= 0.225, d_loss_fake= 0.108, g_loss 2.388, d_loss 0.166\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 346/390 d_loss_real= 0.231, d_loss_fake= 0.101, g_loss 2.429, d_loss 0.166\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 347/390 d_loss_real= 0.474, d_loss_fake= 0.105, g_loss 2.499, d_loss 0.290\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 27 Batch 348/390 d_loss_real= 0.253, d_loss_fake= 0.098, g_loss 2.540, d_loss 0.175\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 27 Batch 349/390 d_loss_real= 0.113, d_loss_fake= 0.094, g_loss 2.539, d_loss 0.104\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 27 Batch 350/390 d_loss_real= 0.500, d_loss_fake= 0.090, g_loss 2.514, d_loss 0.295\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 351/390 d_loss_real= 0.275, d_loss_fake= 0.092, g_loss 2.437, d_loss 0.183\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 352/390 d_loss_real= 0.388, d_loss_fake= 0.115, g_loss 2.249, d_loss 0.251\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 27 Batch 353/390 d_loss_real= 0.563, d_loss_fake= 0.134, g_loss 2.143, d_loss 0.348\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 354/390 d_loss_real= 0.382, d_loss_fake= 0.174, g_loss 2.028, d_loss 0.278\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 355/390 d_loss_real= 0.299, d_loss_fake= 0.172, g_loss 2.220, d_loss 0.236\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 356/390 d_loss_real= 0.431, d_loss_fake= 0.130, g_loss 2.405, d_loss 0.281\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 27 Batch 357/390 d_loss_real= 0.277, d_loss_fake= 0.097, g_loss 2.696, d_loss 0.187\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 27 Batch 358/390 d_loss_real= 0.289, d_loss_fake= 0.070, g_loss 2.846, d_loss 0.179\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 359/390 d_loss_real= 0.388, d_loss_fake= 0.063, g_loss 2.897, d_loss 0.226\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 360/390 d_loss_real= 0.300, d_loss_fake= 0.063, g_loss 2.815, d_loss 0.181\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 361/390 d_loss_real= 0.581, d_loss_fake= 0.073, g_loss 2.589, d_loss 0.327\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 362/390 d_loss_real= 0.324, d_loss_fake= 0.093, g_loss 2.333, d_loss 0.209\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 27 Batch 363/390 d_loss_real= 0.488, d_loss_fake= 0.130, g_loss 2.112, d_loss 0.309\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 364/390 d_loss_real= 0.212, d_loss_fake= 0.180, g_loss 2.010, d_loss 0.196\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 365/390 d_loss_real= 0.164, d_loss_fake= 0.219, g_loss 2.150, d_loss 0.192\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 366/390 d_loss_real= 0.206, d_loss_fake= 0.131, g_loss 2.452, d_loss 0.168\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 27 Batch 367/390 d_loss_real= 0.410, d_loss_fake= 0.090, g_loss 2.655, d_loss 0.250\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 368/390 d_loss_real= 0.255, d_loss_fake= 0.078, g_loss 2.741, d_loss 0.166\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 369/390 d_loss_real= 0.477, d_loss_fake= 0.071, g_loss 2.764, d_loss 0.274\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 370/390 d_loss_real= 0.994, d_loss_fake= 0.078, g_loss 2.625, d_loss 0.536\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 371/390 d_loss_real= 0.597, d_loss_fake= 0.099, g_loss 2.392, d_loss 0.348\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 27 Batch 372/390 d_loss_real= 0.403, d_loss_fake= 0.126, g_loss 2.130, d_loss 0.265\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 27 Batch 373/390 d_loss_real= 0.461, d_loss_fake= 0.170, g_loss 1.923, d_loss 0.316\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 374/390 d_loss_real= 0.598, d_loss_fake= 0.218, g_loss 1.757, d_loss 0.408\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 375/390 d_loss_real= 0.199, d_loss_fake= 0.217, g_loss 1.850, d_loss 0.208\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 376/390 d_loss_real= 0.193, d_loss_fake= 0.184, g_loss 2.114, d_loss 0.188\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27 Batch 377/390 d_loss_real= 0.367, d_loss_fake= 0.128, g_loss 2.354, d_loss 0.247\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 27 Batch 378/390 d_loss_real= 0.301, d_loss_fake= 0.113, g_loss 2.425, d_loss 0.207\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 379/390 d_loss_real= 0.315, d_loss_fake= 0.100, g_loss 2.391, d_loss 0.207\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 380/390 d_loss_real= 0.487, d_loss_fake= 0.111, g_loss 2.306, d_loss 0.299\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27 Batch 381/390 d_loss_real= 0.339, d_loss_fake= 0.126, g_loss 2.226, d_loss 0.232\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 382/390 d_loss_real= 0.429, d_loss_fake= 0.140, g_loss 2.125, d_loss 0.285\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 27 Batch 383/390 d_loss_real= 0.348, d_loss_fake= 0.158, g_loss 2.095, d_loss 0.253\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27 Batch 384/390 d_loss_real= 0.380, d_loss_fake= 0.147, g_loss 2.186, d_loss 0.264\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 27 Batch 385/390 d_loss_real= 0.314, d_loss_fake= 0.129, g_loss 2.192, d_loss 0.222\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 386/390 d_loss_real= 0.332, d_loss_fake= 0.126, g_loss 2.240, d_loss 0.229\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27 Batch 387/390 d_loss_real= 0.308, d_loss_fake= 0.124, g_loss 2.283, d_loss 0.216\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 27 Batch 388/390 d_loss_real= 0.389, d_loss_fake= 0.115, g_loss 2.349, d_loss 0.252\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 27 Batch 389/390 d_loss_real= 0.358, d_loss_fake= 0.108, g_loss 2.430, d_loss 0.233\n",
            "2/2 [==============================] - 0s 11ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27 Batch 390/390 d_loss_real= 0.230, d_loss_fake= 0.095, g_loss 2.474, d_loss 0.162\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 1/390 d_loss_real= 0.288, d_loss_fake= 0.092, g_loss 2.512, d_loss 0.190\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28 Batch 2/390 d_loss_real= 0.285, d_loss_fake= 0.087, g_loss 2.603, d_loss 0.186\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 28 Batch 3/390 d_loss_real= 0.303, d_loss_fake= 0.089, g_loss 2.548, d_loss 0.196\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 4/390 d_loss_real= 0.336, d_loss_fake= 0.081, g_loss 2.525, d_loss 0.209\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 5/390 d_loss_real= 0.194, d_loss_fake= 0.094, g_loss 2.398, d_loss 0.144\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 28 Batch 6/390 d_loss_real= 0.142, d_loss_fake= 0.103, g_loss 2.350, d_loss 0.122\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 28 Batch 7/390 d_loss_real= 0.273, d_loss_fake= 0.088, g_loss 2.522, d_loss 0.181\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 28 Batch 8/390 d_loss_real= 0.139, d_loss_fake= 0.094, g_loss 2.454, d_loss 0.116\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 9/390 d_loss_real= 0.334, d_loss_fake= 0.100, g_loss 2.411, d_loss 0.217\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 10/390 d_loss_real= 0.235, d_loss_fake= 0.112, g_loss 2.407, d_loss 0.173\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 28 Batch 11/390 d_loss_real= 0.223, d_loss_fake= 0.095, g_loss 2.505, d_loss 0.159\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 28 Batch 12/390 d_loss_real= 0.326, d_loss_fake= 0.089, g_loss 2.598, d_loss 0.207\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 28 Batch 13/390 d_loss_real= 0.222, d_loss_fake= 0.078, g_loss 2.686, d_loss 0.150\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 28 Batch 14/390 d_loss_real= 0.363, d_loss_fake= 0.076, g_loss 2.661, d_loss 0.220\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 28 Batch 15/390 d_loss_real= 0.136, d_loss_fake= 0.080, g_loss 2.640, d_loss 0.108\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 16/390 d_loss_real= 0.194, d_loss_fake= 0.081, g_loss 2.651, d_loss 0.138\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 17/390 d_loss_real= 0.142, d_loss_fake= 0.079, g_loss 2.673, d_loss 0.110\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 18/390 d_loss_real= 0.404, d_loss_fake= 0.088, g_loss 2.530, d_loss 0.246\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 19/390 d_loss_real= 0.211, d_loss_fake= 0.101, g_loss 2.470, d_loss 0.156\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 20/390 d_loss_real= 0.078, d_loss_fake= 0.109, g_loss 2.518, d_loss 0.093\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 21/390 d_loss_real= 0.295, d_loss_fake= 0.106, g_loss 2.598, d_loss 0.200\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 28 Batch 22/390 d_loss_real= 0.426, d_loss_fake= 0.107, g_loss 2.594, d_loss 0.267\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 23/390 d_loss_real= 0.330, d_loss_fake= 0.115, g_loss 2.574, d_loss 0.223\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 24/390 d_loss_real= 0.304, d_loss_fake= 0.125, g_loss 2.590, d_loss 0.215\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 28 Batch 25/390 d_loss_real= 0.218, d_loss_fake= 0.077, g_loss 2.900, d_loss 0.148\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 26/390 d_loss_real= 0.321, d_loss_fake= 0.045, g_loss 3.238, d_loss 0.183\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 28 Batch 27/390 d_loss_real= 0.470, d_loss_fake= 0.048, g_loss 3.118, d_loss 0.259\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 28/390 d_loss_real= 0.223, d_loss_fake= 0.106, g_loss 2.607, d_loss 0.164\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 28 Batch 29/390 d_loss_real= 0.323, d_loss_fake= 0.076, g_loss 2.916, d_loss 0.199\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 28 Batch 30/390 d_loss_real= 0.440, d_loss_fake= 0.041, g_loss 3.249, d_loss 0.240\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 28 Batch 31/390 d_loss_real= 0.179, d_loss_fake= 0.043, g_loss 3.197, d_loss 0.111\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 32/390 d_loss_real= 0.242, d_loss_fake= 0.049, g_loss 3.048, d_loss 0.145\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28 Batch 33/390 d_loss_real= 0.241, d_loss_fake= 0.056, g_loss 2.920, d_loss 0.149\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 28 Batch 34/390 d_loss_real= 0.310, d_loss_fake= 0.063, g_loss 2.771, d_loss 0.186\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 35/390 d_loss_real= 0.322, d_loss_fake= 0.076, g_loss 2.566, d_loss 0.199\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 28 Batch 36/390 d_loss_real= 0.315, d_loss_fake= 0.099, g_loss 2.397, d_loss 0.207\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 37/390 d_loss_real= 0.180, d_loss_fake= 0.125, g_loss 2.246, d_loss 0.152\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 28 Batch 38/390 d_loss_real= 0.232, d_loss_fake= 0.138, g_loss 2.298, d_loss 0.185\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28 Batch 39/390 d_loss_real= 0.450, d_loss_fake= 0.103, g_loss 2.429, d_loss 0.276\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 40/390 d_loss_real= 0.202, d_loss_fake= 0.090, g_loss 2.671, d_loss 0.146\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 41/390 d_loss_real= 0.241, d_loss_fake= 0.073, g_loss 2.777, d_loss 0.157\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 42/390 d_loss_real= 0.233, d_loss_fake= 0.064, g_loss 2.823, d_loss 0.148\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 43/390 d_loss_real= 0.213, d_loss_fake= 0.062, g_loss 2.850, d_loss 0.137\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 44/390 d_loss_real= 0.205, d_loss_fake= 0.062, g_loss 2.834, d_loss 0.134\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 28 Batch 45/390 d_loss_real= 0.125, d_loss_fake= 0.063, g_loss 2.823, d_loss 0.094\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 28 Batch 46/390 d_loss_real= 0.241, d_loss_fake= 0.068, g_loss 2.786, d_loss 0.154\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 28 Batch 47/390 d_loss_real= 0.174, d_loss_fake= 0.069, g_loss 2.776, d_loss 0.121\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 48/390 d_loss_real= 0.128, d_loss_fake= 0.076, g_loss 2.774, d_loss 0.102\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 49/390 d_loss_real= 0.194, d_loss_fake= 0.074, g_loss 2.747, d_loss 0.134\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 50/390 d_loss_real= 0.323, d_loss_fake= 0.078, g_loss 2.669, d_loss 0.201\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 51/390 d_loss_real= 0.198, d_loss_fake= 0.079, g_loss 2.701, d_loss 0.139\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 52/390 d_loss_real= 0.263, d_loss_fake= 0.086, g_loss 2.735, d_loss 0.174\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 28 Batch 53/390 d_loss_real= 0.199, d_loss_fake= 0.079, g_loss 2.770, d_loss 0.139\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 54/390 d_loss_real= 0.122, d_loss_fake= 0.069, g_loss 2.855, d_loss 0.095\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 28 Batch 55/390 d_loss_real= 0.359, d_loss_fake= 0.062, g_loss 2.865, d_loss 0.211\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 56/390 d_loss_real= 0.185, d_loss_fake= 0.065, g_loss 2.903, d_loss 0.125\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 57/390 d_loss_real= 0.456, d_loss_fake= 0.065, g_loss 2.835, d_loss 0.261\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28 Batch 58/390 d_loss_real= 0.314, d_loss_fake= 0.064, g_loss 2.812, d_loss 0.189\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 59/390 d_loss_real= 0.236, d_loss_fake= 0.080, g_loss 2.760, d_loss 0.158\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 60/390 d_loss_real= 0.167, d_loss_fake= 0.075, g_loss 2.729, d_loss 0.121\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 61/390 d_loss_real= 0.429, d_loss_fake= 0.070, g_loss 2.757, d_loss 0.250\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 62/390 d_loss_real= 0.103, d_loss_fake= 0.084, g_loss 2.816, d_loss 0.093\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 28 Batch 63/390 d_loss_real= 0.177, d_loss_fake= 0.063, g_loss 2.847, d_loss 0.120\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 28 Batch 64/390 d_loss_real= 0.138, d_loss_fake= 0.066, g_loss 2.937, d_loss 0.102\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 65/390 d_loss_real= 0.305, d_loss_fake= 0.065, g_loss 2.904, d_loss 0.185\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 66/390 d_loss_real= 0.236, d_loss_fake= 0.061, g_loss 2.964, d_loss 0.148\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 28 Batch 67/390 d_loss_real= 0.400, d_loss_fake= 0.059, g_loss 2.938, d_loss 0.229\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 28 Batch 68/390 d_loss_real= 0.062, d_loss_fake= 0.059, g_loss 2.899, d_loss 0.060\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 28 Batch 69/390 d_loss_real= 0.325, d_loss_fake= 0.066, g_loss 2.839, d_loss 0.195\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 70/390 d_loss_real= 0.308, d_loss_fake= 0.069, g_loss 2.853, d_loss 0.189\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 28 Batch 71/390 d_loss_real= 0.243, d_loss_fake= 0.066, g_loss 2.854, d_loss 0.155\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28 Batch 72/390 d_loss_real= 0.257, d_loss_fake= 0.072, g_loss 2.795, d_loss 0.165\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 73/390 d_loss_real= 0.063, d_loss_fake= 0.082, g_loss 2.747, d_loss 0.073\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 28 Batch 74/390 d_loss_real= 0.149, d_loss_fake= 0.103, g_loss 2.746, d_loss 0.126\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 75/390 d_loss_real= 0.352, d_loss_fake= 0.076, g_loss 2.954, d_loss 0.214\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 76/390 d_loss_real= 0.450, d_loss_fake= 0.073, g_loss 2.964, d_loss 0.261\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 77/390 d_loss_real= 0.314, d_loss_fake= 0.065, g_loss 3.048, d_loss 0.190\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 28 Batch 78/390 d_loss_real= 0.100, d_loss_fake= 0.046, g_loss 3.336, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 79/390 d_loss_real= 0.352, d_loss_fake= 0.036, g_loss 3.452, d_loss 0.194\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 28 Batch 80/390 d_loss_real= 0.268, d_loss_fake= 0.034, g_loss 3.451, d_loss 0.151\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 81/390 d_loss_real= 0.254, d_loss_fake= 0.037, g_loss 3.333, d_loss 0.146\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 82/390 d_loss_real= 0.263, d_loss_fake= 0.040, g_loss 3.231, d_loss 0.152\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 83/390 d_loss_real= 0.235, d_loss_fake= 0.045, g_loss 3.093, d_loss 0.140\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 84/390 d_loss_real= 0.259, d_loss_fake= 0.052, g_loss 2.933, d_loss 0.156\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 85/390 d_loss_real= 0.055, d_loss_fake= 0.061, g_loss 2.805, d_loss 0.058\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 86/390 d_loss_real= 0.102, d_loss_fake= 0.066, g_loss 2.800, d_loss 0.084\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 87/390 d_loss_real= 0.155, d_loss_fake= 0.054, g_loss 2.984, d_loss 0.104\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 28 Batch 88/390 d_loss_real= 0.250, d_loss_fake= 0.067, g_loss 2.816, d_loss 0.158\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 28 Batch 89/390 d_loss_real= 0.137, d_loss_fake= 0.067, g_loss 2.841, d_loss 0.102\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 28 Batch 90/390 d_loss_real= 0.210, d_loss_fake= 0.070, g_loss 2.769, d_loss 0.140\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 28 Batch 91/390 d_loss_real= 0.187, d_loss_fake= 0.067, g_loss 2.835, d_loss 0.127\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 92/390 d_loss_real= 0.209, d_loss_fake= 0.061, g_loss 2.908, d_loss 0.135\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 28 Batch 93/390 d_loss_real= 0.120, d_loss_fake= 0.056, g_loss 2.920, d_loss 0.088\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 94/390 d_loss_real= 0.058, d_loss_fake= 0.057, g_loss 2.969, d_loss 0.057\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 95/390 d_loss_real= 0.129, d_loss_fake= 0.058, g_loss 2.936, d_loss 0.094\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28 Batch 96/390 d_loss_real= 0.132, d_loss_fake= 0.062, g_loss 2.883, d_loss 0.097\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 28 Batch 97/390 d_loss_real= 0.263, d_loss_fake= 0.064, g_loss 2.794, d_loss 0.163\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 98/390 d_loss_real= 0.233, d_loss_fake= 0.071, g_loss 2.698, d_loss 0.152\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28 Batch 99/390 d_loss_real= 0.125, d_loss_fake= 0.082, g_loss 2.611, d_loss 0.103\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 100/390 d_loss_real= 0.155, d_loss_fake= 0.090, g_loss 2.573, d_loss 0.123\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28 Batch 101/390 d_loss_real= 0.172, d_loss_fake= 0.096, g_loss 2.520, d_loss 0.134\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 102/390 d_loss_real= 0.196, d_loss_fake= 0.088, g_loss 2.530, d_loss 0.142\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 103/390 d_loss_real= 0.324, d_loss_fake= 0.093, g_loss 2.625, d_loss 0.208\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 28 Batch 104/390 d_loss_real= 0.318, d_loss_fake= 0.078, g_loss 2.613, d_loss 0.198\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 105/390 d_loss_real= 0.184, d_loss_fake= 0.084, g_loss 2.585, d_loss 0.134\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 28 Batch 106/390 d_loss_real= 0.144, d_loss_fake= 0.085, g_loss 2.586, d_loss 0.114\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 107/390 d_loss_real= 0.222, d_loss_fake= 0.086, g_loss 2.568, d_loss 0.154\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 108/390 d_loss_real= 0.214, d_loss_fake= 0.087, g_loss 2.594, d_loss 0.150\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 28 Batch 109/390 d_loss_real= 0.233, d_loss_fake= 0.095, g_loss 2.468, d_loss 0.164\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 110/390 d_loss_real= 0.232, d_loss_fake= 0.101, g_loss 2.496, d_loss 0.167\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 28 Batch 111/390 d_loss_real= 0.102, d_loss_fake= 0.092, g_loss 2.532, d_loss 0.097\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 28 Batch 112/390 d_loss_real= 0.083, d_loss_fake= 0.087, g_loss 2.626, d_loss 0.085\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 28 Batch 113/390 d_loss_real= 0.248, d_loss_fake= 0.084, g_loss 2.619, d_loss 0.166\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 114/390 d_loss_real= 0.255, d_loss_fake= 0.077, g_loss 2.690, d_loss 0.166\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 115/390 d_loss_real= 0.166, d_loss_fake= 0.078, g_loss 2.626, d_loss 0.122\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28 Batch 116/390 d_loss_real= 0.300, d_loss_fake= 0.079, g_loss 2.682, d_loss 0.189\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 117/390 d_loss_real= 0.383, d_loss_fake= 0.078, g_loss 2.689, d_loss 0.230\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 118/390 d_loss_real= 0.325, d_loss_fake= 0.078, g_loss 2.614, d_loss 0.201\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 28 Batch 119/390 d_loss_real= 0.286, d_loss_fake= 0.075, g_loss 2.663, d_loss 0.180\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 120/390 d_loss_real= 0.060, d_loss_fake= 0.065, g_loss 2.855, d_loss 0.062\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 28 Batch 121/390 d_loss_real= 0.007, d_loss_fake= 0.064, g_loss 2.832, d_loss 0.035\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 122/390 d_loss_real= 0.181, d_loss_fake= 0.071, g_loss 2.796, d_loss 0.126\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 28 Batch 123/390 d_loss_real= 0.264, d_loss_fake= 0.063, g_loss 2.837, d_loss 0.164\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 28 Batch 124/390 d_loss_real= 0.217, d_loss_fake= 0.054, g_loss 2.964, d_loss 0.136\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 125/390 d_loss_real= 0.115, d_loss_fake= 0.059, g_loss 2.899, d_loss 0.087\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 126/390 d_loss_real= 0.175, d_loss_fake= 0.069, g_loss 2.797, d_loss 0.122\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 127/390 d_loss_real= 0.127, d_loss_fake= 0.073, g_loss 2.793, d_loss 0.100\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 28 Batch 128/390 d_loss_real= 0.182, d_loss_fake= 0.075, g_loss 2.777, d_loss 0.129\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 28 Batch 129/390 d_loss_real= 0.091, d_loss_fake= 0.082, g_loss 2.776, d_loss 0.087\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 28 Batch 130/390 d_loss_real= 0.380, d_loss_fake= 0.070, g_loss 2.800, d_loss 0.225\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 131/390 d_loss_real= 0.154, d_loss_fake= 0.066, g_loss 2.830, d_loss 0.110\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 132/390 d_loss_real= 0.185, d_loss_fake= 0.074, g_loss 2.802, d_loss 0.130\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 28 Batch 133/390 d_loss_real= 0.156, d_loss_fake= 0.071, g_loss 2.784, d_loss 0.113\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 134/390 d_loss_real= 0.090, d_loss_fake= 0.070, g_loss 2.713, d_loss 0.080\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 135/390 d_loss_real= 0.152, d_loss_fake= 0.080, g_loss 2.645, d_loss 0.116\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28 Batch 136/390 d_loss_real= 0.252, d_loss_fake= 0.106, g_loss 2.526, d_loss 0.179\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 28 Batch 137/390 d_loss_real= 0.129, d_loss_fake= 0.095, g_loss 2.556, d_loss 0.112\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 28 Batch 138/390 d_loss_real= 0.154, d_loss_fake= 0.098, g_loss 2.523, d_loss 0.126\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 139/390 d_loss_real= 0.070, d_loss_fake= 0.095, g_loss 2.442, d_loss 0.083\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 28 Batch 140/390 d_loss_real= 0.345, d_loss_fake= 0.102, g_loss 2.351, d_loss 0.224\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 28 Batch 141/390 d_loss_real= 0.375, d_loss_fake= 0.113, g_loss 2.250, d_loss 0.244\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28 Batch 142/390 d_loss_real= 0.059, d_loss_fake= 0.133, g_loss 2.154, d_loss 0.096\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 143/390 d_loss_real= 0.263, d_loss_fake= 0.157, g_loss 2.132, d_loss 0.210\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 144/390 d_loss_real= 0.228, d_loss_fake= 0.152, g_loss 2.030, d_loss 0.190\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 28 Batch 145/390 d_loss_real= 0.146, d_loss_fake= 0.167, g_loss 2.065, d_loss 0.157\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 146/390 d_loss_real= 0.092, d_loss_fake= 0.155, g_loss 2.089, d_loss 0.124\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 147/390 d_loss_real= 0.163, d_loss_fake= 0.148, g_loss 2.128, d_loss 0.155\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 28 Batch 148/390 d_loss_real= 0.282, d_loss_fake= 0.134, g_loss 2.207, d_loss 0.208\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28 Batch 149/390 d_loss_real= 0.133, d_loss_fake= 0.120, g_loss 2.275, d_loss 0.127\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 150/390 d_loss_real= 0.436, d_loss_fake= 0.116, g_loss 2.206, d_loss 0.276\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 28 Batch 151/390 d_loss_real= 0.250, d_loss_fake= 0.128, g_loss 2.172, d_loss 0.189\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 152/390 d_loss_real= 0.031, d_loss_fake= 0.136, g_loss 2.089, d_loss 0.084\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 153/390 d_loss_real= 0.088, d_loss_fake= 0.143, g_loss 2.140, d_loss 0.115\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 154/390 d_loss_real= 0.118, d_loss_fake= 0.124, g_loss 2.221, d_loss 0.121\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 28 Batch 155/390 d_loss_real= 0.176, d_loss_fake= 0.111, g_loss 2.317, d_loss 0.144\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 156/390 d_loss_real= 0.444, d_loss_fake= 0.116, g_loss 2.292, d_loss 0.280\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 157/390 d_loss_real= 0.229, d_loss_fake= 0.118, g_loss 2.243, d_loss 0.174\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 28 Batch 158/390 d_loss_real= 0.186, d_loss_fake= 0.119, g_loss 2.284, d_loss 0.153\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 159/390 d_loss_real= 0.138, d_loss_fake= 0.115, g_loss 2.317, d_loss 0.127\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 28 Batch 160/390 d_loss_real= 0.135, d_loss_fake= 0.103, g_loss 2.454, d_loss 0.119\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 161/390 d_loss_real= 0.191, d_loss_fake= 0.113, g_loss 2.390, d_loss 0.152\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 162/390 d_loss_real= 0.150, d_loss_fake= 0.101, g_loss 2.410, d_loss 0.125\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 163/390 d_loss_real= 0.220, d_loss_fake= 0.098, g_loss 2.448, d_loss 0.159\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 164/390 d_loss_real= 0.186, d_loss_fake= 0.102, g_loss 2.374, d_loss 0.144\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 165/390 d_loss_real= 0.158, d_loss_fake= 0.098, g_loss 2.494, d_loss 0.128\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28 Batch 166/390 d_loss_real= 0.154, d_loss_fake= 0.093, g_loss 2.503, d_loss 0.124\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28 Batch 167/390 d_loss_real= 0.310, d_loss_fake= 0.087, g_loss 2.537, d_loss 0.199\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 168/390 d_loss_real= 0.062, d_loss_fake= 0.087, g_loss 2.583, d_loss 0.074\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 169/390 d_loss_real= 0.172, d_loss_fake= 0.083, g_loss 2.556, d_loss 0.128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 170/390 d_loss_real= 0.147, d_loss_fake= 0.088, g_loss 2.611, d_loss 0.117\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 171/390 d_loss_real= 0.355, d_loss_fake= 0.087, g_loss 2.518, d_loss 0.221\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 172/390 d_loss_real= 0.144, d_loss_fake= 0.090, g_loss 2.524, d_loss 0.117\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 28 Batch 173/390 d_loss_real= 0.249, d_loss_fake= 0.097, g_loss 2.447, d_loss 0.173\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28 Batch 174/390 d_loss_real= 0.058, d_loss_fake= 0.096, g_loss 2.350, d_loss 0.077\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 175/390 d_loss_real= 0.096, d_loss_fake= 0.103, g_loss 2.361, d_loss 0.099\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 28 Batch 176/390 d_loss_real= 0.179, d_loss_fake= 0.099, g_loss 2.433, d_loss 0.139\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 177/390 d_loss_real= 0.313, d_loss_fake= 0.110, g_loss 2.340, d_loss 0.211\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 28 Batch 178/390 d_loss_real= 0.190, d_loss_fake= 0.104, g_loss 2.413, d_loss 0.147\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 179/390 d_loss_real= 0.210, d_loss_fake= 0.110, g_loss 2.280, d_loss 0.160\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 180/390 d_loss_real= 0.129, d_loss_fake= 0.130, g_loss 2.327, d_loss 0.130\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 181/390 d_loss_real= 0.231, d_loss_fake= 0.097, g_loss 2.561, d_loss 0.164\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 182/390 d_loss_real= 0.080, d_loss_fake= 0.099, g_loss 2.610, d_loss 0.090\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 183/390 d_loss_real= 0.336, d_loss_fake= 0.086, g_loss 2.627, d_loss 0.211\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 184/390 d_loss_real= 0.160, d_loss_fake= 0.067, g_loss 2.775, d_loss 0.114\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 185/390 d_loss_real= 0.242, d_loss_fake= 0.092, g_loss 2.519, d_loss 0.167\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 186/390 d_loss_real= 0.189, d_loss_fake= 0.092, g_loss 2.579, d_loss 0.141\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 187/390 d_loss_real= 0.136, d_loss_fake= 0.071, g_loss 2.788, d_loss 0.103\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 28 Batch 188/390 d_loss_real= 0.163, d_loss_fake= 0.100, g_loss 2.555, d_loss 0.132\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 189/390 d_loss_real= 0.300, d_loss_fake= 0.087, g_loss 2.532, d_loss 0.193\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28 Batch 190/390 d_loss_real= 0.172, d_loss_fake= 0.065, g_loss 2.995, d_loss 0.119\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 191/390 d_loss_real= 0.222, d_loss_fake= 0.080, g_loss 2.815, d_loss 0.151\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 192/390 d_loss_real= 0.220, d_loss_fake= 0.092, g_loss 2.695, d_loss 0.156\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 193/390 d_loss_real= 0.296, d_loss_fake= 0.111, g_loss 2.586, d_loss 0.204\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 28 Batch 194/390 d_loss_real= 0.424, d_loss_fake= 0.111, g_loss 2.662, d_loss 0.267\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 195/390 d_loss_real= 0.270, d_loss_fake= 0.093, g_loss 2.790, d_loss 0.182\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 196/390 d_loss_real= 0.298, d_loss_fake= 0.086, g_loss 2.808, d_loss 0.192\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 28 Batch 197/390 d_loss_real= 0.102, d_loss_fake= 0.073, g_loss 2.862, d_loss 0.088\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 28 Batch 198/390 d_loss_real= 0.230, d_loss_fake= 0.065, g_loss 3.031, d_loss 0.147\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 199/390 d_loss_real= 0.218, d_loss_fake= 0.070, g_loss 3.127, d_loss 0.144\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 28 Batch 200/390 d_loss_real= 0.367, d_loss_fake= 0.050, g_loss 3.242, d_loss 0.208\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 201/390 d_loss_real= 0.118, d_loss_fake= 0.053, g_loss 3.211, d_loss 0.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 202/390 d_loss_real= 0.308, d_loss_fake= 0.058, g_loss 3.092, d_loss 0.183\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 28 Batch 203/390 d_loss_real= 0.267, d_loss_fake= 0.059, g_loss 3.277, d_loss 0.163\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 204/390 d_loss_real= 0.176, d_loss_fake= 0.066, g_loss 3.012, d_loss 0.121\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 205/390 d_loss_real= 0.067, d_loss_fake= 0.062, g_loss 3.106, d_loss 0.065\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 28 Batch 206/390 d_loss_real= 0.168, d_loss_fake= 0.057, g_loss 3.144, d_loss 0.113\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 207/390 d_loss_real= 0.226, d_loss_fake= 0.055, g_loss 3.179, d_loss 0.140\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 208/390 d_loss_real= 0.360, d_loss_fake= 0.061, g_loss 3.157, d_loss 0.210\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 209/390 d_loss_real= 0.337, d_loss_fake= 0.059, g_loss 3.090, d_loss 0.198\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 210/390 d_loss_real= 0.292, d_loss_fake= 0.065, g_loss 2.977, d_loss 0.178\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 28 Batch 211/390 d_loss_real= 0.278, d_loss_fake= 0.061, g_loss 3.004, d_loss 0.169\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 28 Batch 212/390 d_loss_real= 0.075, d_loss_fake= 0.051, g_loss 3.216, d_loss 0.063\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 213/390 d_loss_real= 0.268, d_loss_fake= 0.075, g_loss 2.836, d_loss 0.171\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 214/390 d_loss_real= 0.120, d_loss_fake= 0.088, g_loss 2.808, d_loss 0.104\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 215/390 d_loss_real= 0.133, d_loss_fake= 0.087, g_loss 2.850, d_loss 0.110\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 28 Batch 216/390 d_loss_real= 0.129, d_loss_fake= 0.085, g_loss 2.971, d_loss 0.107\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 217/390 d_loss_real= 0.226, d_loss_fake= 0.070, g_loss 3.312, d_loss 0.148\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 218/390 d_loss_real= 0.248, d_loss_fake= 0.044, g_loss 3.424, d_loss 0.146\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 219/390 d_loss_real= 0.245, d_loss_fake= 0.037, g_loss 3.672, d_loss 0.141\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 28 Batch 220/390 d_loss_real= 0.059, d_loss_fake= 0.033, g_loss 3.609, d_loss 0.046\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 28 Batch 221/390 d_loss_real= 0.215, d_loss_fake= 0.031, g_loss 3.688, d_loss 0.123\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 222/390 d_loss_real= 0.063, d_loss_fake= 0.028, g_loss 3.623, d_loss 0.046\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28 Batch 223/390 d_loss_real= 0.203, d_loss_fake= 0.032, g_loss 3.559, d_loss 0.117\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 224/390 d_loss_real= 0.356, d_loss_fake= 0.038, g_loss 3.423, d_loss 0.197\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 28 Batch 225/390 d_loss_real= 0.240, d_loss_fake= 0.045, g_loss 3.237, d_loss 0.142\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 226/390 d_loss_real= 0.243, d_loss_fake= 0.060, g_loss 3.039, d_loss 0.151\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 227/390 d_loss_real= 0.208, d_loss_fake= 0.068, g_loss 2.935, d_loss 0.138\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 28 Batch 228/390 d_loss_real= 0.181, d_loss_fake= 0.074, g_loss 2.830, d_loss 0.128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 229/390 d_loss_real= 0.143, d_loss_fake= 0.065, g_loss 2.985, d_loss 0.104\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 230/390 d_loss_real= 0.313, d_loss_fake= 0.057, g_loss 3.058, d_loss 0.185\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28 Batch 231/390 d_loss_real= 0.227, d_loss_fake= 0.080, g_loss 2.898, d_loss 0.154\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 28 Batch 232/390 d_loss_real= 0.280, d_loss_fake= 0.067, g_loss 2.972, d_loss 0.174\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 233/390 d_loss_real= 0.303, d_loss_fake= 0.059, g_loss 2.944, d_loss 0.181\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 234/390 d_loss_real= 0.302, d_loss_fake= 0.080, g_loss 2.794, d_loss 0.191\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 235/390 d_loss_real= 0.103, d_loss_fake= 0.065, g_loss 2.904, d_loss 0.084\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 236/390 d_loss_real= 0.097, d_loss_fake= 0.065, g_loss 3.006, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 237/390 d_loss_real= 0.152, d_loss_fake= 0.061, g_loss 3.045, d_loss 0.106\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 28 Batch 238/390 d_loss_real= 0.248, d_loss_fake= 0.054, g_loss 3.092, d_loss 0.151\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 239/390 d_loss_real= 0.254, d_loss_fake= 0.055, g_loss 3.093, d_loss 0.154\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 28 Batch 240/390 d_loss_real= 0.232, d_loss_fake= 0.051, g_loss 3.119, d_loss 0.142\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 241/390 d_loss_real= 0.197, d_loss_fake= 0.050, g_loss 3.031, d_loss 0.124\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 28 Batch 242/390 d_loss_real= 0.156, d_loss_fake= 0.055, g_loss 2.972, d_loss 0.105\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 28 Batch 243/390 d_loss_real= 0.060, d_loss_fake= 0.060, g_loss 2.923, d_loss 0.060\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 244/390 d_loss_real= 0.109, d_loss_fake= 0.076, g_loss 2.795, d_loss 0.092\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 245/390 d_loss_real= 0.244, d_loss_fake= 0.090, g_loss 2.615, d_loss 0.167\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 246/390 d_loss_real= 0.160, d_loss_fake= 0.106, g_loss 2.538, d_loss 0.133\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28 Batch 247/390 d_loss_real= 0.316, d_loss_fake= 0.108, g_loss 2.517, d_loss 0.212\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 248/390 d_loss_real= 0.077, d_loss_fake= 0.111, g_loss 2.573, d_loss 0.094\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28 Batch 249/390 d_loss_real= 0.232, d_loss_fake= 0.122, g_loss 2.459, d_loss 0.177\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 250/390 d_loss_real= 0.318, d_loss_fake= 0.115, g_loss 2.443, d_loss 0.217\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 251/390 d_loss_real= 0.335, d_loss_fake= 0.106, g_loss 2.525, d_loss 0.220\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 252/390 d_loss_real= 0.068, d_loss_fake= 0.094, g_loss 2.638, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 253/390 d_loss_real= 0.347, d_loss_fake= 0.081, g_loss 2.740, d_loss 0.214\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 254/390 d_loss_real= 0.290, d_loss_fake= 0.072, g_loss 2.739, d_loss 0.181\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28 Batch 255/390 d_loss_real= 0.189, d_loss_fake= 0.071, g_loss 2.760, d_loss 0.130\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 256/390 d_loss_real= 0.207, d_loss_fake= 0.076, g_loss 2.759, d_loss 0.141\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 257/390 d_loss_real= 0.615, d_loss_fake= 0.080, g_loss 2.530, d_loss 0.348\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 258/390 d_loss_real= 0.294, d_loss_fake= 0.106, g_loss 2.393, d_loss 0.200\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 28 Batch 259/390 d_loss_real= 0.423, d_loss_fake= 0.117, g_loss 2.423, d_loss 0.270\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 28 Batch 260/390 d_loss_real= 0.169, d_loss_fake= 0.102, g_loss 2.604, d_loss 0.135\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28 Batch 261/390 d_loss_real= 0.169, d_loss_fake= 0.083, g_loss 2.751, d_loss 0.126\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 262/390 d_loss_real= 0.155, d_loss_fake= 0.066, g_loss 2.969, d_loss 0.111\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 263/390 d_loss_real= 0.160, d_loss_fake= 0.056, g_loss 3.072, d_loss 0.108\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 264/390 d_loss_real= 0.427, d_loss_fake= 0.054, g_loss 3.076, d_loss 0.241\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 28 Batch 265/390 d_loss_real= 0.217, d_loss_fake= 0.056, g_loss 2.980, d_loss 0.136\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 266/390 d_loss_real= 0.417, d_loss_fake= 0.062, g_loss 2.799, d_loss 0.239\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 267/390 d_loss_real= 0.308, d_loss_fake= 0.071, g_loss 2.809, d_loss 0.190\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 28 Batch 268/390 d_loss_real= 0.190, d_loss_fake= 0.057, g_loss 2.976, d_loss 0.123\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 28 Batch 269/390 d_loss_real= 0.218, d_loss_fake= 0.048, g_loss 3.082, d_loss 0.133\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28 Batch 270/390 d_loss_real= 0.198, d_loss_fake= 0.065, g_loss 2.891, d_loss 0.131\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 28 Batch 271/390 d_loss_real= 0.265, d_loss_fake= 0.073, g_loss 2.827, d_loss 0.169\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 28 Batch 272/390 d_loss_real= 0.138, d_loss_fake= 0.070, g_loss 2.915, d_loss 0.104\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 273/390 d_loss_real= 0.110, d_loss_fake= 0.052, g_loss 3.208, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 274/390 d_loss_real= 0.255, d_loss_fake= 0.048, g_loss 3.271, d_loss 0.151\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 28 Batch 275/390 d_loss_real= 0.151, d_loss_fake= 0.040, g_loss 3.300, d_loss 0.095\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 28 Batch 276/390 d_loss_real= 0.328, d_loss_fake= 0.042, g_loss 3.212, d_loss 0.185\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 277/390 d_loss_real= 0.185, d_loss_fake= 0.046, g_loss 3.082, d_loss 0.116\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 278/390 d_loss_real= 0.178, d_loss_fake= 0.051, g_loss 3.077, d_loss 0.114\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 28 Batch 279/390 d_loss_real= 0.159, d_loss_fake= 0.046, g_loss 3.200, d_loss 0.103\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 280/390 d_loss_real= 0.173, d_loss_fake= 0.050, g_loss 3.145, d_loss 0.111\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 281/390 d_loss_real= 0.089, d_loss_fake= 0.053, g_loss 3.173, d_loss 0.071\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 282/390 d_loss_real= 0.042, d_loss_fake= 0.043, g_loss 3.351, d_loss 0.043\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 283/390 d_loss_real= 0.094, d_loss_fake= 0.036, g_loss 3.690, d_loss 0.065\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 28 Batch 284/390 d_loss_real= 0.256, d_loss_fake= 0.032, g_loss 3.480, d_loss 0.144\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 28 Batch 285/390 d_loss_real= 0.221, d_loss_fake= 0.041, g_loss 3.431, d_loss 0.131\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 28 Batch 286/390 d_loss_real= 0.162, d_loss_fake= 0.041, g_loss 3.254, d_loss 0.101\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 287/390 d_loss_real= 0.145, d_loss_fake= 0.053, g_loss 3.199, d_loss 0.099\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 288/390 d_loss_real= 0.086, d_loss_fake= 0.047, g_loss 3.493, d_loss 0.066\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 289/390 d_loss_real= 0.237, d_loss_fake= 0.033, g_loss 3.514, d_loss 0.135\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 28 Batch 290/390 d_loss_real= 0.048, d_loss_fake= 0.038, g_loss 3.487, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 291/390 d_loss_real= 0.102, d_loss_fake= 0.035, g_loss 3.528, d_loss 0.068\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 292/390 d_loss_real= 0.058, d_loss_fake= 0.030, g_loss 3.718, d_loss 0.044\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 28 Batch 293/390 d_loss_real= 0.220, d_loss_fake= 0.027, g_loss 3.706, d_loss 0.123\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 294/390 d_loss_real= 0.191, d_loss_fake= 0.032, g_loss 3.663, d_loss 0.112\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 295/390 d_loss_real= 0.115, d_loss_fake= 0.029, g_loss 3.641, d_loss 0.072\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 28 Batch 296/390 d_loss_real= 0.124, d_loss_fake= 0.033, g_loss 3.627, d_loss 0.078\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 28 Batch 297/390 d_loss_real= 0.352, d_loss_fake= 0.036, g_loss 3.425, d_loss 0.194\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 298/390 d_loss_real= 0.119, d_loss_fake= 0.042, g_loss 3.376, d_loss 0.081\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 299/390 d_loss_real= 0.107, d_loss_fake= 0.027, g_loss 3.710, d_loss 0.067\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 28 Batch 300/390 d_loss_real= 0.111, d_loss_fake= 0.040, g_loss 3.443, d_loss 0.076\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 28 Batch 301/390 d_loss_real= 0.145, d_loss_fake= 0.030, g_loss 3.691, d_loss 0.087\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 28 Batch 302/390 d_loss_real= 0.204, d_loss_fake= 0.037, g_loss 3.575, d_loss 0.121\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 303/390 d_loss_real= 0.080, d_loss_fake= 0.038, g_loss 3.589, d_loss 0.059\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 304/390 d_loss_real= 0.053, d_loss_fake= 0.030, g_loss 3.653, d_loss 0.041\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 28 Batch 305/390 d_loss_real= 0.370, d_loss_fake= 0.031, g_loss 3.495, d_loss 0.201\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 306/390 d_loss_real= 0.200, d_loss_fake= 0.038, g_loss 3.403, d_loss 0.119\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 307/390 d_loss_real= 0.106, d_loss_fake= 0.044, g_loss 3.509, d_loss 0.075\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 28 Batch 308/390 d_loss_real= 0.131, d_loss_fake= 0.037, g_loss 3.579, d_loss 0.084\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 309/390 d_loss_real= 0.060, d_loss_fake= 0.033, g_loss 3.564, d_loss 0.047\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 310/390 d_loss_real= 0.261, d_loss_fake= 0.031, g_loss 3.544, d_loss 0.146\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 311/390 d_loss_real= 0.176, d_loss_fake= 0.034, g_loss 3.368, d_loss 0.105\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 28 Batch 312/390 d_loss_real= 0.051, d_loss_fake= 0.040, g_loss 3.287, d_loss 0.045\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 28 Batch 313/390 d_loss_real= 0.135, d_loss_fake= 0.050, g_loss 3.349, d_loss 0.093\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 314/390 d_loss_real= 0.103, d_loss_fake= 0.046, g_loss 3.260, d_loss 0.074\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 315/390 d_loss_real= 0.281, d_loss_fake= 0.041, g_loss 3.406, d_loss 0.161\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 316/390 d_loss_real= 0.108, d_loss_fake= 0.039, g_loss 3.405, d_loss 0.073\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 317/390 d_loss_real= 0.153, d_loss_fake= 0.038, g_loss 3.407, d_loss 0.095\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 28 Batch 318/390 d_loss_real= 0.149, d_loss_fake= 0.037, g_loss 3.381, d_loss 0.093\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 319/390 d_loss_real= 0.183, d_loss_fake= 0.040, g_loss 3.293, d_loss 0.111\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 28 Batch 320/390 d_loss_real= 0.243, d_loss_fake= 0.042, g_loss 3.201, d_loss 0.142\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 28 Batch 321/390 d_loss_real= 0.114, d_loss_fake= 0.046, g_loss 3.123, d_loss 0.080\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 28 Batch 322/390 d_loss_real= 0.174, d_loss_fake= 0.050, g_loss 3.042, d_loss 0.112\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 28 Batch 323/390 d_loss_real= 0.187, d_loss_fake= 0.052, g_loss 2.964, d_loss 0.120\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 324/390 d_loss_real= 0.013, d_loss_fake= 0.059, g_loss 2.968, d_loss 0.036\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 325/390 d_loss_real= 0.109, d_loss_fake= 0.052, g_loss 3.042, d_loss 0.081\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 326/390 d_loss_real= 0.095, d_loss_fake= 0.051, g_loss 3.088, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 327/390 d_loss_real= 0.057, d_loss_fake= 0.047, g_loss 3.161, d_loss 0.052\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 28 Batch 328/390 d_loss_real= 0.223, d_loss_fake= 0.047, g_loss 3.104, d_loss 0.135\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 28 Batch 329/390 d_loss_real= 0.059, d_loss_fake= 0.050, g_loss 3.072, d_loss 0.054\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 28 Batch 330/390 d_loss_real= 0.090, d_loss_fake= 0.052, g_loss 3.028, d_loss 0.071\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 28 Batch 331/390 d_loss_real= 0.105, d_loss_fake= 0.057, g_loss 2.950, d_loss 0.081\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 28 Batch 332/390 d_loss_real= 0.171, d_loss_fake= 0.058, g_loss 2.944, d_loss 0.115\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 333/390 d_loss_real= 0.001, d_loss_fake= 0.054, g_loss 3.100, d_loss 0.028\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 334/390 d_loss_real= 0.102, d_loss_fake= 0.055, g_loss 3.083, d_loss 0.079\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 335/390 d_loss_real= 0.064, d_loss_fake= 0.057, g_loss 3.230, d_loss 0.060\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 336/390 d_loss_real= 0.158, d_loss_fake= 0.051, g_loss 3.273, d_loss 0.104\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 28 Batch 337/390 d_loss_real= 0.141, d_loss_fake= 0.041, g_loss 3.342, d_loss 0.091\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 338/390 d_loss_real= 0.163, d_loss_fake= 0.049, g_loss 3.387, d_loss 0.106\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 28 Batch 339/390 d_loss_real= 0.136, d_loss_fake= 0.045, g_loss 3.267, d_loss 0.090\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 340/390 d_loss_real= 0.109, d_loss_fake= 0.047, g_loss 3.349, d_loss 0.078\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 28 Batch 341/390 d_loss_real= 0.078, d_loss_fake= 0.049, g_loss 3.449, d_loss 0.064\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 28 Batch 342/390 d_loss_real= 0.151, d_loss_fake= 0.052, g_loss 3.338, d_loss 0.101\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 343/390 d_loss_real= 0.075, d_loss_fake= 0.040, g_loss 3.376, d_loss 0.058\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 344/390 d_loss_real= 0.213, d_loss_fake= 0.043, g_loss 3.314, d_loss 0.128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 345/390 d_loss_real= 0.157, d_loss_fake= 0.040, g_loss 3.540, d_loss 0.099\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 346/390 d_loss_real= 0.268, d_loss_fake= 0.050, g_loss 3.147, d_loss 0.159\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 347/390 d_loss_real= 0.143, d_loss_fake= 0.051, g_loss 3.239, d_loss 0.097\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 348/390 d_loss_real= 0.239, d_loss_fake= 0.027, g_loss 3.695, d_loss 0.133\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 349/390 d_loss_real= 0.190, d_loss_fake= 0.040, g_loss 3.331, d_loss 0.115\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 350/390 d_loss_real= 0.065, d_loss_fake= 0.073, g_loss 2.946, d_loss 0.069\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28 Batch 351/390 d_loss_real= 0.137, d_loss_fake= 0.089, g_loss 2.771, d_loss 0.113\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 28 Batch 352/390 d_loss_real= 0.045, d_loss_fake= 0.079, g_loss 2.986, d_loss 0.062\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 353/390 d_loss_real= 0.175, d_loss_fake= 0.058, g_loss 3.131, d_loss 0.116\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 354/390 d_loss_real= 0.232, d_loss_fake= 0.045, g_loss 3.307, d_loss 0.139\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 28 Batch 355/390 d_loss_real= 0.298, d_loss_fake= 0.036, g_loss 3.495, d_loss 0.167\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 356/390 d_loss_real= 0.433, d_loss_fake= 0.040, g_loss 3.330, d_loss 0.236\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 28 Batch 357/390 d_loss_real= 0.116, d_loss_fake= 0.040, g_loss 3.410, d_loss 0.078\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 28 Batch 358/390 d_loss_real= 0.198, d_loss_fake= 0.050, g_loss 3.214, d_loss 0.124\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 28 Batch 359/390 d_loss_real= 0.266, d_loss_fake= 0.052, g_loss 3.083, d_loss 0.159\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 28 Batch 360/390 d_loss_real= 0.063, d_loss_fake= 0.054, g_loss 3.086, d_loss 0.058\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 28 Batch 361/390 d_loss_real= 0.206, d_loss_fake= 0.036, g_loss 3.408, d_loss 0.121\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 28 Batch 362/390 d_loss_real= 0.194, d_loss_fake= 0.068, g_loss 2.797, d_loss 0.131\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 363/390 d_loss_real= 0.144, d_loss_fake= 0.058, g_loss 2.935, d_loss 0.101\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28 Batch 364/390 d_loss_real= 0.110, d_loss_fake= 0.036, g_loss 3.399, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 365/390 d_loss_real= 0.125, d_loss_fake= 0.060, g_loss 2.956, d_loss 0.093\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 366/390 d_loss_real= 0.125, d_loss_fake= 0.172, g_loss 2.202, d_loss 0.148\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 367/390 d_loss_real= 0.142, d_loss_fake= 0.115, g_loss 2.686, d_loss 0.129\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 368/390 d_loss_real= 0.307, d_loss_fake= 0.046, g_loss 3.423, d_loss 0.177\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 369/390 d_loss_real= 0.303, d_loss_fake= 0.046, g_loss 3.347, d_loss 0.175\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28 Batch 370/390 d_loss_real= 0.289, d_loss_fake= 0.053, g_loss 3.082, d_loss 0.171\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 28 Batch 371/390 d_loss_real= 0.090, d_loss_fake= 0.057, g_loss 3.067, d_loss 0.074\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 28 Batch 372/390 d_loss_real= 0.228, d_loss_fake= 0.059, g_loss 2.952, d_loss 0.143\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 373/390 d_loss_real= 0.370, d_loss_fake= 0.073, g_loss 2.699, d_loss 0.222\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 374/390 d_loss_real= 0.185, d_loss_fake= 0.101, g_loss 2.685, d_loss 0.143\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 375/390 d_loss_real= 0.336, d_loss_fake= 0.089, g_loss 2.723, d_loss 0.213\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 28 Batch 376/390 d_loss_real= 0.113, d_loss_fake= 0.077, g_loss 2.808, d_loss 0.095\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 28 Batch 377/390 d_loss_real= 0.298, d_loss_fake= 0.070, g_loss 2.886, d_loss 0.184\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 28 Batch 378/390 d_loss_real= 0.150, d_loss_fake= 0.064, g_loss 2.924, d_loss 0.107\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28 Batch 379/390 d_loss_real= 0.340, d_loss_fake= 0.065, g_loss 2.861, d_loss 0.202\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 28 Batch 380/390 d_loss_real= 0.142, d_loss_fake= 0.069, g_loss 2.779, d_loss 0.105\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 28 Batch 381/390 d_loss_real= 0.054, d_loss_fake= 0.069, g_loss 2.777, d_loss 0.061\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 28 Batch 382/390 d_loss_real= 0.190, d_loss_fake= 0.075, g_loss 2.647, d_loss 0.132\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 383/390 d_loss_real= 0.096, d_loss_fake= 0.087, g_loss 2.565, d_loss 0.091\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28 Batch 384/390 d_loss_real= 0.203, d_loss_fake= 0.091, g_loss 2.501, d_loss 0.147\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28 Batch 385/390 d_loss_real= 0.089, d_loss_fake= 0.100, g_loss 2.470, d_loss 0.095\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28 Batch 386/390 d_loss_real= 0.261, d_loss_fake= 0.100, g_loss 2.423, d_loss 0.180\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 28 Batch 387/390 d_loss_real= 0.165, d_loss_fake= 0.110, g_loss 2.386, d_loss 0.138\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28 Batch 388/390 d_loss_real= 0.041, d_loss_fake= 0.112, g_loss 2.485, d_loss 0.076\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 28 Batch 389/390 d_loss_real= 0.090, d_loss_fake= 0.087, g_loss 2.631, d_loss 0.088\n",
            "2/2 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28 Batch 390/390 d_loss_real= 0.129, d_loss_fake= 0.080, g_loss 2.823, d_loss 0.105\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 1/390 d_loss_real= 0.250, d_loss_fake= 0.068, g_loss 2.792, d_loss 0.159\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 2/390 d_loss_real= 0.280, d_loss_fake= 0.069, g_loss 2.763, d_loss 0.174\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 3/390 d_loss_real= 0.205, d_loss_fake= 0.079, g_loss 2.652, d_loss 0.142\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 4/390 d_loss_real= 0.223, d_loss_fake= 0.081, g_loss 2.567, d_loss 0.152\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 5/390 d_loss_real= 0.181, d_loss_fake= 0.106, g_loss 2.516, d_loss 0.143\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 6/390 d_loss_real= 0.076, d_loss_fake= 0.088, g_loss 2.459, d_loss 0.082\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 29 Batch 7/390 d_loss_real= 0.207, d_loss_fake= 0.104, g_loss 2.437, d_loss 0.155\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 8/390 d_loss_real= 0.162, d_loss_fake= 0.110, g_loss 2.531, d_loss 0.136\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 9/390 d_loss_real= 0.089, d_loss_fake= 0.093, g_loss 2.712, d_loss 0.091\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 29 Batch 10/390 d_loss_real= 0.044, d_loss_fake= 0.076, g_loss 2.739, d_loss 0.060\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 11/390 d_loss_real= 0.219, d_loss_fake= 0.068, g_loss 2.799, d_loss 0.143\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 29 Batch 12/390 d_loss_real= 0.105, d_loss_fake= 0.063, g_loss 2.820, d_loss 0.084\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 29 Batch 13/390 d_loss_real= 0.047, d_loss_fake= 0.063, g_loss 2.937, d_loss 0.055\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 14/390 d_loss_real= 0.213, d_loss_fake= 0.061, g_loss 2.934, d_loss 0.137\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 29 Batch 15/390 d_loss_real= 0.273, d_loss_fake= 0.062, g_loss 2.884, d_loss 0.167\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 29 Batch 16/390 d_loss_real= 0.084, d_loss_fake= 0.067, g_loss 2.825, d_loss 0.075\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 17/390 d_loss_real= 0.111, d_loss_fake= 0.079, g_loss 2.721, d_loss 0.095\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 18/390 d_loss_real= 0.308, d_loss_fake= 0.079, g_loss 2.729, d_loss 0.193\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 29 Batch 19/390 d_loss_real= 0.080, d_loss_fake= 0.075, g_loss 2.782, d_loss 0.078\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 29 Batch 20/390 d_loss_real= 0.076, d_loss_fake= 0.074, g_loss 2.746, d_loss 0.075\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 29 Batch 21/390 d_loss_real= 0.106, d_loss_fake= 0.065, g_loss 2.859, d_loss 0.085\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 22/390 d_loss_real= 0.209, d_loss_fake= 0.065, g_loss 2.911, d_loss 0.137\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 23/390 d_loss_real= 0.168, d_loss_fake= 0.062, g_loss 2.931, d_loss 0.115\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 24/390 d_loss_real= 0.141, d_loss_fake= 0.060, g_loss 2.890, d_loss 0.100\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 25/390 d_loss_real= 0.235, d_loss_fake= 0.069, g_loss 2.809, d_loss 0.152\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 26/390 d_loss_real= 0.173, d_loss_fake= 0.070, g_loss 2.721, d_loss 0.121\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 27/390 d_loss_real= 0.178, d_loss_fake= 0.081, g_loss 2.671, d_loss 0.130\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 28/390 d_loss_real= 0.028, d_loss_fake= 0.089, g_loss 2.657, d_loss 0.059\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 29/390 d_loss_real= 0.072, d_loss_fake= 0.078, g_loss 2.658, d_loss 0.075\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 29 Batch 30/390 d_loss_real= 0.015, d_loss_fake= 0.078, g_loss 2.753, d_loss 0.046\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 31/390 d_loss_real= 0.172, d_loss_fake= 0.073, g_loss 2.800, d_loss 0.123\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 29 Batch 32/390 d_loss_real= 0.185, d_loss_fake= 0.071, g_loss 2.844, d_loss 0.128\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 29 Batch 33/390 d_loss_real= 0.167, d_loss_fake= 0.061, g_loss 2.841, d_loss 0.114\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 29 Batch 34/390 d_loss_real= 0.187, d_loss_fake= 0.060, g_loss 2.855, d_loss 0.123\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 35/390 d_loss_real= 0.177, d_loss_fake= 0.065, g_loss 2.877, d_loss 0.121\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 36/390 d_loss_real= 0.209, d_loss_fake= 0.068, g_loss 2.787, d_loss 0.139\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 29 Batch 37/390 d_loss_real= 0.171, d_loss_fake= 0.070, g_loss 2.748, d_loss 0.121\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 38/390 d_loss_real= 0.390, d_loss_fake= 0.074, g_loss 2.704, d_loss 0.232\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 39/390 d_loss_real= 0.165, d_loss_fake= 0.066, g_loss 2.681, d_loss 0.116\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 40/390 d_loss_real= 0.182, d_loss_fake= 0.077, g_loss 2.660, d_loss 0.129\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 41/390 d_loss_real= 0.183, d_loss_fake= 0.086, g_loss 2.577, d_loss 0.134\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 42/390 d_loss_real= 0.128, d_loss_fake= 0.094, g_loss 2.631, d_loss 0.111\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 43/390 d_loss_real= 0.061, d_loss_fake= 0.088, g_loss 2.569, d_loss 0.074\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 44/390 d_loss_real= 0.051, d_loss_fake= 0.078, g_loss 2.641, d_loss 0.065\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 45/390 d_loss_real= 0.103, d_loss_fake= 0.074, g_loss 2.681, d_loss 0.088\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 46/390 d_loss_real= 0.142, d_loss_fake= 0.070, g_loss 2.697, d_loss 0.106\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 29 Batch 47/390 d_loss_real= 0.095, d_loss_fake= 0.075, g_loss 2.714, d_loss 0.085\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 29 Batch 48/390 d_loss_real= 0.125, d_loss_fake= 0.076, g_loss 2.706, d_loss 0.101\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 29 Batch 49/390 d_loss_real= 0.147, d_loss_fake= 0.076, g_loss 2.711, d_loss 0.111\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 50/390 d_loss_real= 0.182, d_loss_fake= 0.076, g_loss 2.678, d_loss 0.129\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 29 Batch 51/390 d_loss_real= 0.161, d_loss_fake= 0.081, g_loss 2.616, d_loss 0.121\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 52/390 d_loss_real= 0.203, d_loss_fake= 0.087, g_loss 2.568, d_loss 0.145\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 29 Batch 53/390 d_loss_real= 0.172, d_loss_fake= 0.081, g_loss 2.524, d_loss 0.127\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 54/390 d_loss_real= 0.131, d_loss_fake= 0.089, g_loss 2.554, d_loss 0.110\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 55/390 d_loss_real= 0.125, d_loss_fake= 0.086, g_loss 2.552, d_loss 0.106\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 29 Batch 56/390 d_loss_real= 0.068, d_loss_fake= 0.084, g_loss 2.645, d_loss 0.076\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 57/390 d_loss_real= 0.179, d_loss_fake= 0.080, g_loss 2.662, d_loss 0.130\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 58/390 d_loss_real= 0.023, d_loss_fake= 0.077, g_loss 2.751, d_loss 0.050\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 59/390 d_loss_real= 0.124, d_loss_fake= 0.068, g_loss 2.764, d_loss 0.096\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 29 Batch 60/390 d_loss_real= 0.183, d_loss_fake= 0.065, g_loss 2.779, d_loss 0.124\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 61/390 d_loss_real= 0.019, d_loss_fake= 0.069, g_loss 2.804, d_loss 0.044\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 62/390 d_loss_real= 0.159, d_loss_fake= 0.065, g_loss 2.853, d_loss 0.112\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 63/390 d_loss_real= 0.055, d_loss_fake= 0.065, g_loss 2.824, d_loss 0.060\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 29 Batch 64/390 d_loss_real= 0.133, d_loss_fake= 0.067, g_loss 2.840, d_loss 0.100\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 29 Batch 65/390 d_loss_real= 0.188, d_loss_fake= 0.068, g_loss 2.810, d_loss 0.128\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 29 Batch 66/390 d_loss_real= 0.056, d_loss_fake= 0.069, g_loss 2.749, d_loss 0.062\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 67/390 d_loss_real= 0.007, d_loss_fake= 0.069, g_loss 2.726, d_loss 0.038\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 68/390 d_loss_real= 0.114, d_loss_fake= 0.081, g_loss 2.697, d_loss 0.097\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 29 Batch 69/390 d_loss_real= 0.106, d_loss_fake= 0.076, g_loss 2.697, d_loss 0.091\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 70/390 d_loss_real= 0.154, d_loss_fake= 0.076, g_loss 2.700, d_loss 0.115\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 71/390 d_loss_real= 0.119, d_loss_fake= 0.078, g_loss 2.716, d_loss 0.099\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 29 Batch 72/390 d_loss_real= 0.066, d_loss_fake= 0.077, g_loss 2.743, d_loss 0.072\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 29 Batch 73/390 d_loss_real= 0.188, d_loss_fake= 0.077, g_loss 2.756, d_loss 0.133\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 74/390 d_loss_real= 0.047, d_loss_fake= 0.088, g_loss 2.727, d_loss 0.068\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 75/390 d_loss_real= 0.101, d_loss_fake= 0.099, g_loss 2.624, d_loss 0.100\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 29 Batch 76/390 d_loss_real= 0.160, d_loss_fake= 0.159, g_loss 2.500, d_loss 0.159\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 29 Batch 77/390 d_loss_real= 0.220, d_loss_fake= 0.181, g_loss 2.556, d_loss 0.201\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 78/390 d_loss_real= 0.079, d_loss_fake= 0.180, g_loss 2.721, d_loss 0.129\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 79/390 d_loss_real= 0.190, d_loss_fake= 0.228, g_loss 2.977, d_loss 0.209\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 29 Batch 80/390 d_loss_real= 0.252, d_loss_fake= 0.058, g_loss 3.848, d_loss 0.155\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 29 Batch 81/390 d_loss_real= 0.330, d_loss_fake= 0.024, g_loss 4.160, d_loss 0.177\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 29 Batch 82/390 d_loss_real= 0.531, d_loss_fake= 0.020, g_loss 4.183, d_loss 0.276\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 83/390 d_loss_real= 0.613, d_loss_fake= 0.025, g_loss 4.005, d_loss 0.319\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 29 Batch 84/390 d_loss_real= 0.756, d_loss_fake= 0.029, g_loss 3.595, d_loss 0.393\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 85/390 d_loss_real= 0.306, d_loss_fake= 0.051, g_loss 3.046, d_loss 0.178\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 86/390 d_loss_real= 0.270, d_loss_fake= 0.111, g_loss 2.169, d_loss 0.190\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 29 Batch 87/390 d_loss_real= 0.426, d_loss_fake= 0.257, g_loss 2.084, d_loss 0.341\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 88/390 d_loss_real= 0.103, d_loss_fake= 0.150, g_loss 2.681, d_loss 0.126\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 29 Batch 89/390 d_loss_real= 0.252, d_loss_fake= 0.073, g_loss 2.903, d_loss 0.162\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 90/390 d_loss_real= 0.497, d_loss_fake= 0.057, g_loss 3.172, d_loss 0.277\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 29 Batch 91/390 d_loss_real= 0.195, d_loss_fake= 0.055, g_loss 3.082, d_loss 0.125\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 92/390 d_loss_real= 0.427, d_loss_fake= 0.063, g_loss 2.886, d_loss 0.245\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 93/390 d_loss_real= 0.369, d_loss_fake= 0.078, g_loss 2.542, d_loss 0.224\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 94/390 d_loss_real= 0.174, d_loss_fake= 0.108, g_loss 2.315, d_loss 0.141\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 29 Batch 95/390 d_loss_real= 0.199, d_loss_fake= 0.136, g_loss 2.209, d_loss 0.168\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 96/390 d_loss_real= 0.153, d_loss_fake= 0.173, g_loss 2.396, d_loss 0.163\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 97/390 d_loss_real= 0.168, d_loss_fake= 0.104, g_loss 2.819, d_loss 0.136\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 98/390 d_loss_real= 0.090, d_loss_fake= 0.063, g_loss 3.117, d_loss 0.077\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 99/390 d_loss_real= 0.214, d_loss_fake= 0.046, g_loss 3.425, d_loss 0.130\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 29 Batch 100/390 d_loss_real= 0.382, d_loss_fake= 0.037, g_loss 3.463, d_loss 0.209\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 29 Batch 101/390 d_loss_real= 0.191, d_loss_fake= 0.035, g_loss 3.423, d_loss 0.113\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 29 Batch 102/390 d_loss_real= 0.239, d_loss_fake= 0.036, g_loss 3.393, d_loss 0.138\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 103/390 d_loss_real= 0.271, d_loss_fake= 0.040, g_loss 3.245, d_loss 0.155\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 29 Batch 104/390 d_loss_real= 0.257, d_loss_fake= 0.053, g_loss 2.923, d_loss 0.155\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 105/390 d_loss_real= 0.335, d_loss_fake= 0.079, g_loss 2.587, d_loss 0.207\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 106/390 d_loss_real= 0.098, d_loss_fake= 0.109, g_loss 2.569, d_loss 0.104\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 29 Batch 107/390 d_loss_real= 0.096, d_loss_fake= 0.098, g_loss 2.870, d_loss 0.097\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 108/390 d_loss_real= 0.165, d_loss_fake= 0.054, g_loss 3.234, d_loss 0.109\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 29 Batch 109/390 d_loss_real= 0.340, d_loss_fake= 0.039, g_loss 3.460, d_loss 0.189\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 110/390 d_loss_real= 0.238, d_loss_fake= 0.031, g_loss 3.554, d_loss 0.135\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 29 Batch 111/390 d_loss_real= 0.192, d_loss_fake= 0.027, g_loss 3.664, d_loss 0.109\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 29 Batch 112/390 d_loss_real= 0.279, d_loss_fake= 0.027, g_loss 3.748, d_loss 0.153\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 113/390 d_loss_real= 0.169, d_loss_fake= 0.027, g_loss 3.684, d_loss 0.098\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 114/390 d_loss_real= 0.075, d_loss_fake= 0.027, g_loss 3.611, d_loss 0.051\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 29 Batch 115/390 d_loss_real= 0.157, d_loss_fake= 0.031, g_loss 3.406, d_loss 0.094\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 29 Batch 116/390 d_loss_real= 0.129, d_loss_fake= 0.039, g_loss 3.217, d_loss 0.084\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 29 Batch 117/390 d_loss_real= 0.276, d_loss_fake= 0.055, g_loss 2.975, d_loss 0.165\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 118/390 d_loss_real= 0.090, d_loss_fake= 0.067, g_loss 2.985, d_loss 0.079\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 29 Batch 119/390 d_loss_real= 0.314, d_loss_fake= 0.063, g_loss 3.088, d_loss 0.188\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 29 Batch 120/390 d_loss_real= 0.080, d_loss_fake= 0.047, g_loss 3.368, d_loss 0.064\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 121/390 d_loss_real= 0.222, d_loss_fake= 0.033, g_loss 3.600, d_loss 0.128\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 122/390 d_loss_real= 0.178, d_loss_fake= 0.027, g_loss 3.686, d_loss 0.103\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 123/390 d_loss_real= 0.052, d_loss_fake= 0.026, g_loss 3.742, d_loss 0.039\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 29 Batch 124/390 d_loss_real= 0.246, d_loss_fake= 0.025, g_loss 3.713, d_loss 0.135\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 125/390 d_loss_real= 0.121, d_loss_fake= 0.026, g_loss 3.674, d_loss 0.073\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 126/390 d_loss_real= 0.056, d_loss_fake= 0.027, g_loss 3.658, d_loss 0.042\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 29 Batch 127/390 d_loss_real= 0.113, d_loss_fake= 0.029, g_loss 3.544, d_loss 0.071\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 29 Batch 128/390 d_loss_real= 0.028, d_loss_fake= 0.031, g_loss 3.528, d_loss 0.029\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 129/390 d_loss_real= 0.298, d_loss_fake= 0.034, g_loss 3.374, d_loss 0.166\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 29 Batch 130/390 d_loss_real= 0.130, d_loss_fake= 0.039, g_loss 3.208, d_loss 0.085\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 29 Batch 131/390 d_loss_real= 0.001, d_loss_fake= 0.050, g_loss 3.460, d_loss 0.025\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 29 Batch 132/390 d_loss_real= 0.079, d_loss_fake= 0.033, g_loss 3.614, d_loss 0.056\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 29 Batch 133/390 d_loss_real= 0.067, d_loss_fake= 0.026, g_loss 3.816, d_loss 0.046\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 134/390 d_loss_real= 0.079, d_loss_fake= 0.021, g_loss 3.926, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 135/390 d_loss_real= 0.051, d_loss_fake= 0.021, g_loss 3.977, d_loss 0.036\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 29 Batch 136/390 d_loss_real= 0.123, d_loss_fake= 0.020, g_loss 3.989, d_loss 0.072\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 29 Batch 137/390 d_loss_real= 0.058, d_loss_fake= 0.020, g_loss 3.929, d_loss 0.039\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 138/390 d_loss_real= 0.122, d_loss_fake= 0.022, g_loss 3.867, d_loss 0.072\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 29 Batch 139/390 d_loss_real= 0.052, d_loss_fake= 0.023, g_loss 3.816, d_loss 0.038\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 140/390 d_loss_real= 0.106, d_loss_fake= 0.026, g_loss 3.777, d_loss 0.066\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 29 Batch 141/390 d_loss_real= 0.080, d_loss_fake= 0.029, g_loss 3.709, d_loss 0.054\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 142/390 d_loss_real= 0.003, d_loss_fake= 0.024, g_loss 3.802, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 143/390 d_loss_real= 0.200, d_loss_fake= 0.027, g_loss 3.699, d_loss 0.114\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 29 Batch 144/390 d_loss_real= 0.049, d_loss_fake= 0.023, g_loss 3.801, d_loss 0.036\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 145/390 d_loss_real= 0.126, d_loss_fake= 0.026, g_loss 3.762, d_loss 0.076\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 146/390 d_loss_real= 0.062, d_loss_fake= 0.026, g_loss 3.660, d_loss 0.044\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 147/390 d_loss_real= 0.130, d_loss_fake= 0.027, g_loss 3.697, d_loss 0.079\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 148/390 d_loss_real= 0.082, d_loss_fake= 0.032, g_loss 3.612, d_loss 0.057\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 29 Batch 149/390 d_loss_real= 0.223, d_loss_fake= 0.031, g_loss 3.551, d_loss 0.127\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 150/390 d_loss_real= 0.195, d_loss_fake= 0.034, g_loss 3.571, d_loss 0.114\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 151/390 d_loss_real= 0.068, d_loss_fake= 0.048, g_loss 3.349, d_loss 0.058\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 29 Batch 152/390 d_loss_real= 0.038, d_loss_fake= 0.051, g_loss 3.316, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 153/390 d_loss_real= 0.024, d_loss_fake= 0.059, g_loss 3.436, d_loss 0.042\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 29 Batch 154/390 d_loss_real= 0.028, d_loss_fake= 0.048, g_loss 3.617, d_loss 0.038\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 29 Batch 155/390 d_loss_real= 0.208, d_loss_fake= 0.043, g_loss 3.802, d_loss 0.125\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 29 Batch 156/390 d_loss_real= 0.348, d_loss_fake= 0.037, g_loss 3.672, d_loss 0.193\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 157/390 d_loss_real= 0.089, d_loss_fake= 0.046, g_loss 3.777, d_loss 0.067\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 29 Batch 158/390 d_loss_real= 0.022, d_loss_fake= 0.065, g_loss 3.751, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 159/390 d_loss_real= 0.126, d_loss_fake= 0.029, g_loss 4.049, d_loss 0.078\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 29 Batch 160/390 d_loss_real= 0.134, d_loss_fake= 0.026, g_loss 4.053, d_loss 0.080\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 29 Batch 161/390 d_loss_real= 0.251, d_loss_fake= 0.031, g_loss 3.905, d_loss 0.141\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 162/390 d_loss_real= 0.431, d_loss_fake= 0.032, g_loss 3.684, d_loss 0.232\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 163/390 d_loss_real= 0.165, d_loss_fake= 0.031, g_loss 3.576, d_loss 0.098\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 29 Batch 164/390 d_loss_real= 0.230, d_loss_fake= 0.030, g_loss 3.648, d_loss 0.130\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 29 Batch 165/390 d_loss_real= 0.145, d_loss_fake= 0.023, g_loss 3.821, d_loss 0.084\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 166/390 d_loss_real= 0.174, d_loss_fake= 0.035, g_loss 3.406, d_loss 0.104\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 167/390 d_loss_real= 0.209, d_loss_fake= 0.047, g_loss 3.212, d_loss 0.128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 168/390 d_loss_real= 0.134, d_loss_fake= 0.049, g_loss 3.308, d_loss 0.092\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 169/390 d_loss_real= 0.201, d_loss_fake= 0.050, g_loss 3.335, d_loss 0.126\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 29 Batch 170/390 d_loss_real= 0.094, d_loss_fake= 0.037, g_loss 3.510, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 171/390 d_loss_real= 0.128, d_loss_fake= 0.032, g_loss 3.621, d_loss 0.080\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 172/390 d_loss_real= 0.182, d_loss_fake= 0.035, g_loss 3.487, d_loss 0.109\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 173/390 d_loss_real= 0.076, d_loss_fake= 0.031, g_loss 3.624, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 174/390 d_loss_real= 0.126, d_loss_fake= 0.033, g_loss 3.451, d_loss 0.079\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 175/390 d_loss_real= 0.249, d_loss_fake= 0.039, g_loss 3.247, d_loss 0.144\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 176/390 d_loss_real= 0.269, d_loss_fake= 0.050, g_loss 3.021, d_loss 0.160\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 177/390 d_loss_real= 0.185, d_loss_fake= 0.061, g_loss 2.961, d_loss 0.123\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 178/390 d_loss_real= 0.145, d_loss_fake= 0.053, g_loss 3.161, d_loss 0.099\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 179/390 d_loss_real= 0.159, d_loss_fake= 0.043, g_loss 3.304, d_loss 0.101\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 180/390 d_loss_real= 0.074, d_loss_fake= 0.042, g_loss 3.303, d_loss 0.058\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 29 Batch 181/390 d_loss_real= 0.194, d_loss_fake= 0.042, g_loss 3.250, d_loss 0.118\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 182/390 d_loss_real= 0.188, d_loss_fake= 0.043, g_loss 3.192, d_loss 0.116\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 29 Batch 183/390 d_loss_real= 0.134, d_loss_fake= 0.041, g_loss 3.293, d_loss 0.088\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 184/390 d_loss_real= 0.072, d_loss_fake= 0.041, g_loss 3.290, d_loss 0.056\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 29 Batch 185/390 d_loss_real= 0.151, d_loss_fake= 0.039, g_loss 3.332, d_loss 0.095\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 186/390 d_loss_real= 0.125, d_loss_fake= 0.040, g_loss 3.316, d_loss 0.082\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 187/390 d_loss_real= 0.065, d_loss_fake= 0.039, g_loss 3.301, d_loss 0.052\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 29 Batch 188/390 d_loss_real= 0.180, d_loss_fake= 0.041, g_loss 3.310, d_loss 0.110\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 189/390 d_loss_real= 0.093, d_loss_fake= 0.038, g_loss 3.306, d_loss 0.065\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 29 Batch 190/390 d_loss_real= 0.172, d_loss_fake= 0.041, g_loss 3.286, d_loss 0.106\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 191/390 d_loss_real= 0.145, d_loss_fake= 0.043, g_loss 3.251, d_loss 0.094\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 192/390 d_loss_real= 0.123, d_loss_fake= 0.042, g_loss 3.211, d_loss 0.083\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 193/390 d_loss_real= 0.096, d_loss_fake= 0.046, g_loss 3.162, d_loss 0.071\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 194/390 d_loss_real= 0.092, d_loss_fake= 0.054, g_loss 3.023, d_loss 0.073\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 195/390 d_loss_real= 0.088, d_loss_fake= 0.062, g_loss 2.870, d_loss 0.075\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 196/390 d_loss_real= 0.154, d_loss_fake= 0.075, g_loss 2.737, d_loss 0.114\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 29 Batch 197/390 d_loss_real= 0.035, d_loss_fake= 0.081, g_loss 2.918, d_loss 0.058\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 198/390 d_loss_real= 0.110, d_loss_fake= 0.059, g_loss 3.122, d_loss 0.084\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 199/390 d_loss_real= 0.049, d_loss_fake= 0.047, g_loss 3.241, d_loss 0.048\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 200/390 d_loss_real= 0.153, d_loss_fake= 0.043, g_loss 3.254, d_loss 0.098\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 29 Batch 201/390 d_loss_real= 0.085, d_loss_fake= 0.040, g_loss 3.323, d_loss 0.063\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 202/390 d_loss_real= 0.113, d_loss_fake= 0.044, g_loss 3.228, d_loss 0.079\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 203/390 d_loss_real= 0.112, d_loss_fake= 0.049, g_loss 3.055, d_loss 0.081\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 29 Batch 204/390 d_loss_real= 0.057, d_loss_fake= 0.060, g_loss 2.885, d_loss 0.058\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 29 Batch 205/390 d_loss_real= 0.062, d_loss_fake= 0.064, g_loss 2.912, d_loss 0.063\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 29 Batch 206/390 d_loss_real= 0.217, d_loss_fake= 0.068, g_loss 2.790, d_loss 0.143\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 29 Batch 207/390 d_loss_real= 0.095, d_loss_fake= 0.070, g_loss 2.849, d_loss 0.082\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 208/390 d_loss_real= 0.199, d_loss_fake= 0.066, g_loss 2.913, d_loss 0.133\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 209/390 d_loss_real= 0.148, d_loss_fake= 0.060, g_loss 2.967, d_loss 0.104\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 210/390 d_loss_real= 0.107, d_loss_fake= 0.056, g_loss 3.040, d_loss 0.081\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 211/390 d_loss_real= 0.042, d_loss_fake= 0.062, g_loss 2.988, d_loss 0.052\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 212/390 d_loss_real= 0.039, d_loss_fake= 0.059, g_loss 3.009, d_loss 0.049\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 29 Batch 213/390 d_loss_real= 0.212, d_loss_fake= 0.062, g_loss 2.877, d_loss 0.137\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 214/390 d_loss_real= 0.243, d_loss_fake= 0.073, g_loss 2.661, d_loss 0.158\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 215/390 d_loss_real= 0.094, d_loss_fake= 0.097, g_loss 2.460, d_loss 0.096\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 216/390 d_loss_real= 0.201, d_loss_fake= 0.125, g_loss 2.159, d_loss 0.163\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 29 Batch 217/390 d_loss_real= 0.081, d_loss_fake= 0.144, g_loss 2.072, d_loss 0.112\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 218/390 d_loss_real= 0.209, d_loss_fake= 0.159, g_loss 2.023, d_loss 0.184\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 29 Batch 219/390 d_loss_real= 0.082, d_loss_fake= 0.156, g_loss 2.031, d_loss 0.119\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 220/390 d_loss_real= 0.127, d_loss_fake= 0.154, g_loss 2.046, d_loss 0.141\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 29 Batch 221/390 d_loss_real= 0.125, d_loss_fake= 0.148, g_loss 2.072, d_loss 0.136\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 222/390 d_loss_real= 0.144, d_loss_fake= 0.150, g_loss 2.077, d_loss 0.147\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 29 Batch 223/390 d_loss_real= 0.113, d_loss_fake= 0.142, g_loss 2.103, d_loss 0.127\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 29 Batch 224/390 d_loss_real= 0.083, d_loss_fake= 0.140, g_loss 2.112, d_loss 0.111\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 225/390 d_loss_real= 0.194, d_loss_fake= 0.133, g_loss 2.115, d_loss 0.163\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 226/390 d_loss_real= 0.087, d_loss_fake= 0.135, g_loss 2.115, d_loss 0.111\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 29 Batch 227/390 d_loss_real= 0.082, d_loss_fake= 0.134, g_loss 2.165, d_loss 0.108\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 228/390 d_loss_real= 0.000, d_loss_fake= 0.128, g_loss 2.193, d_loss 0.064\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 29 Batch 229/390 d_loss_real= 0.164, d_loss_fake= 0.123, g_loss 2.222, d_loss 0.143\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 29 Batch 230/390 d_loss_real= 0.340, d_loss_fake= 0.119, g_loss 2.246, d_loss 0.229\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 231/390 d_loss_real= 0.147, d_loss_fake= 0.118, g_loss 2.244, d_loss 0.132\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 29 Batch 232/390 d_loss_real= 0.098, d_loss_fake= 0.122, g_loss 2.272, d_loss 0.110\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 233/390 d_loss_real= 0.130, d_loss_fake= 0.113, g_loss 2.297, d_loss 0.121\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 234/390 d_loss_real= 0.094, d_loss_fake= 0.109, g_loss 2.321, d_loss 0.102\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 29 Batch 235/390 d_loss_real= 0.103, d_loss_fake= 0.108, g_loss 2.334, d_loss 0.106\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 29 Batch 236/390 d_loss_real= 0.153, d_loss_fake= 0.109, g_loss 2.367, d_loss 0.131\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 237/390 d_loss_real= 0.062, d_loss_fake= 0.101, g_loss 2.440, d_loss 0.082\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 238/390 d_loss_real= 0.143, d_loss_fake= 0.094, g_loss 2.492, d_loss 0.118\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 239/390 d_loss_real= 0.157, d_loss_fake= 0.090, g_loss 2.513, d_loss 0.124\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 29 Batch 240/390 d_loss_real= 0.161, d_loss_fake= 0.082, g_loss 2.587, d_loss 0.122\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 29 Batch 241/390 d_loss_real= 0.120, d_loss_fake= 0.080, g_loss 2.621, d_loss 0.100\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 29 Batch 242/390 d_loss_real= 0.014, d_loss_fake= 0.074, g_loss 2.695, d_loss 0.044\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 29 Batch 243/390 d_loss_real= 0.107, d_loss_fake= 0.073, g_loss 2.719, d_loss 0.090\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 29 Batch 244/390 d_loss_real= 0.120, d_loss_fake= 0.073, g_loss 2.697, d_loss 0.097\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 245/390 d_loss_real= 0.060, d_loss_fake= 0.072, g_loss 2.728, d_loss 0.066\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 246/390 d_loss_real= 0.141, d_loss_fake= 0.069, g_loss 2.742, d_loss 0.105\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 29 Batch 247/390 d_loss_real= 0.210, d_loss_fake= 0.073, g_loss 2.673, d_loss 0.141\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 248/390 d_loss_real= 0.134, d_loss_fake= 0.075, g_loss 2.641, d_loss 0.104\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 29 Batch 249/390 d_loss_real= 0.113, d_loss_fake= 0.086, g_loss 2.602, d_loss 0.100\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 29 Batch 250/390 d_loss_real= 0.175, d_loss_fake= 0.087, g_loss 2.556, d_loss 0.131\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 29 Batch 251/390 d_loss_real= 0.197, d_loss_fake= 0.097, g_loss 2.554, d_loss 0.147\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 252/390 d_loss_real= 0.005, d_loss_fake= 0.102, g_loss 2.750, d_loss 0.054\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 253/390 d_loss_real= 0.241, d_loss_fake= 0.080, g_loss 2.869, d_loss 0.161\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 29 Batch 254/390 d_loss_real= 0.043, d_loss_fake= 0.060, g_loss 3.021, d_loss 0.052\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 255/390 d_loss_real= 0.352, d_loss_fake= 0.053, g_loss 3.110, d_loss 0.202\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 256/390 d_loss_real= 0.257, d_loss_fake= 0.050, g_loss 3.168, d_loss 0.153\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 29 Batch 257/390 d_loss_real= 0.244, d_loss_fake= 0.054, g_loss 2.965, d_loss 0.149\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 258/390 d_loss_real= 0.219, d_loss_fake= 0.063, g_loss 2.900, d_loss 0.141\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 29 Batch 259/390 d_loss_real= 0.053, d_loss_fake= 0.069, g_loss 2.851, d_loss 0.061\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 260/390 d_loss_real= 0.264, d_loss_fake= 0.088, g_loss 2.704, d_loss 0.176\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 261/390 d_loss_real= 0.091, d_loss_fake= 0.073, g_loss 2.739, d_loss 0.082\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 262/390 d_loss_real= 0.200, d_loss_fake= 0.066, g_loss 2.926, d_loss 0.133\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 263/390 d_loss_real= 0.230, d_loss_fake= 0.083, g_loss 2.702, d_loss 0.157\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 264/390 d_loss_real= 0.105, d_loss_fake= 0.090, g_loss 2.819, d_loss 0.097\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 29 Batch 265/390 d_loss_real= 0.269, d_loss_fake= 0.063, g_loss 3.101, d_loss 0.166\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 266/390 d_loss_real= 0.262, d_loss_fake= 0.044, g_loss 3.294, d_loss 0.153\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 267/390 d_loss_real= 0.150, d_loss_fake= 0.038, g_loss 3.428, d_loss 0.094\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 268/390 d_loss_real= 0.068, d_loss_fake= 0.035, g_loss 3.534, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 269/390 d_loss_real= 0.095, d_loss_fake= 0.029, g_loss 3.596, d_loss 0.062\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 270/390 d_loss_real= 0.149, d_loss_fake= 0.029, g_loss 3.631, d_loss 0.089\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 29 Batch 271/390 d_loss_real= 0.192, d_loss_fake= 0.029, g_loss 3.623, d_loss 0.110\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 272/390 d_loss_real= 0.056, d_loss_fake= 0.030, g_loss 3.569, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 273/390 d_loss_real= 0.176, d_loss_fake= 0.029, g_loss 3.536, d_loss 0.103\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 274/390 d_loss_real= 0.185, d_loss_fake= 0.035, g_loss 3.381, d_loss 0.110\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 275/390 d_loss_real= 0.224, d_loss_fake= 0.040, g_loss 3.189, d_loss 0.132\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 276/390 d_loss_real= 0.216, d_loss_fake= 0.055, g_loss 2.964, d_loss 0.136\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 277/390 d_loss_real= 0.133, d_loss_fake= 0.066, g_loss 2.803, d_loss 0.099\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 29 Batch 278/390 d_loss_real= 0.248, d_loss_fake= 0.080, g_loss 2.828, d_loss 0.164\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 29 Batch 279/390 d_loss_real= 0.049, d_loss_fake= 0.059, g_loss 2.981, d_loss 0.054\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 280/390 d_loss_real= 0.056, d_loss_fake= 0.051, g_loss 3.180, d_loss 0.053\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 281/390 d_loss_real= 0.128, d_loss_fake= 0.062, g_loss 3.172, d_loss 0.095\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 282/390 d_loss_real= 0.137, d_loss_fake= 0.045, g_loss 3.274, d_loss 0.091\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 29 Batch 283/390 d_loss_real= 0.013, d_loss_fake= 0.036, g_loss 3.386, d_loss 0.024\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 284/390 d_loss_real= 0.113, d_loss_fake= 0.036, g_loss 3.530, d_loss 0.074\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 285/390 d_loss_real= 0.208, d_loss_fake= 0.031, g_loss 3.609, d_loss 0.120\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 286/390 d_loss_real= 0.181, d_loss_fake= 0.038, g_loss 3.478, d_loss 0.110\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 29 Batch 287/390 d_loss_real= 0.212, d_loss_fake= 0.035, g_loss 3.451, d_loss 0.123\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 288/390 d_loss_real= 0.213, d_loss_fake= 0.051, g_loss 3.370, d_loss 0.132\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 29 Batch 289/390 d_loss_real= 0.222, d_loss_fake= 0.050, g_loss 3.252, d_loss 0.136\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 290/390 d_loss_real= 0.321, d_loss_fake= 0.058, g_loss 3.237, d_loss 0.190\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 29 Batch 291/390 d_loss_real= 0.181, d_loss_fake= 0.050, g_loss 3.214, d_loss 0.115\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 292/390 d_loss_real= 0.077, d_loss_fake= 0.082, g_loss 3.207, d_loss 0.080\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 293/390 d_loss_real= 0.164, d_loss_fake= 0.056, g_loss 3.227, d_loss 0.110\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 29 Batch 294/390 d_loss_real= 0.057, d_loss_fake= 0.070, g_loss 3.311, d_loss 0.064\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 29 Batch 295/390 d_loss_real= 0.116, d_loss_fake= 0.077, g_loss 3.220, d_loss 0.096\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 29 Batch 296/390 d_loss_real= 0.131, d_loss_fake= 0.054, g_loss 3.386, d_loss 0.093\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 297/390 d_loss_real= 0.304, d_loss_fake= 0.042, g_loss 3.329, d_loss 0.173\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 29 Batch 298/390 d_loss_real= 0.206, d_loss_fake= 0.046, g_loss 3.362, d_loss 0.126\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 299/390 d_loss_real= 0.218, d_loss_fake= 0.047, g_loss 3.372, d_loss 0.132\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 29 Batch 300/390 d_loss_real= 0.339, d_loss_fake= 0.051, g_loss 3.309, d_loss 0.195\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 301/390 d_loss_real= 0.021, d_loss_fake= 0.040, g_loss 3.542, d_loss 0.031\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 302/390 d_loss_real= 0.041, d_loss_fake= 0.061, g_loss 3.239, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 303/390 d_loss_real= 0.155, d_loss_fake= 0.046, g_loss 3.460, d_loss 0.101\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 304/390 d_loss_real= 0.190, d_loss_fake= 0.035, g_loss 3.436, d_loss 0.112\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 305/390 d_loss_real= 0.164, d_loss_fake= 0.065, g_loss 3.073, d_loss 0.114\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 306/390 d_loss_real= 0.044, d_loss_fake= 0.053, g_loss 3.332, d_loss 0.048\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 307/390 d_loss_real= 0.266, d_loss_fake= 0.058, g_loss 3.236, d_loss 0.162\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 308/390 d_loss_real= 0.238, d_loss_fake= 0.078, g_loss 3.208, d_loss 0.158\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 309/390 d_loss_real= 0.379, d_loss_fake= 0.056, g_loss 3.310, d_loss 0.217\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 29 Batch 310/390 d_loss_real= 0.148, d_loss_fake= 0.048, g_loss 3.361, d_loss 0.098\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 29 Batch 311/390 d_loss_real= 0.390, d_loss_fake= 0.054, g_loss 3.153, d_loss 0.222\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 312/390 d_loss_real= 0.229, d_loss_fake= 0.052, g_loss 3.167, d_loss 0.140\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 313/390 d_loss_real= 0.062, d_loss_fake= 0.052, g_loss 3.370, d_loss 0.057\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 314/390 d_loss_real= 0.229, d_loss_fake= 0.067, g_loss 3.189, d_loss 0.148\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 315/390 d_loss_real= 0.048, d_loss_fake= 0.061, g_loss 3.159, d_loss 0.054\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 316/390 d_loss_real= 0.003, d_loss_fake= 0.052, g_loss 3.318, d_loss 0.028\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 317/390 d_loss_real= 0.367, d_loss_fake= 0.041, g_loss 3.453, d_loss 0.204\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 318/390 d_loss_real= 0.319, d_loss_fake= 0.037, g_loss 3.462, d_loss 0.178\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 319/390 d_loss_real= 0.107, d_loss_fake= 0.039, g_loss 3.340, d_loss 0.073\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 320/390 d_loss_real= 0.295, d_loss_fake= 0.046, g_loss 3.127, d_loss 0.171\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 321/390 d_loss_real= 0.145, d_loss_fake= 0.054, g_loss 2.966, d_loss 0.100\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 322/390 d_loss_real= 0.115, d_loss_fake= 0.065, g_loss 2.899, d_loss 0.090\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 323/390 d_loss_real= 0.159, d_loss_fake= 0.060, g_loss 2.931, d_loss 0.109\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 29 Batch 324/390 d_loss_real= 0.067, d_loss_fake= 0.057, g_loss 3.028, d_loss 0.062\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 325/390 d_loss_real= 0.011, d_loss_fake= 0.038, g_loss 3.429, d_loss 0.024\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 326/390 d_loss_real= 0.127, d_loss_fake= 0.051, g_loss 3.105, d_loss 0.089\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 29 Batch 327/390 d_loss_real= 0.324, d_loss_fake= 0.039, g_loss 3.284, d_loss 0.182\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 328/390 d_loss_real= 0.351, d_loss_fake= 0.042, g_loss 3.161, d_loss 0.196\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 329/390 d_loss_real= 0.094, d_loss_fake= 0.067, g_loss 2.715, d_loss 0.081\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 330/390 d_loss_real= 0.063, d_loss_fake= 0.067, g_loss 2.871, d_loss 0.065\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 331/390 d_loss_real= 0.088, d_loss_fake= 0.059, g_loss 2.990, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 332/390 d_loss_real= 0.087, d_loss_fake= 0.066, g_loss 2.906, d_loss 0.077\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 333/390 d_loss_real= 0.180, d_loss_fake= 0.059, g_loss 3.043, d_loss 0.120\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 29 Batch 334/390 d_loss_real= 0.373, d_loss_fake= 0.048, g_loss 3.227, d_loss 0.210\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 335/390 d_loss_real= 0.087, d_loss_fake= 0.046, g_loss 3.239, d_loss 0.067\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 336/390 d_loss_real= 0.370, d_loss_fake= 0.062, g_loss 2.828, d_loss 0.216\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 29 Batch 337/390 d_loss_real= 0.252, d_loss_fake= 0.084, g_loss 2.618, d_loss 0.168\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 29 Batch 338/390 d_loss_real= 0.138, d_loss_fake= 0.068, g_loss 2.907, d_loss 0.103\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 339/390 d_loss_real= 0.131, d_loss_fake= 0.069, g_loss 2.948, d_loss 0.100\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 340/390 d_loss_real= 0.068, d_loss_fake= 0.051, g_loss 3.273, d_loss 0.059\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 341/390 d_loss_real= 0.126, d_loss_fake= 0.077, g_loss 2.938, d_loss 0.101\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 29 Batch 342/390 d_loss_real= 0.173, d_loss_fake= 0.035, g_loss 3.514, d_loss 0.104\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 29 Batch 343/390 d_loss_real= 0.112, d_loss_fake= 0.037, g_loss 3.445, d_loss 0.075\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 344/390 d_loss_real= 0.320, d_loss_fake= 0.056, g_loss 3.024, d_loss 0.188\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 345/390 d_loss_real= 0.331, d_loss_fake= 0.050, g_loss 3.067, d_loss 0.190\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 346/390 d_loss_real= 0.254, d_loss_fake= 0.054, g_loss 3.088, d_loss 0.154\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29 Batch 347/390 d_loss_real= 0.071, d_loss_fake= 0.074, g_loss 2.956, d_loss 0.073\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 29 Batch 348/390 d_loss_real= 0.132, d_loss_fake= 0.052, g_loss 3.195, d_loss 0.092\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 349/390 d_loss_real= 0.104, d_loss_fake= 0.047, g_loss 3.292, d_loss 0.075\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 29 Batch 350/390 d_loss_real= 0.229, d_loss_fake= 0.050, g_loss 3.105, d_loss 0.140\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 351/390 d_loss_real= 0.145, d_loss_fake= 0.072, g_loss 2.942, d_loss 0.109\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 352/390 d_loss_real= 0.125, d_loss_fake= 0.051, g_loss 3.251, d_loss 0.088\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 353/390 d_loss_real= 0.148, d_loss_fake= 0.034, g_loss 3.569, d_loss 0.091\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 29 Batch 354/390 d_loss_real= 0.199, d_loss_fake= 0.028, g_loss 3.598, d_loss 0.114\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 355/390 d_loss_real= 0.143, d_loss_fake= 0.041, g_loss 3.338, d_loss 0.092\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 356/390 d_loss_real= 0.165, d_loss_fake= 0.044, g_loss 3.398, d_loss 0.105\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 357/390 d_loss_real= 0.189, d_loss_fake= 0.045, g_loss 3.384, d_loss 0.117\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 29 Batch 358/390 d_loss_real= 0.140, d_loss_fake= 0.041, g_loss 3.445, d_loss 0.090\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 359/390 d_loss_real= 0.238, d_loss_fake= 0.043, g_loss 3.331, d_loss 0.140\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 360/390 d_loss_real= 0.054, d_loss_fake= 0.050, g_loss 3.331, d_loss 0.052\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 29 Batch 361/390 d_loss_real= 0.124, d_loss_fake= 0.044, g_loss 3.361, d_loss 0.084\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 29 Batch 362/390 d_loss_real= 0.308, d_loss_fake= 0.042, g_loss 3.283, d_loss 0.175\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 363/390 d_loss_real= 0.122, d_loss_fake= 0.039, g_loss 3.360, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 364/390 d_loss_real= 0.198, d_loss_fake= 0.048, g_loss 3.095, d_loss 0.123\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 365/390 d_loss_real= 0.085, d_loss_fake= 0.064, g_loss 3.109, d_loss 0.075\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 366/390 d_loss_real= 0.313, d_loss_fake= 0.058, g_loss 3.099, d_loss 0.185\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 29 Batch 367/390 d_loss_real= 0.129, d_loss_fake= 0.059, g_loss 3.056, d_loss 0.094\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 29 Batch 368/390 d_loss_real= 0.182, d_loss_fake= 0.046, g_loss 3.267, d_loss 0.114\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 29 Batch 369/390 d_loss_real= 0.211, d_loss_fake= 0.040, g_loss 3.362, d_loss 0.125\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 29 Batch 370/390 d_loss_real= 0.275, d_loss_fake= 0.045, g_loss 3.264, d_loss 0.160\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 371/390 d_loss_real= 0.337, d_loss_fake= 0.049, g_loss 3.119, d_loss 0.193\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 372/390 d_loss_real= 0.140, d_loss_fake= 0.060, g_loss 2.958, d_loss 0.100\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 373/390 d_loss_real= 0.060, d_loss_fake= 0.053, g_loss 3.137, d_loss 0.057\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 374/390 d_loss_real= 0.239, d_loss_fake= 0.056, g_loss 2.965, d_loss 0.148\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 375/390 d_loss_real= 0.243, d_loss_fake= 0.068, g_loss 2.892, d_loss 0.156\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 29 Batch 376/390 d_loss_real= 0.127, d_loss_fake= 0.070, g_loss 3.027, d_loss 0.099\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 29 Batch 377/390 d_loss_real= 0.140, d_loss_fake= 0.051, g_loss 3.189, d_loss 0.096\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 378/390 d_loss_real= 0.153, d_loss_fake= 0.042, g_loss 3.324, d_loss 0.098\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 379/390 d_loss_real= 0.293, d_loss_fake= 0.040, g_loss 3.353, d_loss 0.167\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 380/390 d_loss_real= 0.051, d_loss_fake= 0.040, g_loss 3.320, d_loss 0.046\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 29 Batch 381/390 d_loss_real= 0.214, d_loss_fake= 0.044, g_loss 3.189, d_loss 0.129\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 29 Batch 382/390 d_loss_real= 0.107, d_loss_fake= 0.043, g_loss 3.230, d_loss 0.075\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 383/390 d_loss_real= 0.269, d_loss_fake= 0.056, g_loss 2.974, d_loss 0.162\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 29 Batch 384/390 d_loss_real= 0.071, d_loss_fake= 0.065, g_loss 2.990, d_loss 0.068\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 385/390 d_loss_real= 0.170, d_loss_fake= 0.055, g_loss 3.126, d_loss 0.113\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29 Batch 386/390 d_loss_real= 0.158, d_loss_fake= 0.056, g_loss 3.090, d_loss 0.107\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29 Batch 387/390 d_loss_real= 0.133, d_loss_fake= 0.044, g_loss 3.249, d_loss 0.088\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 29 Batch 388/390 d_loss_real= 0.241, d_loss_fake= 0.047, g_loss 3.191, d_loss 0.144\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 29 Batch 389/390 d_loss_real= 0.064, d_loss_fake= 0.045, g_loss 3.322, d_loss 0.054\n",
            "2/2 [==============================] - 0s 11ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29 Batch 390/390 d_loss_real= 0.238, d_loss_fake= 0.041, g_loss 3.341, d_loss 0.139\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 1/390 d_loss_real= 0.117, d_loss_fake= 0.035, g_loss 3.423, d_loss 0.076\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 2/390 d_loss_real= 0.166, d_loss_fake= 0.041, g_loss 3.306, d_loss 0.103\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 30 Batch 3/390 d_loss_real= 0.122, d_loss_fake= 0.046, g_loss 3.220, d_loss 0.084\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 4/390 d_loss_real= 0.087, d_loss_fake= 0.044, g_loss 3.287, d_loss 0.066\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 5/390 d_loss_real= 0.182, d_loss_fake= 0.043, g_loss 3.174, d_loss 0.113\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 6/390 d_loss_real= 0.194, d_loss_fake= 0.047, g_loss 3.111, d_loss 0.120\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 7/390 d_loss_real= 0.079, d_loss_fake= 0.059, g_loss 3.028, d_loss 0.069\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 30 Batch 8/390 d_loss_real= 0.109, d_loss_fake= 0.055, g_loss 3.147, d_loss 0.082\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 9/390 d_loss_real= 0.102, d_loss_fake= 0.044, g_loss 3.201, d_loss 0.073\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 30 Batch 10/390 d_loss_real= 0.109, d_loss_fake= 0.041, g_loss 3.294, d_loss 0.075\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 11/390 d_loss_real= 0.059, d_loss_fake= 0.039, g_loss 3.352, d_loss 0.049\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 12/390 d_loss_real= 0.157, d_loss_fake= 0.040, g_loss 3.407, d_loss 0.098\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 13/390 d_loss_real= 0.367, d_loss_fake= 0.037, g_loss 3.289, d_loss 0.202\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 14/390 d_loss_real= 0.039, d_loss_fake= 0.044, g_loss 3.184, d_loss 0.041\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 15/390 d_loss_real= 0.157, d_loss_fake= 0.061, g_loss 2.983, d_loss 0.109\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 16/390 d_loss_real= 0.131, d_loss_fake= 0.070, g_loss 2.885, d_loss 0.100\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 17/390 d_loss_real= 0.032, d_loss_fake= 0.057, g_loss 3.154, d_loss 0.045\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 18/390 d_loss_real= 0.040, d_loss_fake= 0.046, g_loss 3.412, d_loss 0.043\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 30 Batch 19/390 d_loss_real= 0.149, d_loss_fake= 0.035, g_loss 3.512, d_loss 0.092\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 20/390 d_loss_real= 0.229, d_loss_fake= 0.032, g_loss 3.593, d_loss 0.130\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 21/390 d_loss_real= 0.271, d_loss_fake= 0.033, g_loss 3.461, d_loss 0.152\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 22/390 d_loss_real= 0.223, d_loss_fake= 0.038, g_loss 3.427, d_loss 0.131\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 23/390 d_loss_real= 0.097, d_loss_fake= 0.041, g_loss 3.369, d_loss 0.069\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 30 Batch 24/390 d_loss_real= 0.141, d_loss_fake= 0.039, g_loss 3.230, d_loss 0.090\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 25/390 d_loss_real= 0.272, d_loss_fake= 0.048, g_loss 3.063, d_loss 0.160\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 26/390 d_loss_real= 0.028, d_loss_fake= 0.056, g_loss 2.877, d_loss 0.042\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 30 Batch 27/390 d_loss_real= 0.189, d_loss_fake= 0.066, g_loss 2.814, d_loss 0.127\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 28/390 d_loss_real= 0.121, d_loss_fake= 0.076, g_loss 2.649, d_loss 0.099\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 30 Batch 29/390 d_loss_real= 0.122, d_loss_fake= 0.095, g_loss 2.530, d_loss 0.109\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 30/390 d_loss_real= 0.148, d_loss_fake= 0.097, g_loss 2.588, d_loss 0.122\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 30 Batch 31/390 d_loss_real= 0.133, d_loss_fake= 0.087, g_loss 2.741, d_loss 0.110\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 30 Batch 32/390 d_loss_real= 0.215, d_loss_fake= 0.070, g_loss 2.869, d_loss 0.143\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 33/390 d_loss_real= 0.138, d_loss_fake= 0.060, g_loss 2.945, d_loss 0.099\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 34/390 d_loss_real= 0.049, d_loss_fake= 0.064, g_loss 2.880, d_loss 0.056\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 35/390 d_loss_real= 0.035, d_loss_fake= 0.063, g_loss 2.899, d_loss 0.049\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 36/390 d_loss_real= 0.343, d_loss_fake= 0.067, g_loss 2.784, d_loss 0.205\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 37/390 d_loss_real= 0.024, d_loss_fake= 0.075, g_loss 2.695, d_loss 0.050\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 30 Batch 38/390 d_loss_real= 0.264, d_loss_fake= 0.079, g_loss 2.562, d_loss 0.172\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 30 Batch 39/390 d_loss_real= 0.132, d_loss_fake= 0.094, g_loss 2.461, d_loss 0.113\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 40/390 d_loss_real= 0.233, d_loss_fake= 0.105, g_loss 2.354, d_loss 0.169\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 41/390 d_loss_real= 0.138, d_loss_fake= 0.116, g_loss 2.263, d_loss 0.127\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 42/390 d_loss_real= 0.176, d_loss_fake= 0.122, g_loss 2.211, d_loss 0.149\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 30 Batch 43/390 d_loss_real= 0.086, d_loss_fake= 0.118, g_loss 2.270, d_loss 0.102\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 30 Batch 44/390 d_loss_real= 0.082, d_loss_fake= 0.105, g_loss 2.417, d_loss 0.093\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 45/390 d_loss_real= 0.077, d_loss_fake= 0.100, g_loss 2.524, d_loss 0.089\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 46/390 d_loss_real= 0.206, d_loss_fake= 0.088, g_loss 2.639, d_loss 0.147\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 30 Batch 47/390 d_loss_real= 0.229, d_loss_fake= 0.084, g_loss 2.610, d_loss 0.157\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 48/390 d_loss_real= 0.192, d_loss_fake= 0.079, g_loss 2.662, d_loss 0.136\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 49/390 d_loss_real= 0.212, d_loss_fake= 0.084, g_loss 2.644, d_loss 0.148\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 30 Batch 50/390 d_loss_real= 0.147, d_loss_fake= 0.083, g_loss 2.499, d_loss 0.115\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 30 Batch 51/390 d_loss_real= 0.119, d_loss_fake= 0.096, g_loss 2.428, d_loss 0.108\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 52/390 d_loss_real= 0.334, d_loss_fake= 0.108, g_loss 2.281, d_loss 0.221\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 30 Batch 53/390 d_loss_real= 0.170, d_loss_fake= 0.126, g_loss 2.203, d_loss 0.148\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 30 Batch 54/390 d_loss_real= 0.229, d_loss_fake= 0.137, g_loss 2.229, d_loss 0.183\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 55/390 d_loss_real= 0.093, d_loss_fake= 0.132, g_loss 2.239, d_loss 0.113\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 56/390 d_loss_real= 0.140, d_loss_fake= 0.114, g_loss 2.356, d_loss 0.127\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 57/390 d_loss_real= 0.131, d_loss_fake= 0.111, g_loss 2.386, d_loss 0.121\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 58/390 d_loss_real= 0.035, d_loss_fake= 0.099, g_loss 2.517, d_loss 0.067\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 30 Batch 59/390 d_loss_real= 0.287, d_loss_fake= 0.089, g_loss 2.589, d_loss 0.188\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 60/390 d_loss_real= 0.026, d_loss_fake= 0.082, g_loss 2.636, d_loss 0.054\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 30 Batch 61/390 d_loss_real= 0.147, d_loss_fake= 0.077, g_loss 2.670, d_loss 0.112\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 62/390 d_loss_real= 0.134, d_loss_fake= 0.074, g_loss 2.719, d_loss 0.104\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 63/390 d_loss_real= 0.269, d_loss_fake= 0.072, g_loss 2.787, d_loss 0.170\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 30 Batch 64/390 d_loss_real= 0.237, d_loss_fake= 0.072, g_loss 2.689, d_loss 0.154\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 65/390 d_loss_real= 0.344, d_loss_fake= 0.078, g_loss 2.630, d_loss 0.211\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 66/390 d_loss_real= 0.245, d_loss_fake= 0.084, g_loss 2.542, d_loss 0.165\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 67/390 d_loss_real= 0.077, d_loss_fake= 0.089, g_loss 2.529, d_loss 0.083\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 30 Batch 68/390 d_loss_real= 0.141, d_loss_fake= 0.093, g_loss 2.505, d_loss 0.117\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 69/390 d_loss_real= 0.044, d_loss_fake= 0.110, g_loss 2.467, d_loss 0.077\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 70/390 d_loss_real= 0.286, d_loss_fake= 0.097, g_loss 2.462, d_loss 0.191\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 71/390 d_loss_real= 0.020, d_loss_fake= 0.088, g_loss 2.604, d_loss 0.054\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 72/390 d_loss_real= 0.062, d_loss_fake= 0.076, g_loss 2.789, d_loss 0.069\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 73/390 d_loss_real= 0.103, d_loss_fake= 0.062, g_loss 2.919, d_loss 0.083\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 74/390 d_loss_real= 0.300, d_loss_fake= 0.055, g_loss 3.029, d_loss 0.177\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 75/390 d_loss_real= 0.256, d_loss_fake= 0.053, g_loss 3.001, d_loss 0.154\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 30 Batch 76/390 d_loss_real= 0.169, d_loss_fake= 0.054, g_loss 2.921, d_loss 0.111\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 77/390 d_loss_real= 0.268, d_loss_fake= 0.063, g_loss 2.761, d_loss 0.165\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 30 Batch 78/390 d_loss_real= 0.257, d_loss_fake= 0.082, g_loss 2.493, d_loss 0.170\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 30 Batch 79/390 d_loss_real= 0.053, d_loss_fake= 0.104, g_loss 2.380, d_loss 0.078\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 80/390 d_loss_real= 0.121, d_loss_fake= 0.093, g_loss 2.619, d_loss 0.107\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 81/390 d_loss_real= 0.042, d_loss_fake= 0.066, g_loss 2.893, d_loss 0.054\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 82/390 d_loss_real= 0.218, d_loss_fake= 0.053, g_loss 3.110, d_loss 0.135\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 83/390 d_loss_real= 0.279, d_loss_fake= 0.053, g_loss 3.075, d_loss 0.166\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 84/390 d_loss_real= 0.098, d_loss_fake= 0.044, g_loss 3.209, d_loss 0.071\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 85/390 d_loss_real= 0.146, d_loss_fake= 0.046, g_loss 3.209, d_loss 0.096\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 86/390 d_loss_real= 0.212, d_loss_fake= 0.046, g_loss 3.101, d_loss 0.129\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 87/390 d_loss_real= 0.081, d_loss_fake= 0.051, g_loss 3.007, d_loss 0.066\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 88/390 d_loss_real= 0.212, d_loss_fake= 0.061, g_loss 2.816, d_loss 0.136\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 89/390 d_loss_real= 0.125, d_loss_fake= 0.079, g_loss 2.618, d_loss 0.102\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 90/390 d_loss_real= 0.123, d_loss_fake= 0.083, g_loss 2.649, d_loss 0.103\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 91/390 d_loss_real= 0.141, d_loss_fake= 0.074, g_loss 2.846, d_loss 0.108\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 92/390 d_loss_real= 0.051, d_loss_fake= 0.057, g_loss 3.034, d_loss 0.054\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 93/390 d_loss_real= 0.173, d_loss_fake= 0.051, g_loss 3.194, d_loss 0.112\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 94/390 d_loss_real= 0.224, d_loss_fake= 0.042, g_loss 3.260, d_loss 0.133\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 95/390 d_loss_real= 0.121, d_loss_fake= 0.043, g_loss 3.297, d_loss 0.082\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 30 Batch 96/390 d_loss_real= 0.315, d_loss_fake= 0.043, g_loss 3.226, d_loss 0.179\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 97/390 d_loss_real= 0.039, d_loss_fake= 0.044, g_loss 3.140, d_loss 0.042\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 98/390 d_loss_real= 0.097, d_loss_fake= 0.053, g_loss 3.014, d_loss 0.075\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 99/390 d_loss_real= 0.113, d_loss_fake= 0.063, g_loss 2.758, d_loss 0.088\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 100/390 d_loss_real= 0.116, d_loss_fake= 0.084, g_loss 2.618, d_loss 0.100\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 101/390 d_loss_real= 0.190, d_loss_fake= 0.084, g_loss 2.766, d_loss 0.137\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 30 Batch 102/390 d_loss_real= 0.289, d_loss_fake= 0.078, g_loss 2.896, d_loss 0.183\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 103/390 d_loss_real= 0.266, d_loss_fake= 0.056, g_loss 3.080, d_loss 0.161\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 104/390 d_loss_real= 0.037, d_loss_fake= 0.049, g_loss 3.166, d_loss 0.043\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 30 Batch 105/390 d_loss_real= 0.153, d_loss_fake= 0.046, g_loss 3.194, d_loss 0.100\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 106/390 d_loss_real= 0.154, d_loss_fake= 0.044, g_loss 3.226, d_loss 0.099\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 107/390 d_loss_real= 0.172, d_loss_fake= 0.043, g_loss 3.229, d_loss 0.108\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 108/390 d_loss_real= 0.034, d_loss_fake= 0.044, g_loss 3.225, d_loss 0.039\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 109/390 d_loss_real= 0.229, d_loss_fake= 0.045, g_loss 3.204, d_loss 0.137\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 110/390 d_loss_real= 0.178, d_loss_fake= 0.044, g_loss 3.202, d_loss 0.111\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 30 Batch 111/390 d_loss_real= 0.225, d_loss_fake= 0.048, g_loss 3.111, d_loss 0.136\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 30 Batch 112/390 d_loss_real= 0.085, d_loss_fake= 0.058, g_loss 3.015, d_loss 0.072\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 113/390 d_loss_real= 0.040, d_loss_fake= 0.055, g_loss 3.071, d_loss 0.048\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 114/390 d_loss_real= 0.093, d_loss_fake= 0.061, g_loss 3.001, d_loss 0.077\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 115/390 d_loss_real= 0.176, d_loss_fake= 0.053, g_loss 3.142, d_loss 0.114\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 116/390 d_loss_real= 0.217, d_loss_fake= 0.047, g_loss 3.179, d_loss 0.132\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 117/390 d_loss_real= 0.001, d_loss_fake= 0.044, g_loss 3.226, d_loss 0.023\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 118/390 d_loss_real= 0.230, d_loss_fake= 0.042, g_loss 3.344, d_loss 0.136\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 30 Batch 119/390 d_loss_real= 0.204, d_loss_fake= 0.037, g_loss 3.288, d_loss 0.120\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 120/390 d_loss_real= 0.126, d_loss_fake= 0.042, g_loss 3.265, d_loss 0.084\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 30 Batch 121/390 d_loss_real= 0.019, d_loss_fake= 0.043, g_loss 3.277, d_loss 0.031\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 122/390 d_loss_real= 0.227, d_loss_fake= 0.042, g_loss 3.308, d_loss 0.134\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 30 Batch 123/390 d_loss_real= 0.208, d_loss_fake= 0.041, g_loss 3.244, d_loss 0.125\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 124/390 d_loss_real= 0.162, d_loss_fake= 0.047, g_loss 3.170, d_loss 0.104\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 30 Batch 125/390 d_loss_real= 0.144, d_loss_fake= 0.057, g_loss 2.990, d_loss 0.100\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 126/390 d_loss_real= 0.099, d_loss_fake= 0.065, g_loss 2.943, d_loss 0.082\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 30 Batch 127/390 d_loss_real= 0.029, d_loss_fake= 0.087, g_loss 3.064, d_loss 0.058\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 128/390 d_loss_real= 0.092, d_loss_fake= 0.055, g_loss 3.344, d_loss 0.074\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 30 Batch 129/390 d_loss_real= 0.324, d_loss_fake= 0.032, g_loss 3.542, d_loss 0.178\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 130/390 d_loss_real= 0.151, d_loss_fake= 0.030, g_loss 3.620, d_loss 0.090\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 131/390 d_loss_real= 0.308, d_loss_fake= 0.033, g_loss 3.475, d_loss 0.170\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 132/390 d_loss_real= 0.484, d_loss_fake= 0.038, g_loss 3.178, d_loss 0.261\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 133/390 d_loss_real= 0.199, d_loss_fake= 0.084, g_loss 2.900, d_loss 0.141\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 134/390 d_loss_real= 0.125, d_loss_fake= 0.121, g_loss 2.819, d_loss 0.123\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 135/390 d_loss_real= 0.074, d_loss_fake= 0.070, g_loss 3.114, d_loss 0.072\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 136/390 d_loss_real= 0.258, d_loss_fake= 0.045, g_loss 3.310, d_loss 0.152\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 137/390 d_loss_real= 0.074, d_loss_fake= 0.038, g_loss 3.391, d_loss 0.056\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 30 Batch 138/390 d_loss_real= 0.202, d_loss_fake= 0.039, g_loss 3.393, d_loss 0.120\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 139/390 d_loss_real= 0.126, d_loss_fake= 0.039, g_loss 3.291, d_loss 0.082\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 30 Batch 140/390 d_loss_real= 0.020, d_loss_fake= 0.044, g_loss 3.235, d_loss 0.032\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 30 Batch 141/390 d_loss_real= 0.263, d_loss_fake= 0.051, g_loss 2.948, d_loss 0.157\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 142/390 d_loss_real= 0.010, d_loss_fake= 0.066, g_loss 2.841, d_loss 0.038\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 143/390 d_loss_real= 0.091, d_loss_fake= 0.084, g_loss 2.871, d_loss 0.087\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 144/390 d_loss_real= 0.266, d_loss_fake= 0.060, g_loss 3.176, d_loss 0.163\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 30 Batch 145/390 d_loss_real= 0.325, d_loss_fake= 0.047, g_loss 3.422, d_loss 0.186\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 146/390 d_loss_real= 0.271, d_loss_fake= 0.037, g_loss 3.565, d_loss 0.154\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 147/390 d_loss_real= 0.243, d_loss_fake= 0.028, g_loss 3.772, d_loss 0.136\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 148/390 d_loss_real= 0.314, d_loss_fake= 0.030, g_loss 3.645, d_loss 0.172\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 30 Batch 149/390 d_loss_real= 0.278, d_loss_fake= 0.033, g_loss 3.500, d_loss 0.155\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 150/390 d_loss_real= 0.165, d_loss_fake= 0.040, g_loss 3.303, d_loss 0.103\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 151/390 d_loss_real= 0.156, d_loss_fake= 0.045, g_loss 3.273, d_loss 0.101\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 30 Batch 152/390 d_loss_real= 0.262, d_loss_fake= 0.054, g_loss 3.079, d_loss 0.158\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 153/390 d_loss_real= 0.253, d_loss_fake= 0.060, g_loss 3.076, d_loss 0.156\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 154/390 d_loss_real= 0.164, d_loss_fake= 0.049, g_loss 3.207, d_loss 0.107\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 155/390 d_loss_real= 0.219, d_loss_fake= 0.049, g_loss 3.299, d_loss 0.134\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 156/390 d_loss_real= 0.233, d_loss_fake= 0.037, g_loss 3.584, d_loss 0.135\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 157/390 d_loss_real= 0.162, d_loss_fake= 0.042, g_loss 3.457, d_loss 0.102\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 158/390 d_loss_real= 0.273, d_loss_fake= 0.042, g_loss 3.349, d_loss 0.158\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 159/390 d_loss_real= 0.330, d_loss_fake= 0.056, g_loss 3.116, d_loss 0.193\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 160/390 d_loss_real= 0.254, d_loss_fake= 0.066, g_loss 3.147, d_loss 0.160\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 30 Batch 161/390 d_loss_real= 0.170, d_loss_fake= 0.066, g_loss 3.174, d_loss 0.118\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 162/390 d_loss_real= 0.160, d_loss_fake= 0.060, g_loss 3.547, d_loss 0.110\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 163/390 d_loss_real= 0.181, d_loss_fake= 0.051, g_loss 3.731, d_loss 0.116\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 30 Batch 164/390 d_loss_real= 0.193, d_loss_fake= 0.036, g_loss 3.589, d_loss 0.115\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 165/390 d_loss_real= 0.164, d_loss_fake= 0.048, g_loss 3.474, d_loss 0.106\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 166/390 d_loss_real= 0.283, d_loss_fake= 0.054, g_loss 3.451, d_loss 0.168\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 167/390 d_loss_real= 0.374, d_loss_fake= 0.052, g_loss 3.294, d_loss 0.213\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 168/390 d_loss_real= 0.161, d_loss_fake= 0.059, g_loss 3.175, d_loss 0.110\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 169/390 d_loss_real= 0.150, d_loss_fake= 0.048, g_loss 3.342, d_loss 0.099\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 30 Batch 170/390 d_loss_real= 0.194, d_loss_fake= 0.041, g_loss 3.391, d_loss 0.118\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 171/390 d_loss_real= 0.450, d_loss_fake= 0.048, g_loss 3.156, d_loss 0.249\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 30 Batch 172/390 d_loss_real= 0.172, d_loss_fake= 0.043, g_loss 3.129, d_loss 0.108\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 173/390 d_loss_real= 0.093, d_loss_fake= 0.060, g_loss 2.978, d_loss 0.076\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 30 Batch 174/390 d_loss_real= 0.139, d_loss_fake= 0.067, g_loss 2.850, d_loss 0.103\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 175/390 d_loss_real= 0.161, d_loss_fake= 0.073, g_loss 2.812, d_loss 0.117\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 176/390 d_loss_real= 0.099, d_loss_fake= 0.074, g_loss 2.842, d_loss 0.086\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 177/390 d_loss_real= 0.087, d_loss_fake= 0.066, g_loss 2.906, d_loss 0.077\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 30 Batch 178/390 d_loss_real= 0.026, d_loss_fake= 0.059, g_loss 3.017, d_loss 0.042\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 179/390 d_loss_real= 0.062, d_loss_fake= 0.054, g_loss 3.125, d_loss 0.058\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 30 Batch 180/390 d_loss_real= 0.201, d_loss_fake= 0.050, g_loss 3.135, d_loss 0.126\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 181/390 d_loss_real= 0.112, d_loss_fake= 0.053, g_loss 3.018, d_loss 0.083\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 30 Batch 182/390 d_loss_real= 0.001, d_loss_fake= 0.056, g_loss 3.074, d_loss 0.029\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 30 Batch 183/390 d_loss_real= 0.311, d_loss_fake= 0.056, g_loss 3.012, d_loss 0.184\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 184/390 d_loss_real= 0.093, d_loss_fake= 0.055, g_loss 2.958, d_loss 0.074\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 185/390 d_loss_real= 0.118, d_loss_fake= 0.059, g_loss 2.970, d_loss 0.089\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 30 Batch 186/390 d_loss_real= 0.212, d_loss_fake= 0.059, g_loss 3.031, d_loss 0.136\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 187/390 d_loss_real= 0.241, d_loss_fake= 0.062, g_loss 2.929, d_loss 0.152\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 188/390 d_loss_real= 0.109, d_loss_fake= 0.064, g_loss 2.886, d_loss 0.086\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 189/390 d_loss_real= 0.236, d_loss_fake= 0.073, g_loss 2.929, d_loss 0.154\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 190/390 d_loss_real= 0.070, d_loss_fake= 0.066, g_loss 2.964, d_loss 0.068\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 191/390 d_loss_real= 0.097, d_loss_fake= 0.056, g_loss 3.164, d_loss 0.076\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 192/390 d_loss_real= 0.271, d_loss_fake= 0.055, g_loss 3.102, d_loss 0.163\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 193/390 d_loss_real= 0.068, d_loss_fake= 0.060, g_loss 3.032, d_loss 0.064\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 194/390 d_loss_real= 0.152, d_loss_fake= 0.071, g_loss 3.008, d_loss 0.111\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 195/390 d_loss_real= 0.251, d_loss_fake= 0.077, g_loss 2.966, d_loss 0.164\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 196/390 d_loss_real= 0.126, d_loss_fake= 0.043, g_loss 3.417, d_loss 0.084\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 197/390 d_loss_real= 0.264, d_loss_fake= 0.052, g_loss 3.279, d_loss 0.158\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 198/390 d_loss_real= 0.320, d_loss_fake= 0.095, g_loss 2.626, d_loss 0.208\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 199/390 d_loss_real= 0.058, d_loss_fake= 0.099, g_loss 2.902, d_loss 0.078\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 200/390 d_loss_real= 0.207, d_loss_fake= 0.042, g_loss 3.550, d_loss 0.125\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 201/390 d_loss_real= 0.428, d_loss_fake= 0.026, g_loss 4.022, d_loss 0.227\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 202/390 d_loss_real= 0.136, d_loss_fake= 0.072, g_loss 2.831, d_loss 0.104\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 203/390 d_loss_real= 0.183, d_loss_fake= 0.074, g_loss 3.022, d_loss 0.129\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 204/390 d_loss_real= 0.070, d_loss_fake= 0.029, g_loss 3.882, d_loss 0.049\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 205/390 d_loss_real= 0.094, d_loss_fake= 0.058, g_loss 3.295, d_loss 0.076\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 206/390 d_loss_real= 0.235, d_loss_fake= 0.037, g_loss 3.659, d_loss 0.136\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 207/390 d_loss_real= 0.146, d_loss_fake= 0.028, g_loss 3.775, d_loss 0.087\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 30 Batch 208/390 d_loss_real= 0.067, d_loss_fake= 0.030, g_loss 3.783, d_loss 0.048\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 30 Batch 209/390 d_loss_real= 0.099, d_loss_fake= 0.028, g_loss 3.749, d_loss 0.064\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 210/390 d_loss_real= 0.113, d_loss_fake= 0.029, g_loss 3.636, d_loss 0.071\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 211/390 d_loss_real= 0.100, d_loss_fake= 0.030, g_loss 3.563, d_loss 0.065\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 212/390 d_loss_real= 0.058, d_loss_fake= 0.035, g_loss 3.532, d_loss 0.047\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 213/390 d_loss_real= 0.198, d_loss_fake= 0.041, g_loss 3.447, d_loss 0.119\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 214/390 d_loss_real= 0.052, d_loss_fake= 0.056, g_loss 3.399, d_loss 0.054\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 30 Batch 215/390 d_loss_real= 0.062, d_loss_fake= 0.041, g_loss 3.629, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 216/390 d_loss_real= 0.109, d_loss_fake= 0.027, g_loss 3.865, d_loss 0.068\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 30 Batch 217/390 d_loss_real= 0.132, d_loss_fake= 0.025, g_loss 3.958, d_loss 0.079\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 218/390 d_loss_real= 0.157, d_loss_fake= 0.024, g_loss 3.859, d_loss 0.091\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 30 Batch 219/390 d_loss_real= 0.184, d_loss_fake= 0.026, g_loss 3.651, d_loss 0.105\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 30 Batch 220/390 d_loss_real= 0.225, d_loss_fake= 0.038, g_loss 3.339, d_loss 0.131\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 221/390 d_loss_real= 0.202, d_loss_fake= 0.046, g_loss 3.339, d_loss 0.124\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 30 Batch 222/390 d_loss_real= 0.112, d_loss_fake= 0.043, g_loss 3.403, d_loss 0.077\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 223/390 d_loss_real= 0.167, d_loss_fake= 0.045, g_loss 3.362, d_loss 0.106\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 30 Batch 224/390 d_loss_real= 0.176, d_loss_fake= 0.041, g_loss 3.400, d_loss 0.108\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 225/390 d_loss_real= 0.105, d_loss_fake= 0.045, g_loss 3.288, d_loss 0.075\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 226/390 d_loss_real= 0.128, d_loss_fake= 0.043, g_loss 3.291, d_loss 0.086\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 227/390 d_loss_real= 0.245, d_loss_fake= 0.045, g_loss 3.259, d_loss 0.145\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 30 Batch 228/390 d_loss_real= 0.164, d_loss_fake= 0.054, g_loss 3.233, d_loss 0.109\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 229/390 d_loss_real= 0.357, d_loss_fake= 0.063, g_loss 3.031, d_loss 0.210\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 230/390 d_loss_real= 0.058, d_loss_fake= 0.069, g_loss 3.158, d_loss 0.064\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 231/390 d_loss_real= 0.416, d_loss_fake= 0.050, g_loss 3.228, d_loss 0.233\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 232/390 d_loss_real= 0.135, d_loss_fake= 0.049, g_loss 3.199, d_loss 0.092\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 233/390 d_loss_real= 0.157, d_loss_fake= 0.047, g_loss 3.174, d_loss 0.102\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 234/390 d_loss_real= 0.270, d_loss_fake= 0.050, g_loss 3.064, d_loss 0.160\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 235/390 d_loss_real= 0.007, d_loss_fake= 0.056, g_loss 3.013, d_loss 0.032\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 30 Batch 236/390 d_loss_real= 0.247, d_loss_fake= 0.058, g_loss 2.900, d_loss 0.153\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 237/390 d_loss_real= 0.243, d_loss_fake= 0.067, g_loss 2.731, d_loss 0.155\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 238/390 d_loss_real= 0.180, d_loss_fake= 0.099, g_loss 2.632, d_loss 0.140\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 239/390 d_loss_real= 0.173, d_loss_fake= 0.086, g_loss 2.674, d_loss 0.130\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 30 Batch 240/390 d_loss_real= 0.195, d_loss_fake= 0.077, g_loss 2.820, d_loss 0.136\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 30 Batch 241/390 d_loss_real= 0.190, d_loss_fake= 0.062, g_loss 2.962, d_loss 0.126\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 242/390 d_loss_real= 0.139, d_loss_fake= 0.056, g_loss 3.066, d_loss 0.097\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 243/390 d_loss_real= 0.212, d_loss_fake= 0.049, g_loss 3.082, d_loss 0.131\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 244/390 d_loss_real= 0.225, d_loss_fake= 0.051, g_loss 3.036, d_loss 0.138\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 30 Batch 245/390 d_loss_real= 0.177, d_loss_fake= 0.056, g_loss 2.914, d_loss 0.117\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 246/390 d_loss_real= 0.169, d_loss_fake= 0.065, g_loss 2.789, d_loss 0.117\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 247/390 d_loss_real= 0.165, d_loss_fake= 0.073, g_loss 2.722, d_loss 0.119\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 248/390 d_loss_real= 0.143, d_loss_fake= 0.074, g_loss 2.764, d_loss 0.108\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 249/390 d_loss_real= 0.148, d_loss_fake= 0.072, g_loss 2.772, d_loss 0.110\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 250/390 d_loss_real= 0.067, d_loss_fake= 0.065, g_loss 2.921, d_loss 0.066\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 251/390 d_loss_real= 0.063, d_loss_fake= 0.059, g_loss 2.978, d_loss 0.061\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 252/390 d_loss_real= 0.077, d_loss_fake= 0.055, g_loss 3.037, d_loss 0.066\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 253/390 d_loss_real= 0.107, d_loss_fake= 0.049, g_loss 3.113, d_loss 0.078\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 30 Batch 254/390 d_loss_real= 0.179, d_loss_fake= 0.047, g_loss 3.157, d_loss 0.113\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 30 Batch 255/390 d_loss_real= 0.145, d_loss_fake= 0.047, g_loss 3.236, d_loss 0.096\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 256/390 d_loss_real= 0.117, d_loss_fake= 0.044, g_loss 3.201, d_loss 0.081\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 30 Batch 257/390 d_loss_real= 0.143, d_loss_fake= 0.045, g_loss 3.143, d_loss 0.094\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 258/390 d_loss_real= 0.171, d_loss_fake= 0.052, g_loss 3.013, d_loss 0.112\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 259/390 d_loss_real= 0.158, d_loss_fake= 0.058, g_loss 2.942, d_loss 0.108\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 260/390 d_loss_real= 0.153, d_loss_fake= 0.062, g_loss 2.874, d_loss 0.107\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 261/390 d_loss_real= 0.149, d_loss_fake= 0.085, g_loss 2.804, d_loss 0.117\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 262/390 d_loss_real= 0.212, d_loss_fake= 0.073, g_loss 2.965, d_loss 0.143\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 30 Batch 263/390 d_loss_real= 0.188, d_loss_fake= 0.063, g_loss 3.046, d_loss 0.125\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 30 Batch 264/390 d_loss_real= 0.086, d_loss_fake= 0.056, g_loss 3.197, d_loss 0.071\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 265/390 d_loss_real= 0.054, d_loss_fake= 0.043, g_loss 3.402, d_loss 0.048\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 30 Batch 266/390 d_loss_real= 0.197, d_loss_fake= 0.036, g_loss 3.491, d_loss 0.116\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 30 Batch 267/390 d_loss_real= 0.184, d_loss_fake= 0.034, g_loss 3.458, d_loss 0.109\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 30 Batch 268/390 d_loss_real= 0.150, d_loss_fake= 0.034, g_loss 3.377, d_loss 0.092\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 269/390 d_loss_real= 0.167, d_loss_fake= 0.039, g_loss 3.311, d_loss 0.103\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 270/390 d_loss_real= 0.238, d_loss_fake= 0.045, g_loss 3.105, d_loss 0.142\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 271/390 d_loss_real= 0.065, d_loss_fake= 0.057, g_loss 2.953, d_loss 0.061\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 272/390 d_loss_real= 0.148, d_loss_fake= 0.070, g_loss 2.945, d_loss 0.109\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 273/390 d_loss_real= 0.139, d_loss_fake= 0.057, g_loss 2.962, d_loss 0.098\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 30 Batch 274/390 d_loss_real= 0.211, d_loss_fake= 0.062, g_loss 2.870, d_loss 0.137\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 30 Batch 275/390 d_loss_real= 0.125, d_loss_fake= 0.067, g_loss 2.928, d_loss 0.096\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 30 Batch 276/390 d_loss_real= 0.117, d_loss_fake= 0.078, g_loss 2.930, d_loss 0.098\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 277/390 d_loss_real= 0.088, d_loss_fake= 0.057, g_loss 3.118, d_loss 0.073\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 30 Batch 278/390 d_loss_real= 0.097, d_loss_fake= 0.045, g_loss 3.246, d_loss 0.071\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 279/390 d_loss_real= 0.076, d_loss_fake= 0.042, g_loss 3.326, d_loss 0.059\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 30 Batch 280/390 d_loss_real= 0.193, d_loss_fake= 0.040, g_loss 3.301, d_loss 0.116\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 281/390 d_loss_real= 0.058, d_loss_fake= 0.040, g_loss 3.250, d_loss 0.049\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 30 Batch 282/390 d_loss_real= 0.108, d_loss_fake= 0.043, g_loss 3.188, d_loss 0.075\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 30 Batch 283/390 d_loss_real= 0.103, d_loss_fake= 0.048, g_loss 3.059, d_loss 0.075\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 284/390 d_loss_real= 0.075, d_loss_fake= 0.053, g_loss 2.979, d_loss 0.064\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 30 Batch 285/390 d_loss_real= 0.177, d_loss_fake= 0.060, g_loss 2.887, d_loss 0.118\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 286/390 d_loss_real= 0.133, d_loss_fake= 0.066, g_loss 2.732, d_loss 0.100\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 30 Batch 287/390 d_loss_real= 0.150, d_loss_fake= 0.076, g_loss 2.781, d_loss 0.113\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 288/390 d_loss_real= 0.043, d_loss_fake= 0.068, g_loss 2.927, d_loss 0.055\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 289/390 d_loss_real= 0.172, d_loss_fake= 0.054, g_loss 3.101, d_loss 0.113\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 30 Batch 290/390 d_loss_real= 0.128, d_loss_fake= 0.047, g_loss 3.182, d_loss 0.087\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 30 Batch 291/390 d_loss_real= 0.129, d_loss_fake= 0.045, g_loss 3.233, d_loss 0.087\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 292/390 d_loss_real= 0.114, d_loss_fake= 0.048, g_loss 3.198, d_loss 0.081\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 293/390 d_loss_real= 0.044, d_loss_fake= 0.049, g_loss 3.196, d_loss 0.046\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 30 Batch 294/390 d_loss_real= 0.109, d_loss_fake= 0.048, g_loss 3.068, d_loss 0.078\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 295/390 d_loss_real= 0.124, d_loss_fake= 0.059, g_loss 3.027, d_loss 0.092\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 30 Batch 296/390 d_loss_real= 0.168, d_loss_fake= 0.062, g_loss 2.921, d_loss 0.115\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 297/390 d_loss_real= 0.051, d_loss_fake= 0.067, g_loss 2.904, d_loss 0.059\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 30 Batch 298/390 d_loss_real= 0.196, d_loss_fake= 0.068, g_loss 2.847, d_loss 0.132\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 30 Batch 299/390 d_loss_real= 0.018, d_loss_fake= 0.075, g_loss 2.807, d_loss 0.046\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 30 Batch 300/390 d_loss_real= 0.054, d_loss_fake= 0.078, g_loss 2.723, d_loss 0.066\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 30 Batch 301/390 d_loss_real= 0.144, d_loss_fake= 0.079, g_loss 2.729, d_loss 0.112\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 30 Batch 302/390 d_loss_real= 0.066, d_loss_fake= 0.084, g_loss 2.831, d_loss 0.075\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 303/390 d_loss_real= 0.203, d_loss_fake= 0.073, g_loss 2.740, d_loss 0.138\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 30 Batch 304/390 d_loss_real= 0.200, d_loss_fake= 0.081, g_loss 2.768, d_loss 0.141\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 30 Batch 305/390 d_loss_real= 0.156, d_loss_fake= 0.078, g_loss 2.765, d_loss 0.117\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 30 Batch 306/390 d_loss_real= 0.304, d_loss_fake= 0.073, g_loss 2.889, d_loss 0.188\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 307/390 d_loss_real= 0.048, d_loss_fake= 0.064, g_loss 2.951, d_loss 0.056\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 308/390 d_loss_real= 0.071, d_loss_fake= 0.061, g_loss 2.937, d_loss 0.066\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 30 Batch 309/390 d_loss_real= 0.191, d_loss_fake= 0.068, g_loss 2.876, d_loss 0.129\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 310/390 d_loss_real= 0.139, d_loss_fake= 0.071, g_loss 2.786, d_loss 0.105\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 311/390 d_loss_real= 0.011, d_loss_fake= 0.070, g_loss 2.700, d_loss 0.040\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 30 Batch 312/390 d_loss_real= 0.086, d_loss_fake= 0.072, g_loss 2.694, d_loss 0.079\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 313/390 d_loss_real= 0.065, d_loss_fake= 0.076, g_loss 2.629, d_loss 0.071\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 314/390 d_loss_real= 0.069, d_loss_fake= 0.087, g_loss 2.564, d_loss 0.078\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 30 Batch 315/390 d_loss_real= 0.177, d_loss_fake= 0.095, g_loss 2.474, d_loss 0.136\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 30 Batch 316/390 d_loss_real= 0.040, d_loss_fake= 0.099, g_loss 2.475, d_loss 0.069\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 317/390 d_loss_real= 0.162, d_loss_fake= 0.102, g_loss 2.467, d_loss 0.132\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 318/390 d_loss_real= 0.248, d_loss_fake= 0.103, g_loss 2.502, d_loss 0.176\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 30 Batch 319/390 d_loss_real= 0.049, d_loss_fake= 0.097, g_loss 2.546, d_loss 0.073\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 320/390 d_loss_real= 0.271, d_loss_fake= 0.097, g_loss 2.549, d_loss 0.184\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 30 Batch 321/390 d_loss_real= 0.232, d_loss_fake= 0.092, g_loss 2.526, d_loss 0.162\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 322/390 d_loss_real= 0.124, d_loss_fake= 0.095, g_loss 2.502, d_loss 0.110\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 30 Batch 323/390 d_loss_real= 0.093, d_loss_fake= 0.096, g_loss 2.581, d_loss 0.095\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 324/390 d_loss_real= 0.229, d_loss_fake= 0.089, g_loss 2.538, d_loss 0.159\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 325/390 d_loss_real= 0.186, d_loss_fake= 0.092, g_loss 2.583, d_loss 0.139\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 326/390 d_loss_real= 0.164, d_loss_fake= 0.088, g_loss 2.656, d_loss 0.126\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 327/390 d_loss_real= 0.294, d_loss_fake= 0.081, g_loss 2.687, d_loss 0.188\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 328/390 d_loss_real= 0.288, d_loss_fake= 0.091, g_loss 2.522, d_loss 0.190\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 30 Batch 329/390 d_loss_real= 0.195, d_loss_fake= 0.088, g_loss 2.557, d_loss 0.142\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 330/390 d_loss_real= 0.285, d_loss_fake= 0.122, g_loss 2.512, d_loss 0.203\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 30 Batch 331/390 d_loss_real= 0.279, d_loss_fake= 0.127, g_loss 2.444, d_loss 0.203\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 332/390 d_loss_real= 0.174, d_loss_fake= 0.100, g_loss 2.689, d_loss 0.137\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 333/390 d_loss_real= 0.156, d_loss_fake= 0.084, g_loss 2.822, d_loss 0.120\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 334/390 d_loss_real= 0.133, d_loss_fake= 0.058, g_loss 3.049, d_loss 0.095\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 335/390 d_loss_real= 0.140, d_loss_fake= 0.051, g_loss 3.219, d_loss 0.096\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 336/390 d_loss_real= 0.104, d_loss_fake= 0.041, g_loss 3.286, d_loss 0.073\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 337/390 d_loss_real= 0.451, d_loss_fake= 0.043, g_loss 3.191, d_loss 0.247\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 338/390 d_loss_real= 0.144, d_loss_fake= 0.047, g_loss 3.033, d_loss 0.096\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 339/390 d_loss_real= 0.192, d_loss_fake= 0.050, g_loss 3.064, d_loss 0.121\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 340/390 d_loss_real= 0.027, d_loss_fake= 0.053, g_loss 2.968, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 341/390 d_loss_real= 0.095, d_loss_fake= 0.063, g_loss 2.920, d_loss 0.079\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 30 Batch 342/390 d_loss_real= 0.241, d_loss_fake= 0.065, g_loss 2.794, d_loss 0.153\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 343/390 d_loss_real= 0.144, d_loss_fake= 0.083, g_loss 2.836, d_loss 0.114\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 30 Batch 344/390 d_loss_real= 0.177, d_loss_fake= 0.069, g_loss 2.894, d_loss 0.123\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 30 Batch 345/390 d_loss_real= 0.359, d_loss_fake= 0.072, g_loss 2.814, d_loss 0.216\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 346/390 d_loss_real= 0.233, d_loss_fake= 0.062, g_loss 3.101, d_loss 0.148\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 347/390 d_loss_real= 0.235, d_loss_fake= 0.053, g_loss 3.072, d_loss 0.144\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 348/390 d_loss_real= 0.304, d_loss_fake= 0.052, g_loss 3.033, d_loss 0.178\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 349/390 d_loss_real= 0.296, d_loss_fake= 0.058, g_loss 2.951, d_loss 0.177\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30 Batch 350/390 d_loss_real= 0.211, d_loss_fake= 0.067, g_loss 2.893, d_loss 0.139\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 351/390 d_loss_real= 0.072, d_loss_fake= 0.069, g_loss 2.846, d_loss 0.070\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 352/390 d_loss_real= 0.141, d_loss_fake= 0.075, g_loss 2.821, d_loss 0.108\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 353/390 d_loss_real= 0.125, d_loss_fake= 0.084, g_loss 2.843, d_loss 0.104\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 354/390 d_loss_real= 0.460, d_loss_fake= 0.114, g_loss 2.664, d_loss 0.287\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 355/390 d_loss_real= 0.192, d_loss_fake= 0.111, g_loss 2.747, d_loss 0.152\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 356/390 d_loss_real= 0.289, d_loss_fake= 0.083, g_loss 2.828, d_loss 0.186\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 30 Batch 357/390 d_loss_real= 0.092, d_loss_fake= 0.063, g_loss 3.109, d_loss 0.077\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 30 Batch 358/390 d_loss_real= 0.536, d_loss_fake= 0.057, g_loss 3.003, d_loss 0.297\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 359/390 d_loss_real= 0.113, d_loss_fake= 0.064, g_loss 2.959, d_loss 0.088\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 360/390 d_loss_real= 0.232, d_loss_fake= 0.074, g_loss 2.697, d_loss 0.153\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 361/390 d_loss_real= 0.076, d_loss_fake= 0.083, g_loss 2.783, d_loss 0.079\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 362/390 d_loss_real= 0.210, d_loss_fake= 0.076, g_loss 2.860, d_loss 0.143\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 363/390 d_loss_real= 0.134, d_loss_fake= 0.048, g_loss 3.251, d_loss 0.091\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 364/390 d_loss_real= 0.088, d_loss_fake= 0.064, g_loss 3.285, d_loss 0.076\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 365/390 d_loss_real= 0.245, d_loss_fake= 0.035, g_loss 3.715, d_loss 0.140\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 30 Batch 366/390 d_loss_real= 0.160, d_loss_fake= 0.027, g_loss 3.914, d_loss 0.093\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 367/390 d_loss_real= 0.283, d_loss_fake= 0.031, g_loss 3.789, d_loss 0.157\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 368/390 d_loss_real= 0.081, d_loss_fake= 0.039, g_loss 3.810, d_loss 0.060\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 369/390 d_loss_real= 0.085, d_loss_fake= 0.026, g_loss 4.182, d_loss 0.056\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 370/390 d_loss_real= 0.256, d_loss_fake= 0.018, g_loss 4.235, d_loss 0.137\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 371/390 d_loss_real= 0.553, d_loss_fake= 0.019, g_loss 3.974, d_loss 0.286\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 372/390 d_loss_real= 0.195, d_loss_fake= 0.032, g_loss 3.832, d_loss 0.114\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 373/390 d_loss_real= 0.203, d_loss_fake= 0.022, g_loss 3.943, d_loss 0.113\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 374/390 d_loss_real= 0.259, d_loss_fake= 0.029, g_loss 3.548, d_loss 0.144\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 375/390 d_loss_real= 0.420, d_loss_fake= 0.031, g_loss 3.610, d_loss 0.225\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 376/390 d_loss_real= 0.168, d_loss_fake= 0.064, g_loss 3.435, d_loss 0.116\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 377/390 d_loss_real= 0.133, d_loss_fake= 0.028, g_loss 4.031, d_loss 0.081\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 30 Batch 378/390 d_loss_real= 0.165, d_loss_fake= 0.018, g_loss 4.157, d_loss 0.091\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30 Batch 379/390 d_loss_real= 0.116, d_loss_fake= 0.018, g_loss 4.209, d_loss 0.067\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 30 Batch 380/390 d_loss_real= 0.207, d_loss_fake= 0.016, g_loss 4.112, d_loss 0.111\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 30 Batch 381/390 d_loss_real= 0.164, d_loss_fake= 0.020, g_loss 3.975, d_loss 0.092\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 382/390 d_loss_real= 0.162, d_loss_fake= 0.024, g_loss 3.762, d_loss 0.093\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 383/390 d_loss_real= 0.335, d_loss_fake= 0.031, g_loss 3.381, d_loss 0.183\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 384/390 d_loss_real= 0.075, d_loss_fake= 0.053, g_loss 3.157, d_loss 0.064\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 385/390 d_loss_real= 0.132, d_loss_fake= 0.075, g_loss 3.140, d_loss 0.104\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30 Batch 386/390 d_loss_real= 0.212, d_loss_fake= 0.065, g_loss 3.313, d_loss 0.138\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30 Batch 387/390 d_loss_real= 0.208, d_loss_fake= 0.031, g_loss 3.706, d_loss 0.120\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 30 Batch 388/390 d_loss_real= 0.212, d_loss_fake= 0.026, g_loss 3.772, d_loss 0.119\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30 Batch 389/390 d_loss_real= 0.355, d_loss_fake= 0.027, g_loss 3.746, d_loss 0.191\n",
            "2/2 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30 Batch 390/390 d_loss_real= 0.183, d_loss_fake= 0.028, g_loss 3.589, d_loss 0.106\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 31 Batch 1/390 d_loss_real= 0.144, d_loss_fake= 0.035, g_loss 3.395, d_loss 0.089\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 2/390 d_loss_real= 0.149, d_loss_fake= 0.047, g_loss 3.064, d_loss 0.098\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 3/390 d_loss_real= 0.171, d_loss_fake= 0.067, g_loss 2.926, d_loss 0.119\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 31 Batch 4/390 d_loss_real= 0.257, d_loss_fake= 0.067, g_loss 3.229, d_loss 0.162\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 31 Batch 5/390 d_loss_real= 0.222, d_loss_fake= 0.044, g_loss 3.479, d_loss 0.133\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 6/390 d_loss_real= 0.185, d_loss_fake= 0.034, g_loss 3.601, d_loss 0.109\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 7/390 d_loss_real= 0.137, d_loss_fake= 0.033, g_loss 3.543, d_loss 0.085\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 8/390 d_loss_real= 0.122, d_loss_fake= 0.034, g_loss 3.401, d_loss 0.078\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 9/390 d_loss_real= 0.247, d_loss_fake= 0.042, g_loss 3.279, d_loss 0.144\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 31 Batch 10/390 d_loss_real= 0.122, d_loss_fake= 0.058, g_loss 2.902, d_loss 0.090\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 31 Batch 11/390 d_loss_real= 0.112, d_loss_fake= 0.086, g_loss 2.793, d_loss 0.099\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 31 Batch 12/390 d_loss_real= 0.050, d_loss_fake= 0.067, g_loss 3.270, d_loss 0.059\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 13/390 d_loss_real= 0.081, d_loss_fake= 0.038, g_loss 3.633, d_loss 0.059\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 31 Batch 14/390 d_loss_real= 0.095, d_loss_fake= 0.027, g_loss 3.762, d_loss 0.061\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 31 Batch 15/390 d_loss_real= 0.083, d_loss_fake= 0.024, g_loss 3.884, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 16/390 d_loss_real= 0.159, d_loss_fake= 0.023, g_loss 3.898, d_loss 0.091\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 17/390 d_loss_real= 0.125, d_loss_fake= 0.024, g_loss 3.785, d_loss 0.074\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 18/390 d_loss_real= 0.036, d_loss_fake= 0.029, g_loss 3.575, d_loss 0.032\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 31 Batch 19/390 d_loss_real= 0.174, d_loss_fake= 0.041, g_loss 3.291, d_loss 0.107\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 20/390 d_loss_real= 0.157, d_loss_fake= 0.078, g_loss 3.081, d_loss 0.117\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 31 Batch 21/390 d_loss_real= 0.099, d_loss_fake= 0.053, g_loss 3.398, d_loss 0.076\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 22/390 d_loss_real= 0.099, d_loss_fake= 0.039, g_loss 3.555, d_loss 0.069\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 31 Batch 23/390 d_loss_real= 0.153, d_loss_fake= 0.024, g_loss 3.904, d_loss 0.088\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 31 Batch 24/390 d_loss_real= 0.306, d_loss_fake= 0.031, g_loss 3.676, d_loss 0.168\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 25/390 d_loss_real= 0.135, d_loss_fake= 0.035, g_loss 3.562, d_loss 0.085\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 31 Batch 26/390 d_loss_real= 0.191, d_loss_fake= 0.045, g_loss 3.479, d_loss 0.118\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 27/390 d_loss_real= 0.197, d_loss_fake= 0.035, g_loss 3.562, d_loss 0.116\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 28/390 d_loss_real= 0.305, d_loss_fake= 0.039, g_loss 3.363, d_loss 0.172\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 29/390 d_loss_real= 0.093, d_loss_fake= 0.045, g_loss 3.150, d_loss 0.069\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 30/390 d_loss_real= 0.210, d_loss_fake= 0.068, g_loss 2.953, d_loss 0.139\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 31/390 d_loss_real= 0.121, d_loss_fake= 0.080, g_loss 2.899, d_loss 0.101\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 31 Batch 32/390 d_loss_real= 0.146, d_loss_fake= 0.069, g_loss 3.113, d_loss 0.108\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 31 Batch 33/390 d_loss_real= 0.147, d_loss_fake= 0.053, g_loss 3.250, d_loss 0.100\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 34/390 d_loss_real= 0.203, d_loss_fake= 0.041, g_loss 3.401, d_loss 0.122\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 35/390 d_loss_real= 0.206, d_loss_fake= 0.036, g_loss 3.432, d_loss 0.121\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 31 Batch 36/390 d_loss_real= 0.067, d_loss_fake= 0.038, g_loss 3.399, d_loss 0.052\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 37/390 d_loss_real= 0.177, d_loss_fake= 0.040, g_loss 3.243, d_loss 0.108\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 38/390 d_loss_real= 0.169, d_loss_fake= 0.047, g_loss 3.083, d_loss 0.108\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 39/390 d_loss_real= 0.222, d_loss_fake= 0.057, g_loss 2.879, d_loss 0.139\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 31 Batch 40/390 d_loss_real= 0.141, d_loss_fake= 0.072, g_loss 2.727, d_loss 0.106\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 41/390 d_loss_real= 0.098, d_loss_fake= 0.079, g_loss 2.609, d_loss 0.089\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 31 Batch 42/390 d_loss_real= 0.065, d_loss_fake= 0.089, g_loss 2.562, d_loss 0.077\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 31 Batch 43/390 d_loss_real= 0.075, d_loss_fake= 0.089, g_loss 2.674, d_loss 0.082\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 31 Batch 44/390 d_loss_real= 0.107, d_loss_fake= 0.070, g_loss 2.896, d_loss 0.089\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 31 Batch 45/390 d_loss_real= 0.197, d_loss_fake= 0.060, g_loss 2.987, d_loss 0.129\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 31 Batch 46/390 d_loss_real= 0.194, d_loss_fake= 0.054, g_loss 3.067, d_loss 0.124\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 47/390 d_loss_real= 0.233, d_loss_fake= 0.056, g_loss 2.919, d_loss 0.144\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 48/390 d_loss_real= 0.037, d_loss_fake= 0.061, g_loss 2.849, d_loss 0.049\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 31 Batch 49/390 d_loss_real= 0.207, d_loss_fake= 0.067, g_loss 2.796, d_loss 0.137\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 31 Batch 50/390 d_loss_real= 0.207, d_loss_fake= 0.073, g_loss 2.671, d_loss 0.140\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 31 Batch 51/390 d_loss_real= 0.318, d_loss_fake= 0.093, g_loss 2.466, d_loss 0.206\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 31 Batch 52/390 d_loss_real= 0.047, d_loss_fake= 0.104, g_loss 2.623, d_loss 0.075\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 53/390 d_loss_real= 0.113, d_loss_fake= 0.074, g_loss 2.858, d_loss 0.093\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 31 Batch 54/390 d_loss_real= 0.083, d_loss_fake= 0.056, g_loss 3.109, d_loss 0.069\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 55/390 d_loss_real= 0.176, d_loss_fake= 0.048, g_loss 3.121, d_loss 0.112\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 56/390 d_loss_real= 0.130, d_loss_fake= 0.048, g_loss 3.131, d_loss 0.089\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 57/390 d_loss_real= 0.093, d_loss_fake= 0.046, g_loss 3.169, d_loss 0.069\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 31 Batch 58/390 d_loss_real= 0.082, d_loss_fake= 0.051, g_loss 3.102, d_loss 0.066\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 59/390 d_loss_real= 0.135, d_loss_fake= 0.052, g_loss 3.016, d_loss 0.093\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 31 Batch 60/390 d_loss_real= 0.293, d_loss_fake= 0.059, g_loss 2.910, d_loss 0.176\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 61/390 d_loss_real= 0.086, d_loss_fake= 0.069, g_loss 2.719, d_loss 0.077\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 62/390 d_loss_real= 0.145, d_loss_fake= 0.083, g_loss 2.654, d_loss 0.114\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 31 Batch 63/390 d_loss_real= 0.135, d_loss_fake= 0.091, g_loss 2.593, d_loss 0.113\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 64/390 d_loss_real= 0.049, d_loss_fake= 0.095, g_loss 2.719, d_loss 0.072\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 65/390 d_loss_real= 0.096, d_loss_fake= 0.072, g_loss 2.909, d_loss 0.084\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 66/390 d_loss_real= 0.076, d_loss_fake= 0.056, g_loss 3.028, d_loss 0.066\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 31 Batch 67/390 d_loss_real= 0.146, d_loss_fake= 0.051, g_loss 3.251, d_loss 0.099\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 68/390 d_loss_real= 0.083, d_loss_fake= 0.046, g_loss 3.262, d_loss 0.065\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 31 Batch 69/390 d_loss_real= 0.094, d_loss_fake= 0.058, g_loss 3.292, d_loss 0.076\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 31 Batch 70/390 d_loss_real= 0.160, d_loss_fake= 0.052, g_loss 3.138, d_loss 0.106\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 71/390 d_loss_real= 0.112, d_loss_fake= 0.057, g_loss 3.052, d_loss 0.084\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 72/390 d_loss_real= 0.248, d_loss_fake= 0.075, g_loss 2.864, d_loss 0.162\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 31 Batch 73/390 d_loss_real= 0.093, d_loss_fake= 0.076, g_loss 2.713, d_loss 0.084\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 74/390 d_loss_real= 0.068, d_loss_fake= 0.081, g_loss 2.587, d_loss 0.074\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 31 Batch 75/390 d_loss_real= 0.160, d_loss_fake= 0.090, g_loss 2.514, d_loss 0.125\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 76/390 d_loss_real= 0.231, d_loss_fake= 0.102, g_loss 2.421, d_loss 0.166\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 77/390 d_loss_real= 0.095, d_loss_fake= 0.124, g_loss 2.270, d_loss 0.109\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 31 Batch 78/390 d_loss_real= 0.121, d_loss_fake= 0.156, g_loss 2.239, d_loss 0.139\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 79/390 d_loss_real= 0.046, d_loss_fake= 0.142, g_loss 2.337, d_loss 0.094\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 80/390 d_loss_real= 0.095, d_loss_fake= 0.095, g_loss 2.556, d_loss 0.095\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 31 Batch 81/390 d_loss_real= 0.206, d_loss_fake= 0.078, g_loss 2.796, d_loss 0.142\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 31 Batch 82/390 d_loss_real= 0.038, d_loss_fake= 0.066, g_loss 2.893, d_loss 0.052\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 31 Batch 83/390 d_loss_real= 0.172, d_loss_fake= 0.066, g_loss 2.925, d_loss 0.119\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 31 Batch 84/390 d_loss_real= 0.138, d_loss_fake= 0.061, g_loss 3.017, d_loss 0.099\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 85/390 d_loss_real= 0.072, d_loss_fake= 0.066, g_loss 3.070, d_loss 0.069\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 86/390 d_loss_real= 0.212, d_loss_fake= 0.058, g_loss 2.992, d_loss 0.135\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 31 Batch 87/390 d_loss_real= 0.192, d_loss_fake= 0.062, g_loss 2.950, d_loss 0.127\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 31 Batch 88/390 d_loss_real= 0.097, d_loss_fake= 0.068, g_loss 2.818, d_loss 0.082\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 89/390 d_loss_real= 0.322, d_loss_fake= 0.064, g_loss 2.821, d_loss 0.193\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 31 Batch 90/390 d_loss_real= 0.322, d_loss_fake= 0.078, g_loss 2.508, d_loss 0.200\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 31 Batch 91/390 d_loss_real= 0.012, d_loss_fake= 0.131, g_loss 2.396, d_loss 0.071\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 31 Batch 92/390 d_loss_real= 0.100, d_loss_fake= 0.117, g_loss 2.493, d_loss 0.109\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 93/390 d_loss_real= 0.068, d_loss_fake= 0.081, g_loss 2.737, d_loss 0.074\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 31 Batch 94/390 d_loss_real= 0.244, d_loss_fake= 0.060, g_loss 2.997, d_loss 0.152\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 31 Batch 95/390 d_loss_real= 0.111, d_loss_fake= 0.049, g_loss 3.166, d_loss 0.080\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 31 Batch 96/390 d_loss_real= 0.183, d_loss_fake= 0.049, g_loss 3.134, d_loss 0.116\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 97/390 d_loss_real= 0.144, d_loss_fake= 0.047, g_loss 3.165, d_loss 0.095\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 98/390 d_loss_real= 0.141, d_loss_fake= 0.053, g_loss 2.909, d_loss 0.097\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 99/390 d_loss_real= 0.183, d_loss_fake= 0.074, g_loss 2.732, d_loss 0.129\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 100/390 d_loss_real= 0.102, d_loss_fake= 0.115, g_loss 2.774, d_loss 0.108\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 101/390 d_loss_real= 0.178, d_loss_fake= 0.075, g_loss 2.934, d_loss 0.126\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 31 Batch 102/390 d_loss_real= 0.178, d_loss_fake= 0.064, g_loss 3.062, d_loss 0.121\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 103/390 d_loss_real= 0.077, d_loss_fake= 0.051, g_loss 3.215, d_loss 0.064\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 31 Batch 104/390 d_loss_real= 0.068, d_loss_fake= 0.046, g_loss 3.243, d_loss 0.057\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 105/390 d_loss_real= 0.186, d_loss_fake= 0.045, g_loss 3.153, d_loss 0.115\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 106/390 d_loss_real= 0.272, d_loss_fake= 0.052, g_loss 3.002, d_loss 0.162\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 31 Batch 107/390 d_loss_real= 0.100, d_loss_fake= 0.072, g_loss 2.772, d_loss 0.086\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 108/390 d_loss_real= 0.084, d_loss_fake= 0.100, g_loss 2.707, d_loss 0.092\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 109/390 d_loss_real= 0.123, d_loss_fake= 0.079, g_loss 2.854, d_loss 0.101\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 31 Batch 110/390 d_loss_real= 0.278, d_loss_fake= 0.068, g_loss 2.995, d_loss 0.173\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 31 Batch 111/390 d_loss_real= 0.305, d_loss_fake= 0.053, g_loss 3.138, d_loss 0.179\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 31 Batch 112/390 d_loss_real= 0.164, d_loss_fake= 0.053, g_loss 3.191, d_loss 0.108\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 31 Batch 113/390 d_loss_real= 0.162, d_loss_fake= 0.046, g_loss 3.090, d_loss 0.104\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 31 Batch 114/390 d_loss_real= 0.154, d_loss_fake= 0.057, g_loss 3.110, d_loss 0.105\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 31 Batch 115/390 d_loss_real= 0.089, d_loss_fake= 0.061, g_loss 2.949, d_loss 0.075\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 116/390 d_loss_real= 0.294, d_loss_fake= 0.076, g_loss 2.636, d_loss 0.185\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 117/390 d_loss_real= 0.370, d_loss_fake= 0.096, g_loss 2.273, d_loss 0.233\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 118/390 d_loss_real= 0.127, d_loss_fake= 0.242, g_loss 2.615, d_loss 0.184\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 119/390 d_loss_real= 0.194, d_loss_fake= 0.058, g_loss 3.258, d_loss 0.126\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 120/390 d_loss_real= 0.129, d_loss_fake= 0.043, g_loss 3.479, d_loss 0.086\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 121/390 d_loss_real= 0.192, d_loss_fake= 0.035, g_loss 3.539, d_loss 0.113\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 31 Batch 122/390 d_loss_real= 0.195, d_loss_fake= 0.039, g_loss 3.652, d_loss 0.117\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 123/390 d_loss_real= 0.153, d_loss_fake= 0.033, g_loss 3.520, d_loss 0.093\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 31 Batch 124/390 d_loss_real= 0.120, d_loss_fake= 0.037, g_loss 3.453, d_loss 0.078\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 125/390 d_loss_real= 0.180, d_loss_fake= 0.041, g_loss 3.295, d_loss 0.110\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 31 Batch 126/390 d_loss_real= 0.199, d_loss_fake= 0.047, g_loss 3.157, d_loss 0.123\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 127/390 d_loss_real= 0.100, d_loss_fake= 0.058, g_loss 2.795, d_loss 0.079\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 128/390 d_loss_real= 0.076, d_loss_fake= 0.101, g_loss 2.348, d_loss 0.088\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 129/390 d_loss_real= 0.195, d_loss_fake= 0.185, g_loss 2.541, d_loss 0.190\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 31 Batch 130/390 d_loss_real= 0.002, d_loss_fake= 0.076, g_loss 2.814, d_loss 0.039\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 131/390 d_loss_real= 0.079, d_loss_fake= 0.053, g_loss 3.192, d_loss 0.066\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 132/390 d_loss_real= 0.098, d_loss_fake= 0.040, g_loss 3.355, d_loss 0.069\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 133/390 d_loss_real= 0.074, d_loss_fake= 0.039, g_loss 3.531, d_loss 0.056\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 134/390 d_loss_real= 0.360, d_loss_fake= 0.037, g_loss 3.490, d_loss 0.198\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 135/390 d_loss_real= 0.348, d_loss_fake= 0.038, g_loss 3.322, d_loss 0.193\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 136/390 d_loss_real= 0.140, d_loss_fake= 0.044, g_loss 3.160, d_loss 0.092\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 137/390 d_loss_real= 0.234, d_loss_fake= 0.056, g_loss 2.970, d_loss 0.145\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 31 Batch 138/390 d_loss_real= 0.073, d_loss_fake= 0.066, g_loss 2.843, d_loss 0.069\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 31 Batch 139/390 d_loss_real= 0.155, d_loss_fake= 0.078, g_loss 2.676, d_loss 0.117\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 31 Batch 140/390 d_loss_real= 0.156, d_loss_fake= 0.101, g_loss 2.496, d_loss 0.129\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 31 Batch 141/390 d_loss_real= 0.195, d_loss_fake= 0.109, g_loss 2.685, d_loss 0.152\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 31 Batch 142/390 d_loss_real= 0.153, d_loss_fake= 0.077, g_loss 2.926, d_loss 0.115\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 143/390 d_loss_real= 0.109, d_loss_fake= 0.049, g_loss 3.128, d_loss 0.079\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 144/390 d_loss_real= 0.054, d_loss_fake= 0.039, g_loss 3.345, d_loss 0.047\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 145/390 d_loss_real= 0.004, d_loss_fake= 0.038, g_loss 3.499, d_loss 0.021\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 31 Batch 146/390 d_loss_real= 0.159, d_loss_fake= 0.033, g_loss 3.482, d_loss 0.096\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 147/390 d_loss_real= 0.178, d_loss_fake= 0.032, g_loss 3.367, d_loss 0.105\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 148/390 d_loss_real= 0.187, d_loss_fake= 0.040, g_loss 3.236, d_loss 0.113\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 31 Batch 149/390 d_loss_real= 0.192, d_loss_fake= 0.046, g_loss 2.957, d_loss 0.119\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 150/390 d_loss_real= 0.129, d_loss_fake= 0.119, g_loss 2.398, d_loss 0.124\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 151/390 d_loss_real= 0.064, d_loss_fake= 0.282, g_loss 2.368, d_loss 0.173\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 31 Batch 152/390 d_loss_real= 0.116, d_loss_fake= 0.155, g_loss 3.088, d_loss 0.135\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 31 Batch 153/390 d_loss_real= 0.257, d_loss_fake= 0.033, g_loss 4.064, d_loss 0.145\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 154/390 d_loss_real= 0.341, d_loss_fake= 0.017, g_loss 4.383, d_loss 0.179\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 31 Batch 155/390 d_loss_real= 0.246, d_loss_fake= 0.014, g_loss 4.492, d_loss 0.130\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 31 Batch 156/390 d_loss_real= 0.486, d_loss_fake= 0.015, g_loss 4.266, d_loss 0.251\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 31 Batch 157/390 d_loss_real= 0.322, d_loss_fake= 0.018, g_loss 4.056, d_loss 0.170\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 158/390 d_loss_real= 0.363, d_loss_fake= 0.023, g_loss 3.739, d_loss 0.193\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 159/390 d_loss_real= 0.333, d_loss_fake= 0.038, g_loss 3.029, d_loss 0.185\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 31 Batch 160/390 d_loss_real= 0.230, d_loss_fake= 0.091, g_loss 2.263, d_loss 0.161\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 161/390 d_loss_real= 0.054, d_loss_fake= 0.181, g_loss 2.239, d_loss 0.118\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 31 Batch 162/390 d_loss_real= 0.081, d_loss_fake= 0.097, g_loss 2.961, d_loss 0.089\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 163/390 d_loss_real= 0.108, d_loss_fake= 0.044, g_loss 3.487, d_loss 0.076\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 31 Batch 164/390 d_loss_real= 0.151, d_loss_fake= 0.032, g_loss 3.617, d_loss 0.091\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 165/390 d_loss_real= 0.143, d_loss_fake= 0.028, g_loss 3.679, d_loss 0.085\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 31 Batch 166/390 d_loss_real= 0.127, d_loss_fake= 0.026, g_loss 3.747, d_loss 0.077\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 167/390 d_loss_real= 0.128, d_loss_fake= 0.027, g_loss 3.693, d_loss 0.077\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 31 Batch 168/390 d_loss_real= 0.000, d_loss_fake= 0.028, g_loss 3.694, d_loss 0.014\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 169/390 d_loss_real= 0.122, d_loss_fake= 0.028, g_loss 3.634, d_loss 0.075\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 31 Batch 170/390 d_loss_real= 0.095, d_loss_fake= 0.028, g_loss 3.568, d_loss 0.062\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 171/390 d_loss_real= 0.161, d_loss_fake= 0.043, g_loss 3.368, d_loss 0.102\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 172/390 d_loss_real= 0.046, d_loss_fake= 0.058, g_loss 3.033, d_loss 0.052\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 31 Batch 173/390 d_loss_real= 0.076, d_loss_fake= 0.096, g_loss 3.162, d_loss 0.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 174/390 d_loss_real= 0.160, d_loss_fake= 0.052, g_loss 3.484, d_loss 0.106\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 175/390 d_loss_real= 0.110, d_loss_fake= 0.044, g_loss 3.763, d_loss 0.077\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 31 Batch 176/390 d_loss_real= 0.071, d_loss_fake= 0.024, g_loss 3.916, d_loss 0.047\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 177/390 d_loss_real= 0.094, d_loss_fake= 0.019, g_loss 4.048, d_loss 0.057\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 178/390 d_loss_real= 0.123, d_loss_fake= 0.018, g_loss 4.154, d_loss 0.070\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 31 Batch 179/390 d_loss_real= 0.106, d_loss_fake= 0.017, g_loss 4.132, d_loss 0.062\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 180/390 d_loss_real= 0.209, d_loss_fake= 0.019, g_loss 3.988, d_loss 0.114\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 181/390 d_loss_real= 0.244, d_loss_fake= 0.022, g_loss 3.680, d_loss 0.133\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 31 Batch 182/390 d_loss_real= 0.045, d_loss_fake= 0.032, g_loss 3.444, d_loss 0.039\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 183/390 d_loss_real= 0.007, d_loss_fake= 0.050, g_loss 3.247, d_loss 0.028\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 184/390 d_loss_real= 0.029, d_loss_fake= 0.049, g_loss 3.534, d_loss 0.039\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 185/390 d_loss_real= 0.026, d_loss_fake= 0.032, g_loss 3.785, d_loss 0.029\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 186/390 d_loss_real= 0.161, d_loss_fake= 0.024, g_loss 3.896, d_loss 0.093\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 187/390 d_loss_real= 0.103, d_loss_fake= 0.024, g_loss 3.830, d_loss 0.064\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 188/390 d_loss_real= 0.147, d_loss_fake= 0.027, g_loss 3.841, d_loss 0.087\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 31 Batch 189/390 d_loss_real= 0.113, d_loss_fake= 0.025, g_loss 3.722, d_loss 0.069\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 31 Batch 190/390 d_loss_real= 0.086, d_loss_fake= 0.033, g_loss 3.564, d_loss 0.059\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 31 Batch 191/390 d_loss_real= 0.156, d_loss_fake= 0.047, g_loss 3.564, d_loss 0.102\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 31 Batch 192/390 d_loss_real= 0.369, d_loss_fake= 0.080, g_loss 3.556, d_loss 0.225\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 31 Batch 193/390 d_loss_real= 0.139, d_loss_fake= 0.046, g_loss 3.773, d_loss 0.092\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 194/390 d_loss_real= 0.058, d_loss_fake= 0.026, g_loss 3.965, d_loss 0.042\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 31 Batch 195/390 d_loss_real= 0.185, d_loss_fake= 0.022, g_loss 3.957, d_loss 0.104\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 196/390 d_loss_real= 0.180, d_loss_fake= 0.021, g_loss 3.956, d_loss 0.100\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 31 Batch 197/390 d_loss_real= 0.095, d_loss_fake= 0.022, g_loss 3.856, d_loss 0.058\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 31 Batch 198/390 d_loss_real= 0.245, d_loss_fake= 0.026, g_loss 3.676, d_loss 0.135\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 199/390 d_loss_real= 0.118, d_loss_fake= 0.031, g_loss 3.434, d_loss 0.075\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 200/390 d_loss_real= 0.125, d_loss_fake= 0.042, g_loss 3.230, d_loss 0.083\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 201/390 d_loss_real= 0.059, d_loss_fake= 0.085, g_loss 3.070, d_loss 0.072\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 202/390 d_loss_real= 0.134, d_loss_fake= 0.063, g_loss 3.249, d_loss 0.099\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 203/390 d_loss_real= 0.187, d_loss_fake= 0.040, g_loss 3.445, d_loss 0.114\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 31 Batch 204/390 d_loss_real= 0.150, d_loss_fake= 0.037, g_loss 3.533, d_loss 0.094\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 31 Batch 205/390 d_loss_real= 0.114, d_loss_fake= 0.034, g_loss 3.509, d_loss 0.074\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 206/390 d_loss_real= 0.211, d_loss_fake= 0.039, g_loss 3.396, d_loss 0.125\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 207/390 d_loss_real= 0.363, d_loss_fake= 0.039, g_loss 3.199, d_loss 0.201\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 31 Batch 208/390 d_loss_real= 0.216, d_loss_fake= 0.080, g_loss 2.935, d_loss 0.148\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 209/390 d_loss_real= 0.123, d_loss_fake= 0.045, g_loss 3.075, d_loss 0.084\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 210/390 d_loss_real= 0.210, d_loss_fake= 0.105, g_loss 3.045, d_loss 0.158\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 211/390 d_loss_real= 0.064, d_loss_fake= 0.064, g_loss 3.281, d_loss 0.064\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 212/390 d_loss_real= 0.116, d_loss_fake= 0.037, g_loss 3.469, d_loss 0.076\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 213/390 d_loss_real= 0.213, d_loss_fake= 0.033, g_loss 3.520, d_loss 0.123\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 214/390 d_loss_real= 0.197, d_loss_fake= 0.032, g_loss 3.533, d_loss 0.115\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 31 Batch 215/390 d_loss_real= 0.068, d_loss_fake= 0.033, g_loss 3.489, d_loss 0.050\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 31 Batch 216/390 d_loss_real= 0.082, d_loss_fake= 0.033, g_loss 3.468, d_loss 0.057\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 217/390 d_loss_real= 0.188, d_loss_fake= 0.034, g_loss 3.369, d_loss 0.111\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 218/390 d_loss_real= 0.229, d_loss_fake= 0.040, g_loss 3.283, d_loss 0.135\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 219/390 d_loss_real= 0.135, d_loss_fake= 0.042, g_loss 3.189, d_loss 0.089\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 31 Batch 220/390 d_loss_real= 0.045, d_loss_fake= 0.044, g_loss 3.162, d_loss 0.044\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 31 Batch 221/390 d_loss_real= 0.087, d_loss_fake= 0.048, g_loss 3.132, d_loss 0.067\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 222/390 d_loss_real= 0.029, d_loss_fake= 0.056, g_loss 3.138, d_loss 0.042\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 223/390 d_loss_real= 0.063, d_loss_fake= 0.059, g_loss 3.133, d_loss 0.061\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 224/390 d_loss_real= 0.070, d_loss_fake= 0.053, g_loss 3.223, d_loss 0.061\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 31 Batch 225/390 d_loss_real= 0.046, d_loss_fake= 0.053, g_loss 3.234, d_loss 0.049\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 226/390 d_loss_real= 0.076, d_loss_fake= 0.055, g_loss 3.141, d_loss 0.066\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 227/390 d_loss_real= 0.162, d_loss_fake= 0.052, g_loss 3.167, d_loss 0.107\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 228/390 d_loss_real= 0.085, d_loss_fake= 0.048, g_loss 3.140, d_loss 0.067\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 229/390 d_loss_real= 0.027, d_loss_fake= 0.057, g_loss 3.134, d_loss 0.042\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 230/390 d_loss_real= 0.197, d_loss_fake= 0.055, g_loss 3.035, d_loss 0.126\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 31 Batch 231/390 d_loss_real= 0.001, d_loss_fake= 0.063, g_loss 2.993, d_loss 0.032\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 31 Batch 232/390 d_loss_real= 0.204, d_loss_fake= 0.063, g_loss 2.841, d_loss 0.133\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 31 Batch 233/390 d_loss_real= 0.129, d_loss_fake= 0.072, g_loss 2.773, d_loss 0.101\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 31 Batch 234/390 d_loss_real= 0.093, d_loss_fake= 0.079, g_loss 2.754, d_loss 0.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 235/390 d_loss_real= 0.152, d_loss_fake= 0.072, g_loss 2.828, d_loss 0.112\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 236/390 d_loss_real= 0.023, d_loss_fake= 0.065, g_loss 2.900, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 237/390 d_loss_real= 0.060, d_loss_fake= 0.057, g_loss 2.950, d_loss 0.059\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 238/390 d_loss_real= 0.122, d_loss_fake= 0.056, g_loss 3.040, d_loss 0.089\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 31 Batch 239/390 d_loss_real= 0.194, d_loss_fake= 0.054, g_loss 2.935, d_loss 0.124\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 31 Batch 240/390 d_loss_real= 0.186, d_loss_fake= 0.058, g_loss 2.941, d_loss 0.122\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 241/390 d_loss_real= 0.075, d_loss_fake= 0.060, g_loss 2.866, d_loss 0.068\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 242/390 d_loss_real= 0.105, d_loss_fake= 0.073, g_loss 2.759, d_loss 0.089\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 31 Batch 243/390 d_loss_real= 0.310, d_loss_fake= 0.076, g_loss 2.614, d_loss 0.193\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 244/390 d_loss_real= 0.078, d_loss_fake= 0.090, g_loss 2.623, d_loss 0.084\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 31 Batch 245/390 d_loss_real= 0.318, d_loss_fake= 0.102, g_loss 2.579, d_loss 0.210\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 246/390 d_loss_real= 0.037, d_loss_fake= 0.079, g_loss 2.699, d_loss 0.058\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 247/390 d_loss_real= 0.104, d_loss_fake= 0.069, g_loss 2.807, d_loss 0.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 248/390 d_loss_real= 0.190, d_loss_fake= 0.069, g_loss 2.713, d_loss 0.130\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 249/390 d_loss_real= 0.138, d_loss_fake= 0.072, g_loss 2.720, d_loss 0.105\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 31 Batch 250/390 d_loss_real= 0.339, d_loss_fake= 0.081, g_loss 2.620, d_loss 0.210\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 251/390 d_loss_real= 0.049, d_loss_fake= 0.095, g_loss 2.615, d_loss 0.072\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 31 Batch 252/390 d_loss_real= 0.143, d_loss_fake= 0.099, g_loss 2.672, d_loss 0.121\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 253/390 d_loss_real= 0.197, d_loss_fake= 0.080, g_loss 2.770, d_loss 0.138\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 254/390 d_loss_real= 0.009, d_loss_fake= 0.066, g_loss 2.968, d_loss 0.038\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 31 Batch 255/390 d_loss_real= 0.146, d_loss_fake= 0.059, g_loss 3.044, d_loss 0.103\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 256/390 d_loss_real= 0.033, d_loss_fake= 0.057, g_loss 3.019, d_loss 0.045\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 257/390 d_loss_real= 0.339, d_loss_fake= 0.056, g_loss 2.977, d_loss 0.198\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 258/390 d_loss_real= 0.222, d_loss_fake= 0.060, g_loss 2.844, d_loss 0.141\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 259/390 d_loss_real= 0.169, d_loss_fake= 0.074, g_loss 2.711, d_loss 0.121\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 260/390 d_loss_real= 0.327, d_loss_fake= 0.084, g_loss 2.515, d_loss 0.205\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 261/390 d_loss_real= 0.067, d_loss_fake= 0.085, g_loss 2.520, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 262/390 d_loss_real= 0.048, d_loss_fake= 0.095, g_loss 2.530, d_loss 0.072\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 263/390 d_loss_real= 0.322, d_loss_fake= 0.083, g_loss 2.627, d_loss 0.203\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 31 Batch 264/390 d_loss_real= 0.229, d_loss_fake= 0.087, g_loss 2.635, d_loss 0.158\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 31 Batch 265/390 d_loss_real= 0.226, d_loss_fake= 0.079, g_loss 2.670, d_loss 0.152\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 266/390 d_loss_real= 0.163, d_loss_fake= 0.081, g_loss 2.610, d_loss 0.122\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 267/390 d_loss_real= 0.098, d_loss_fake= 0.080, g_loss 2.605, d_loss 0.089\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 268/390 d_loss_real= 0.099, d_loss_fake= 0.081, g_loss 2.665, d_loss 0.090\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 31 Batch 269/390 d_loss_real= 0.021, d_loss_fake= 0.081, g_loss 2.617, d_loss 0.051\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 270/390 d_loss_real= 0.065, d_loss_fake= 0.077, g_loss 2.749, d_loss 0.071\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 271/390 d_loss_real= 0.153, d_loss_fake= 0.070, g_loss 2.726, d_loss 0.112\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 31 Batch 272/390 d_loss_real= 0.129, d_loss_fake= 0.063, g_loss 2.844, d_loss 0.096\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 31 Batch 273/390 d_loss_real= 0.164, d_loss_fake= 0.085, g_loss 2.577, d_loss 0.125\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 31 Batch 274/390 d_loss_real= 0.178, d_loss_fake= 0.070, g_loss 2.795, d_loss 0.124\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 275/390 d_loss_real= 0.143, d_loss_fake= 0.043, g_loss 3.269, d_loss 0.093\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 276/390 d_loss_real= 0.162, d_loss_fake= 0.051, g_loss 3.140, d_loss 0.106\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 31 Batch 277/390 d_loss_real= 0.209, d_loss_fake= 0.075, g_loss 2.633, d_loss 0.142\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 278/390 d_loss_real= 0.075, d_loss_fake= 0.094, g_loss 2.469, d_loss 0.085\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 279/390 d_loss_real= 0.244, d_loss_fake= 0.092, g_loss 2.582, d_loss 0.168\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 31 Batch 280/390 d_loss_real= 0.086, d_loss_fake= 0.100, g_loss 2.643, d_loss 0.093\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 31 Batch 281/390 d_loss_real= 0.187, d_loss_fake= 0.076, g_loss 2.842, d_loss 0.132\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 282/390 d_loss_real= 0.058, d_loss_fake= 0.066, g_loss 2.934, d_loss 0.062\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 283/390 d_loss_real= 0.280, d_loss_fake= 0.055, g_loss 3.045, d_loss 0.168\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 284/390 d_loss_real= 0.033, d_loss_fake= 0.047, g_loss 3.207, d_loss 0.040\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 285/390 d_loss_real= 0.118, d_loss_fake= 0.051, g_loss 3.096, d_loss 0.084\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 31 Batch 286/390 d_loss_real= 0.119, d_loss_fake= 0.043, g_loss 3.222, d_loss 0.081\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 31 Batch 287/390 d_loss_real= 0.000, d_loss_fake= 0.046, g_loss 3.282, d_loss 0.023\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 31 Batch 288/390 d_loss_real= 0.342, d_loss_fake= 0.053, g_loss 3.085, d_loss 0.198\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 289/390 d_loss_real= 0.219, d_loss_fake= 0.052, g_loss 2.924, d_loss 0.136\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 290/390 d_loss_real= 0.164, d_loss_fake= 0.050, g_loss 3.074, d_loss 0.107\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 291/390 d_loss_real= 0.077, d_loss_fake= 0.081, g_loss 2.685, d_loss 0.079\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 31 Batch 292/390 d_loss_real= 0.105, d_loss_fake= 0.078, g_loss 2.873, d_loss 0.091\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 293/390 d_loss_real= 0.305, d_loss_fake= 0.072, g_loss 2.927, d_loss 0.188\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 294/390 d_loss_real= 0.022, d_loss_fake= 0.052, g_loss 3.197, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 295/390 d_loss_real= 0.040, d_loss_fake= 0.044, g_loss 3.305, d_loss 0.042\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 296/390 d_loss_real= 0.133, d_loss_fake= 0.037, g_loss 3.459, d_loss 0.085\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 31 Batch 297/390 d_loss_real= 0.215, d_loss_fake= 0.041, g_loss 3.243, d_loss 0.128\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 31 Batch 298/390 d_loss_real= 0.423, d_loss_fake= 0.050, g_loss 3.101, d_loss 0.236\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 31 Batch 299/390 d_loss_real= 0.103, d_loss_fake= 0.058, g_loss 2.970, d_loss 0.081\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 31 Batch 300/390 d_loss_real= 0.055, d_loss_fake= 0.103, g_loss 2.658, d_loss 0.079\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 301/390 d_loss_real= 0.050, d_loss_fake= 0.135, g_loss 2.580, d_loss 0.093\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 31 Batch 302/390 d_loss_real= 0.220, d_loss_fake= 0.147, g_loss 2.641, d_loss 0.184\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 303/390 d_loss_real= 0.352, d_loss_fake= 0.094, g_loss 3.106, d_loss 0.223\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 31 Batch 304/390 d_loss_real= 0.043, d_loss_fake= 0.050, g_loss 3.624, d_loss 0.046\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 305/390 d_loss_real= 0.444, d_loss_fake= 0.028, g_loss 3.836, d_loss 0.236\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 31 Batch 306/390 d_loss_real= 0.399, d_loss_fake= 0.026, g_loss 3.770, d_loss 0.213\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 307/390 d_loss_real= 0.416, d_loss_fake= 0.031, g_loss 3.594, d_loss 0.224\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 308/390 d_loss_real= 0.548, d_loss_fake= 0.038, g_loss 3.272, d_loss 0.293\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 31 Batch 309/390 d_loss_real= 0.143, d_loss_fake= 0.051, g_loss 2.881, d_loss 0.097\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 310/390 d_loss_real= 0.440, d_loss_fake= 0.083, g_loss 2.601, d_loss 0.261\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 31 Batch 311/390 d_loss_real= 0.175, d_loss_fake= 0.099, g_loss 2.552, d_loss 0.137\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 312/390 d_loss_real= 0.195, d_loss_fake= 0.064, g_loss 2.890, d_loss 0.129\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 313/390 d_loss_real= 0.197, d_loss_fake= 0.089, g_loss 2.761, d_loss 0.143\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 314/390 d_loss_real= 0.126, d_loss_fake= 0.058, g_loss 3.082, d_loss 0.092\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 315/390 d_loss_real= 0.164, d_loss_fake= 0.050, g_loss 3.159, d_loss 0.107\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 316/390 d_loss_real= 0.138, d_loss_fake= 0.049, g_loss 3.102, d_loss 0.093\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 31 Batch 317/390 d_loss_real= 0.175, d_loss_fake= 0.055, g_loss 2.969, d_loss 0.115\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 31 Batch 318/390 d_loss_real= 0.084, d_loss_fake= 0.065, g_loss 2.814, d_loss 0.074\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 31 Batch 319/390 d_loss_real= 0.133, d_loss_fake= 0.080, g_loss 2.641, d_loss 0.106\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 320/390 d_loss_real= 0.056, d_loss_fake= 0.089, g_loss 2.645, d_loss 0.073\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 321/390 d_loss_real= 0.104, d_loss_fake= 0.082, g_loss 2.743, d_loss 0.093\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 31 Batch 322/390 d_loss_real= 0.007, d_loss_fake= 0.065, g_loss 2.970, d_loss 0.036\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 31 Batch 323/390 d_loss_real= 0.130, d_loss_fake= 0.056, g_loss 3.075, d_loss 0.093\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 31 Batch 324/390 d_loss_real= 0.039, d_loss_fake= 0.048, g_loss 3.217, d_loss 0.043\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 325/390 d_loss_real= 0.111, d_loss_fake= 0.044, g_loss 3.332, d_loss 0.077\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 326/390 d_loss_real= 0.046, d_loss_fake= 0.036, g_loss 3.518, d_loss 0.041\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 31 Batch 327/390 d_loss_real= 0.243, d_loss_fake= 0.033, g_loss 3.567, d_loss 0.138\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 328/390 d_loss_real= 0.068, d_loss_fake= 0.030, g_loss 3.607, d_loss 0.049\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 31 Batch 329/390 d_loss_real= 0.059, d_loss_fake= 0.028, g_loss 3.610, d_loss 0.044\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 31 Batch 330/390 d_loss_real= 0.232, d_loss_fake= 0.033, g_loss 3.518, d_loss 0.133\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 31 Batch 331/390 d_loss_real= 0.187, d_loss_fake= 0.045, g_loss 3.324, d_loss 0.116\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 31 Batch 332/390 d_loss_real= 0.077, d_loss_fake= 0.095, g_loss 3.441, d_loss 0.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 333/390 d_loss_real= 0.075, d_loss_fake= 0.032, g_loss 3.699, d_loss 0.054\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 334/390 d_loss_real= 0.044, d_loss_fake= 0.026, g_loss 3.756, d_loss 0.035\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 31 Batch 335/390 d_loss_real= 0.102, d_loss_fake= 0.027, g_loss 3.780, d_loss 0.065\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 31 Batch 336/390 d_loss_real= 0.149, d_loss_fake= 0.027, g_loss 3.662, d_loss 0.088\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 31 Batch 337/390 d_loss_real= 0.113, d_loss_fake= 0.031, g_loss 3.568, d_loss 0.072\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 31 Batch 338/390 d_loss_real= 0.135, d_loss_fake= 0.036, g_loss 3.430, d_loss 0.085\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 339/390 d_loss_real= 0.250, d_loss_fake= 0.042, g_loss 3.255, d_loss 0.146\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 340/390 d_loss_real= 0.067, d_loss_fake= 0.051, g_loss 3.011, d_loss 0.059\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 31 Batch 341/390 d_loss_real= 0.119, d_loss_fake= 0.074, g_loss 2.776, d_loss 0.096\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 342/390 d_loss_real= 0.058, d_loss_fake= 0.115, g_loss 2.900, d_loss 0.086\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 31 Batch 343/390 d_loss_real= 0.142, d_loss_fake= 0.056, g_loss 3.053, d_loss 0.099\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 31 Batch 344/390 d_loss_real= 0.232, d_loss_fake= 0.053, g_loss 3.122, d_loss 0.143\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 345/390 d_loss_real= 0.019, d_loss_fake= 0.048, g_loss 3.178, d_loss 0.034\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 346/390 d_loss_real= 0.021, d_loss_fake= 0.047, g_loss 3.186, d_loss 0.034\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 347/390 d_loss_real= 0.134, d_loss_fake= 0.044, g_loss 3.184, d_loss 0.089\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 31 Batch 348/390 d_loss_real= 0.099, d_loss_fake= 0.044, g_loss 3.197, d_loss 0.072\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 349/390 d_loss_real= 0.105, d_loss_fake= 0.040, g_loss 3.185, d_loss 0.073\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 31 Batch 350/390 d_loss_real= 0.080, d_loss_fake= 0.044, g_loss 3.225, d_loss 0.062\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 351/390 d_loss_real= 0.024, d_loss_fake= 0.044, g_loss 3.247, d_loss 0.034\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 352/390 d_loss_real= 0.246, d_loss_fake= 0.046, g_loss 3.120, d_loss 0.146\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 353/390 d_loss_real= 0.134, d_loss_fake= 0.052, g_loss 2.945, d_loss 0.093\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 354/390 d_loss_real= 0.071, d_loss_fake= 0.066, g_loss 2.779, d_loss 0.069\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 355/390 d_loss_real= 0.086, d_loss_fake= 0.091, g_loss 2.810, d_loss 0.089\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 31 Batch 356/390 d_loss_real= 0.131, d_loss_fake= 0.088, g_loss 2.828, d_loss 0.110\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 357/390 d_loss_real= 0.015, d_loss_fake= 0.069, g_loss 3.023, d_loss 0.042\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 31 Batch 358/390 d_loss_real= 0.079, d_loss_fake= 0.051, g_loss 3.238, d_loss 0.065\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 31 Batch 359/390 d_loss_real= 0.002, d_loss_fake= 0.037, g_loss 3.473, d_loss 0.020\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 31 Batch 360/390 d_loss_real= 0.358, d_loss_fake= 0.034, g_loss 3.499, d_loss 0.196\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 31 Batch 361/390 d_loss_real= 0.028, d_loss_fake= 0.034, g_loss 3.486, d_loss 0.031\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 31 Batch 362/390 d_loss_real= 0.297, d_loss_fake= 0.036, g_loss 3.358, d_loss 0.166\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 363/390 d_loss_real= 0.217, d_loss_fake= 0.039, g_loss 3.231, d_loss 0.128\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 31 Batch 364/390 d_loss_real= 0.181, d_loss_fake= 0.057, g_loss 2.879, d_loss 0.119\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 31 Batch 365/390 d_loss_real= 0.001, d_loss_fake= 0.102, g_loss 2.801, d_loss 0.051\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 366/390 d_loss_real= 0.237, d_loss_fake= 0.079, g_loss 3.041, d_loss 0.158\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 367/390 d_loss_real= 0.167, d_loss_fake= 0.065, g_loss 3.128, d_loss 0.116\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 368/390 d_loss_real= 0.062, d_loss_fake= 0.044, g_loss 3.271, d_loss 0.053\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 369/390 d_loss_real= 0.026, d_loss_fake= 0.038, g_loss 3.424, d_loss 0.032\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 31 Batch 370/390 d_loss_real= 0.108, d_loss_fake= 0.035, g_loss 3.476, d_loss 0.071\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 31 Batch 371/390 d_loss_real= 0.161, d_loss_fake= 0.034, g_loss 3.466, d_loss 0.098\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 372/390 d_loss_real= 0.172, d_loss_fake= 0.035, g_loss 3.287, d_loss 0.103\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 373/390 d_loss_real= 0.228, d_loss_fake= 0.047, g_loss 3.119, d_loss 0.137\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 31 Batch 374/390 d_loss_real= 0.048, d_loss_fake= 0.064, g_loss 3.029, d_loss 0.056\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 31 Batch 375/390 d_loss_real= 0.119, d_loss_fake= 0.069, g_loss 2.941, d_loss 0.094\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 376/390 d_loss_real= 0.114, d_loss_fake= 0.057, g_loss 3.165, d_loss 0.085\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 31 Batch 377/390 d_loss_real= 0.111, d_loss_fake= 0.045, g_loss 3.310, d_loss 0.078\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 31 Batch 378/390 d_loss_real= 0.035, d_loss_fake= 0.035, g_loss 3.514, d_loss 0.035\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 379/390 d_loss_real= 0.128, d_loss_fake= 0.030, g_loss 3.605, d_loss 0.079\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 380/390 d_loss_real= 0.193, d_loss_fake= 0.031, g_loss 3.554, d_loss 0.112\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 381/390 d_loss_real= 0.106, d_loss_fake= 0.031, g_loss 3.543, d_loss 0.069\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 382/390 d_loss_real= 0.278, d_loss_fake= 0.033, g_loss 3.433, d_loss 0.155\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 383/390 d_loss_real= 0.059, d_loss_fake= 0.038, g_loss 3.331, d_loss 0.048\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 384/390 d_loss_real= 0.196, d_loss_fake= 0.044, g_loss 3.176, d_loss 0.120\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31 Batch 385/390 d_loss_real= 0.169, d_loss_fake= 0.051, g_loss 3.061, d_loss 0.110\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 31 Batch 386/390 d_loss_real= 0.231, d_loss_fake= 0.066, g_loss 2.776, d_loss 0.148\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31 Batch 387/390 d_loss_real= 0.125, d_loss_fake= 0.110, g_loss 2.994, d_loss 0.117\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31 Batch 388/390 d_loss_real= 0.142, d_loss_fake= 0.073, g_loss 3.151, d_loss 0.108\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 31 Batch 389/390 d_loss_real= 0.150, d_loss_fake= 0.042, g_loss 3.418, d_loss 0.096\n",
            "2/2 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31 Batch 390/390 d_loss_real= 0.254, d_loss_fake= 0.034, g_loss 3.474, d_loss 0.144\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 1/390 d_loss_real= 0.185, d_loss_fake= 0.031, g_loss 3.459, d_loss 0.108\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 32 Batch 2/390 d_loss_real= 0.319, d_loss_fake= 0.034, g_loss 3.441, d_loss 0.176\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 32 Batch 3/390 d_loss_real= 0.133, d_loss_fake= 0.038, g_loss 3.250, d_loss 0.086\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 4/390 d_loss_real= 0.157, d_loss_fake= 0.046, g_loss 3.134, d_loss 0.102\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 32 Batch 5/390 d_loss_real= 0.174, d_loss_fake= 0.051, g_loss 3.052, d_loss 0.113\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 6/390 d_loss_real= 0.087, d_loss_fake= 0.056, g_loss 3.024, d_loss 0.072\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 7/390 d_loss_real= 0.066, d_loss_fake= 0.059, g_loss 2.986, d_loss 0.063\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 8/390 d_loss_real= 0.170, d_loss_fake= 0.054, g_loss 3.050, d_loss 0.112\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 32 Batch 9/390 d_loss_real= 0.001, d_loss_fake= 0.047, g_loss 3.130, d_loss 0.024\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 32 Batch 10/390 d_loss_real= 0.172, d_loss_fake= 0.046, g_loss 3.138, d_loss 0.109\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 11/390 d_loss_real= 0.171, d_loss_fake= 0.049, g_loss 3.116, d_loss 0.110\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 12/390 d_loss_real= 0.212, d_loss_fake= 0.052, g_loss 3.118, d_loss 0.132\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 13/390 d_loss_real= 0.040, d_loss_fake= 0.053, g_loss 3.040, d_loss 0.046\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 14/390 d_loss_real= 0.109, d_loss_fake= 0.048, g_loss 3.123, d_loss 0.078\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 15/390 d_loss_real= 0.345, d_loss_fake= 0.053, g_loss 2.995, d_loss 0.199\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 16/390 d_loss_real= 0.039, d_loss_fake= 0.051, g_loss 3.002, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 17/390 d_loss_real= 0.208, d_loss_fake= 0.055, g_loss 3.022, d_loss 0.132\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 18/390 d_loss_real= 0.378, d_loss_fake= 0.062, g_loss 2.925, d_loss 0.220\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 32 Batch 19/390 d_loss_real= 0.053, d_loss_fake= 0.065, g_loss 2.860, d_loss 0.059\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 20/390 d_loss_real= 0.046, d_loss_fake= 0.062, g_loss 2.927, d_loss 0.054\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 32 Batch 21/390 d_loss_real= 0.038, d_loss_fake= 0.057, g_loss 3.030, d_loss 0.048\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 22/390 d_loss_real= 0.193, d_loss_fake= 0.049, g_loss 3.091, d_loss 0.121\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 32 Batch 23/390 d_loss_real= 0.129, d_loss_fake= 0.052, g_loss 3.085, d_loss 0.090\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 24/390 d_loss_real= 0.208, d_loss_fake= 0.054, g_loss 3.052, d_loss 0.131\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 25/390 d_loss_real= 0.047, d_loss_fake= 0.056, g_loss 2.985, d_loss 0.051\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 26/390 d_loss_real= 0.146, d_loss_fake= 0.056, g_loss 3.042, d_loss 0.101\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 27/390 d_loss_real= 0.147, d_loss_fake= 0.055, g_loss 2.982, d_loss 0.101\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 28/390 d_loss_real= 0.232, d_loss_fake= 0.059, g_loss 2.956, d_loss 0.146\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 32 Batch 29/390 d_loss_real= 0.050, d_loss_fake= 0.053, g_loss 2.942, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 30/390 d_loss_real= 0.188, d_loss_fake= 0.057, g_loss 2.932, d_loss 0.123\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 31/390 d_loss_real= 0.054, d_loss_fake= 0.054, g_loss 2.991, d_loss 0.054\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 32 Batch 32/390 d_loss_real= 0.074, d_loss_fake= 0.054, g_loss 3.021, d_loss 0.064\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 32 Batch 33/390 d_loss_real= 0.151, d_loss_fake= 0.053, g_loss 2.945, d_loss 0.102\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 34/390 d_loss_real= 0.147, d_loss_fake= 0.058, g_loss 3.013, d_loss 0.102\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 35/390 d_loss_real= 0.129, d_loss_fake= 0.058, g_loss 2.935, d_loss 0.094\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 36/390 d_loss_real= 0.095, d_loss_fake= 0.063, g_loss 2.853, d_loss 0.079\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 32 Batch 37/390 d_loss_real= 0.144, d_loss_fake= 0.066, g_loss 2.819, d_loss 0.105\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 32 Batch 38/390 d_loss_real= 0.191, d_loss_fake= 0.059, g_loss 2.905, d_loss 0.125\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 39/390 d_loss_real= 0.153, d_loss_fake= 0.065, g_loss 2.883, d_loss 0.109\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 40/390 d_loss_real= 0.133, d_loss_fake= 0.064, g_loss 2.954, d_loss 0.099\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 41/390 d_loss_real= 0.060, d_loss_fake= 0.060, g_loss 2.992, d_loss 0.060\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 42/390 d_loss_real= 0.104, d_loss_fake= 0.053, g_loss 3.086, d_loss 0.078\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 43/390 d_loss_real= 0.084, d_loss_fake= 0.050, g_loss 3.125, d_loss 0.067\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 44/390 d_loss_real= 0.142, d_loss_fake= 0.050, g_loss 3.137, d_loss 0.096\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 32 Batch 45/390 d_loss_real= 0.050, d_loss_fake= 0.048, g_loss 3.161, d_loss 0.049\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 46/390 d_loss_real= 0.283, d_loss_fake= 0.048, g_loss 3.221, d_loss 0.165\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 32 Batch 47/390 d_loss_real= 0.133, d_loss_fake= 0.048, g_loss 3.151, d_loss 0.091\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 48/390 d_loss_real= 0.113, d_loss_fake= 0.052, g_loss 3.113, d_loss 0.083\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 49/390 d_loss_real= 0.097, d_loss_fake= 0.072, g_loss 3.063, d_loss 0.084\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 32 Batch 50/390 d_loss_real= 0.127, d_loss_fake= 0.054, g_loss 3.090, d_loss 0.090\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 51/390 d_loss_real= 0.131, d_loss_fake= 0.061, g_loss 3.055, d_loss 0.096\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 52/390 d_loss_real= 0.092, d_loss_fake= 0.067, g_loss 3.074, d_loss 0.079\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 53/390 d_loss_real= 0.040, d_loss_fake= 0.067, g_loss 3.125, d_loss 0.053\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 54/390 d_loss_real= 0.225, d_loss_fake= 0.072, g_loss 3.132, d_loss 0.149\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 55/390 d_loss_real= 0.215, d_loss_fake= 0.057, g_loss 3.442, d_loss 0.136\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 56/390 d_loss_real= 0.260, d_loss_fake= 0.043, g_loss 3.470, d_loss 0.152\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 57/390 d_loss_real= 0.166, d_loss_fake= 0.033, g_loss 3.749, d_loss 0.100\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 58/390 d_loss_real= 0.064, d_loss_fake= 0.028, g_loss 3.944, d_loss 0.046\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 32 Batch 59/390 d_loss_real= 0.250, d_loss_fake= 0.024, g_loss 3.783, d_loss 0.137\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 60/390 d_loss_real= 0.255, d_loss_fake= 0.029, g_loss 3.516, d_loss 0.142\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 61/390 d_loss_real= 0.104, d_loss_fake= 0.041, g_loss 3.332, d_loss 0.073\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 62/390 d_loss_real= 0.301, d_loss_fake= 0.052, g_loss 3.132, d_loss 0.176\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 63/390 d_loss_real= 0.245, d_loss_fake= 0.058, g_loss 3.090, d_loss 0.152\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 64/390 d_loss_real= 0.048, d_loss_fake= 0.049, g_loss 3.409, d_loss 0.049\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 32 Batch 65/390 d_loss_real= 0.071, d_loss_fake= 0.032, g_loss 3.763, d_loss 0.051\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 66/390 d_loss_real= 0.157, d_loss_fake= 0.025, g_loss 3.852, d_loss 0.091\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 67/390 d_loss_real= 0.131, d_loss_fake= 0.025, g_loss 3.735, d_loss 0.078\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 68/390 d_loss_real= 0.060, d_loss_fake= 0.027, g_loss 3.713, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 69/390 d_loss_real= 0.142, d_loss_fake= 0.028, g_loss 3.651, d_loss 0.085\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 32 Batch 70/390 d_loss_real= 0.098, d_loss_fake= 0.029, g_loss 3.635, d_loss 0.064\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 71/390 d_loss_real= 0.265, d_loss_fake= 0.033, g_loss 3.584, d_loss 0.149\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 72/390 d_loss_real= 0.027, d_loss_fake= 0.038, g_loss 3.497, d_loss 0.032\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 32 Batch 73/390 d_loss_real= 0.072, d_loss_fake= 0.033, g_loss 3.624, d_loss 0.052\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 74/390 d_loss_real= 0.061, d_loss_fake= 0.028, g_loss 3.781, d_loss 0.044\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 32 Batch 75/390 d_loss_real= 0.100, d_loss_fake= 0.030, g_loss 3.690, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 76/390 d_loss_real= 0.052, d_loss_fake= 0.030, g_loss 3.732, d_loss 0.041\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 77/390 d_loss_real= 0.127, d_loss_fake= 0.030, g_loss 3.725, d_loss 0.078\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 32 Batch 78/390 d_loss_real= 0.157, d_loss_fake= 0.034, g_loss 3.734, d_loss 0.095\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 79/390 d_loss_real= 0.210, d_loss_fake= 0.037, g_loss 3.690, d_loss 0.124\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 80/390 d_loss_real= 0.006, d_loss_fake= 0.029, g_loss 3.750, d_loss 0.017\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 81/390 d_loss_real= 0.109, d_loss_fake= 0.029, g_loss 3.617, d_loss 0.069\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 32 Batch 82/390 d_loss_real= 0.104, d_loss_fake= 0.027, g_loss 3.860, d_loss 0.065\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 32 Batch 83/390 d_loss_real= 0.145, d_loss_fake= 0.023, g_loss 3.887, d_loss 0.084\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 84/390 d_loss_real= 0.233, d_loss_fake= 0.026, g_loss 3.893, d_loss 0.129\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 85/390 d_loss_real= 0.111, d_loss_fake= 0.023, g_loss 3.815, d_loss 0.067\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 86/390 d_loss_real= 0.087, d_loss_fake= 0.025, g_loss 3.824, d_loss 0.056\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 87/390 d_loss_real= 0.241, d_loss_fake= 0.030, g_loss 3.618, d_loss 0.136\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 32 Batch 88/390 d_loss_real= 0.119, d_loss_fake= 0.036, g_loss 3.383, d_loss 0.078\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 89/390 d_loss_real= 0.000, d_loss_fake= 0.043, g_loss 3.362, d_loss 0.021\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 90/390 d_loss_real= 0.148, d_loss_fake= 0.038, g_loss 3.347, d_loss 0.093\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 91/390 d_loss_real= 0.120, d_loss_fake= 0.037, g_loss 3.536, d_loss 0.078\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 32 Batch 92/390 d_loss_real= 0.146, d_loss_fake= 0.038, g_loss 3.520, d_loss 0.092\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 32 Batch 93/390 d_loss_real= 0.176, d_loss_fake= 0.035, g_loss 3.532, d_loss 0.106\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 32 Batch 94/390 d_loss_real= 0.217, d_loss_fake= 0.034, g_loss 3.460, d_loss 0.126\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 95/390 d_loss_real= 0.160, d_loss_fake= 0.041, g_loss 3.303, d_loss 0.100\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 96/390 d_loss_real= 0.104, d_loss_fake= 0.042, g_loss 3.283, d_loss 0.073\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 97/390 d_loss_real= 0.159, d_loss_fake= 0.040, g_loss 3.191, d_loss 0.099\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 98/390 d_loss_real= 0.088, d_loss_fake= 0.047, g_loss 3.020, d_loss 0.067\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 99/390 d_loss_real= 0.073, d_loss_fake= 0.085, g_loss 2.907, d_loss 0.079\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 100/390 d_loss_real= 0.127, d_loss_fake= 0.086, g_loss 3.052, d_loss 0.107\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 101/390 d_loss_real= 0.038, d_loss_fake= 0.048, g_loss 3.285, d_loss 0.043\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 102/390 d_loss_real= 0.087, d_loss_fake= 0.037, g_loss 3.420, d_loss 0.062\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 32 Batch 103/390 d_loss_real= 0.054, d_loss_fake= 0.033, g_loss 3.493, d_loss 0.043\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 32 Batch 104/390 d_loss_real= 0.114, d_loss_fake= 0.032, g_loss 3.536, d_loss 0.073\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 32 Batch 105/390 d_loss_real= 0.116, d_loss_fake= 0.035, g_loss 3.434, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 106/390 d_loss_real= 0.146, d_loss_fake= 0.038, g_loss 3.342, d_loss 0.092\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 107/390 d_loss_real= 0.301, d_loss_fake= 0.046, g_loss 3.035, d_loss 0.174\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 32 Batch 108/390 d_loss_real= 0.236, d_loss_fake= 0.071, g_loss 2.702, d_loss 0.153\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 109/390 d_loss_real= 0.120, d_loss_fake= 0.112, g_loss 2.463, d_loss 0.116\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 32 Batch 110/390 d_loss_real= 0.077, d_loss_fake= 0.137, g_loss 2.626, d_loss 0.107\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 111/390 d_loss_real= 0.180, d_loss_fake= 0.080, g_loss 2.804, d_loss 0.130\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 112/390 d_loss_real= 0.203, d_loss_fake= 0.068, g_loss 2.884, d_loss 0.135\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 113/390 d_loss_real= 0.037, d_loss_fake= 0.066, g_loss 2.865, d_loss 0.051\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 32 Batch 114/390 d_loss_real= 0.170, d_loss_fake= 0.065, g_loss 2.830, d_loss 0.118\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 115/390 d_loss_real= 0.086, d_loss_fake= 0.065, g_loss 2.826, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 116/390 d_loss_real= 0.283, d_loss_fake= 0.071, g_loss 2.739, d_loss 0.177\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 32 Batch 117/390 d_loss_real= 0.054, d_loss_fake= 0.073, g_loss 2.667, d_loss 0.064\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 118/390 d_loss_real= 0.071, d_loss_fake= 0.080, g_loss 2.626, d_loss 0.075\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 119/390 d_loss_real= 0.136, d_loss_fake= 0.084, g_loss 2.559, d_loss 0.110\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 32 Batch 120/390 d_loss_real= 0.071, d_loss_fake= 0.088, g_loss 2.523, d_loss 0.080\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 121/390 d_loss_real= 0.154, d_loss_fake= 0.094, g_loss 2.481, d_loss 0.124\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 32 Batch 122/390 d_loss_real= 0.070, d_loss_fake= 0.093, g_loss 2.509, d_loss 0.082\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 123/390 d_loss_real= 0.123, d_loss_fake= 0.092, g_loss 2.604, d_loss 0.108\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 32 Batch 124/390 d_loss_real= 0.018, d_loss_fake= 0.078, g_loss 2.713, d_loss 0.048\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 32 Batch 125/390 d_loss_real= 0.052, d_loss_fake= 0.073, g_loss 2.823, d_loss 0.062\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 32 Batch 126/390 d_loss_real= 0.089, d_loss_fake= 0.063, g_loss 2.882, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 127/390 d_loss_real= 0.083, d_loss_fake= 0.059, g_loss 2.985, d_loss 0.071\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 128/390 d_loss_real= 0.207, d_loss_fake= 0.057, g_loss 2.978, d_loss 0.132\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 129/390 d_loss_real= 0.066, d_loss_fake= 0.054, g_loss 3.013, d_loss 0.060\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 130/390 d_loss_real= 0.198, d_loss_fake= 0.056, g_loss 2.957, d_loss 0.127\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 32 Batch 131/390 d_loss_real= 0.300, d_loss_fake= 0.060, g_loss 2.883, d_loss 0.180\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 132/390 d_loss_real= 0.118, d_loss_fake= 0.063, g_loss 2.892, d_loss 0.091\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 133/390 d_loss_real= 0.042, d_loss_fake= 0.061, g_loss 2.865, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 134/390 d_loss_real= 0.107, d_loss_fake= 0.058, g_loss 2.930, d_loss 0.083\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 32 Batch 135/390 d_loss_real= 0.148, d_loss_fake= 0.060, g_loss 2.950, d_loss 0.104\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 136/390 d_loss_real= 0.455, d_loss_fake= 0.058, g_loss 2.913, d_loss 0.257\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 32 Batch 137/390 d_loss_real= 0.137, d_loss_fake= 0.071, g_loss 2.781, d_loss 0.104\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 32 Batch 138/390 d_loss_real= 0.070, d_loss_fake= 0.073, g_loss 2.816, d_loss 0.072\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 32 Batch 139/390 d_loss_real= 0.098, d_loss_fake= 0.063, g_loss 2.927, d_loss 0.081\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 32 Batch 140/390 d_loss_real= 0.321, d_loss_fake= 0.063, g_loss 2.828, d_loss 0.192\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 32 Batch 141/390 d_loss_real= 0.148, d_loss_fake= 0.063, g_loss 2.908, d_loss 0.106\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 142/390 d_loss_real= 0.059, d_loss_fake= 0.055, g_loss 2.918, d_loss 0.057\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 143/390 d_loss_real= 0.298, d_loss_fake= 0.065, g_loss 2.734, d_loss 0.181\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 144/390 d_loss_real= 0.143, d_loss_fake= 0.070, g_loss 2.685, d_loss 0.107\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 145/390 d_loss_real= 0.234, d_loss_fake= 0.080, g_loss 2.809, d_loss 0.157\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 32 Batch 146/390 d_loss_real= 0.002, d_loss_fake= 0.064, g_loss 2.951, d_loss 0.033\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 147/390 d_loss_real= 0.177, d_loss_fake= 0.056, g_loss 2.977, d_loss 0.117\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 148/390 d_loss_real= 0.097, d_loss_fake= 0.053, g_loss 3.061, d_loss 0.075\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 149/390 d_loss_real= 0.108, d_loss_fake= 0.049, g_loss 3.083, d_loss 0.079\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 150/390 d_loss_real= 0.052, d_loss_fake= 0.048, g_loss 3.079, d_loss 0.050\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 151/390 d_loss_real= 0.247, d_loss_fake= 0.052, g_loss 2.968, d_loss 0.149\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 32 Batch 152/390 d_loss_real= 0.067, d_loss_fake= 0.056, g_loss 2.892, d_loss 0.061\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 32 Batch 153/390 d_loss_real= 0.141, d_loss_fake= 0.064, g_loss 2.872, d_loss 0.102\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 32 Batch 154/390 d_loss_real= 0.176, d_loss_fake= 0.068, g_loss 2.713, d_loss 0.122\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 155/390 d_loss_real= 0.009, d_loss_fake= 0.073, g_loss 2.810, d_loss 0.041\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 32 Batch 156/390 d_loss_real= 0.067, d_loss_fake= 0.068, g_loss 2.968, d_loss 0.068\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 32 Batch 157/390 d_loss_real= 0.116, d_loss_fake= 0.048, g_loss 3.209, d_loss 0.082\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 32 Batch 158/390 d_loss_real= 0.038, d_loss_fake= 0.039, g_loss 3.339, d_loss 0.038\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 159/390 d_loss_real= 0.109, d_loss_fake= 0.036, g_loss 3.401, d_loss 0.072\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 32 Batch 160/390 d_loss_real= 0.067, d_loss_fake= 0.035, g_loss 3.452, d_loss 0.051\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 32 Batch 161/390 d_loss_real= 0.117, d_loss_fake= 0.034, g_loss 3.452, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 162/390 d_loss_real= 0.115, d_loss_fake= 0.035, g_loss 3.403, d_loss 0.075\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 163/390 d_loss_real= 0.173, d_loss_fake= 0.038, g_loss 3.246, d_loss 0.105\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 164/390 d_loss_real= 0.054, d_loss_fake= 0.044, g_loss 3.094, d_loss 0.049\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 32 Batch 165/390 d_loss_real= 0.254, d_loss_fake= 0.053, g_loss 3.039, d_loss 0.153\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 32 Batch 166/390 d_loss_real= 0.054, d_loss_fake= 0.050, g_loss 3.093, d_loss 0.052\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 32 Batch 167/390 d_loss_real= 0.103, d_loss_fake= 0.050, g_loss 3.172, d_loss 0.076\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 32 Batch 168/390 d_loss_real= 0.212, d_loss_fake= 0.046, g_loss 3.154, d_loss 0.129\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 169/390 d_loss_real= 0.094, d_loss_fake= 0.047, g_loss 3.088, d_loss 0.071\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 170/390 d_loss_real= 0.107, d_loss_fake= 0.058, g_loss 3.067, d_loss 0.082\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 32 Batch 171/390 d_loss_real= 0.227, d_loss_fake= 0.065, g_loss 3.042, d_loss 0.146\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 172/390 d_loss_real= 0.115, d_loss_fake= 0.053, g_loss 3.096, d_loss 0.084\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 32 Batch 173/390 d_loss_real= 0.048, d_loss_fake= 0.049, g_loss 3.314, d_loss 0.048\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 32 Batch 174/390 d_loss_real= 0.124, d_loss_fake= 0.038, g_loss 3.457, d_loss 0.081\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 32 Batch 175/390 d_loss_real= 0.160, d_loss_fake= 0.032, g_loss 3.524, d_loss 0.096\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 176/390 d_loss_real= 0.061, d_loss_fake= 0.030, g_loss 3.564, d_loss 0.046\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 177/390 d_loss_real= 0.182, d_loss_fake= 0.030, g_loss 3.508, d_loss 0.106\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 32 Batch 178/390 d_loss_real= 0.277, d_loss_fake= 0.035, g_loss 3.364, d_loss 0.156\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 179/390 d_loss_real= 0.082, d_loss_fake= 0.041, g_loss 3.140, d_loss 0.061\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 180/390 d_loss_real= 0.116, d_loss_fake= 0.076, g_loss 2.850, d_loss 0.096\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 32 Batch 181/390 d_loss_real= 0.139, d_loss_fake= 0.110, g_loss 3.064, d_loss 0.125\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 32 Batch 182/390 d_loss_real= 0.057, d_loss_fake= 0.038, g_loss 3.531, d_loss 0.048\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 183/390 d_loss_real= 0.193, d_loss_fake= 0.030, g_loss 3.611, d_loss 0.111\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 184/390 d_loss_real= 0.038, d_loss_fake= 0.030, g_loss 3.741, d_loss 0.034\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 185/390 d_loss_real= 0.272, d_loss_fake= 0.027, g_loss 3.666, d_loss 0.149\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 186/390 d_loss_real= 0.183, d_loss_fake= 0.032, g_loss 3.518, d_loss 0.107\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 32 Batch 187/390 d_loss_real= 0.152, d_loss_fake= 0.033, g_loss 3.527, d_loss 0.093\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 188/390 d_loss_real= 0.273, d_loss_fake= 0.036, g_loss 3.289, d_loss 0.155\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 189/390 d_loss_real= 0.041, d_loss_fake= 0.047, g_loss 3.040, d_loss 0.044\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 190/390 d_loss_real= 0.052, d_loss_fake= 0.072, g_loss 2.724, d_loss 0.062\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 191/390 d_loss_real= 0.035, d_loss_fake= 0.105, g_loss 2.644, d_loss 0.070\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 192/390 d_loss_real= 0.111, d_loss_fake= 0.081, g_loss 2.776, d_loss 0.096\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 193/390 d_loss_real= 0.142, d_loss_fake= 0.059, g_loss 3.185, d_loss 0.101\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 194/390 d_loss_real= 0.053, d_loss_fake= 0.040, g_loss 3.499, d_loss 0.047\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 195/390 d_loss_real= 0.095, d_loss_fake= 0.036, g_loss 3.484, d_loss 0.066\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 196/390 d_loss_real= 0.164, d_loss_fake= 0.034, g_loss 3.364, d_loss 0.099\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 197/390 d_loss_real= 0.084, d_loss_fake= 0.038, g_loss 3.301, d_loss 0.061\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 32 Batch 198/390 d_loss_real= 0.224, d_loss_fake= 0.045, g_loss 3.270, d_loss 0.135\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 199/390 d_loss_real= 0.041, d_loss_fake= 0.045, g_loss 3.107, d_loss 0.043\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 200/390 d_loss_real= 0.004, d_loss_fake= 0.053, g_loss 3.131, d_loss 0.029\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 32 Batch 201/390 d_loss_real= 0.188, d_loss_fake= 0.053, g_loss 3.161, d_loss 0.120\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 202/390 d_loss_real= 0.142, d_loss_fake= 0.041, g_loss 3.347, d_loss 0.092\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 203/390 d_loss_real= 0.102, d_loss_fake= 0.045, g_loss 3.191, d_loss 0.073\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 204/390 d_loss_real= 0.089, d_loss_fake= 0.049, g_loss 3.125, d_loss 0.069\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 32 Batch 205/390 d_loss_real= 0.096, d_loss_fake= 0.049, g_loss 3.167, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 206/390 d_loss_real= 0.056, d_loss_fake= 0.046, g_loss 3.278, d_loss 0.051\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 207/390 d_loss_real= 0.089, d_loss_fake= 0.040, g_loss 3.415, d_loss 0.065\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 208/390 d_loss_real= 0.056, d_loss_fake= 0.041, g_loss 3.285, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 209/390 d_loss_real= 0.112, d_loss_fake= 0.047, g_loss 3.201, d_loss 0.080\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 210/390 d_loss_real= 0.088, d_loss_fake= 0.056, g_loss 3.098, d_loss 0.072\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 211/390 d_loss_real= 0.098, d_loss_fake= 0.046, g_loss 3.312, d_loss 0.072\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 212/390 d_loss_real= 0.146, d_loss_fake= 0.040, g_loss 3.363, d_loss 0.093\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 213/390 d_loss_real= 0.089, d_loss_fake= 0.039, g_loss 3.358, d_loss 0.064\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 214/390 d_loss_real= 0.265, d_loss_fake= 0.037, g_loss 3.303, d_loss 0.151\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 215/390 d_loss_real= 0.246, d_loss_fake= 0.050, g_loss 3.190, d_loss 0.148\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 216/390 d_loss_real= 0.349, d_loss_fake= 0.086, g_loss 2.959, d_loss 0.218\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 217/390 d_loss_real= 0.196, d_loss_fake= 0.078, g_loss 3.005, d_loss 0.137\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 218/390 d_loss_real= 0.070, d_loss_fake= 0.043, g_loss 3.403, d_loss 0.056\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 219/390 d_loss_real= 0.167, d_loss_fake= 0.038, g_loss 3.434, d_loss 0.103\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 220/390 d_loss_real= 0.189, d_loss_fake= 0.042, g_loss 3.389, d_loss 0.115\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 221/390 d_loss_real= 0.294, d_loss_fake= 0.041, g_loss 3.201, d_loss 0.168\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 222/390 d_loss_real= 0.167, d_loss_fake= 0.058, g_loss 3.008, d_loss 0.112\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 223/390 d_loss_real= 0.287, d_loss_fake= 0.057, g_loss 2.851, d_loss 0.172\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 224/390 d_loss_real= 0.099, d_loss_fake= 0.077, g_loss 2.606, d_loss 0.088\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 225/390 d_loss_real= 0.116, d_loss_fake= 0.080, g_loss 2.739, d_loss 0.098\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 226/390 d_loss_real= 0.058, d_loss_fake= 0.083, g_loss 2.721, d_loss 0.071\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 227/390 d_loss_real= 0.144, d_loss_fake= 0.089, g_loss 2.713, d_loss 0.117\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 228/390 d_loss_real= 0.129, d_loss_fake= 0.099, g_loss 2.830, d_loss 0.114\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 229/390 d_loss_real= 0.093, d_loss_fake= 0.115, g_loss 2.860, d_loss 0.104\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 32 Batch 230/390 d_loss_real= 0.287, d_loss_fake= 0.114, g_loss 3.143, d_loss 0.201\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 231/390 d_loss_real= 0.413, d_loss_fake= 0.064, g_loss 3.385, d_loss 0.238\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 232/390 d_loss_real= 0.259, d_loss_fake= 0.065, g_loss 3.385, d_loss 0.162\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 32 Batch 233/390 d_loss_real= 0.402, d_loss_fake= 0.065, g_loss 3.246, d_loss 0.233\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 32 Batch 234/390 d_loss_real= 0.333, d_loss_fake= 0.067, g_loss 3.134, d_loss 0.200\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 32 Batch 235/390 d_loss_real= 0.233, d_loss_fake= 0.049, g_loss 3.196, d_loss 0.141\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 236/390 d_loss_real= 0.207, d_loss_fake= 0.038, g_loss 3.592, d_loss 0.122\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 237/390 d_loss_real= 0.207, d_loss_fake= 0.057, g_loss 3.153, d_loss 0.132\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 238/390 d_loss_real= 0.197, d_loss_fake= 0.054, g_loss 3.210, d_loss 0.126\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 239/390 d_loss_real= 0.162, d_loss_fake= 0.061, g_loss 3.141, d_loss 0.112\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 240/390 d_loss_real= 0.025, d_loss_fake= 0.083, g_loss 3.092, d_loss 0.054\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 241/390 d_loss_real= 0.360, d_loss_fake= 0.056, g_loss 3.285, d_loss 0.208\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 32 Batch 242/390 d_loss_real= 0.306, d_loss_fake= 0.050, g_loss 3.311, d_loss 0.178\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 32 Batch 243/390 d_loss_real= 0.083, d_loss_fake= 0.045, g_loss 3.352, d_loss 0.064\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 244/390 d_loss_real= 0.050, d_loss_fake= 0.039, g_loss 3.452, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 245/390 d_loss_real= 0.168, d_loss_fake= 0.039, g_loss 3.419, d_loss 0.104\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 246/390 d_loss_real= 0.112, d_loss_fake= 0.045, g_loss 3.269, d_loss 0.079\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 247/390 d_loss_real= 0.117, d_loss_fake= 0.095, g_loss 3.126, d_loss 0.106\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 248/390 d_loss_real= 0.005, d_loss_fake= 0.266, g_loss 4.156, d_loss 0.135\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 249/390 d_loss_real= 0.234, d_loss_fake= 0.012, g_loss 4.807, d_loss 0.123\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 32 Batch 250/390 d_loss_real= 0.911, d_loss_fake= 0.011, g_loss 4.623, d_loss 0.461\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 32 Batch 251/390 d_loss_real= 0.677, d_loss_fake= 0.015, g_loss 4.133, d_loss 0.346\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 32 Batch 252/390 d_loss_real= 0.444, d_loss_fake= 0.022, g_loss 3.840, d_loss 0.233\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 32 Batch 253/390 d_loss_real= 0.204, d_loss_fake= 0.028, g_loss 3.567, d_loss 0.116\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 254/390 d_loss_real= 0.206, d_loss_fake= 0.039, g_loss 2.994, d_loss 0.123\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 255/390 d_loss_real= 0.046, d_loss_fake= 0.369, g_loss 2.582, d_loss 0.208\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 256/390 d_loss_real= 0.069, d_loss_fake= 0.110, g_loss 3.479, d_loss 0.089\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 32 Batch 257/390 d_loss_real= 0.171, d_loss_fake= 0.030, g_loss 3.564, d_loss 0.101\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 32 Batch 258/390 d_loss_real= 0.046, d_loss_fake= 0.032, g_loss 3.486, d_loss 0.039\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 32 Batch 259/390 d_loss_real= 0.310, d_loss_fake= 0.034, g_loss 3.453, d_loss 0.172\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 260/390 d_loss_real= 0.319, d_loss_fake= 0.035, g_loss 3.358, d_loss 0.177\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 261/390 d_loss_real= 0.276, d_loss_fake= 0.038, g_loss 3.254, d_loss 0.157\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 262/390 d_loss_real= 0.404, d_loss_fake= 0.044, g_loss 3.141, d_loss 0.224\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 263/390 d_loss_real= 0.139, d_loss_fake= 0.049, g_loss 3.075, d_loss 0.094\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 264/390 d_loss_real= 0.194, d_loss_fake= 0.054, g_loss 2.985, d_loss 0.124\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 265/390 d_loss_real= 0.185, d_loss_fake= 0.058, g_loss 2.924, d_loss 0.121\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 32 Batch 266/390 d_loss_real= 0.074, d_loss_fake= 0.063, g_loss 2.871, d_loss 0.068\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 267/390 d_loss_real= 0.039, d_loss_fake= 0.070, g_loss 2.780, d_loss 0.054\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 268/390 d_loss_real= 0.112, d_loss_fake= 0.084, g_loss 2.514, d_loss 0.098\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 269/390 d_loss_real= 0.035, d_loss_fake= 0.535, g_loss 2.380, d_loss 0.285\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 32 Batch 270/390 d_loss_real= 0.042, d_loss_fake= 0.136, g_loss 2.752, d_loss 0.089\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 271/390 d_loss_real= 0.095, d_loss_fake= 0.078, g_loss 3.221, d_loss 0.087\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 32 Batch 272/390 d_loss_real= 0.349, d_loss_fake= 0.041, g_loss 3.404, d_loss 0.195\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 32 Batch 273/390 d_loss_real= 0.234, d_loss_fake= 0.044, g_loss 3.355, d_loss 0.139\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 274/390 d_loss_real= 0.392, d_loss_fake= 0.050, g_loss 3.166, d_loss 0.221\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 275/390 d_loss_real= 0.114, d_loss_fake= 0.056, g_loss 3.029, d_loss 0.085\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 276/390 d_loss_real= 0.453, d_loss_fake= 0.061, g_loss 2.875, d_loss 0.257\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 277/390 d_loss_real= 0.129, d_loss_fake= 0.068, g_loss 2.813, d_loss 0.098\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 278/390 d_loss_real= 0.139, d_loss_fake= 0.074, g_loss 2.723, d_loss 0.106\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 279/390 d_loss_real= 0.032, d_loss_fake= 0.087, g_loss 2.615, d_loss 0.059\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 280/390 d_loss_real= 0.100, d_loss_fake= 0.091, g_loss 2.495, d_loss 0.096\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 281/390 d_loss_real= 0.167, d_loss_fake= 0.125, g_loss 2.325, d_loss 0.146\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 32 Batch 282/390 d_loss_real= 0.035, d_loss_fake= 0.266, g_loss 1.893, d_loss 0.150\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 283/390 d_loss_real= 0.028, d_loss_fake= 0.595, g_loss 2.449, d_loss 0.312\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 32 Batch 284/390 d_loss_real= 0.117, d_loss_fake= 0.065, g_loss 3.382, d_loss 0.091\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 285/390 d_loss_real= 0.116, d_loss_fake= 0.035, g_loss 3.587, d_loss 0.076\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 286/390 d_loss_real= 0.139, d_loss_fake= 0.028, g_loss 3.725, d_loss 0.083\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 287/390 d_loss_real= 0.164, d_loss_fake= 0.028, g_loss 3.750, d_loss 0.096\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 32 Batch 288/390 d_loss_real= 0.270, d_loss_fake= 0.025, g_loss 3.747, d_loss 0.148\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 289/390 d_loss_real= 0.459, d_loss_fake= 0.026, g_loss 3.663, d_loss 0.242\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 290/390 d_loss_real= 0.518, d_loss_fake= 0.031, g_loss 3.514, d_loss 0.275\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 291/390 d_loss_real= 0.183, d_loss_fake= 0.033, g_loss 3.391, d_loss 0.108\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 292/390 d_loss_real= 0.363, d_loss_fake= 0.042, g_loss 3.173, d_loss 0.202\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 293/390 d_loss_real= 0.112, d_loss_fake= 0.049, g_loss 3.003, d_loss 0.081\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 294/390 d_loss_real= 0.131, d_loss_fake= 0.063, g_loss 2.828, d_loss 0.097\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 32 Batch 295/390 d_loss_real= 0.124, d_loss_fake= 0.077, g_loss 2.610, d_loss 0.100\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 296/390 d_loss_real= 0.001, d_loss_fake= 0.108, g_loss 2.473, d_loss 0.054\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 297/390 d_loss_real= 0.046, d_loss_fake= 0.161, g_loss 2.282, d_loss 0.103\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 298/390 d_loss_real= 0.050, d_loss_fake= 0.231, g_loss 2.518, d_loss 0.140\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 299/390 d_loss_real= 0.059, d_loss_fake= 0.083, g_loss 3.153, d_loss 0.071\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 32 Batch 300/390 d_loss_real= 0.090, d_loss_fake= 0.037, g_loss 3.474, d_loss 0.064\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 301/390 d_loss_real= 0.164, d_loss_fake= 0.033, g_loss 3.568, d_loss 0.099\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 32 Batch 302/390 d_loss_real= 0.376, d_loss_fake= 0.029, g_loss 3.610, d_loss 0.203\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 32 Batch 303/390 d_loss_real= 0.072, d_loss_fake= 0.029, g_loss 3.670, d_loss 0.050\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 32 Batch 304/390 d_loss_real= 0.222, d_loss_fake= 0.029, g_loss 3.627, d_loss 0.125\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 305/390 d_loss_real= 0.233, d_loss_fake= 0.029, g_loss 3.547, d_loss 0.131\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 306/390 d_loss_real= 0.361, d_loss_fake= 0.032, g_loss 3.405, d_loss 0.197\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 32 Batch 307/390 d_loss_real= 0.095, d_loss_fake= 0.039, g_loss 3.289, d_loss 0.067\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 308/390 d_loss_real= 0.051, d_loss_fake= 0.043, g_loss 3.083, d_loss 0.047\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 32 Batch 309/390 d_loss_real= 0.177, d_loss_fake= 0.062, g_loss 2.826, d_loss 0.120\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 32 Batch 310/390 d_loss_real= 0.132, d_loss_fake= 0.115, g_loss 2.811, d_loss 0.124\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 32 Batch 311/390 d_loss_real= 0.242, d_loss_fake= 0.085, g_loss 2.964, d_loss 0.164\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 312/390 d_loss_real= 0.047, d_loss_fake= 0.072, g_loss 3.187, d_loss 0.059\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 313/390 d_loss_real= 0.292, d_loss_fake= 0.043, g_loss 3.430, d_loss 0.168\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 314/390 d_loss_real= 0.040, d_loss_fake= 0.032, g_loss 3.521, d_loss 0.036\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 32 Batch 315/390 d_loss_real= 0.320, d_loss_fake= 0.032, g_loss 3.505, d_loss 0.176\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 316/390 d_loss_real= 0.086, d_loss_fake= 0.033, g_loss 3.430, d_loss 0.060\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 317/390 d_loss_real= 0.223, d_loss_fake= 0.035, g_loss 3.363, d_loss 0.129\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 318/390 d_loss_real= 0.077, d_loss_fake= 0.037, g_loss 3.298, d_loss 0.057\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 319/390 d_loss_real= 0.071, d_loss_fake= 0.048, g_loss 3.081, d_loss 0.059\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 320/390 d_loss_real= 0.184, d_loss_fake= 0.069, g_loss 3.032, d_loss 0.127\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 321/390 d_loss_real= 0.331, d_loss_fake= 0.099, g_loss 2.803, d_loss 0.215\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 322/390 d_loss_real= 0.100, d_loss_fake= 0.084, g_loss 3.118, d_loss 0.092\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 32 Batch 323/390 d_loss_real= 0.187, d_loss_fake= 0.049, g_loss 3.366, d_loss 0.118\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 324/390 d_loss_real= 0.012, d_loss_fake= 0.034, g_loss 3.527, d_loss 0.023\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 32 Batch 325/390 d_loss_real= 0.187, d_loss_fake= 0.030, g_loss 3.583, d_loss 0.108\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 326/390 d_loss_real= 0.221, d_loss_fake= 0.028, g_loss 3.588, d_loss 0.124\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 327/390 d_loss_real= 0.215, d_loss_fake= 0.029, g_loss 3.568, d_loss 0.122\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 328/390 d_loss_real= 0.109, d_loss_fake= 0.030, g_loss 3.480, d_loss 0.070\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 32 Batch 329/390 d_loss_real= 0.094, d_loss_fake= 0.034, g_loss 3.386, d_loss 0.064\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 330/390 d_loss_real= 0.199, d_loss_fake= 0.042, g_loss 3.178, d_loss 0.120\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 331/390 d_loss_real= 0.035, d_loss_fake= 0.051, g_loss 3.033, d_loss 0.043\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 332/390 d_loss_real= 0.080, d_loss_fake= 0.103, g_loss 2.785, d_loss 0.091\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 333/390 d_loss_real= 0.196, d_loss_fake= 0.075, g_loss 2.978, d_loss 0.135\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 334/390 d_loss_real= 0.103, d_loss_fake= 0.053, g_loss 3.239, d_loss 0.078\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 335/390 d_loss_real= 0.136, d_loss_fake= 0.037, g_loss 3.370, d_loss 0.086\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 32 Batch 336/390 d_loss_real= 0.046, d_loss_fake= 0.034, g_loss 3.462, d_loss 0.040\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 337/390 d_loss_real= 0.158, d_loss_fake= 0.033, g_loss 3.473, d_loss 0.095\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 32 Batch 338/390 d_loss_real= 0.273, d_loss_fake= 0.033, g_loss 3.378, d_loss 0.153\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 339/390 d_loss_real= 0.102, d_loss_fake= 0.037, g_loss 3.274, d_loss 0.069\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 340/390 d_loss_real= 0.300, d_loss_fake= 0.040, g_loss 3.239, d_loss 0.170\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 341/390 d_loss_real= 0.000, d_loss_fake= 0.051, g_loss 3.180, d_loss 0.025\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 342/390 d_loss_real= 0.158, d_loss_fake= 0.048, g_loss 3.091, d_loss 0.103\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 343/390 d_loss_real= 0.196, d_loss_fake= 0.054, g_loss 3.092, d_loss 0.125\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 344/390 d_loss_real= 0.124, d_loss_fake= 0.055, g_loss 3.094, d_loss 0.089\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 345/390 d_loss_real= 0.014, d_loss_fake= 0.055, g_loss 3.081, d_loss 0.035\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 346/390 d_loss_real= 0.097, d_loss_fake= 0.057, g_loss 3.161, d_loss 0.077\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 347/390 d_loss_real= 0.144, d_loss_fake= 0.044, g_loss 3.210, d_loss 0.094\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 348/390 d_loss_real= 0.093, d_loss_fake= 0.041, g_loss 3.296, d_loss 0.067\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 349/390 d_loss_real= 0.034, d_loss_fake= 0.041, g_loss 3.290, d_loss 0.037\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 32 Batch 350/390 d_loss_real= 0.157, d_loss_fake= 0.044, g_loss 3.291, d_loss 0.100\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 32 Batch 351/390 d_loss_real= 0.078, d_loss_fake= 0.038, g_loss 3.373, d_loss 0.058\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 352/390 d_loss_real= 0.067, d_loss_fake= 0.036, g_loss 3.443, d_loss 0.051\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32 Batch 353/390 d_loss_real= 0.123, d_loss_fake= 0.035, g_loss 3.419, d_loss 0.079\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 354/390 d_loss_real= 0.129, d_loss_fake= 0.036, g_loss 3.363, d_loss 0.082\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 32 Batch 355/390 d_loss_real= 0.197, d_loss_fake= 0.039, g_loss 3.318, d_loss 0.118\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 32 Batch 356/390 d_loss_real= 0.147, d_loss_fake= 0.059, g_loss 3.153, d_loss 0.103\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 357/390 d_loss_real= 0.003, d_loss_fake= 0.053, g_loss 3.225, d_loss 0.028\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 358/390 d_loss_real= 0.098, d_loss_fake= 0.053, g_loss 3.389, d_loss 0.076\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 359/390 d_loss_real= 0.167, d_loss_fake= 0.039, g_loss 3.478, d_loss 0.103\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 360/390 d_loss_real= 0.166, d_loss_fake= 0.031, g_loss 3.494, d_loss 0.099\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 361/390 d_loss_real= 0.193, d_loss_fake= 0.035, g_loss 3.495, d_loss 0.114\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 362/390 d_loss_real= 0.109, d_loss_fake= 0.040, g_loss 3.282, d_loss 0.074\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 363/390 d_loss_real= 0.192, d_loss_fake= 0.063, g_loss 3.136, d_loss 0.127\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 32 Batch 364/390 d_loss_real= 0.169, d_loss_fake= 0.056, g_loss 3.201, d_loss 0.113\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 365/390 d_loss_real= 0.163, d_loss_fake= 0.054, g_loss 3.297, d_loss 0.109\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32 Batch 366/390 d_loss_real= 0.315, d_loss_fake= 0.056, g_loss 3.274, d_loss 0.185\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 32 Batch 367/390 d_loss_real= 0.218, d_loss_fake= 0.053, g_loss 3.218, d_loss 0.136\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 32 Batch 368/390 d_loss_real= 0.195, d_loss_fake= 0.065, g_loss 3.096, d_loss 0.130\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 369/390 d_loss_real= 0.131, d_loss_fake= 0.095, g_loss 2.809, d_loss 0.113\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 32 Batch 370/390 d_loss_real= 0.124, d_loss_fake= 0.135, g_loss 2.861, d_loss 0.129\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 32 Batch 371/390 d_loss_real= 0.160, d_loss_fake= 0.073, g_loss 3.416, d_loss 0.116\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 372/390 d_loss_real= 0.309, d_loss_fake= 0.035, g_loss 3.863, d_loss 0.172\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 373/390 d_loss_real= 0.207, d_loss_fake= 0.028, g_loss 3.879, d_loss 0.118\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 374/390 d_loss_real= 0.122, d_loss_fake= 0.019, g_loss 4.060, d_loss 0.071\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 32 Batch 375/390 d_loss_real= 0.521, d_loss_fake= 0.017, g_loss 3.968, d_loss 0.269\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 376/390 d_loss_real= 0.357, d_loss_fake= 0.032, g_loss 3.326, d_loss 0.194\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 377/390 d_loss_real= 0.164, d_loss_fake= 0.043, g_loss 3.188, d_loss 0.103\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 378/390 d_loss_real= 0.090, d_loss_fake= 0.037, g_loss 3.375, d_loss 0.063\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 379/390 d_loss_real= 0.179, d_loss_fake= 0.052, g_loss 3.088, d_loss 0.115\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 380/390 d_loss_real= 0.232, d_loss_fake= 0.085, g_loss 3.206, d_loss 0.158\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32 Batch 381/390 d_loss_real= 0.070, d_loss_fake= 0.041, g_loss 3.715, d_loss 0.055\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 382/390 d_loss_real= 0.224, d_loss_fake= 0.023, g_loss 4.128, d_loss 0.123\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 32 Batch 383/390 d_loss_real= 0.112, d_loss_fake= 0.017, g_loss 4.282, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 384/390 d_loss_real= 0.162, d_loss_fake= 0.014, g_loss 4.350, d_loss 0.088\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 32 Batch 385/390 d_loss_real= 0.148, d_loss_fake= 0.015, g_loss 4.251, d_loss 0.082\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 386/390 d_loss_real= 0.139, d_loss_fake= 0.016, g_loss 4.141, d_loss 0.077\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32 Batch 387/390 d_loss_real= 0.105, d_loss_fake= 0.019, g_loss 3.989, d_loss 0.062\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 388/390 d_loss_real= 0.016, d_loss_fake= 0.023, g_loss 3.770, d_loss 0.020\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32 Batch 389/390 d_loss_real= 0.057, d_loss_fake= 0.031, g_loss 3.673, d_loss 0.044\n",
            "2/2 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32 Batch 390/390 d_loss_real= 0.053, d_loss_fake= 0.031, g_loss 3.655, d_loss 0.042\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 1/390 d_loss_real= 0.120, d_loss_fake= 0.036, g_loss 3.683, d_loss 0.078\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 2/390 d_loss_real= 0.124, d_loss_fake= 0.030, g_loss 3.802, d_loss 0.077\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 3/390 d_loss_real= 0.191, d_loss_fake= 0.025, g_loss 3.858, d_loss 0.108\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 4/390 d_loss_real= 0.078, d_loss_fake= 0.026, g_loss 3.881, d_loss 0.052\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 33 Batch 5/390 d_loss_real= 0.092, d_loss_fake= 0.022, g_loss 3.881, d_loss 0.057\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 6/390 d_loss_real= 0.201, d_loss_fake= 0.024, g_loss 3.909, d_loss 0.112\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 33 Batch 7/390 d_loss_real= 0.047, d_loss_fake= 0.023, g_loss 3.898, d_loss 0.035\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 8/390 d_loss_real= 0.084, d_loss_fake= 0.021, g_loss 3.993, d_loss 0.053\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 33 Batch 9/390 d_loss_real= 0.067, d_loss_fake= 0.020, g_loss 3.991, d_loss 0.043\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 33 Batch 10/390 d_loss_real= 0.102, d_loss_fake= 0.020, g_loss 3.930, d_loss 0.061\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 33 Batch 11/390 d_loss_real= 0.091, d_loss_fake= 0.021, g_loss 3.872, d_loss 0.056\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 12/390 d_loss_real= 0.102, d_loss_fake= 0.023, g_loss 3.734, d_loss 0.062\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 13/390 d_loss_real= 0.055, d_loss_fake= 0.033, g_loss 3.668, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 14/390 d_loss_real= 0.153, d_loss_fake= 0.038, g_loss 3.635, d_loss 0.096\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 15/390 d_loss_real= 0.056, d_loss_fake= 0.030, g_loss 3.682, d_loss 0.043\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 16/390 d_loss_real= 0.136, d_loss_fake= 0.026, g_loss 3.813, d_loss 0.081\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 33 Batch 17/390 d_loss_real= 0.105, d_loss_fake= 0.029, g_loss 3.776, d_loss 0.067\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 33 Batch 18/390 d_loss_real= 0.047, d_loss_fake= 0.025, g_loss 3.944, d_loss 0.036\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 33 Batch 19/390 d_loss_real= 0.136, d_loss_fake= 0.021, g_loss 4.007, d_loss 0.078\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 33 Batch 20/390 d_loss_real= 0.104, d_loss_fake= 0.020, g_loss 4.023, d_loss 0.062\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 21/390 d_loss_real= 0.092, d_loss_fake= 0.019, g_loss 3.976, d_loss 0.055\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 33 Batch 22/390 d_loss_real= 0.002, d_loss_fake= 0.020, g_loss 4.035, d_loss 0.011\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 33 Batch 23/390 d_loss_real= 0.070, d_loss_fake= 0.021, g_loss 4.000, d_loss 0.045\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 33 Batch 24/390 d_loss_real= 0.105, d_loss_fake= 0.023, g_loss 3.838, d_loss 0.064\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 33 Batch 25/390 d_loss_real= 0.046, d_loss_fake= 0.024, g_loss 3.765, d_loss 0.035\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 33 Batch 26/390 d_loss_real= 0.130, d_loss_fake= 0.031, g_loss 3.559, d_loss 0.081\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 27/390 d_loss_real= 0.042, d_loss_fake= 0.036, g_loss 3.373, d_loss 0.039\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 33 Batch 28/390 d_loss_real= 0.000, d_loss_fake= 0.042, g_loss 3.293, d_loss 0.021\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 33 Batch 29/390 d_loss_real= 0.065, d_loss_fake= 0.046, g_loss 3.259, d_loss 0.056\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 33 Batch 30/390 d_loss_real= 0.084, d_loss_fake= 0.048, g_loss 3.230, d_loss 0.066\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 33 Batch 31/390 d_loss_real= 0.185, d_loss_fake= 0.051, g_loss 3.180, d_loss 0.118\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 32/390 d_loss_real= 0.071, d_loss_fake= 0.057, g_loss 3.135, d_loss 0.064\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 33/390 d_loss_real= 0.098, d_loss_fake= 0.061, g_loss 3.211, d_loss 0.080\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 34/390 d_loss_real= 0.065, d_loss_fake= 0.066, g_loss 3.328, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 35/390 d_loss_real= 0.106, d_loss_fake= 0.058, g_loss 3.356, d_loss 0.082\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 33 Batch 36/390 d_loss_real= 0.052, d_loss_fake= 0.057, g_loss 3.274, d_loss 0.054\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 37/390 d_loss_real= 0.204, d_loss_fake= 0.058, g_loss 3.237, d_loss 0.131\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 33 Batch 38/390 d_loss_real= 0.108, d_loss_fake= 0.060, g_loss 3.307, d_loss 0.084\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 39/390 d_loss_real= 0.260, d_loss_fake= 0.052, g_loss 3.282, d_loss 0.156\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 40/390 d_loss_real= 0.179, d_loss_fake= 0.055, g_loss 3.275, d_loss 0.117\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 33 Batch 41/390 d_loss_real= 0.077, d_loss_fake= 0.049, g_loss 3.301, d_loss 0.063\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 42/390 d_loss_real= 0.194, d_loss_fake= 0.052, g_loss 3.177, d_loss 0.123\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 43/390 d_loss_real= 0.325, d_loss_fake= 0.056, g_loss 2.973, d_loss 0.191\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 33 Batch 44/390 d_loss_real= 0.212, d_loss_fake= 0.079, g_loss 2.696, d_loss 0.146\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 33 Batch 45/390 d_loss_real= 0.235, d_loss_fake= 0.098, g_loss 2.475, d_loss 0.167\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 33 Batch 46/390 d_loss_real= 0.094, d_loss_fake= 0.109, g_loss 2.288, d_loss 0.102\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 33 Batch 47/390 d_loss_real= 0.120, d_loss_fake= 0.130, g_loss 2.209, d_loss 0.125\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 48/390 d_loss_real= 0.104, d_loss_fake= 0.138, g_loss 2.190, d_loss 0.121\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 49/390 d_loss_real= 0.038, d_loss_fake= 0.142, g_loss 2.282, d_loss 0.090\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 33 Batch 50/390 d_loss_real= 0.037, d_loss_fake= 0.118, g_loss 2.498, d_loss 0.078\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 51/390 d_loss_real= 0.073, d_loss_fake= 0.087, g_loss 2.718, d_loss 0.080\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 33 Batch 52/390 d_loss_real= 0.088, d_loss_fake= 0.072, g_loss 2.853, d_loss 0.080\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 33 Batch 53/390 d_loss_real= 0.231, d_loss_fake= 0.062, g_loss 3.008, d_loss 0.146\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 54/390 d_loss_real= 0.008, d_loss_fake= 0.055, g_loss 3.040, d_loss 0.031\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 55/390 d_loss_real= 0.064, d_loss_fake= 0.051, g_loss 3.135, d_loss 0.058\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 56/390 d_loss_real= 0.149, d_loss_fake= 0.049, g_loss 3.218, d_loss 0.099\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 57/390 d_loss_real= 0.205, d_loss_fake= 0.045, g_loss 3.117, d_loss 0.125\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 58/390 d_loss_real= 0.129, d_loss_fake= 0.054, g_loss 2.941, d_loss 0.091\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 33 Batch 59/390 d_loss_real= 0.175, d_loss_fake= 0.073, g_loss 2.823, d_loss 0.124\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 60/390 d_loss_real= 0.154, d_loss_fake= 0.105, g_loss 2.940, d_loss 0.130\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 61/390 d_loss_real= 0.001, d_loss_fake= 0.054, g_loss 3.339, d_loss 0.028\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 62/390 d_loss_real= 0.103, d_loss_fake= 0.038, g_loss 3.518, d_loss 0.070\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 63/390 d_loss_real= 0.063, d_loss_fake= 0.028, g_loss 3.687, d_loss 0.046\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 64/390 d_loss_real= 0.075, d_loss_fake= 0.025, g_loss 3.793, d_loss 0.050\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 65/390 d_loss_real= 0.139, d_loss_fake= 0.023, g_loss 3.761, d_loss 0.081\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 33 Batch 66/390 d_loss_real= 0.221, d_loss_fake= 0.025, g_loss 3.692, d_loss 0.123\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 67/390 d_loss_real= 0.290, d_loss_fake= 0.030, g_loss 3.402, d_loss 0.160\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 68/390 d_loss_real= 0.111, d_loss_fake= 0.044, g_loss 3.131, d_loss 0.078\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 33 Batch 69/390 d_loss_real= 0.190, d_loss_fake= 0.065, g_loss 2.875, d_loss 0.128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 70/390 d_loss_real= 0.043, d_loss_fake= 0.065, g_loss 2.821, d_loss 0.054\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 71/390 d_loss_real= 0.079, d_loss_fake= 0.069, g_loss 3.117, d_loss 0.074\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 33 Batch 72/390 d_loss_real= 0.049, d_loss_fake= 0.064, g_loss 3.233, d_loss 0.057\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 73/390 d_loss_real= 0.245, d_loss_fake= 0.037, g_loss 3.492, d_loss 0.141\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 33 Batch 74/390 d_loss_real= 0.052, d_loss_fake= 0.036, g_loss 3.595, d_loss 0.044\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 33 Batch 75/390 d_loss_real= 0.187, d_loss_fake= 0.029, g_loss 3.642, d_loss 0.108\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 76/390 d_loss_real= 0.228, d_loss_fake= 0.029, g_loss 3.627, d_loss 0.129\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 77/390 d_loss_real= 0.211, d_loss_fake= 0.033, g_loss 3.511, d_loss 0.122\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 78/390 d_loss_real= 0.165, d_loss_fake= 0.032, g_loss 3.395, d_loss 0.099\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 33 Batch 79/390 d_loss_real= 0.328, d_loss_fake= 0.044, g_loss 3.089, d_loss 0.186\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 33 Batch 80/390 d_loss_real= 0.144, d_loss_fake= 0.065, g_loss 2.792, d_loss 0.105\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 81/390 d_loss_real= 0.032, d_loss_fake= 0.087, g_loss 2.667, d_loss 0.060\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 33 Batch 82/390 d_loss_real= 0.174, d_loss_fake= 0.071, g_loss 2.965, d_loss 0.122\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 83/390 d_loss_real= 0.122, d_loss_fake= 0.069, g_loss 2.931, d_loss 0.095\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 84/390 d_loss_real= 0.144, d_loss_fake= 0.059, g_loss 3.119, d_loss 0.101\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 85/390 d_loss_real= 0.351, d_loss_fake= 0.055, g_loss 3.262, d_loss 0.203\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 33 Batch 86/390 d_loss_real= 0.075, d_loss_fake= 0.043, g_loss 3.325, d_loss 0.059\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 33 Batch 87/390 d_loss_real= 0.142, d_loss_fake= 0.043, g_loss 3.489, d_loss 0.093\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 33 Batch 88/390 d_loss_real= 0.153, d_loss_fake= 0.034, g_loss 3.478, d_loss 0.093\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 89/390 d_loss_real= 0.378, d_loss_fake= 0.035, g_loss 3.477, d_loss 0.207\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 33 Batch 90/390 d_loss_real= 0.072, d_loss_fake= 0.039, g_loss 3.335, d_loss 0.056\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 91/390 d_loss_real= 0.219, d_loss_fake= 0.044, g_loss 3.203, d_loss 0.132\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 92/390 d_loss_real= 0.114, d_loss_fake= 0.055, g_loss 3.021, d_loss 0.085\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 33 Batch 93/390 d_loss_real= 0.104, d_loss_fake= 0.069, g_loss 2.939, d_loss 0.086\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 33 Batch 94/390 d_loss_real= 0.139, d_loss_fake= 0.071, g_loss 2.905, d_loss 0.105\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 95/390 d_loss_real= 0.195, d_loss_fake= 0.070, g_loss 2.937, d_loss 0.132\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 33 Batch 96/390 d_loss_real= 0.038, d_loss_fake= 0.057, g_loss 3.040, d_loss 0.047\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 33 Batch 97/390 d_loss_real= 0.208, d_loss_fake= 0.053, g_loss 3.177, d_loss 0.131\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 33 Batch 98/390 d_loss_real= 0.130, d_loss_fake= 0.047, g_loss 3.300, d_loss 0.088\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 99/390 d_loss_real= 0.203, d_loss_fake= 0.044, g_loss 3.236, d_loss 0.123\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 100/390 d_loss_real= 0.228, d_loss_fake= 0.041, g_loss 3.299, d_loss 0.134\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 101/390 d_loss_real= 0.041, d_loss_fake= 0.045, g_loss 3.310, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 102/390 d_loss_real= 0.039, d_loss_fake= 0.045, g_loss 3.223, d_loss 0.042\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 33 Batch 103/390 d_loss_real= 0.193, d_loss_fake= 0.051, g_loss 3.154, d_loss 0.122\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 104/390 d_loss_real= 0.135, d_loss_fake= 0.051, g_loss 3.115, d_loss 0.093\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 105/390 d_loss_real= 0.106, d_loss_fake= 0.049, g_loss 3.038, d_loss 0.077\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 33 Batch 106/390 d_loss_real= 0.051, d_loss_fake= 0.058, g_loss 3.041, d_loss 0.055\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 107/390 d_loss_real= 0.000, d_loss_fake= 0.052, g_loss 3.184, d_loss 0.026\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 33 Batch 108/390 d_loss_real= 0.012, d_loss_fake= 0.046, g_loss 3.267, d_loss 0.029\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 33 Batch 109/390 d_loss_real= 0.137, d_loss_fake= 0.037, g_loss 3.407, d_loss 0.087\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 110/390 d_loss_real= 0.125, d_loss_fake= 0.033, g_loss 3.541, d_loss 0.079\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 111/390 d_loss_real= 0.124, d_loss_fake= 0.033, g_loss 3.580, d_loss 0.079\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 33 Batch 112/390 d_loss_real= 0.080, d_loss_fake= 0.030, g_loss 3.587, d_loss 0.055\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 113/390 d_loss_real= 0.011, d_loss_fake= 0.031, g_loss 3.569, d_loss 0.021\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 114/390 d_loss_real= 0.314, d_loss_fake= 0.033, g_loss 3.496, d_loss 0.174\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 115/390 d_loss_real= 0.048, d_loss_fake= 0.038, g_loss 3.381, d_loss 0.043\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 116/390 d_loss_real= 0.069, d_loss_fake= 0.041, g_loss 3.288, d_loss 0.055\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 33 Batch 117/390 d_loss_real= 0.205, d_loss_fake= 0.051, g_loss 3.060, d_loss 0.128\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 118/390 d_loss_real= 0.095, d_loss_fake= 0.059, g_loss 2.879, d_loss 0.077\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 119/390 d_loss_real= 0.078, d_loss_fake= 0.062, g_loss 3.139, d_loss 0.070\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 120/390 d_loss_real= 0.138, d_loss_fake= 0.054, g_loss 3.163, d_loss 0.096\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 121/390 d_loss_real= 0.084, d_loss_fake= 0.049, g_loss 3.261, d_loss 0.066\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 122/390 d_loss_real= 0.069, d_loss_fake= 0.048, g_loss 3.228, d_loss 0.058\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 123/390 d_loss_real= 0.090, d_loss_fake= 0.045, g_loss 3.328, d_loss 0.068\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 33 Batch 124/390 d_loss_real= 0.062, d_loss_fake= 0.044, g_loss 3.273, d_loss 0.053\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 33 Batch 125/390 d_loss_real= 0.134, d_loss_fake= 0.047, g_loss 3.253, d_loss 0.091\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 126/390 d_loss_real= 0.108, d_loss_fake= 0.045, g_loss 3.294, d_loss 0.076\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 33 Batch 127/390 d_loss_real= 0.022, d_loss_fake= 0.043, g_loss 3.314, d_loss 0.033\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 33 Batch 128/390 d_loss_real= 0.144, d_loss_fake= 0.043, g_loss 3.230, d_loss 0.093\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 33 Batch 129/390 d_loss_real= 0.114, d_loss_fake= 0.046, g_loss 3.204, d_loss 0.080\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 33 Batch 130/390 d_loss_real= 0.211, d_loss_fake= 0.048, g_loss 3.225, d_loss 0.129\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 131/390 d_loss_real= 0.193, d_loss_fake= 0.054, g_loss 3.031, d_loss 0.123\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 33 Batch 132/390 d_loss_real= 0.126, d_loss_fake= 0.064, g_loss 3.138, d_loss 0.095\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 133/390 d_loss_real= 0.056, d_loss_fake= 0.051, g_loss 3.214, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 134/390 d_loss_real= 0.240, d_loss_fake= 0.047, g_loss 3.218, d_loss 0.144\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 135/390 d_loss_real= 0.099, d_loss_fake= 0.043, g_loss 3.305, d_loss 0.071\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 33 Batch 136/390 d_loss_real= 0.077, d_loss_fake= 0.047, g_loss 3.219, d_loss 0.062\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 33 Batch 137/390 d_loss_real= 0.203, d_loss_fake= 0.051, g_loss 3.033, d_loss 0.127\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 138/390 d_loss_real= 0.096, d_loss_fake= 0.069, g_loss 2.925, d_loss 0.082\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 139/390 d_loss_real= 0.325, d_loss_fake= 0.107, g_loss 2.614, d_loss 0.216\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 33 Batch 140/390 d_loss_real= 0.228, d_loss_fake= 0.140, g_loss 2.529, d_loss 0.184\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 33 Batch 141/390 d_loss_real= 0.191, d_loss_fake= 0.108, g_loss 2.979, d_loss 0.150\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 33 Batch 142/390 d_loss_real= 0.280, d_loss_fake= 0.049, g_loss 3.461, d_loss 0.164\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 33 Batch 143/390 d_loss_real= 0.250, d_loss_fake= 0.031, g_loss 3.643, d_loss 0.141\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 144/390 d_loss_real= 0.308, d_loss_fake= 0.032, g_loss 3.612, d_loss 0.170\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 145/390 d_loss_real= 0.329, d_loss_fake= 0.036, g_loss 3.358, d_loss 0.182\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 146/390 d_loss_real= 0.279, d_loss_fake= 0.051, g_loss 2.999, d_loss 0.165\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 33 Batch 147/390 d_loss_real= 0.121, d_loss_fake= 0.084, g_loss 2.628, d_loss 0.103\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 148/390 d_loss_real= 0.120, d_loss_fake= 0.155, g_loss 2.802, d_loss 0.138\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 33 Batch 149/390 d_loss_real= 0.131, d_loss_fake= 0.041, g_loss 3.987, d_loss 0.086\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 33 Batch 150/390 d_loss_real= 0.101, d_loss_fake= 0.009, g_loss 4.975, d_loss 0.055\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 33 Batch 151/390 d_loss_real= 0.102, d_loss_fake= 0.008, g_loss 4.875, d_loss 0.055\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 152/390 d_loss_real= 0.103, d_loss_fake= 0.011, g_loss 4.568, d_loss 0.057\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 33 Batch 153/390 d_loss_real= 0.289, d_loss_fake= 0.014, g_loss 4.301, d_loss 0.152\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 154/390 d_loss_real= 0.220, d_loss_fake= 0.017, g_loss 4.034, d_loss 0.118\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 33 Batch 155/390 d_loss_real= 0.250, d_loss_fake= 0.022, g_loss 3.852, d_loss 0.136\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 156/390 d_loss_real= 0.317, d_loss_fake= 0.025, g_loss 3.659, d_loss 0.171\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 33 Batch 157/390 d_loss_real= 0.131, d_loss_fake= 0.030, g_loss 3.575, d_loss 0.081\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 33 Batch 158/390 d_loss_real= 0.056, d_loss_fake= 0.036, g_loss 3.345, d_loss 0.046\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 159/390 d_loss_real= 0.071, d_loss_fake= 0.042, g_loss 3.212, d_loss 0.056\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 160/390 d_loss_real= 0.094, d_loss_fake= 0.046, g_loss 3.071, d_loss 0.070\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 33 Batch 161/390 d_loss_real= 0.001, d_loss_fake= 0.053, g_loss 3.020, d_loss 0.027\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 162/390 d_loss_real= 0.158, d_loss_fake= 0.058, g_loss 2.899, d_loss 0.108\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 33 Batch 163/390 d_loss_real= 0.055, d_loss_fake= 0.070, g_loss 2.762, d_loss 0.062\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 33 Batch 164/390 d_loss_real= 0.010, d_loss_fake= 0.089, g_loss 2.619, d_loss 0.050\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 165/390 d_loss_real= 0.001, d_loss_fake= 0.170, g_loss 2.467, d_loss 0.085\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 33 Batch 166/390 d_loss_real= 0.002, d_loss_fake= 0.293, g_loss 2.819, d_loss 0.147\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 33 Batch 167/390 d_loss_real= 0.143, d_loss_fake= 0.062, g_loss 3.536, d_loss 0.102\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 33 Batch 168/390 d_loss_real= 0.098, d_loss_fake= 0.030, g_loss 3.703, d_loss 0.064\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 169/390 d_loss_real= 0.180, d_loss_fake= 0.027, g_loss 3.710, d_loss 0.104\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 170/390 d_loss_real= 0.113, d_loss_fake= 0.025, g_loss 3.710, d_loss 0.069\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 171/390 d_loss_real= 0.284, d_loss_fake= 0.027, g_loss 3.750, d_loss 0.155\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 172/390 d_loss_real= 0.283, d_loss_fake= 0.028, g_loss 3.611, d_loss 0.156\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 33 Batch 173/390 d_loss_real= 0.395, d_loss_fake= 0.033, g_loss 3.507, d_loss 0.214\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 174/390 d_loss_real= 0.214, d_loss_fake= 0.036, g_loss 3.290, d_loss 0.125\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 33 Batch 175/390 d_loss_real= 0.152, d_loss_fake= 0.044, g_loss 3.064, d_loss 0.098\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 33 Batch 176/390 d_loss_real= 0.172, d_loss_fake= 0.063, g_loss 2.743, d_loss 0.117\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 177/390 d_loss_real= 0.083, d_loss_fake= 0.157, g_loss 2.468, d_loss 0.120\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 178/390 d_loss_real= 0.100, d_loss_fake= 0.367, g_loss 2.769, d_loss 0.234\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 33 Batch 179/390 d_loss_real= 0.079, d_loss_fake= 0.049, g_loss 3.364, d_loss 0.064\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 180/390 d_loss_real= 0.208, d_loss_fake= 0.036, g_loss 3.490, d_loss 0.122\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 33 Batch 181/390 d_loss_real= 0.337, d_loss_fake= 0.031, g_loss 3.545, d_loss 0.184\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 33 Batch 182/390 d_loss_real= 0.216, d_loss_fake= 0.030, g_loss 3.509, d_loss 0.123\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 183/390 d_loss_real= 0.429, d_loss_fake= 0.032, g_loss 3.445, d_loss 0.231\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 33 Batch 184/390 d_loss_real= 0.025, d_loss_fake= 0.035, g_loss 3.403, d_loss 0.030\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 185/390 d_loss_real= 0.210, d_loss_fake= 0.038, g_loss 3.310, d_loss 0.124\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 186/390 d_loss_real= 0.200, d_loss_fake= 0.043, g_loss 3.095, d_loss 0.122\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 33 Batch 187/390 d_loss_real= 0.111, d_loss_fake= 0.057, g_loss 2.736, d_loss 0.084\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 33 Batch 188/390 d_loss_real= 0.090, d_loss_fake= 0.112, g_loss 2.232, d_loss 0.101\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 33 Batch 189/390 d_loss_real= 0.100, d_loss_fake= 0.238, g_loss 2.588, d_loss 0.169\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 33 Batch 190/390 d_loss_real= 0.111, d_loss_fake= 0.067, g_loss 3.118, d_loss 0.089\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 33 Batch 191/390 d_loss_real= 0.104, d_loss_fake= 0.045, g_loss 3.273, d_loss 0.074\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 33 Batch 192/390 d_loss_real= 0.064, d_loss_fake= 0.037, g_loss 3.351, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 193/390 d_loss_real= 0.081, d_loss_fake= 0.037, g_loss 3.405, d_loss 0.059\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 33 Batch 194/390 d_loss_real= 0.243, d_loss_fake= 0.037, g_loss 3.387, d_loss 0.140\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 33 Batch 195/390 d_loss_real= 0.107, d_loss_fake= 0.042, g_loss 3.297, d_loss 0.074\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 196/390 d_loss_real= 0.198, d_loss_fake= 0.039, g_loss 3.281, d_loss 0.119\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 33 Batch 197/390 d_loss_real= 0.175, d_loss_fake= 0.043, g_loss 3.170, d_loss 0.109\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 198/390 d_loss_real= 0.197, d_loss_fake= 0.045, g_loss 3.102, d_loss 0.121\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 199/390 d_loss_real= 0.187, d_loss_fake= 0.050, g_loss 3.012, d_loss 0.119\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 200/390 d_loss_real= 0.299, d_loss_fake= 0.058, g_loss 2.864, d_loss 0.179\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 33 Batch 201/390 d_loss_real= 0.000, d_loss_fake= 0.068, g_loss 2.722, d_loss 0.034\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 202/390 d_loss_real= 0.206, d_loss_fake= 0.077, g_loss 2.613, d_loss 0.142\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 203/390 d_loss_real= 0.064, d_loss_fake= 0.104, g_loss 2.445, d_loss 0.084\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 33 Batch 204/390 d_loss_real= 0.103, d_loss_fake= 0.151, g_loss 2.649, d_loss 0.127\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 205/390 d_loss_real= 0.214, d_loss_fake= 0.084, g_loss 2.891, d_loss 0.149\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 33 Batch 206/390 d_loss_real= 0.278, d_loss_fake= 0.054, g_loss 3.065, d_loss 0.166\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 33 Batch 207/390 d_loss_real= 0.082, d_loss_fake= 0.047, g_loss 3.303, d_loss 0.064\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 33 Batch 208/390 d_loss_real= 0.158, d_loss_fake= 0.038, g_loss 3.372, d_loss 0.098\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 209/390 d_loss_real= 0.173, d_loss_fake= 0.034, g_loss 3.406, d_loss 0.104\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 210/390 d_loss_real= 0.295, d_loss_fake= 0.035, g_loss 3.373, d_loss 0.165\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 33 Batch 211/390 d_loss_real= 0.003, d_loss_fake= 0.035, g_loss 3.371, d_loss 0.019\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 212/390 d_loss_real= 0.126, d_loss_fake= 0.036, g_loss 3.333, d_loss 0.081\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 213/390 d_loss_real= 0.178, d_loss_fake= 0.038, g_loss 3.310, d_loss 0.108\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 33 Batch 214/390 d_loss_real= 0.045, d_loss_fake= 0.040, g_loss 3.305, d_loss 0.042\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 215/390 d_loss_real= 0.112, d_loss_fake= 0.042, g_loss 3.282, d_loss 0.077\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 33 Batch 216/390 d_loss_real= 0.103, d_loss_fake= 0.046, g_loss 3.187, d_loss 0.074\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 217/390 d_loss_real= 0.282, d_loss_fake= 0.049, g_loss 3.023, d_loss 0.165\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 33 Batch 218/390 d_loss_real= 0.047, d_loss_fake= 0.086, g_loss 2.835, d_loss 0.066\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 33 Batch 219/390 d_loss_real= 0.006, d_loss_fake= 0.074, g_loss 2.930, d_loss 0.040\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 33 Batch 220/390 d_loss_real= 0.117, d_loss_fake= 0.057, g_loss 3.120, d_loss 0.087\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 221/390 d_loss_real= 0.214, d_loss_fake= 0.050, g_loss 3.205, d_loss 0.132\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 222/390 d_loss_real= 0.050, d_loss_fake= 0.048, g_loss 3.360, d_loss 0.049\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 223/390 d_loss_real= 0.130, d_loss_fake= 0.042, g_loss 3.418, d_loss 0.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 224/390 d_loss_real= 0.023, d_loss_fake= 0.035, g_loss 3.400, d_loss 0.029\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 33 Batch 225/390 d_loss_real= 0.000, d_loss_fake= 0.033, g_loss 3.498, d_loss 0.017\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 226/390 d_loss_real= 0.225, d_loss_fake= 0.032, g_loss 3.388, d_loss 0.128\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 227/390 d_loss_real= 0.036, d_loss_fake= 0.043, g_loss 3.198, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 228/390 d_loss_real= 0.048, d_loss_fake= 0.057, g_loss 3.014, d_loss 0.052\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 33 Batch 229/390 d_loss_real= 0.000, d_loss_fake= 0.056, g_loss 3.368, d_loss 0.028\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 33 Batch 230/390 d_loss_real= 0.002, d_loss_fake= 0.038, g_loss 3.594, d_loss 0.020\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 231/390 d_loss_real= 0.083, d_loss_fake= 0.028, g_loss 3.838, d_loss 0.056\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 232/390 d_loss_real= 0.281, d_loss_fake= 0.025, g_loss 3.736, d_loss 0.153\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 33 Batch 233/390 d_loss_real= 0.191, d_loss_fake= 0.029, g_loss 3.563, d_loss 0.110\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 33 Batch 234/390 d_loss_real= 0.233, d_loss_fake= 0.048, g_loss 3.203, d_loss 0.141\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 235/390 d_loss_real= 0.067, d_loss_fake= 0.071, g_loss 3.072, d_loss 0.069\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 33 Batch 236/390 d_loss_real= 0.127, d_loss_fake= 0.063, g_loss 3.338, d_loss 0.095\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 237/390 d_loss_real= 0.306, d_loss_fake= 0.038, g_loss 3.697, d_loss 0.172\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 33 Batch 238/390 d_loss_real= 0.108, d_loss_fake= 0.026, g_loss 3.926, d_loss 0.067\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 239/390 d_loss_real= 0.284, d_loss_fake= 0.024, g_loss 3.923, d_loss 0.154\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 33 Batch 240/390 d_loss_real= 0.356, d_loss_fake= 0.027, g_loss 3.645, d_loss 0.191\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 241/390 d_loss_real= 0.346, d_loss_fake= 0.038, g_loss 3.329, d_loss 0.192\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 33 Batch 242/390 d_loss_real= 0.153, d_loss_fake= 0.048, g_loss 3.130, d_loss 0.101\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 243/390 d_loss_real= 0.132, d_loss_fake= 0.054, g_loss 3.143, d_loss 0.093\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 244/390 d_loss_real= 0.285, d_loss_fake= 0.057, g_loss 3.071, d_loss 0.171\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 33 Batch 245/390 d_loss_real= 0.157, d_loss_fake= 0.053, g_loss 3.149, d_loss 0.105\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 33 Batch 246/390 d_loss_real= 0.186, d_loss_fake= 0.044, g_loss 3.370, d_loss 0.115\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 247/390 d_loss_real= 0.179, d_loss_fake= 0.037, g_loss 3.464, d_loss 0.108\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 33 Batch 248/390 d_loss_real= 0.170, d_loss_fake= 0.035, g_loss 3.467, d_loss 0.102\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 249/390 d_loss_real= 0.054, d_loss_fake= 0.034, g_loss 3.540, d_loss 0.044\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 33 Batch 250/390 d_loss_real= 0.224, d_loss_fake= 0.034, g_loss 3.381, d_loss 0.129\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 251/390 d_loss_real= 0.113, d_loss_fake= 0.043, g_loss 3.266, d_loss 0.078\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 33 Batch 252/390 d_loss_real= 0.130, d_loss_fake= 0.041, g_loss 3.311, d_loss 0.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 253/390 d_loss_real= 0.103, d_loss_fake= 0.042, g_loss 3.342, d_loss 0.072\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 33 Batch 254/390 d_loss_real= 0.056, d_loss_fake= 0.036, g_loss 3.543, d_loss 0.046\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 255/390 d_loss_real= 0.121, d_loss_fake= 0.031, g_loss 3.633, d_loss 0.076\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 256/390 d_loss_real= 0.203, d_loss_fake= 0.030, g_loss 3.739, d_loss 0.117\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 33 Batch 257/390 d_loss_real= 0.207, d_loss_fake= 0.029, g_loss 3.638, d_loss 0.118\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 33 Batch 258/390 d_loss_real= 0.207, d_loss_fake= 0.031, g_loss 3.583, d_loss 0.119\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 33 Batch 259/390 d_loss_real= 0.121, d_loss_fake= 0.031, g_loss 3.557, d_loss 0.076\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 33 Batch 260/390 d_loss_real= 0.267, d_loss_fake= 0.035, g_loss 3.467, d_loss 0.151\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 261/390 d_loss_real= 0.158, d_loss_fake= 0.045, g_loss 3.245, d_loss 0.101\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 33 Batch 262/390 d_loss_real= 0.178, d_loss_fake= 0.046, g_loss 3.237, d_loss 0.112\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 33 Batch 263/390 d_loss_real= 0.120, d_loss_fake= 0.038, g_loss 3.516, d_loss 0.079\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 33 Batch 264/390 d_loss_real= 0.117, d_loss_fake= 0.044, g_loss 3.386, d_loss 0.080\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 33 Batch 265/390 d_loss_real= 0.141, d_loss_fake= 0.034, g_loss 3.611, d_loss 0.087\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 33 Batch 266/390 d_loss_real= 0.046, d_loss_fake= 0.034, g_loss 3.489, d_loss 0.040\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 33 Batch 267/390 d_loss_real= 0.146, d_loss_fake= 0.038, g_loss 3.444, d_loss 0.092\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 268/390 d_loss_real= 0.173, d_loss_fake= 0.037, g_loss 3.366, d_loss 0.105\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 33 Batch 269/390 d_loss_real= 0.168, d_loss_fake= 0.049, g_loss 3.206, d_loss 0.109\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 33 Batch 270/390 d_loss_real= 0.189, d_loss_fake= 0.039, g_loss 3.292, d_loss 0.114\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 33 Batch 271/390 d_loss_real= 0.218, d_loss_fake= 0.043, g_loss 3.287, d_loss 0.131\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 33 Batch 272/390 d_loss_real= 0.061, d_loss_fake= 0.039, g_loss 3.344, d_loss 0.050\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 33 Batch 273/390 d_loss_real= 0.099, d_loss_fake= 0.048, g_loss 3.245, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 274/390 d_loss_real= 0.093, d_loss_fake= 0.048, g_loss 3.251, d_loss 0.070\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 275/390 d_loss_real= 0.350, d_loss_fake= 0.049, g_loss 3.215, d_loss 0.199\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 33 Batch 276/390 d_loss_real= 0.206, d_loss_fake= 0.050, g_loss 3.111, d_loss 0.128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 277/390 d_loss_real= 0.103, d_loss_fake= 0.051, g_loss 3.153, d_loss 0.077\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 33 Batch 278/390 d_loss_real= 0.098, d_loss_fake= 0.051, g_loss 3.179, d_loss 0.074\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 33 Batch 279/390 d_loss_real= 0.156, d_loss_fake= 0.050, g_loss 3.164, d_loss 0.103\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 280/390 d_loss_real= 0.155, d_loss_fake= 0.051, g_loss 3.099, d_loss 0.103\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 33 Batch 281/390 d_loss_real= 0.104, d_loss_fake= 0.048, g_loss 3.168, d_loss 0.076\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 33 Batch 282/390 d_loss_real= 0.068, d_loss_fake= 0.056, g_loss 3.069, d_loss 0.062\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 33 Batch 283/390 d_loss_real= 0.061, d_loss_fake= 0.057, g_loss 3.003, d_loss 0.059\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 33 Batch 284/390 d_loss_real= 0.086, d_loss_fake= 0.057, g_loss 3.028, d_loss 0.071\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 285/390 d_loss_real= 0.120, d_loss_fake= 0.064, g_loss 2.923, d_loss 0.092\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 286/390 d_loss_real= 0.090, d_loss_fake= 0.067, g_loss 2.942, d_loss 0.078\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 287/390 d_loss_real= 0.035, d_loss_fake= 0.056, g_loss 3.032, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 288/390 d_loss_real= 0.077, d_loss_fake= 0.052, g_loss 3.089, d_loss 0.064\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 33 Batch 289/390 d_loss_real= 0.081, d_loss_fake= 0.047, g_loss 3.114, d_loss 0.064\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 290/390 d_loss_real= 0.206, d_loss_fake= 0.049, g_loss 3.139, d_loss 0.127\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 291/390 d_loss_real= 0.026, d_loss_fake= 0.048, g_loss 3.118, d_loss 0.037\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 292/390 d_loss_real= 0.152, d_loss_fake= 0.051, g_loss 3.094, d_loss 0.102\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 293/390 d_loss_real= 0.099, d_loss_fake= 0.051, g_loss 3.088, d_loss 0.075\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 294/390 d_loss_real= 0.126, d_loss_fake= 0.051, g_loss 3.047, d_loss 0.088\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 33 Batch 295/390 d_loss_real= 0.122, d_loss_fake= 0.052, g_loss 3.010, d_loss 0.087\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 33 Batch 296/390 d_loss_real= 0.218, d_loss_fake= 0.055, g_loss 2.894, d_loss 0.137\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 33 Batch 297/390 d_loss_real= 0.006, d_loss_fake= 0.063, g_loss 2.836, d_loss 0.035\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 33 Batch 298/390 d_loss_real= 0.095, d_loss_fake= 0.069, g_loss 2.785, d_loss 0.082\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 33 Batch 299/390 d_loss_real= 0.062, d_loss_fake= 0.079, g_loss 2.845, d_loss 0.071\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 300/390 d_loss_real= 0.022, d_loss_fake= 0.070, g_loss 2.890, d_loss 0.046\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 33 Batch 301/390 d_loss_real= 0.140, d_loss_fake= 0.061, g_loss 2.960, d_loss 0.101\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 302/390 d_loss_real= 0.095, d_loss_fake= 0.054, g_loss 3.078, d_loss 0.074\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 303/390 d_loss_real= 0.225, d_loss_fake= 0.051, g_loss 3.063, d_loss 0.138\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 33 Batch 304/390 d_loss_real= 0.096, d_loss_fake= 0.052, g_loss 3.096, d_loss 0.074\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 33 Batch 305/390 d_loss_real= 0.072, d_loss_fake= 0.047, g_loss 3.090, d_loss 0.060\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 306/390 d_loss_real= 0.085, d_loss_fake= 0.053, g_loss 3.015, d_loss 0.069\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 307/390 d_loss_real= 0.087, d_loss_fake= 0.058, g_loss 3.049, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 308/390 d_loss_real= 0.061, d_loss_fake= 0.064, g_loss 3.021, d_loss 0.062\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 309/390 d_loss_real= 0.098, d_loss_fake= 0.052, g_loss 3.077, d_loss 0.075\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 310/390 d_loss_real= 0.177, d_loss_fake= 0.051, g_loss 3.121, d_loss 0.114\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 311/390 d_loss_real= 0.105, d_loss_fake= 0.048, g_loss 3.125, d_loss 0.077\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 312/390 d_loss_real= 0.052, d_loss_fake= 0.046, g_loss 3.192, d_loss 0.049\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 33 Batch 313/390 d_loss_real= 0.102, d_loss_fake= 0.042, g_loss 3.236, d_loss 0.072\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 33 Batch 314/390 d_loss_real= 0.256, d_loss_fake= 0.044, g_loss 3.206, d_loss 0.150\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 315/390 d_loss_real= 0.150, d_loss_fake= 0.046, g_loss 3.195, d_loss 0.098\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 33 Batch 316/390 d_loss_real= 0.164, d_loss_fake= 0.045, g_loss 3.166, d_loss 0.104\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 317/390 d_loss_real= 0.159, d_loss_fake= 0.046, g_loss 3.098, d_loss 0.102\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 33 Batch 318/390 d_loss_real= 0.101, d_loss_fake= 0.051, g_loss 2.997, d_loss 0.076\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 319/390 d_loss_real= 0.064, d_loss_fake= 0.057, g_loss 2.949, d_loss 0.060\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 33 Batch 320/390 d_loss_real= 0.116, d_loss_fake= 0.062, g_loss 2.936, d_loss 0.089\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 321/390 d_loss_real= 0.108, d_loss_fake= 0.059, g_loss 2.892, d_loss 0.084\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 33 Batch 322/390 d_loss_real= 0.105, d_loss_fake= 0.066, g_loss 3.013, d_loss 0.085\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 323/390 d_loss_real= 0.183, d_loss_fake= 0.058, g_loss 3.027, d_loss 0.121\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 324/390 d_loss_real= 0.008, d_loss_fake= 0.054, g_loss 3.124, d_loss 0.031\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 325/390 d_loss_real= 0.154, d_loss_fake= 0.047, g_loss 3.221, d_loss 0.101\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 326/390 d_loss_real= 0.106, d_loss_fake= 0.043, g_loss 3.245, d_loss 0.075\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 327/390 d_loss_real= 0.145, d_loss_fake= 0.040, g_loss 3.301, d_loss 0.093\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 328/390 d_loss_real= 0.085, d_loss_fake= 0.040, g_loss 3.346, d_loss 0.062\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 329/390 d_loss_real= 0.045, d_loss_fake= 0.038, g_loss 3.354, d_loss 0.042\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 33 Batch 330/390 d_loss_real= 0.048, d_loss_fake= 0.038, g_loss 3.403, d_loss 0.043\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 33 Batch 331/390 d_loss_real= 0.046, d_loss_fake= 0.037, g_loss 3.443, d_loss 0.041\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 33 Batch 332/390 d_loss_real= 0.084, d_loss_fake= 0.038, g_loss 3.472, d_loss 0.061\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 33 Batch 333/390 d_loss_real= 0.056, d_loss_fake= 0.035, g_loss 3.385, d_loss 0.045\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 33 Batch 334/390 d_loss_real= 0.208, d_loss_fake= 0.036, g_loss 3.359, d_loss 0.122\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 335/390 d_loss_real= 0.042, d_loss_fake= 0.036, g_loss 3.391, d_loss 0.039\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 33 Batch 336/390 d_loss_real= 0.083, d_loss_fake= 0.040, g_loss 3.276, d_loss 0.062\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 33 Batch 337/390 d_loss_real= 0.158, d_loss_fake= 0.044, g_loss 3.239, d_loss 0.101\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 33 Batch 338/390 d_loss_real= 0.110, d_loss_fake= 0.052, g_loss 3.329, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 339/390 d_loss_real= 0.103, d_loss_fake= 0.039, g_loss 3.441, d_loss 0.071\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 340/390 d_loss_real= 0.144, d_loss_fake= 0.036, g_loss 3.476, d_loss 0.090\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 33 Batch 341/390 d_loss_real= 0.177, d_loss_fake= 0.035, g_loss 3.473, d_loss 0.106\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 33 Batch 342/390 d_loss_real= 0.205, d_loss_fake= 0.035, g_loss 3.495, d_loss 0.120\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 33 Batch 343/390 d_loss_real= 0.053, d_loss_fake= 0.035, g_loss 3.503, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 344/390 d_loss_real= 0.123, d_loss_fake= 0.032, g_loss 3.562, d_loss 0.077\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 345/390 d_loss_real= 0.056, d_loss_fake= 0.030, g_loss 3.554, d_loss 0.043\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 33 Batch 346/390 d_loss_real= 0.146, d_loss_fake= 0.028, g_loss 3.590, d_loss 0.087\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 33 Batch 347/390 d_loss_real= 0.195, d_loss_fake= 0.031, g_loss 3.530, d_loss 0.113\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 33 Batch 348/390 d_loss_real= 0.057, d_loss_fake= 0.033, g_loss 3.454, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 349/390 d_loss_real= 0.177, d_loss_fake= 0.038, g_loss 3.328, d_loss 0.107\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 33 Batch 350/390 d_loss_real= 0.008, d_loss_fake= 0.040, g_loss 3.281, d_loss 0.024\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 33 Batch 351/390 d_loss_real= 0.043, d_loss_fake= 0.041, g_loss 3.228, d_loss 0.042\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 33 Batch 352/390 d_loss_real= 0.146, d_loss_fake= 0.047, g_loss 3.165, d_loss 0.097\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 33 Batch 353/390 d_loss_real= 0.078, d_loss_fake= 0.047, g_loss 3.134, d_loss 0.063\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 33 Batch 354/390 d_loss_real= 0.098, d_loss_fake= 0.053, g_loss 3.151, d_loss 0.075\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 355/390 d_loss_real= 0.102, d_loss_fake= 0.059, g_loss 3.101, d_loss 0.080\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 356/390 d_loss_real= 0.001, d_loss_fake= 0.046, g_loss 3.228, d_loss 0.024\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 357/390 d_loss_real= 0.086, d_loss_fake= 0.039, g_loss 3.429, d_loss 0.062\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 33 Batch 358/390 d_loss_real= 0.086, d_loss_fake= 0.038, g_loss 3.380, d_loss 0.062\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 359/390 d_loss_real= 0.250, d_loss_fake= 0.040, g_loss 3.344, d_loss 0.145\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 33 Batch 360/390 d_loss_real= 0.012, d_loss_fake= 0.038, g_loss 3.356, d_loss 0.025\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 361/390 d_loss_real= 0.176, d_loss_fake= 0.040, g_loss 3.324, d_loss 0.108\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 33 Batch 362/390 d_loss_real= 0.108, d_loss_fake= 0.038, g_loss 3.291, d_loss 0.073\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 33 Batch 363/390 d_loss_real= 0.217, d_loss_fake= 0.043, g_loss 3.215, d_loss 0.130\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 364/390 d_loss_real= 0.157, d_loss_fake= 0.046, g_loss 3.125, d_loss 0.102\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 33 Batch 365/390 d_loss_real= 0.114, d_loss_fake= 0.054, g_loss 3.117, d_loss 0.084\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 33 Batch 366/390 d_loss_real= 0.335, d_loss_fake= 0.052, g_loss 3.216, d_loss 0.194\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 33 Batch 367/390 d_loss_real= 0.126, d_loss_fake= 0.046, g_loss 3.278, d_loss 0.086\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 33 Batch 368/390 d_loss_real= 0.097, d_loss_fake= 0.052, g_loss 3.038, d_loss 0.075\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 369/390 d_loss_real= 0.123, d_loss_fake= 0.056, g_loss 3.085, d_loss 0.089\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 370/390 d_loss_real= 0.148, d_loss_fake= 0.057, g_loss 3.107, d_loss 0.103\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 371/390 d_loss_real= 0.092, d_loss_fake= 0.055, g_loss 3.095, d_loss 0.074\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 372/390 d_loss_real= 0.304, d_loss_fake= 0.056, g_loss 3.028, d_loss 0.180\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 373/390 d_loss_real= 0.202, d_loss_fake= 0.063, g_loss 2.959, d_loss 0.133\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 33 Batch 374/390 d_loss_real= 0.234, d_loss_fake= 0.071, g_loss 2.823, d_loss 0.152\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 375/390 d_loss_real= 0.079, d_loss_fake= 0.071, g_loss 2.938, d_loss 0.075\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 376/390 d_loss_real= 0.051, d_loss_fake= 0.046, g_loss 3.373, d_loss 0.049\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 33 Batch 377/390 d_loss_real= 0.062, d_loss_fake= 0.040, g_loss 3.414, d_loss 0.051\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 33 Batch 378/390 d_loss_real= 0.132, d_loss_fake= 0.032, g_loss 3.705, d_loss 0.082\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 379/390 d_loss_real= 0.111, d_loss_fake= 0.028, g_loss 3.710, d_loss 0.070\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 380/390 d_loss_real= 0.075, d_loss_fake= 0.027, g_loss 3.674, d_loss 0.051\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 381/390 d_loss_real= 0.193, d_loss_fake= 0.030, g_loss 3.568, d_loss 0.112\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33 Batch 382/390 d_loss_real= 0.214, d_loss_fake= 0.030, g_loss 3.464, d_loss 0.122\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 383/390 d_loss_real= 0.044, d_loss_fake= 0.044, g_loss 3.146, d_loss 0.044\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 384/390 d_loss_real= 0.050, d_loss_fake= 0.041, g_loss 3.101, d_loss 0.046\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 385/390 d_loss_real= 0.064, d_loss_fake= 0.029, g_loss 3.630, d_loss 0.046\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33 Batch 386/390 d_loss_real= 0.188, d_loss_fake= 0.069, g_loss 3.345, d_loss 0.128\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 33 Batch 387/390 d_loss_real= 0.292, d_loss_fake= 0.042, g_loss 3.601, d_loss 0.167\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 33 Batch 388/390 d_loss_real= 0.000, d_loss_fake= 0.030, g_loss 3.740, d_loss 0.015\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33 Batch 389/390 d_loss_real= 0.050, d_loss_fake= 0.023, g_loss 4.037, d_loss 0.037\n",
            "2/2 [==============================] - 0s 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33 Batch 390/390 d_loss_real= 0.231, d_loss_fake= 0.020, g_loss 4.022, d_loss 0.125\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 1/390 d_loss_real= 0.311, d_loss_fake= 0.021, g_loss 3.916, d_loss 0.166\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 2/390 d_loss_real= 0.088, d_loss_fake= 0.023, g_loss 3.860, d_loss 0.055\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 3/390 d_loss_real= 0.155, d_loss_fake= 0.026, g_loss 3.679, d_loss 0.091\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 34 Batch 4/390 d_loss_real= 0.031, d_loss_fake= 0.033, g_loss 3.426, d_loss 0.032\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 5/390 d_loss_real= 0.064, d_loss_fake= 0.044, g_loss 3.275, d_loss 0.054\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 6/390 d_loss_real= 0.222, d_loss_fake= 0.051, g_loss 3.080, d_loss 0.137\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 7/390 d_loss_real= 0.180, d_loss_fake= 0.066, g_loss 3.096, d_loss 0.123\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 34 Batch 8/390 d_loss_real= 0.086, d_loss_fake= 0.060, g_loss 3.106, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 9/390 d_loss_real= 0.249, d_loss_fake= 0.049, g_loss 3.290, d_loss 0.149\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 10/390 d_loss_real= 0.239, d_loss_fake= 0.046, g_loss 3.121, d_loss 0.143\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 11/390 d_loss_real= 0.103, d_loss_fake= 0.058, g_loss 3.139, d_loss 0.081\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 34 Batch 12/390 d_loss_real= 0.308, d_loss_fake= 0.049, g_loss 3.061, d_loss 0.179\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 13/390 d_loss_real= 0.250, d_loss_fake= 0.054, g_loss 3.006, d_loss 0.152\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 14/390 d_loss_real= 0.053, d_loss_fake= 0.054, g_loss 2.970, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 15/390 d_loss_real= 0.161, d_loss_fake= 0.078, g_loss 3.011, d_loss 0.119\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 16/390 d_loss_real= 0.123, d_loss_fake= 0.063, g_loss 2.948, d_loss 0.093\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 17/390 d_loss_real= 0.159, d_loss_fake= 0.058, g_loss 3.127, d_loss 0.108\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 34 Batch 18/390 d_loss_real= 0.060, d_loss_fake= 0.046, g_loss 3.224, d_loss 0.053\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 19/390 d_loss_real= 0.124, d_loss_fake= 0.045, g_loss 3.266, d_loss 0.085\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 20/390 d_loss_real= 0.174, d_loss_fake= 0.043, g_loss 3.278, d_loss 0.109\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 34 Batch 21/390 d_loss_real= 0.157, d_loss_fake= 0.041, g_loss 3.209, d_loss 0.099\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 22/390 d_loss_real= 0.256, d_loss_fake= 0.047, g_loss 3.053, d_loss 0.151\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 23/390 d_loss_real= 0.203, d_loss_fake= 0.057, g_loss 2.909, d_loss 0.130\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 34 Batch 24/390 d_loss_real= 0.006, d_loss_fake= 0.068, g_loss 2.996, d_loss 0.037\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 25/390 d_loss_real= 0.143, d_loss_fake= 0.057, g_loss 3.049, d_loss 0.100\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 26/390 d_loss_real= 0.106, d_loss_fake= 0.049, g_loss 3.127, d_loss 0.077\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 34 Batch 27/390 d_loss_real= 0.013, d_loss_fake= 0.044, g_loss 3.203, d_loss 0.029\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 28/390 d_loss_real= 0.250, d_loss_fake= 0.048, g_loss 3.161, d_loss 0.149\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 29/390 d_loss_real= 0.071, d_loss_fake= 0.047, g_loss 3.112, d_loss 0.059\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 30/390 d_loss_real= 0.103, d_loss_fake= 0.049, g_loss 3.075, d_loss 0.076\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 31/390 d_loss_real= 0.135, d_loss_fake= 0.051, g_loss 3.026, d_loss 0.093\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 32/390 d_loss_real= 0.121, d_loss_fake= 0.055, g_loss 2.943, d_loss 0.088\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 33/390 d_loss_real= 0.047, d_loss_fake= 0.061, g_loss 2.925, d_loss 0.054\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 34/390 d_loss_real= 0.024, d_loss_fake= 0.069, g_loss 2.924, d_loss 0.046\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 35/390 d_loss_real= 0.159, d_loss_fake= 0.057, g_loss 3.070, d_loss 0.108\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 36/390 d_loss_real= 0.203, d_loss_fake= 0.051, g_loss 3.110, d_loss 0.127\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 37/390 d_loss_real= 0.201, d_loss_fake= 0.048, g_loss 3.171, d_loss 0.125\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 34 Batch 38/390 d_loss_real= 0.148, d_loss_fake= 0.049, g_loss 3.093, d_loss 0.098\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 34 Batch 39/390 d_loss_real= 0.012, d_loss_fake= 0.051, g_loss 3.089, d_loss 0.031\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 34 Batch 40/390 d_loss_real= 0.070, d_loss_fake= 0.050, g_loss 3.124, d_loss 0.060\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 41/390 d_loss_real= 0.000, d_loss_fake= 0.044, g_loss 3.219, d_loss 0.022\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 42/390 d_loss_real= 0.333, d_loss_fake= 0.047, g_loss 3.080, d_loss 0.190\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 43/390 d_loss_real= 0.168, d_loss_fake= 0.052, g_loss 3.048, d_loss 0.110\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 44/390 d_loss_real= 0.111, d_loss_fake= 0.053, g_loss 2.954, d_loss 0.082\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 34 Batch 45/390 d_loss_real= 0.129, d_loss_fake= 0.057, g_loss 2.960, d_loss 0.093\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 46/390 d_loss_real= 0.004, d_loss_fake= 0.053, g_loss 3.108, d_loss 0.028\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 34 Batch 47/390 d_loss_real= 0.168, d_loss_fake= 0.041, g_loss 3.376, d_loss 0.104\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 48/390 d_loss_real= 0.077, d_loss_fake= 0.060, g_loss 3.214, d_loss 0.069\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 49/390 d_loss_real= 0.176, d_loss_fake= 0.041, g_loss 3.420, d_loss 0.108\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 50/390 d_loss_real= 0.273, d_loss_fake= 0.032, g_loss 3.584, d_loss 0.153\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 51/390 d_loss_real= 0.205, d_loss_fake= 0.036, g_loss 3.405, d_loss 0.121\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 34 Batch 52/390 d_loss_real= 0.115, d_loss_fake= 0.040, g_loss 3.412, d_loss 0.077\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 34 Batch 53/390 d_loss_real= 0.232, d_loss_fake= 0.038, g_loss 3.465, d_loss 0.135\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 34 Batch 54/390 d_loss_real= 0.159, d_loss_fake= 0.025, g_loss 3.801, d_loss 0.092\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 34 Batch 55/390 d_loss_real= 0.158, d_loss_fake= 0.045, g_loss 3.514, d_loss 0.102\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 56/390 d_loss_real= 0.060, d_loss_fake= 0.023, g_loss 3.920, d_loss 0.041\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 34 Batch 57/390 d_loss_real= 0.065, d_loss_fake= 0.028, g_loss 3.675, d_loss 0.047\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 58/390 d_loss_real= 0.021, d_loss_fake= 0.028, g_loss 3.780, d_loss 0.025\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 59/390 d_loss_real= 0.214, d_loss_fake= 0.023, g_loss 3.868, d_loss 0.119\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 60/390 d_loss_real= 0.296, d_loss_fake= 0.030, g_loss 3.623, d_loss 0.163\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 61/390 d_loss_real= 0.071, d_loss_fake= 0.037, g_loss 3.410, d_loss 0.054\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 62/390 d_loss_real= 0.072, d_loss_fake= 0.034, g_loss 3.665, d_loss 0.053\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 34 Batch 63/390 d_loss_real= 0.056, d_loss_fake= 0.024, g_loss 4.067, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 64/390 d_loss_real= 0.000, d_loss_fake= 0.019, g_loss 4.046, d_loss 0.009\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 65/390 d_loss_real= 0.163, d_loss_fake= 0.023, g_loss 3.874, d_loss 0.093\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 34 Batch 66/390 d_loss_real= 0.056, d_loss_fake= 0.029, g_loss 3.752, d_loss 0.043\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 67/390 d_loss_real= 0.113, d_loss_fake= 0.031, g_loss 3.773, d_loss 0.072\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 34 Batch 68/390 d_loss_real= 0.010, d_loss_fake= 0.027, g_loss 3.816, d_loss 0.018\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 69/390 d_loss_real= 0.000, d_loss_fake= 0.026, g_loss 3.869, d_loss 0.013\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 34 Batch 70/390 d_loss_real= 0.060, d_loss_fake= 0.021, g_loss 3.934, d_loss 0.041\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 34 Batch 71/390 d_loss_real= 0.055, d_loss_fake= 0.023, g_loss 3.887, d_loss 0.039\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 72/390 d_loss_real= 0.055, d_loss_fake= 0.023, g_loss 3.781, d_loss 0.039\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 34 Batch 73/390 d_loss_real= 0.000, d_loss_fake= 0.027, g_loss 3.767, d_loss 0.013\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 74/390 d_loss_real= 0.045, d_loss_fake= 0.028, g_loss 3.638, d_loss 0.036\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 75/390 d_loss_real= 0.099, d_loss_fake= 0.032, g_loss 3.525, d_loss 0.065\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 76/390 d_loss_real= 0.003, d_loss_fake= 0.036, g_loss 3.367, d_loss 0.019\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 77/390 d_loss_real= 0.081, d_loss_fake= 0.046, g_loss 3.169, d_loss 0.063\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 78/390 d_loss_real= 0.046, d_loss_fake= 0.061, g_loss 2.992, d_loss 0.054\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 79/390 d_loss_real= 0.176, d_loss_fake= 0.074, g_loss 2.725, d_loss 0.125\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 34 Batch 80/390 d_loss_real= 0.087, d_loss_fake= 0.095, g_loss 2.632, d_loss 0.091\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 81/390 d_loss_real= 0.032, d_loss_fake= 0.090, g_loss 2.694, d_loss 0.061\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 34 Batch 82/390 d_loss_real= 0.119, d_loss_fake= 0.082, g_loss 2.790, d_loss 0.101\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 83/390 d_loss_real= 0.351, d_loss_fake= 0.075, g_loss 2.790, d_loss 0.213\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 84/390 d_loss_real= 0.092, d_loss_fake= 0.069, g_loss 2.869, d_loss 0.081\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 85/390 d_loss_real= 0.029, d_loss_fake= 0.055, g_loss 2.973, d_loss 0.042\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 86/390 d_loss_real= 0.157, d_loss_fake= 0.056, g_loss 3.048, d_loss 0.107\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 87/390 d_loss_real= 0.268, d_loss_fake= 0.053, g_loss 3.011, d_loss 0.160\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 88/390 d_loss_real= 0.271, d_loss_fake= 0.059, g_loss 2.869, d_loss 0.165\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 34 Batch 89/390 d_loss_real= 0.132, d_loss_fake= 0.080, g_loss 2.770, d_loss 0.106\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 90/390 d_loss_real= 0.000, d_loss_fake= 0.076, g_loss 2.903, d_loss 0.038\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 34 Batch 91/390 d_loss_real= 0.023, d_loss_fake= 0.055, g_loss 3.128, d_loss 0.039\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 92/390 d_loss_real= 0.150, d_loss_fake= 0.049, g_loss 3.216, d_loss 0.100\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 34 Batch 93/390 d_loss_real= 0.293, d_loss_fake= 0.045, g_loss 3.304, d_loss 0.169\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 94/390 d_loss_real= 0.068, d_loss_fake= 0.039, g_loss 3.460, d_loss 0.053\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 95/390 d_loss_real= 0.148, d_loss_fake= 0.038, g_loss 3.388, d_loss 0.093\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 96/390 d_loss_real= 0.168, d_loss_fake= 0.039, g_loss 3.404, d_loss 0.103\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 34 Batch 97/390 d_loss_real= 0.241, d_loss_fake= 0.041, g_loss 3.255, d_loss 0.141\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 98/390 d_loss_real= 0.121, d_loss_fake= 0.048, g_loss 3.007, d_loss 0.085\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 99/390 d_loss_real= 0.057, d_loss_fake= 0.079, g_loss 2.937, d_loss 0.068\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 34 Batch 100/390 d_loss_real= 0.019, d_loss_fake= 0.072, g_loss 3.018, d_loss 0.045\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 34 Batch 101/390 d_loss_real= 0.140, d_loss_fake= 0.070, g_loss 3.167, d_loss 0.105\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 34 Batch 102/390 d_loss_real= 0.139, d_loss_fake= 0.043, g_loss 3.282, d_loss 0.091\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 34 Batch 103/390 d_loss_real= 0.131, d_loss_fake= 0.043, g_loss 3.310, d_loss 0.087\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 104/390 d_loss_real= 0.101, d_loss_fake= 0.039, g_loss 3.452, d_loss 0.070\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 105/390 d_loss_real= 0.064, d_loss_fake= 0.036, g_loss 3.479, d_loss 0.050\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 106/390 d_loss_real= 0.170, d_loss_fake= 0.039, g_loss 3.516, d_loss 0.104\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 107/390 d_loss_real= 0.266, d_loss_fake= 0.043, g_loss 3.332, d_loss 0.154\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 108/390 d_loss_real= 0.049, d_loss_fake= 0.049, g_loss 3.320, d_loss 0.049\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 34 Batch 109/390 d_loss_real= 0.065, d_loss_fake= 0.066, g_loss 3.261, d_loss 0.065\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 110/390 d_loss_real= 0.134, d_loss_fake= 0.058, g_loss 3.502, d_loss 0.096\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 34 Batch 111/390 d_loss_real= 0.243, d_loss_fake= 0.044, g_loss 3.591, d_loss 0.144\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 112/390 d_loss_real= 0.069, d_loss_fake= 0.032, g_loss 3.657, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 113/390 d_loss_real= 0.251, d_loss_fake= 0.028, g_loss 3.634, d_loss 0.140\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 34 Batch 114/390 d_loss_real= 0.237, d_loss_fake= 0.043, g_loss 3.667, d_loss 0.140\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 115/390 d_loss_real= 0.387, d_loss_fake= 0.068, g_loss 3.525, d_loss 0.228\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 116/390 d_loss_real= 0.234, d_loss_fake= 0.057, g_loss 3.547, d_loss 0.146\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 34 Batch 117/390 d_loss_real= 0.205, d_loss_fake= 0.058, g_loss 3.741, d_loss 0.131\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 34 Batch 118/390 d_loss_real= 0.315, d_loss_fake= 0.025, g_loss 4.053, d_loss 0.170\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 34 Batch 119/390 d_loss_real= 0.234, d_loss_fake= 0.018, g_loss 4.274, d_loss 0.126\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 120/390 d_loss_real= 0.183, d_loss_fake= 0.015, g_loss 4.334, d_loss 0.099\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 121/390 d_loss_real= 0.094, d_loss_fake= 0.015, g_loss 4.250, d_loss 0.055\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 122/390 d_loss_real= 0.127, d_loss_fake= 0.017, g_loss 4.005, d_loss 0.072\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 123/390 d_loss_real= 0.170, d_loss_fake= 0.023, g_loss 3.711, d_loss 0.096\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 34 Batch 124/390 d_loss_real= 0.096, d_loss_fake= 0.028, g_loss 3.507, d_loss 0.062\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 34 Batch 125/390 d_loss_real= 0.062, d_loss_fake= 0.037, g_loss 3.299, d_loss 0.049\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 126/390 d_loss_real= 0.049, d_loss_fake= 0.045, g_loss 3.166, d_loss 0.047\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 34 Batch 127/390 d_loss_real= 0.249, d_loss_fake= 0.060, g_loss 2.930, d_loss 0.155\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 34 Batch 128/390 d_loss_real= 0.001, d_loss_fake= 0.076, g_loss 2.988, d_loss 0.039\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 129/390 d_loss_real= 0.083, d_loss_fake= 0.049, g_loss 3.264, d_loss 0.066\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 130/390 d_loss_real= 0.106, d_loss_fake= 0.038, g_loss 3.524, d_loss 0.072\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 131/390 d_loss_real= 0.047, d_loss_fake= 0.029, g_loss 3.601, d_loss 0.038\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 132/390 d_loss_real= 0.138, d_loss_fake= 0.030, g_loss 3.632, d_loss 0.084\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 133/390 d_loss_real= 0.158, d_loss_fake= 0.031, g_loss 3.572, d_loss 0.094\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 134/390 d_loss_real= 0.009, d_loss_fake= 0.033, g_loss 3.559, d_loss 0.021\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 135/390 d_loss_real= 0.081, d_loss_fake= 0.034, g_loss 3.532, d_loss 0.058\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 136/390 d_loss_real= 0.112, d_loss_fake= 0.044, g_loss 3.393, d_loss 0.078\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 34 Batch 137/390 d_loss_real= 0.063, d_loss_fake= 0.058, g_loss 3.221, d_loss 0.061\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 138/390 d_loss_real= 0.162, d_loss_fake= 0.099, g_loss 2.687, d_loss 0.131\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 139/390 d_loss_real= 0.061, d_loss_fake= 0.427, g_loss 3.791, d_loss 0.244\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 140/390 d_loss_real= 0.088, d_loss_fake= 0.021, g_loss 4.229, d_loss 0.054\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 141/390 d_loss_real= 0.402, d_loss_fake= 0.017, g_loss 4.268, d_loss 0.209\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 142/390 d_loss_real= 0.947, d_loss_fake= 0.019, g_loss 4.090, d_loss 0.483\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 143/390 d_loss_real= 0.693, d_loss_fake= 0.024, g_loss 3.761, d_loss 0.359\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 34 Batch 144/390 d_loss_real= 0.547, d_loss_fake= 0.034, g_loss 3.390, d_loss 0.291\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 34 Batch 145/390 d_loss_real= 0.570, d_loss_fake= 0.042, g_loss 3.137, d_loss 0.306\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 146/390 d_loss_real= 0.318, d_loss_fake= 0.062, g_loss 2.767, d_loss 0.190\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 34 Batch 147/390 d_loss_real= 0.211, d_loss_fake= 0.083, g_loss 2.477, d_loss 0.147\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 34 Batch 148/390 d_loss_real= 0.060, d_loss_fake= 0.131, g_loss 2.054, d_loss 0.095\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 34 Batch 149/390 d_loss_real= 0.000, d_loss_fake= 0.240, g_loss 1.712, d_loss 0.120\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 150/390 d_loss_real= 0.001, d_loss_fake= 0.374, g_loss 2.328, d_loss 0.187\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 151/390 d_loss_real= 0.079, d_loss_fake= 0.076, g_loss 3.003, d_loss 0.077\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 152/390 d_loss_real= 0.065, d_loss_fake= 0.047, g_loss 3.195, d_loss 0.056\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 34 Batch 153/390 d_loss_real= 0.025, d_loss_fake= 0.043, g_loss 3.277, d_loss 0.034\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 154/390 d_loss_real= 0.121, d_loss_fake= 0.039, g_loss 3.329, d_loss 0.080\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 155/390 d_loss_real= 0.235, d_loss_fake= 0.037, g_loss 3.329, d_loss 0.136\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 156/390 d_loss_real= 0.282, d_loss_fake= 0.037, g_loss 3.316, d_loss 0.160\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 157/390 d_loss_real= 0.330, d_loss_fake= 0.039, g_loss 3.252, d_loss 0.185\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 34 Batch 158/390 d_loss_real= 0.107, d_loss_fake= 0.042, g_loss 3.203, d_loss 0.075\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 34 Batch 159/390 d_loss_real= 0.088, d_loss_fake= 0.045, g_loss 3.120, d_loss 0.067\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 34 Batch 160/390 d_loss_real= 0.280, d_loss_fake= 0.048, g_loss 3.018, d_loss 0.164\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 161/390 d_loss_real= 0.100, d_loss_fake= 0.053, g_loss 2.955, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 162/390 d_loss_real= 0.182, d_loss_fake= 0.058, g_loss 2.823, d_loss 0.120\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 163/390 d_loss_real= 0.004, d_loss_fake= 0.070, g_loss 2.639, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 164/390 d_loss_real= 0.027, d_loss_fake= 0.089, g_loss 2.517, d_loss 0.058\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 165/390 d_loss_real= 0.012, d_loss_fake= 0.173, g_loss 2.395, d_loss 0.092\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 166/390 d_loss_real= 0.154, d_loss_fake= 0.143, g_loss 2.727, d_loss 0.149\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 34 Batch 167/390 d_loss_real= 0.085, d_loss_fake= 0.080, g_loss 3.103, d_loss 0.083\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 34 Batch 168/390 d_loss_real= 0.163, d_loss_fake= 0.045, g_loss 3.263, d_loss 0.104\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 169/390 d_loss_real= 0.211, d_loss_fake= 0.036, g_loss 3.414, d_loss 0.123\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 170/390 d_loss_real= 0.070, d_loss_fake= 0.034, g_loss 3.494, d_loss 0.052\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 171/390 d_loss_real= 0.102, d_loss_fake= 0.032, g_loss 3.511, d_loss 0.067\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 172/390 d_loss_real= 0.102, d_loss_fake= 0.031, g_loss 3.519, d_loss 0.067\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 173/390 d_loss_real= 0.147, d_loss_fake= 0.031, g_loss 3.548, d_loss 0.089\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 174/390 d_loss_real= 0.098, d_loss_fake= 0.030, g_loss 3.541, d_loss 0.064\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 34 Batch 175/390 d_loss_real= 0.182, d_loss_fake= 0.031, g_loss 3.481, d_loss 0.107\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 176/390 d_loss_real= 0.353, d_loss_fake= 0.033, g_loss 3.445, d_loss 0.193\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 34 Batch 177/390 d_loss_real= 0.000, d_loss_fake= 0.035, g_loss 3.334, d_loss 0.018\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 178/390 d_loss_real= 0.017, d_loss_fake= 0.037, g_loss 3.304, d_loss 0.027\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 179/390 d_loss_real= 0.013, d_loss_fake= 0.041, g_loss 3.251, d_loss 0.027\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 34 Batch 180/390 d_loss_real= 0.001, d_loss_fake= 0.042, g_loss 3.192, d_loss 0.022\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 34 Batch 181/390 d_loss_real= 0.057, d_loss_fake= 0.044, g_loss 3.121, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 182/390 d_loss_real= 0.054, d_loss_fake= 0.052, g_loss 3.177, d_loss 0.053\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 34 Batch 183/390 d_loss_real= 0.087, d_loss_fake= 0.050, g_loss 3.176, d_loss 0.069\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 184/390 d_loss_real= 0.046, d_loss_fake= 0.049, g_loss 3.305, d_loss 0.047\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 185/390 d_loss_real= 0.094, d_loss_fake= 0.037, g_loss 3.385, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 186/390 d_loss_real= 0.099, d_loss_fake= 0.035, g_loss 3.461, d_loss 0.067\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 187/390 d_loss_real= 0.027, d_loss_fake= 0.032, g_loss 3.468, d_loss 0.030\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 188/390 d_loss_real= 0.000, d_loss_fake= 0.031, g_loss 3.558, d_loss 0.016\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 34 Batch 189/390 d_loss_real= 0.144, d_loss_fake= 0.030, g_loss 3.565, d_loss 0.087\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 190/390 d_loss_real= 0.263, d_loss_fake= 0.030, g_loss 3.547, d_loss 0.147\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 191/390 d_loss_real= 0.014, d_loss_fake= 0.031, g_loss 3.561, d_loss 0.022\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 192/390 d_loss_real= 0.006, d_loss_fake= 0.032, g_loss 3.524, d_loss 0.019\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 34 Batch 193/390 d_loss_real= 0.183, d_loss_fake= 0.032, g_loss 3.443, d_loss 0.108\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 194/390 d_loss_real= 0.139, d_loss_fake= 0.036, g_loss 3.335, d_loss 0.088\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 195/390 d_loss_real= 0.057, d_loss_fake= 0.039, g_loss 3.251, d_loss 0.048\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 196/390 d_loss_real= 0.093, d_loss_fake= 0.048, g_loss 3.169, d_loss 0.070\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 34 Batch 197/390 d_loss_real= 0.273, d_loss_fake= 0.049, g_loss 3.154, d_loss 0.161\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 198/390 d_loss_real= 0.238, d_loss_fake= 0.048, g_loss 3.054, d_loss 0.143\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 199/390 d_loss_real= 0.041, d_loss_fake= 0.057, g_loss 3.088, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 200/390 d_loss_real= 0.011, d_loss_fake= 0.049, g_loss 3.173, d_loss 0.030\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 201/390 d_loss_real= 0.046, d_loss_fake= 0.043, g_loss 3.269, d_loss 0.045\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 34 Batch 202/390 d_loss_real= 0.153, d_loss_fake= 0.043, g_loss 3.312, d_loss 0.098\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 203/390 d_loss_real= 0.119, d_loss_fake= 0.047, g_loss 3.212, d_loss 0.083\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 204/390 d_loss_real= 0.169, d_loss_fake= 0.048, g_loss 3.250, d_loss 0.108\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 205/390 d_loss_real= 0.029, d_loss_fake= 0.048, g_loss 3.273, d_loss 0.039\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 206/390 d_loss_real= 0.056, d_loss_fake= 0.043, g_loss 3.335, d_loss 0.049\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 34 Batch 207/390 d_loss_real= 0.008, d_loss_fake= 0.041, g_loss 3.360, d_loss 0.024\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 208/390 d_loss_real= 0.076, d_loss_fake= 0.040, g_loss 3.401, d_loss 0.058\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 209/390 d_loss_real= 0.119, d_loss_fake= 0.036, g_loss 3.475, d_loss 0.078\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 210/390 d_loss_real= 0.120, d_loss_fake= 0.034, g_loss 3.502, d_loss 0.077\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 211/390 d_loss_real= 0.153, d_loss_fake= 0.033, g_loss 3.446, d_loss 0.093\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 212/390 d_loss_real= 0.155, d_loss_fake= 0.039, g_loss 3.329, d_loss 0.097\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 213/390 d_loss_real= 0.174, d_loss_fake= 0.057, g_loss 3.049, d_loss 0.116\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 34 Batch 214/390 d_loss_real= 0.071, d_loss_fake= 0.077, g_loss 3.099, d_loss 0.074\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 215/390 d_loss_real= 0.170, d_loss_fake= 0.055, g_loss 3.441, d_loss 0.113\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 34 Batch 216/390 d_loss_real= 0.057, d_loss_fake= 0.030, g_loss 3.738, d_loss 0.043\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 217/390 d_loss_real= 0.011, d_loss_fake= 0.023, g_loss 3.887, d_loss 0.017\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 218/390 d_loss_real= 0.128, d_loss_fake= 0.022, g_loss 3.922, d_loss 0.075\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 34 Batch 219/390 d_loss_real= 0.154, d_loss_fake= 0.023, g_loss 3.905, d_loss 0.089\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 34 Batch 220/390 d_loss_real= 0.270, d_loss_fake= 0.023, g_loss 3.866, d_loss 0.146\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 34 Batch 221/390 d_loss_real= 0.205, d_loss_fake= 0.026, g_loss 3.667, d_loss 0.115\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 34 Batch 222/390 d_loss_real= 0.119, d_loss_fake= 0.033, g_loss 3.358, d_loss 0.076\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 223/390 d_loss_real= 0.127, d_loss_fake= 0.048, g_loss 3.082, d_loss 0.088\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 34 Batch 224/390 d_loss_real= 0.053, d_loss_fake= 0.087, g_loss 3.031, d_loss 0.070\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 225/390 d_loss_real= 0.033, d_loss_fake= 0.063, g_loss 3.310, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 226/390 d_loss_real= 0.214, d_loss_fake= 0.042, g_loss 3.454, d_loss 0.128\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 34 Batch 227/390 d_loss_real= 0.396, d_loss_fake= 0.037, g_loss 3.466, d_loss 0.216\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 228/390 d_loss_real= 0.274, d_loss_fake= 0.044, g_loss 3.285, d_loss 0.159\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 34 Batch 229/390 d_loss_real= 0.159, d_loss_fake= 0.052, g_loss 2.970, d_loss 0.106\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 34 Batch 230/390 d_loss_real= 0.195, d_loss_fake= 0.073, g_loss 2.958, d_loss 0.134\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 231/390 d_loss_real= 0.100, d_loss_fake= 0.067, g_loss 3.162, d_loss 0.083\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 232/390 d_loss_real= 0.203, d_loss_fake= 0.053, g_loss 3.130, d_loss 0.128\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 34 Batch 233/390 d_loss_real= 0.230, d_loss_fake= 0.044, g_loss 3.237, d_loss 0.137\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 234/390 d_loss_real= 0.254, d_loss_fake= 0.044, g_loss 3.149, d_loss 0.149\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 34 Batch 235/390 d_loss_real= 0.127, d_loss_fake= 0.054, g_loss 2.982, d_loss 0.091\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 236/390 d_loss_real= 0.056, d_loss_fake= 0.059, g_loss 3.071, d_loss 0.057\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 237/390 d_loss_real= 0.020, d_loss_fake= 0.050, g_loss 3.175, d_loss 0.035\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 238/390 d_loss_real= 0.128, d_loss_fake= 0.043, g_loss 3.213, d_loss 0.086\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 239/390 d_loss_real= 0.155, d_loss_fake= 0.045, g_loss 3.179, d_loss 0.100\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 240/390 d_loss_real= 0.128, d_loss_fake= 0.044, g_loss 3.193, d_loss 0.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 241/390 d_loss_real= 0.044, d_loss_fake= 0.046, g_loss 3.217, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 242/390 d_loss_real= 0.180, d_loss_fake= 0.045, g_loss 3.258, d_loss 0.113\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 34 Batch 243/390 d_loss_real= 0.296, d_loss_fake= 0.050, g_loss 3.065, d_loss 0.173\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 34 Batch 244/390 d_loss_real= 0.122, d_loss_fake= 0.056, g_loss 2.999, d_loss 0.089\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 34 Batch 245/390 d_loss_real= 0.145, d_loss_fake= 0.057, g_loss 3.002, d_loss 0.101\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 34 Batch 246/390 d_loss_real= 0.036, d_loss_fake= 0.054, g_loss 3.080, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 247/390 d_loss_real= 0.140, d_loss_fake= 0.045, g_loss 3.244, d_loss 0.093\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 248/390 d_loss_real= 0.054, d_loss_fake= 0.041, g_loss 3.290, d_loss 0.047\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 249/390 d_loss_real= 0.067, d_loss_fake= 0.037, g_loss 3.401, d_loss 0.052\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 250/390 d_loss_real= 0.215, d_loss_fake= 0.038, g_loss 3.390, d_loss 0.127\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 251/390 d_loss_real= 0.123, d_loss_fake= 0.039, g_loss 3.354, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 252/390 d_loss_real= 0.156, d_loss_fake= 0.039, g_loss 3.327, d_loss 0.098\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 253/390 d_loss_real= 0.046, d_loss_fake= 0.042, g_loss 3.282, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 254/390 d_loss_real= 0.129, d_loss_fake= 0.043, g_loss 3.227, d_loss 0.086\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 255/390 d_loss_real= 0.130, d_loss_fake= 0.047, g_loss 3.210, d_loss 0.089\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 34 Batch 256/390 d_loss_real= 0.331, d_loss_fake= 0.056, g_loss 3.040, d_loss 0.193\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 257/390 d_loss_real= 0.138, d_loss_fake= 0.059, g_loss 2.927, d_loss 0.099\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 258/390 d_loss_real= 0.394, d_loss_fake= 0.059, g_loss 2.711, d_loss 0.226\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 259/390 d_loss_real= 0.026, d_loss_fake= 0.103, g_loss 2.629, d_loss 0.064\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 34 Batch 260/390 d_loss_real= 0.115, d_loss_fake= 0.110, g_loss 2.763, d_loss 0.112\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 261/390 d_loss_real= 0.134, d_loss_fake= 0.070, g_loss 3.068, d_loss 0.102\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 262/390 d_loss_real= 0.156, d_loss_fake= 0.050, g_loss 3.133, d_loss 0.103\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 263/390 d_loss_real= 0.119, d_loss_fake= 0.043, g_loss 3.316, d_loss 0.081\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 34 Batch 264/390 d_loss_real= 0.177, d_loss_fake= 0.042, g_loss 3.295, d_loss 0.109\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 265/390 d_loss_real= 0.175, d_loss_fake= 0.045, g_loss 3.329, d_loss 0.110\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 34 Batch 266/390 d_loss_real= 0.287, d_loss_fake= 0.043, g_loss 3.265, d_loss 0.165\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 34 Batch 267/390 d_loss_real= 0.106, d_loss_fake= 0.045, g_loss 3.234, d_loss 0.075\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 34 Batch 268/390 d_loss_real= 0.111, d_loss_fake= 0.046, g_loss 3.134, d_loss 0.079\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 34 Batch 269/390 d_loss_real= 0.063, d_loss_fake= 0.049, g_loss 3.135, d_loss 0.056\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 270/390 d_loss_real= 0.161, d_loss_fake= 0.050, g_loss 3.138, d_loss 0.106\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 271/390 d_loss_real= 0.046, d_loss_fake= 0.052, g_loss 3.143, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 272/390 d_loss_real= 0.116, d_loss_fake= 0.049, g_loss 3.152, d_loss 0.083\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 273/390 d_loss_real= 0.318, d_loss_fake= 0.050, g_loss 3.101, d_loss 0.184\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 274/390 d_loss_real= 0.122, d_loss_fake= 0.048, g_loss 3.105, d_loss 0.085\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 34 Batch 275/390 d_loss_real= 0.294, d_loss_fake= 0.056, g_loss 2.962, d_loss 0.175\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 276/390 d_loss_real= 0.103, d_loss_fake= 0.058, g_loss 2.933, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 277/390 d_loss_real= 0.080, d_loss_fake= 0.057, g_loss 2.992, d_loss 0.068\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 278/390 d_loss_real= 0.088, d_loss_fake= 0.053, g_loss 3.081, d_loss 0.070\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 279/390 d_loss_real= 0.000, d_loss_fake= 0.049, g_loss 3.150, d_loss 0.025\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 280/390 d_loss_real= 0.000, d_loss_fake= 0.042, g_loss 3.364, d_loss 0.021\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 34 Batch 281/390 d_loss_real= 0.100, d_loss_fake= 0.036, g_loss 3.450, d_loss 0.068\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 282/390 d_loss_real= 0.037, d_loss_fake= 0.032, g_loss 3.536, d_loss 0.034\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 283/390 d_loss_real= 0.055, d_loss_fake= 0.030, g_loss 3.616, d_loss 0.042\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 284/390 d_loss_real= 0.228, d_loss_fake= 0.030, g_loss 3.609, d_loss 0.129\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 285/390 d_loss_real= 0.097, d_loss_fake= 0.031, g_loss 3.472, d_loss 0.064\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 34 Batch 286/390 d_loss_real= 0.106, d_loss_fake= 0.036, g_loss 3.389, d_loss 0.071\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 287/390 d_loss_real= 0.012, d_loss_fake= 0.038, g_loss 3.311, d_loss 0.025\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 288/390 d_loss_real= 0.065, d_loss_fake= 0.039, g_loss 3.243, d_loss 0.052\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 34 Batch 289/390 d_loss_real= 0.248, d_loss_fake= 0.052, g_loss 3.016, d_loss 0.150\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 290/390 d_loss_real= 0.124, d_loss_fake= 0.058, g_loss 2.978, d_loss 0.091\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 291/390 d_loss_real= 0.087, d_loss_fake= 0.065, g_loss 2.874, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 292/390 d_loss_real= 0.074, d_loss_fake= 0.070, g_loss 3.015, d_loss 0.072\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 293/390 d_loss_real= 0.069, d_loss_fake= 0.052, g_loss 3.274, d_loss 0.061\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 34 Batch 294/390 d_loss_real= 0.148, d_loss_fake= 0.038, g_loss 3.390, d_loss 0.093\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 295/390 d_loss_real= 0.152, d_loss_fake= 0.042, g_loss 3.450, d_loss 0.097\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 296/390 d_loss_real= 0.184, d_loss_fake= 0.038, g_loss 3.413, d_loss 0.111\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 34 Batch 297/390 d_loss_real= 0.219, d_loss_fake= 0.035, g_loss 3.432, d_loss 0.127\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 34 Batch 298/390 d_loss_real= 0.047, d_loss_fake= 0.032, g_loss 3.571, d_loss 0.040\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 299/390 d_loss_real= 0.058, d_loss_fake= 0.030, g_loss 3.724, d_loss 0.044\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 34 Batch 300/390 d_loss_real= 0.186, d_loss_fake= 0.028, g_loss 3.748, d_loss 0.107\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 34 Batch 301/390 d_loss_real= 0.299, d_loss_fake= 0.027, g_loss 3.737, d_loss 0.163\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 302/390 d_loss_real= 0.142, d_loss_fake= 0.027, g_loss 3.578, d_loss 0.085\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 303/390 d_loss_real= 0.154, d_loss_fake= 0.036, g_loss 3.430, d_loss 0.095\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 34 Batch 304/390 d_loss_real= 0.047, d_loss_fake= 0.039, g_loss 3.339, d_loss 0.043\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 34 Batch 305/390 d_loss_real= 0.078, d_loss_fake= 0.048, g_loss 3.235, d_loss 0.063\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 306/390 d_loss_real= 0.070, d_loss_fake= 0.054, g_loss 3.177, d_loss 0.062\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 307/390 d_loss_real= 0.099, d_loss_fake= 0.052, g_loss 3.146, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 308/390 d_loss_real= 0.166, d_loss_fake= 0.048, g_loss 3.287, d_loss 0.107\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 309/390 d_loss_real= 0.098, d_loss_fake= 0.044, g_loss 3.242, d_loss 0.071\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 310/390 d_loss_real= 0.302, d_loss_fake= 0.039, g_loss 3.326, d_loss 0.170\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 311/390 d_loss_real= 0.092, d_loss_fake= 0.038, g_loss 3.386, d_loss 0.065\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 312/390 d_loss_real= 0.134, d_loss_fake= 0.037, g_loss 3.411, d_loss 0.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 313/390 d_loss_real= 0.128, d_loss_fake= 0.032, g_loss 3.538, d_loss 0.080\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 314/390 d_loss_real= 0.338, d_loss_fake= 0.031, g_loss 3.474, d_loss 0.185\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 315/390 d_loss_real= 0.119, d_loss_fake= 0.036, g_loss 3.351, d_loss 0.078\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 34 Batch 316/390 d_loss_real= 0.085, d_loss_fake= 0.038, g_loss 3.306, d_loss 0.062\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 34 Batch 317/390 d_loss_real= 0.149, d_loss_fake= 0.041, g_loss 3.268, d_loss 0.095\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 318/390 d_loss_real= 0.069, d_loss_fake= 0.041, g_loss 3.330, d_loss 0.055\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 319/390 d_loss_real= 0.143, d_loss_fake= 0.041, g_loss 3.303, d_loss 0.092\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 320/390 d_loss_real= 0.130, d_loss_fake= 0.040, g_loss 3.269, d_loss 0.085\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 321/390 d_loss_real= 0.101, d_loss_fake= 0.042, g_loss 3.253, d_loss 0.071\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 322/390 d_loss_real= 0.002, d_loss_fake= 0.041, g_loss 3.237, d_loss 0.021\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 34 Batch 323/390 d_loss_real= 0.085, d_loss_fake= 0.041, g_loss 3.261, d_loss 0.063\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 324/390 d_loss_real= 0.150, d_loss_fake= 0.040, g_loss 3.285, d_loss 0.095\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 325/390 d_loss_real= 0.113, d_loss_fake= 0.044, g_loss 3.231, d_loss 0.078\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 326/390 d_loss_real= 0.120, d_loss_fake= 0.047, g_loss 3.153, d_loss 0.084\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 327/390 d_loss_real= 0.010, d_loss_fake= 0.050, g_loss 3.111, d_loss 0.030\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 328/390 d_loss_real= 0.003, d_loss_fake= 0.048, g_loss 3.162, d_loss 0.025\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 34 Batch 329/390 d_loss_real= 0.094, d_loss_fake= 0.051, g_loss 3.156, d_loss 0.072\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 330/390 d_loss_real= 0.043, d_loss_fake= 0.058, g_loss 3.167, d_loss 0.051\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 331/390 d_loss_real= 0.095, d_loss_fake= 0.051, g_loss 3.151, d_loss 0.073\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 34 Batch 332/390 d_loss_real= 0.192, d_loss_fake= 0.058, g_loss 3.115, d_loss 0.125\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 34 Batch 333/390 d_loss_real= 0.004, d_loss_fake= 0.059, g_loss 3.011, d_loss 0.032\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 34 Batch 334/390 d_loss_real= 0.018, d_loss_fake= 0.067, g_loss 3.154, d_loss 0.043\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 335/390 d_loss_real= 0.074, d_loss_fake= 0.053, g_loss 3.140, d_loss 0.063\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 336/390 d_loss_real= 0.101, d_loss_fake= 0.056, g_loss 3.290, d_loss 0.078\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 337/390 d_loss_real= 0.150, d_loss_fake= 0.063, g_loss 3.133, d_loss 0.106\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 338/390 d_loss_real= 0.127, d_loss_fake= 0.062, g_loss 3.044, d_loss 0.094\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 339/390 d_loss_real= 0.184, d_loss_fake= 0.069, g_loss 2.879, d_loss 0.126\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 340/390 d_loss_real= 0.099, d_loss_fake= 0.085, g_loss 2.681, d_loss 0.092\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 341/390 d_loss_real= 0.117, d_loss_fake= 0.080, g_loss 2.591, d_loss 0.099\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 342/390 d_loss_real= 0.126, d_loss_fake= 0.097, g_loss 2.629, d_loss 0.111\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 34 Batch 343/390 d_loss_real= 0.119, d_loss_fake= 0.088, g_loss 2.723, d_loss 0.104\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 344/390 d_loss_real= 0.219, d_loss_fake= 0.086, g_loss 2.804, d_loss 0.153\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 34 Batch 345/390 d_loss_real= 0.084, d_loss_fake= 0.069, g_loss 2.829, d_loss 0.077\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 346/390 d_loss_real= 0.114, d_loss_fake= 0.095, g_loss 2.954, d_loss 0.105\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 347/390 d_loss_real= 0.080, d_loss_fake= 0.066, g_loss 2.995, d_loss 0.073\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 348/390 d_loss_real= 0.002, d_loss_fake= 0.060, g_loss 3.137, d_loss 0.031\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 349/390 d_loss_real= 0.067, d_loss_fake= 0.056, g_loss 3.481, d_loss 0.061\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 34 Batch 350/390 d_loss_real= 0.181, d_loss_fake= 0.038, g_loss 3.556, d_loss 0.110\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 351/390 d_loss_real= 0.100, d_loss_fake= 0.033, g_loss 3.647, d_loss 0.067\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 352/390 d_loss_real= 0.129, d_loss_fake= 0.037, g_loss 3.596, d_loss 0.083\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 34 Batch 353/390 d_loss_real= 0.194, d_loss_fake= 0.035, g_loss 3.729, d_loss 0.114\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 354/390 d_loss_real= 0.186, d_loss_fake= 0.032, g_loss 3.610, d_loss 0.109\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 355/390 d_loss_real= 0.058, d_loss_fake= 0.035, g_loss 3.695, d_loss 0.046\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 356/390 d_loss_real= 0.000, d_loss_fake= 0.035, g_loss 3.625, d_loss 0.017\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 34 Batch 357/390 d_loss_real= 0.039, d_loss_fake= 0.040, g_loss 3.770, d_loss 0.040\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 358/390 d_loss_real= 0.217, d_loss_fake= 0.053, g_loss 3.703, d_loss 0.135\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 34 Batch 359/390 d_loss_real= 0.160, d_loss_fake= 0.028, g_loss 3.650, d_loss 0.094\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 360/390 d_loss_real= 0.104, d_loss_fake= 0.033, g_loss 3.758, d_loss 0.069\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 34 Batch 361/390 d_loss_real= 0.168, d_loss_fake= 0.037, g_loss 3.744, d_loss 0.103\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 362/390 d_loss_real= 0.251, d_loss_fake= 0.054, g_loss 3.438, d_loss 0.153\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 34 Batch 363/390 d_loss_real= 0.186, d_loss_fake= 0.081, g_loss 3.543, d_loss 0.133\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 34 Batch 364/390 d_loss_real= 0.095, d_loss_fake= 0.063, g_loss 3.683, d_loss 0.079\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 365/390 d_loss_real= 0.192, d_loss_fake= 0.053, g_loss 3.995, d_loss 0.122\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 366/390 d_loss_real= 0.161, d_loss_fake= 0.017, g_loss 4.291, d_loss 0.089\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 367/390 d_loss_real= 0.101, d_loss_fake= 0.013, g_loss 4.401, d_loss 0.057\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 34 Batch 368/390 d_loss_real= 0.300, d_loss_fake= 0.015, g_loss 4.180, d_loss 0.158\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 369/390 d_loss_real= 0.206, d_loss_fake= 0.021, g_loss 3.930, d_loss 0.114\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 34 Batch 370/390 d_loss_real= 0.160, d_loss_fake= 0.028, g_loss 3.614, d_loss 0.094\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 34 Batch 371/390 d_loss_real= 0.154, d_loss_fake= 0.022, g_loss 3.818, d_loss 0.088\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 372/390 d_loss_real= 0.037, d_loss_fake= 0.136, g_loss 3.679, d_loss 0.087\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 373/390 d_loss_real= 0.197, d_loss_fake= 0.030, g_loss 3.998, d_loss 0.113\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 34 Batch 374/390 d_loss_real= 0.145, d_loss_fake= 0.017, g_loss 4.183, d_loss 0.081\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 375/390 d_loss_real= 0.521, d_loss_fake= 0.018, g_loss 4.152, d_loss 0.270\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34 Batch 376/390 d_loss_real= 0.239, d_loss_fake= 0.020, g_loss 3.882, d_loss 0.130\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 377/390 d_loss_real= 0.040, d_loss_fake= 0.028, g_loss 3.603, d_loss 0.034\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 34 Batch 378/390 d_loss_real= 0.153, d_loss_fake= 0.036, g_loss 3.235, d_loss 0.094\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 34 Batch 379/390 d_loss_real= 0.128, d_loss_fake= 0.052, g_loss 3.199, d_loss 0.090\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 380/390 d_loss_real= 0.008, d_loss_fake= 0.089, g_loss 2.949, d_loss 0.048\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 34 Batch 381/390 d_loss_real= 0.216, d_loss_fake= 0.068, g_loss 3.174, d_loss 0.142\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 382/390 d_loss_real= 0.186, d_loss_fake= 0.063, g_loss 3.383, d_loss 0.124\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 383/390 d_loss_real= 0.202, d_loss_fake= 0.050, g_loss 3.507, d_loss 0.126\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34 Batch 384/390 d_loss_real= 0.252, d_loss_fake= 0.047, g_loss 3.654, d_loss 0.149\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 385/390 d_loss_real= 0.194, d_loss_fake= 0.042, g_loss 3.760, d_loss 0.118\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 386/390 d_loss_real= 0.216, d_loss_fake= 0.030, g_loss 3.815, d_loss 0.123\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34 Batch 387/390 d_loss_real= 0.113, d_loss_fake= 0.027, g_loss 3.919, d_loss 0.070\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34 Batch 388/390 d_loss_real= 0.205, d_loss_fake= 0.027, g_loss 3.865, d_loss 0.116\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 34 Batch 389/390 d_loss_real= 0.056, d_loss_fake= 0.031, g_loss 3.750, d_loss 0.043\n",
            "2/2 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34 Batch 390/390 d_loss_real= 0.125, d_loss_fake= 0.027, g_loss 3.713, d_loss 0.076\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 35 Batch 1/390 d_loss_real= 0.102, d_loss_fake= 0.029, g_loss 3.642, d_loss 0.066\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 2/390 d_loss_real= 0.220, d_loss_fake= 0.034, g_loss 3.487, d_loss 0.127\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 3/390 d_loss_real= 0.229, d_loss_fake= 0.044, g_loss 3.315, d_loss 0.136\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 4/390 d_loss_real= 0.113, d_loss_fake= 0.068, g_loss 3.216, d_loss 0.090\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 5/390 d_loss_real= 0.006, d_loss_fake= 0.054, g_loss 3.603, d_loss 0.030\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 35 Batch 6/390 d_loss_real= 0.010, d_loss_fake= 0.030, g_loss 4.036, d_loss 0.020\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 35 Batch 7/390 d_loss_real= 0.143, d_loss_fake= 0.018, g_loss 4.249, d_loss 0.081\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 8/390 d_loss_real= 0.166, d_loss_fake= 0.015, g_loss 4.455, d_loss 0.090\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 9/390 d_loss_real= 0.239, d_loss_fake= 0.014, g_loss 4.408, d_loss 0.127\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 10/390 d_loss_real= 0.259, d_loss_fake= 0.015, g_loss 4.236, d_loss 0.137\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 11/390 d_loss_real= 0.074, d_loss_fake= 0.019, g_loss 4.012, d_loss 0.046\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 35 Batch 12/390 d_loss_real= 0.097, d_loss_fake= 0.029, g_loss 3.597, d_loss 0.063\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 35 Batch 13/390 d_loss_real= 0.128, d_loss_fake= 0.058, g_loss 3.359, d_loss 0.093\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 35 Batch 14/390 d_loss_real= 0.141, d_loss_fake= 0.064, g_loss 3.526, d_loss 0.103\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 35 Batch 15/390 d_loss_real= 0.004, d_loss_fake= 0.035, g_loss 3.943, d_loss 0.019\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 35 Batch 16/390 d_loss_real= 0.133, d_loss_fake= 0.022, g_loss 4.174, d_loss 0.078\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 17/390 d_loss_real= 0.132, d_loss_fake= 0.020, g_loss 4.156, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 18/390 d_loss_real= 0.168, d_loss_fake= 0.019, g_loss 4.079, d_loss 0.093\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 19/390 d_loss_real= 0.005, d_loss_fake= 0.018, g_loss 4.000, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 20/390 d_loss_real= 0.180, d_loss_fake= 0.023, g_loss 3.899, d_loss 0.101\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 21/390 d_loss_real= 0.112, d_loss_fake= 0.027, g_loss 3.750, d_loss 0.070\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 35 Batch 22/390 d_loss_real= 0.090, d_loss_fake= 0.035, g_loss 3.524, d_loss 0.063\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 23/390 d_loss_real= 0.064, d_loss_fake= 0.056, g_loss 3.119, d_loss 0.060\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 35 Batch 24/390 d_loss_real= 0.321, d_loss_fake= 0.066, g_loss 3.019, d_loss 0.193\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 35 Batch 25/390 d_loss_real= 0.051, d_loss_fake= 0.073, g_loss 3.286, d_loss 0.062\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 35 Batch 26/390 d_loss_real= 0.037, d_loss_fake= 0.033, g_loss 3.657, d_loss 0.035\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 35 Batch 27/390 d_loss_real= 0.118, d_loss_fake= 0.026, g_loss 3.813, d_loss 0.072\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 35 Batch 28/390 d_loss_real= 0.178, d_loss_fake= 0.026, g_loss 3.707, d_loss 0.102\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 29/390 d_loss_real= 0.027, d_loss_fake= 0.029, g_loss 3.763, d_loss 0.028\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 35 Batch 30/390 d_loss_real= 0.186, d_loss_fake= 0.030, g_loss 3.599, d_loss 0.108\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 35 Batch 31/390 d_loss_real= 0.133, d_loss_fake= 0.037, g_loss 3.427, d_loss 0.085\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 32/390 d_loss_real= 0.193, d_loss_fake= 0.050, g_loss 3.164, d_loss 0.122\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 35 Batch 33/390 d_loss_real= 0.222, d_loss_fake= 0.047, g_loss 3.244, d_loss 0.135\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 35 Batch 34/390 d_loss_real= 0.216, d_loss_fake= 0.038, g_loss 3.422, d_loss 0.127\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 35/390 d_loss_real= 0.076, d_loss_fake= 0.075, g_loss 3.141, d_loss 0.075\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 35 Batch 36/390 d_loss_real= 0.150, d_loss_fake= 0.044, g_loss 3.364, d_loss 0.097\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 35 Batch 37/390 d_loss_real= 0.076, d_loss_fake= 0.041, g_loss 3.326, d_loss 0.058\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 38/390 d_loss_real= 0.164, d_loss_fake= 0.046, g_loss 3.460, d_loss 0.105\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 39/390 d_loss_real= 0.102, d_loss_fake= 0.034, g_loss 3.525, d_loss 0.068\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 40/390 d_loss_real= 0.094, d_loss_fake= 0.038, g_loss 3.519, d_loss 0.066\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 41/390 d_loss_real= 0.102, d_loss_fake= 0.035, g_loss 3.455, d_loss 0.068\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 42/390 d_loss_real= 0.146, d_loss_fake= 0.039, g_loss 3.401, d_loss 0.093\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 43/390 d_loss_real= 0.067, d_loss_fake= 0.042, g_loss 3.330, d_loss 0.055\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 35 Batch 44/390 d_loss_real= 0.072, d_loss_fake= 0.039, g_loss 3.301, d_loss 0.056\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 35 Batch 45/390 d_loss_real= 0.152, d_loss_fake= 0.045, g_loss 3.203, d_loss 0.099\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 46/390 d_loss_real= 0.176, d_loss_fake= 0.049, g_loss 3.116, d_loss 0.113\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 47/390 d_loss_real= 0.137, d_loss_fake= 0.051, g_loss 3.068, d_loss 0.094\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 35 Batch 48/390 d_loss_real= 0.171, d_loss_fake= 0.047, g_loss 3.205, d_loss 0.109\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 35 Batch 49/390 d_loss_real= 0.093, d_loss_fake= 0.046, g_loss 3.295, d_loss 0.070\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 35 Batch 50/390 d_loss_real= 0.161, d_loss_fake= 0.042, g_loss 3.212, d_loss 0.102\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 35 Batch 51/390 d_loss_real= 0.105, d_loss_fake= 0.049, g_loss 3.104, d_loss 0.077\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 35 Batch 52/390 d_loss_real= 0.060, d_loss_fake= 0.051, g_loss 3.082, d_loss 0.056\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 53/390 d_loss_real= 0.138, d_loss_fake= 0.053, g_loss 3.072, d_loss 0.096\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 35 Batch 54/390 d_loss_real= 0.038, d_loss_fake= 0.054, g_loss 3.106, d_loss 0.046\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 35 Batch 55/390 d_loss_real= 0.100, d_loss_fake= 0.049, g_loss 3.173, d_loss 0.075\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 56/390 d_loss_real= 0.013, d_loss_fake= 0.047, g_loss 3.205, d_loss 0.030\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 35 Batch 57/390 d_loss_real= 0.119, d_loss_fake= 0.045, g_loss 3.317, d_loss 0.082\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 58/390 d_loss_real= 0.077, d_loss_fake= 0.040, g_loss 3.333, d_loss 0.059\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 59/390 d_loss_real= 0.068, d_loss_fake= 0.040, g_loss 3.259, d_loss 0.054\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 60/390 d_loss_real= 0.016, d_loss_fake= 0.037, g_loss 3.298, d_loss 0.027\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 61/390 d_loss_real= 0.142, d_loss_fake= 0.035, g_loss 3.474, d_loss 0.088\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 35 Batch 62/390 d_loss_real= 0.169, d_loss_fake= 0.038, g_loss 3.272, d_loss 0.103\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 35 Batch 63/390 d_loss_real= 0.198, d_loss_fake= 0.059, g_loss 3.087, d_loss 0.129\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 64/390 d_loss_real= 0.197, d_loss_fake= 0.068, g_loss 3.145, d_loss 0.132\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 35 Batch 65/390 d_loss_real= 0.348, d_loss_fake= 0.057, g_loss 3.310, d_loss 0.202\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 35 Batch 66/390 d_loss_real= 0.053, d_loss_fake= 0.040, g_loss 3.504, d_loss 0.046\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 67/390 d_loss_real= 0.129, d_loss_fake= 0.032, g_loss 3.639, d_loss 0.080\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 68/390 d_loss_real= 0.353, d_loss_fake= 0.033, g_loss 3.445, d_loss 0.193\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 69/390 d_loss_real= 0.228, d_loss_fake= 0.040, g_loss 3.309, d_loss 0.134\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 70/390 d_loss_real= 0.169, d_loss_fake= 0.046, g_loss 3.213, d_loss 0.107\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 35 Batch 71/390 d_loss_real= 0.205, d_loss_fake= 0.056, g_loss 2.967, d_loss 0.130\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 35 Batch 72/390 d_loss_real= 0.056, d_loss_fake= 0.069, g_loss 3.077, d_loss 0.063\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 73/390 d_loss_real= 0.113, d_loss_fake= 0.059, g_loss 3.110, d_loss 0.086\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 35 Batch 74/390 d_loss_real= 0.178, d_loss_fake= 0.047, g_loss 3.136, d_loss 0.113\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 35 Batch 75/390 d_loss_real= 0.142, d_loss_fake= 0.047, g_loss 3.262, d_loss 0.094\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 76/390 d_loss_real= 0.092, d_loss_fake= 0.040, g_loss 3.335, d_loss 0.066\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 77/390 d_loss_real= 0.135, d_loss_fake= 0.038, g_loss 3.309, d_loss 0.087\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 78/390 d_loss_real= 0.025, d_loss_fake= 0.038, g_loss 3.297, d_loss 0.032\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 35 Batch 79/390 d_loss_real= 0.181, d_loss_fake= 0.041, g_loss 3.208, d_loss 0.111\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 80/390 d_loss_real= 0.134, d_loss_fake= 0.046, g_loss 3.139, d_loss 0.090\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 35 Batch 81/390 d_loss_real= 0.090, d_loss_fake= 0.048, g_loss 3.125, d_loss 0.069\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 82/390 d_loss_real= 0.095, d_loss_fake= 0.048, g_loss 3.126, d_loss 0.072\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 83/390 d_loss_real= 0.153, d_loss_fake= 0.048, g_loss 3.106, d_loss 0.101\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 35 Batch 84/390 d_loss_real= 0.059, d_loss_fake= 0.049, g_loss 3.093, d_loss 0.054\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 35 Batch 85/390 d_loss_real= 0.075, d_loss_fake= 0.050, g_loss 3.075, d_loss 0.063\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 86/390 d_loss_real= 0.151, d_loss_fake= 0.052, g_loss 3.051, d_loss 0.102\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 35 Batch 87/390 d_loss_real= 0.069, d_loss_fake= 0.054, g_loss 2.992, d_loss 0.061\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 35 Batch 88/390 d_loss_real= 0.042, d_loss_fake= 0.052, g_loss 3.066, d_loss 0.047\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 35 Batch 89/390 d_loss_real= 0.222, d_loss_fake= 0.054, g_loss 3.103, d_loss 0.138\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 35 Batch 90/390 d_loss_real= 0.113, d_loss_fake= 0.050, g_loss 3.016, d_loss 0.082\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 91/390 d_loss_real= 0.081, d_loss_fake= 0.051, g_loss 3.130, d_loss 0.066\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 92/390 d_loss_real= 0.309, d_loss_fake= 0.053, g_loss 3.014, d_loss 0.181\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 35 Batch 93/390 d_loss_real= 0.189, d_loss_fake= 0.064, g_loss 2.902, d_loss 0.126\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 35 Batch 94/390 d_loss_real= 0.065, d_loss_fake= 0.065, g_loss 3.004, d_loss 0.065\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 35 Batch 95/390 d_loss_real= 0.006, d_loss_fake= 0.060, g_loss 3.108, d_loss 0.033\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 35 Batch 96/390 d_loss_real= 0.050, d_loss_fake= 0.046, g_loss 3.239, d_loss 0.048\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 35 Batch 97/390 d_loss_real= 0.068, d_loss_fake= 0.041, g_loss 3.316, d_loss 0.054\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 35 Batch 98/390 d_loss_real= 0.173, d_loss_fake= 0.042, g_loss 3.404, d_loss 0.107\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 99/390 d_loss_real= 0.115, d_loss_fake= 0.043, g_loss 3.315, d_loss 0.079\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 35 Batch 100/390 d_loss_real= 0.127, d_loss_fake= 0.048, g_loss 3.259, d_loss 0.087\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 101/390 d_loss_real= 0.042, d_loss_fake= 0.048, g_loss 3.187, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 102/390 d_loss_real= 0.232, d_loss_fake= 0.057, g_loss 3.152, d_loss 0.144\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 35 Batch 103/390 d_loss_real= 0.090, d_loss_fake= 0.064, g_loss 3.094, d_loss 0.077\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 104/390 d_loss_real= 0.095, d_loss_fake= 0.057, g_loss 3.199, d_loss 0.076\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 105/390 d_loss_real= 0.185, d_loss_fake= 0.054, g_loss 3.419, d_loss 0.120\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 35 Batch 106/390 d_loss_real= 0.187, d_loss_fake= 0.040, g_loss 3.491, d_loss 0.114\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 107/390 d_loss_real= 0.255, d_loss_fake= 0.041, g_loss 3.472, d_loss 0.148\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 35 Batch 108/390 d_loss_real= 0.094, d_loss_fake= 0.037, g_loss 3.638, d_loss 0.065\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 35 Batch 109/390 d_loss_real= 0.068, d_loss_fake= 0.028, g_loss 3.864, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 110/390 d_loss_real= 0.248, d_loss_fake= 0.023, g_loss 3.918, d_loss 0.136\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 35 Batch 111/390 d_loss_real= 0.175, d_loss_fake= 0.024, g_loss 3.714, d_loss 0.100\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 112/390 d_loss_real= 0.249, d_loss_fake= 0.029, g_loss 3.604, d_loss 0.139\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 113/390 d_loss_real= 0.188, d_loss_fake= 0.032, g_loss 3.570, d_loss 0.110\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 114/390 d_loss_real= 0.049, d_loss_fake= 0.033, g_loss 3.494, d_loss 0.041\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 115/390 d_loss_real= 0.226, d_loss_fake= 0.052, g_loss 3.249, d_loss 0.139\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 116/390 d_loss_real= 0.092, d_loss_fake= 0.066, g_loss 3.507, d_loss 0.079\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 35 Batch 117/390 d_loss_real= 0.292, d_loss_fake= 0.030, g_loss 3.883, d_loss 0.161\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 118/390 d_loss_real= 0.135, d_loss_fake= 0.023, g_loss 3.878, d_loss 0.079\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 119/390 d_loss_real= 0.143, d_loss_fake= 0.025, g_loss 3.690, d_loss 0.084\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 120/390 d_loss_real= 0.213, d_loss_fake= 0.032, g_loss 3.457, d_loss 0.122\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 121/390 d_loss_real= 0.114, d_loss_fake= 0.043, g_loss 3.166, d_loss 0.079\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 122/390 d_loss_real= 0.151, d_loss_fake= 0.053, g_loss 2.990, d_loss 0.102\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 35 Batch 123/390 d_loss_real= 0.433, d_loss_fake= 0.067, g_loss 2.757, d_loss 0.250\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 124/390 d_loss_real= 0.174, d_loss_fake= 0.083, g_loss 2.626, d_loss 0.128\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 35 Batch 125/390 d_loss_real= 0.071, d_loss_fake= 0.092, g_loss 2.557, d_loss 0.082\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 126/390 d_loss_real= 0.099, d_loss_fake= 0.096, g_loss 2.586, d_loss 0.097\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 35 Batch 127/390 d_loss_real= 0.047, d_loss_fake= 0.085, g_loss 2.611, d_loss 0.066\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 35 Batch 128/390 d_loss_real= 0.004, d_loss_fake= 0.090, g_loss 2.696, d_loss 0.047\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 129/390 d_loss_real= 0.071, d_loss_fake= 0.114, g_loss 2.800, d_loss 0.092\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 35 Batch 130/390 d_loss_real= 0.062, d_loss_fake= 0.144, g_loss 3.317, d_loss 0.103\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 35 Batch 131/390 d_loss_real= 0.000, d_loss_fake= 0.027, g_loss 4.182, d_loss 0.013\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 35 Batch 132/390 d_loss_real= 0.126, d_loss_fake= 0.014, g_loss 4.520, d_loss 0.070\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 35 Batch 133/390 d_loss_real= 0.136, d_loss_fake= 0.013, g_loss 4.445, d_loss 0.074\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 35 Batch 134/390 d_loss_real= 0.053, d_loss_fake= 0.012, g_loss 4.552, d_loss 0.033\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 135/390 d_loss_real= 0.122, d_loss_fake= 0.012, g_loss 4.522, d_loss 0.067\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 136/390 d_loss_real= 0.247, d_loss_fake= 0.013, g_loss 4.433, d_loss 0.130\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 137/390 d_loss_real= 0.497, d_loss_fake= 0.015, g_loss 4.181, d_loss 0.256\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 138/390 d_loss_real= 0.202, d_loss_fake= 0.018, g_loss 4.016, d_loss 0.110\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 139/390 d_loss_real= 0.116, d_loss_fake= 0.024, g_loss 3.806, d_loss 0.070\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 140/390 d_loss_real= 0.038, d_loss_fake= 0.029, g_loss 3.546, d_loss 0.033\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 141/390 d_loss_real= 0.157, d_loss_fake= 0.035, g_loss 3.284, d_loss 0.096\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 142/390 d_loss_real= 0.000, d_loss_fake= 0.056, g_loss 2.858, d_loss 0.028\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 143/390 d_loss_real= 0.147, d_loss_fake= 0.191, g_loss 2.788, d_loss 0.169\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 144/390 d_loss_real= 0.130, d_loss_fake= 0.057, g_loss 3.259, d_loss 0.093\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 145/390 d_loss_real= 0.183, d_loss_fake= 0.042, g_loss 3.339, d_loss 0.112\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 146/390 d_loss_real= 0.169, d_loss_fake= 0.040, g_loss 3.380, d_loss 0.104\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 147/390 d_loss_real= 0.243, d_loss_fake= 0.040, g_loss 3.317, d_loss 0.141\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 148/390 d_loss_real= 0.064, d_loss_fake= 0.043, g_loss 3.270, d_loss 0.053\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 35 Batch 149/390 d_loss_real= 0.178, d_loss_fake= 0.045, g_loss 3.165, d_loss 0.111\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 150/390 d_loss_real= 0.142, d_loss_fake= 0.046, g_loss 3.077, d_loss 0.094\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 35 Batch 151/390 d_loss_real= 0.014, d_loss_fake= 0.052, g_loss 3.052, d_loss 0.033\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 35 Batch 152/390 d_loss_real= 0.119, d_loss_fake= 0.056, g_loss 2.939, d_loss 0.087\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 35 Batch 153/390 d_loss_real= 0.172, d_loss_fake= 0.062, g_loss 2.817, d_loss 0.117\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 154/390 d_loss_real= 0.059, d_loss_fake= 0.068, g_loss 2.656, d_loss 0.063\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 155/390 d_loss_real= 0.000, d_loss_fake= 0.087, g_loss 2.545, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 156/390 d_loss_real= 0.055, d_loss_fake= 0.106, g_loss 2.651, d_loss 0.080\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 157/390 d_loss_real= 0.115, d_loss_fake= 0.084, g_loss 2.825, d_loss 0.100\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 158/390 d_loss_real= 0.192, d_loss_fake= 0.068, g_loss 3.154, d_loss 0.130\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 159/390 d_loss_real= 0.095, d_loss_fake= 0.048, g_loss 3.287, d_loss 0.072\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 160/390 d_loss_real= 0.080, d_loss_fake= 0.041, g_loss 3.440, d_loss 0.061\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 35 Batch 161/390 d_loss_real= 0.102, d_loss_fake= 0.035, g_loss 3.499, d_loss 0.068\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 162/390 d_loss_real= 0.231, d_loss_fake= 0.034, g_loss 3.403, d_loss 0.132\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 35 Batch 163/390 d_loss_real= 0.236, d_loss_fake= 0.038, g_loss 3.258, d_loss 0.137\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 35 Batch 164/390 d_loss_real= 0.198, d_loss_fake= 0.066, g_loss 3.095, d_loss 0.132\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 165/390 d_loss_real= 0.111, d_loss_fake= 0.090, g_loss 2.985, d_loss 0.101\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 166/390 d_loss_real= 0.131, d_loss_fake= 0.077, g_loss 3.295, d_loss 0.104\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 35 Batch 167/390 d_loss_real= 0.101, d_loss_fake= 0.042, g_loss 3.643, d_loss 0.071\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 35 Batch 168/390 d_loss_real= 0.163, d_loss_fake= 0.027, g_loss 3.843, d_loss 0.095\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 169/390 d_loss_real= 0.081, d_loss_fake= 0.021, g_loss 3.928, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 170/390 d_loss_real= 0.245, d_loss_fake= 0.020, g_loss 3.943, d_loss 0.132\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 171/390 d_loss_real= 0.188, d_loss_fake= 0.021, g_loss 3.877, d_loss 0.104\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 172/390 d_loss_real= 0.049, d_loss_fake= 0.022, g_loss 3.823, d_loss 0.035\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 35 Batch 173/390 d_loss_real= 0.060, d_loss_fake= 0.023, g_loss 3.780, d_loss 0.042\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 35 Batch 174/390 d_loss_real= 0.162, d_loss_fake= 0.024, g_loss 3.682, d_loss 0.093\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 175/390 d_loss_real= 0.170, d_loss_fake= 0.029, g_loss 3.509, d_loss 0.099\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 35 Batch 176/390 d_loss_real= 0.260, d_loss_fake= 0.037, g_loss 3.230, d_loss 0.148\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 35 Batch 177/390 d_loss_real= 0.138, d_loss_fake= 0.065, g_loss 2.911, d_loss 0.102\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 35 Batch 178/390 d_loss_real= 0.076, d_loss_fake= 0.103, g_loss 2.955, d_loss 0.089\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 179/390 d_loss_real= 0.163, d_loss_fake= 0.070, g_loss 3.249, d_loss 0.117\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 35 Batch 180/390 d_loss_real= 0.108, d_loss_fake= 0.040, g_loss 3.510, d_loss 0.074\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 181/390 d_loss_real= 0.035, d_loss_fake= 0.028, g_loss 3.672, d_loss 0.031\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 35 Batch 182/390 d_loss_real= 0.153, d_loss_fake= 0.026, g_loss 3.702, d_loss 0.089\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 35 Batch 183/390 d_loss_real= 0.095, d_loss_fake= 0.026, g_loss 3.671, d_loss 0.060\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 35 Batch 184/390 d_loss_real= 0.083, d_loss_fake= 0.028, g_loss 3.644, d_loss 0.055\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 185/390 d_loss_real= 0.112, d_loss_fake= 0.030, g_loss 3.579, d_loss 0.071\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 35 Batch 186/390 d_loss_real= 0.108, d_loss_fake= 0.031, g_loss 3.434, d_loss 0.070\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 35 Batch 187/390 d_loss_real= 0.000, d_loss_fake= 0.042, g_loss 3.234, d_loss 0.021\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 35 Batch 188/390 d_loss_real= 0.007, d_loss_fake= 0.053, g_loss 3.090, d_loss 0.030\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 35 Batch 189/390 d_loss_real= 0.057, d_loss_fake= 0.054, g_loss 3.113, d_loss 0.056\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 35 Batch 190/390 d_loss_real= 0.015, d_loss_fake= 0.052, g_loss 3.225, d_loss 0.033\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 35 Batch 191/390 d_loss_real= 0.179, d_loss_fake= 0.049, g_loss 3.333, d_loss 0.114\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 192/390 d_loss_real= 0.094, d_loss_fake= 0.044, g_loss 3.384, d_loss 0.069\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 193/390 d_loss_real= 0.113, d_loss_fake= 0.034, g_loss 3.513, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 194/390 d_loss_real= 0.111, d_loss_fake= 0.031, g_loss 3.552, d_loss 0.071\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 35 Batch 195/390 d_loss_real= 0.084, d_loss_fake= 0.031, g_loss 3.585, d_loss 0.057\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 196/390 d_loss_real= 0.190, d_loss_fake= 0.032, g_loss 3.552, d_loss 0.111\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 197/390 d_loss_real= 0.147, d_loss_fake= 0.032, g_loss 3.465, d_loss 0.090\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 198/390 d_loss_real= 0.124, d_loss_fake= 0.038, g_loss 3.420, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 199/390 d_loss_real= 0.039, d_loss_fake= 0.071, g_loss 3.369, d_loss 0.055\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 35 Batch 200/390 d_loss_real= 0.000, d_loss_fake= 0.039, g_loss 3.523, d_loss 0.020\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 35 Batch 201/390 d_loss_real= 0.143, d_loss_fake= 0.033, g_loss 3.643, d_loss 0.088\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 35 Batch 202/390 d_loss_real= 0.166, d_loss_fake= 0.027, g_loss 3.814, d_loss 0.097\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 203/390 d_loss_real= 0.211, d_loss_fake= 0.029, g_loss 3.710, d_loss 0.120\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 204/390 d_loss_real= 0.161, d_loss_fake= 0.035, g_loss 3.690, d_loss 0.098\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 35 Batch 205/390 d_loss_real= 0.215, d_loss_fake= 0.035, g_loss 3.631, d_loss 0.125\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 206/390 d_loss_real= 0.071, d_loss_fake= 0.033, g_loss 3.757, d_loss 0.052\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 207/390 d_loss_real= 0.107, d_loss_fake= 0.025, g_loss 3.869, d_loss 0.066\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 208/390 d_loss_real= 0.061, d_loss_fake= 0.053, g_loss 3.537, d_loss 0.057\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 35 Batch 209/390 d_loss_real= 0.098, d_loss_fake= 0.044, g_loss 3.860, d_loss 0.071\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 35 Batch 210/390 d_loss_real= 0.170, d_loss_fake= 0.025, g_loss 4.193, d_loss 0.097\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 211/390 d_loss_real= 0.083, d_loss_fake= 0.017, g_loss 4.362, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 212/390 d_loss_real= 0.140, d_loss_fake= 0.014, g_loss 4.337, d_loss 0.077\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 35 Batch 213/390 d_loss_real= 0.100, d_loss_fake= 0.019, g_loss 4.320, d_loss 0.059\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 214/390 d_loss_real= 0.055, d_loss_fake= 0.017, g_loss 4.223, d_loss 0.036\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 215/390 d_loss_real= 0.062, d_loss_fake= 0.019, g_loss 4.206, d_loss 0.040\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 35 Batch 216/390 d_loss_real= 0.103, d_loss_fake= 0.030, g_loss 4.050, d_loss 0.067\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 217/390 d_loss_real= 0.071, d_loss_fake= 0.029, g_loss 3.808, d_loss 0.050\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 35 Batch 218/390 d_loss_real= 0.142, d_loss_fake= 0.032, g_loss 3.751, d_loss 0.087\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 35 Batch 219/390 d_loss_real= 0.223, d_loss_fake= 0.040, g_loss 3.531, d_loss 0.132\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 35 Batch 220/390 d_loss_real= 0.052, d_loss_fake= 0.056, g_loss 3.213, d_loss 0.054\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 35 Batch 221/390 d_loss_real= 0.244, d_loss_fake= 0.082, g_loss 3.089, d_loss 0.163\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 222/390 d_loss_real= 0.180, d_loss_fake= 0.076, g_loss 3.127, d_loss 0.128\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 223/390 d_loss_real= 0.136, d_loss_fake= 0.087, g_loss 3.120, d_loss 0.112\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 224/390 d_loss_real= 0.422, d_loss_fake= 0.230, g_loss 3.528, d_loss 0.326\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 35 Batch 225/390 d_loss_real= 0.390, d_loss_fake= 0.084, g_loss 4.455, d_loss 0.237\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 35 Batch 226/390 d_loss_real= 0.233, d_loss_fake= 0.009, g_loss 5.581, d_loss 0.121\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 35 Batch 227/390 d_loss_real= 0.335, d_loss_fake= 0.005, g_loss 5.719, d_loss 0.170\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 35 Batch 228/390 d_loss_real= 0.506, d_loss_fake= 0.006, g_loss 5.261, d_loss 0.256\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 229/390 d_loss_real= 0.222, d_loss_fake= 0.009, g_loss 4.716, d_loss 0.116\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 35 Batch 230/390 d_loss_real= 0.168, d_loss_fake= 0.012, g_loss 4.329, d_loss 0.090\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 231/390 d_loss_real= 0.135, d_loss_fake= 0.018, g_loss 4.089, d_loss 0.077\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 232/390 d_loss_real= 0.107, d_loss_fake= 0.025, g_loss 3.798, d_loss 0.066\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 35 Batch 233/390 d_loss_real= 0.205, d_loss_fake= 0.032, g_loss 3.581, d_loss 0.119\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 234/390 d_loss_real= 0.073, d_loss_fake= 0.037, g_loss 3.284, d_loss 0.055\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 235/390 d_loss_real= 0.155, d_loss_fake= 0.053, g_loss 3.008, d_loss 0.104\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 236/390 d_loss_real= 0.000, d_loss_fake= 0.104, g_loss 2.396, d_loss 0.052\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 35 Batch 237/390 d_loss_real= 0.072, d_loss_fake= 0.898, g_loss 3.471, d_loss 0.485\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 238/390 d_loss_real= 0.149, d_loss_fake= 0.029, g_loss 3.723, d_loss 0.089\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 35 Batch 239/390 d_loss_real= 0.349, d_loss_fake= 0.026, g_loss 3.815, d_loss 0.188\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 240/390 d_loss_real= 0.889, d_loss_fake= 0.023, g_loss 3.749, d_loss 0.456\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 35 Batch 241/390 d_loss_real= 1.302, d_loss_fake= 0.029, g_loss 3.433, d_loss 0.665\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 35 Batch 242/390 d_loss_real= 0.862, d_loss_fake= 0.043, g_loss 3.021, d_loss 0.452\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 243/390 d_loss_real= 0.677, d_loss_fake= 0.066, g_loss 2.575, d_loss 0.371\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 244/390 d_loss_real= 0.404, d_loss_fake= 0.100, g_loss 2.181, d_loss 0.252\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 245/390 d_loss_real= 0.102, d_loss_fake= 0.145, g_loss 1.912, d_loss 0.124\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 246/390 d_loss_real= 0.043, d_loss_fake= 0.190, g_loss 1.723, d_loss 0.116\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 247/390 d_loss_real= 0.012, d_loss_fake= 0.220, g_loss 1.570, d_loss 0.116\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 248/390 d_loss_real= 0.028, d_loss_fake= 0.304, g_loss 1.547, d_loss 0.166\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 249/390 d_loss_real= 0.065, d_loss_fake= 0.469, g_loss 1.557, d_loss 0.267\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 250/390 d_loss_real= 0.025, d_loss_fake= 0.354, g_loss 1.868, d_loss 0.190\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 251/390 d_loss_real= 0.144, d_loss_fake= 0.156, g_loss 2.463, d_loss 0.150\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 252/390 d_loss_real= 0.077, d_loss_fake= 0.068, g_loss 2.926, d_loss 0.073\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 35 Batch 253/390 d_loss_real= 0.108, d_loss_fake= 0.048, g_loss 3.196, d_loss 0.078\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 35 Batch 254/390 d_loss_real= 0.164, d_loss_fake= 0.040, g_loss 3.386, d_loss 0.102\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 35 Batch 255/390 d_loss_real= 0.260, d_loss_fake= 0.034, g_loss 3.474, d_loss 0.147\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 35 Batch 256/390 d_loss_real= 0.416, d_loss_fake= 0.032, g_loss 3.497, d_loss 0.224\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 257/390 d_loss_real= 0.163, d_loss_fake= 0.033, g_loss 3.493, d_loss 0.098\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 35 Batch 258/390 d_loss_real= 0.173, d_loss_fake= 0.034, g_loss 3.443, d_loss 0.103\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 35 Batch 259/390 d_loss_real= 0.053, d_loss_fake= 0.035, g_loss 3.406, d_loss 0.044\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 35 Batch 260/390 d_loss_real= 0.152, d_loss_fake= 0.038, g_loss 3.326, d_loss 0.095\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 35 Batch 261/390 d_loss_real= 0.258, d_loss_fake= 0.041, g_loss 3.216, d_loss 0.150\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 35 Batch 262/390 d_loss_real= 0.225, d_loss_fake= 0.045, g_loss 3.071, d_loss 0.135\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 263/390 d_loss_real= 0.104, d_loss_fake= 0.051, g_loss 2.945, d_loss 0.077\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 264/390 d_loss_real= 0.106, d_loss_fake= 0.060, g_loss 2.801, d_loss 0.083\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 35 Batch 265/390 d_loss_real= 0.097, d_loss_fake= 0.071, g_loss 2.622, d_loss 0.084\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 266/390 d_loss_real= 0.060, d_loss_fake= 0.092, g_loss 2.480, d_loss 0.076\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 267/390 d_loss_real= 0.069, d_loss_fake= 0.160, g_loss 2.236, d_loss 0.115\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 268/390 d_loss_real= 0.001, d_loss_fake= 0.176, g_loss 2.331, d_loss 0.089\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 35 Batch 269/390 d_loss_real= 0.097, d_loss_fake= 0.125, g_loss 2.679, d_loss 0.111\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 270/390 d_loss_real= 0.115, d_loss_fake= 0.072, g_loss 3.037, d_loss 0.093\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 35 Batch 271/390 d_loss_real= 0.115, d_loss_fake= 0.045, g_loss 3.243, d_loss 0.080\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 272/390 d_loss_real= 0.168, d_loss_fake= 0.038, g_loss 3.411, d_loss 0.103\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 273/390 d_loss_real= 0.126, d_loss_fake= 0.034, g_loss 3.458, d_loss 0.080\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 274/390 d_loss_real= 0.155, d_loss_fake= 0.032, g_loss 3.499, d_loss 0.094\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 35 Batch 275/390 d_loss_real= 0.061, d_loss_fake= 0.032, g_loss 3.530, d_loss 0.047\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 35 Batch 276/390 d_loss_real= 0.101, d_loss_fake= 0.031, g_loss 3.536, d_loss 0.066\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 35 Batch 277/390 d_loss_real= 0.007, d_loss_fake= 0.031, g_loss 3.522, d_loss 0.019\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 35 Batch 278/390 d_loss_real= 0.091, d_loss_fake= 0.032, g_loss 3.517, d_loss 0.061\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 279/390 d_loss_real= 0.047, d_loss_fake= 0.032, g_loss 3.459, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 280/390 d_loss_real= 0.022, d_loss_fake= 0.034, g_loss 3.441, d_loss 0.028\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 281/390 d_loss_real= 0.178, d_loss_fake= 0.035, g_loss 3.365, d_loss 0.106\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 282/390 d_loss_real= 0.048, d_loss_fake= 0.043, g_loss 3.248, d_loss 0.045\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 35 Batch 283/390 d_loss_real= 0.074, d_loss_fake= 0.046, g_loss 3.135, d_loss 0.060\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 35 Batch 284/390 d_loss_real= 0.000, d_loss_fake= 0.048, g_loss 3.014, d_loss 0.024\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 35 Batch 285/390 d_loss_real= 0.081, d_loss_fake= 0.070, g_loss 2.951, d_loss 0.075\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 286/390 d_loss_real= 0.019, d_loss_fake= 0.071, g_loss 2.997, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 287/390 d_loss_real= 0.058, d_loss_fake= 0.060, g_loss 3.017, d_loss 0.059\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 288/390 d_loss_real= 0.037, d_loss_fake= 0.074, g_loss 3.178, d_loss 0.055\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 35 Batch 289/390 d_loss_real= 0.223, d_loss_fake= 0.047, g_loss 3.296, d_loss 0.135\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 290/390 d_loss_real= 0.093, d_loss_fake= 0.039, g_loss 3.403, d_loss 0.066\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 291/390 d_loss_real= 0.248, d_loss_fake= 0.040, g_loss 3.383, d_loss 0.144\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 292/390 d_loss_real= 0.056, d_loss_fake= 0.034, g_loss 3.513, d_loss 0.045\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 35 Batch 293/390 d_loss_real= 0.058, d_loss_fake= 0.030, g_loss 3.530, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 294/390 d_loss_real= 0.062, d_loss_fake= 0.029, g_loss 3.649, d_loss 0.046\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 295/390 d_loss_real= 0.000, d_loss_fake= 0.026, g_loss 3.721, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 296/390 d_loss_real= 0.217, d_loss_fake= 0.026, g_loss 3.686, d_loss 0.122\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 35 Batch 297/390 d_loss_real= 0.203, d_loss_fake= 0.026, g_loss 3.701, d_loss 0.114\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 298/390 d_loss_real= 0.111, d_loss_fake= 0.028, g_loss 3.704, d_loss 0.070\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 299/390 d_loss_real= 0.044, d_loss_fake= 0.030, g_loss 3.595, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 300/390 d_loss_real= 0.263, d_loss_fake= 0.031, g_loss 3.512, d_loss 0.147\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 301/390 d_loss_real= 0.062, d_loss_fake= 0.031, g_loss 3.566, d_loss 0.046\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 302/390 d_loss_real= 0.000, d_loss_fake= 0.038, g_loss 3.391, d_loss 0.019\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 303/390 d_loss_real= 0.063, d_loss_fake= 0.035, g_loss 3.437, d_loss 0.049\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 304/390 d_loss_real= 0.131, d_loss_fake= 0.032, g_loss 3.537, d_loss 0.082\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 305/390 d_loss_real= 0.058, d_loss_fake= 0.039, g_loss 3.454, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 306/390 d_loss_real= 0.065, d_loss_fake= 0.038, g_loss 3.460, d_loss 0.052\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 35 Batch 307/390 d_loss_real= 0.065, d_loss_fake= 0.034, g_loss 3.552, d_loss 0.049\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 35 Batch 308/390 d_loss_real= 0.069, d_loss_fake= 0.033, g_loss 3.594, d_loss 0.051\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 35 Batch 309/390 d_loss_real= 0.072, d_loss_fake= 0.031, g_loss 3.608, d_loss 0.052\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 35 Batch 310/390 d_loss_real= 0.024, d_loss_fake= 0.029, g_loss 3.629, d_loss 0.026\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 311/390 d_loss_real= 0.018, d_loss_fake= 0.029, g_loss 3.668, d_loss 0.023\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 35 Batch 312/390 d_loss_real= 0.070, d_loss_fake= 0.030, g_loss 3.613, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 313/390 d_loss_real= 0.072, d_loss_fake= 0.026, g_loss 3.629, d_loss 0.049\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 314/390 d_loss_real= 0.177, d_loss_fake= 0.028, g_loss 3.663, d_loss 0.103\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 35 Batch 315/390 d_loss_real= 0.228, d_loss_fake= 0.025, g_loss 3.751, d_loss 0.127\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 316/390 d_loss_real= 0.124, d_loss_fake= 0.036, g_loss 3.449, d_loss 0.080\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 35 Batch 317/390 d_loss_real= 0.108, d_loss_fake= 0.040, g_loss 3.476, d_loss 0.074\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 318/390 d_loss_real= 0.114, d_loss_fake= 0.041, g_loss 3.315, d_loss 0.078\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 319/390 d_loss_real= 0.176, d_loss_fake= 0.049, g_loss 2.959, d_loss 0.112\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 35 Batch 320/390 d_loss_real= 0.053, d_loss_fake= 0.076, g_loss 2.968, d_loss 0.065\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 321/390 d_loss_real= 0.149, d_loss_fake= 0.063, g_loss 3.146, d_loss 0.106\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 35 Batch 322/390 d_loss_real= 0.173, d_loss_fake= 0.050, g_loss 3.322, d_loss 0.112\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 323/390 d_loss_real= 0.011, d_loss_fake= 0.045, g_loss 3.452, d_loss 0.028\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 35 Batch 324/390 d_loss_real= 0.181, d_loss_fake= 0.037, g_loss 3.522, d_loss 0.109\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 35 Batch 325/390 d_loss_real= 0.130, d_loss_fake= 0.031, g_loss 3.592, d_loss 0.080\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 326/390 d_loss_real= 0.067, d_loss_fake= 0.034, g_loss 3.520, d_loss 0.051\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 35 Batch 327/390 d_loss_real= 0.097, d_loss_fake= 0.039, g_loss 3.382, d_loss 0.068\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 328/390 d_loss_real= 0.048, d_loss_fake= 0.041, g_loss 3.309, d_loss 0.045\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 35 Batch 329/390 d_loss_real= 0.156, d_loss_fake= 0.046, g_loss 3.352, d_loss 0.101\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 330/390 d_loss_real= 0.184, d_loss_fake= 0.051, g_loss 3.244, d_loss 0.117\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 331/390 d_loss_real= 0.050, d_loss_fake= 0.048, g_loss 3.269, d_loss 0.049\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 35 Batch 332/390 d_loss_real= 0.154, d_loss_fake= 0.065, g_loss 3.259, d_loss 0.110\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 333/390 d_loss_real= 0.159, d_loss_fake= 0.069, g_loss 3.409, d_loss 0.114\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 35 Batch 334/390 d_loss_real= 0.016, d_loss_fake= 0.041, g_loss 3.498, d_loss 0.028\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 335/390 d_loss_real= 0.151, d_loss_fake= 0.033, g_loss 3.674, d_loss 0.092\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 35 Batch 336/390 d_loss_real= 0.258, d_loss_fake= 0.031, g_loss 3.688, d_loss 0.144\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 337/390 d_loss_real= 0.122, d_loss_fake= 0.035, g_loss 3.556, d_loss 0.078\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 35 Batch 338/390 d_loss_real= 0.160, d_loss_fake= 0.034, g_loss 3.587, d_loss 0.097\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 339/390 d_loss_real= 0.377, d_loss_fake= 0.034, g_loss 3.480, d_loss 0.205\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 340/390 d_loss_real= 0.480, d_loss_fake= 0.051, g_loss 2.983, d_loss 0.265\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 341/390 d_loss_real= 0.377, d_loss_fake= 0.086, g_loss 2.525, d_loss 0.232\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 35 Batch 342/390 d_loss_real= 0.234, d_loss_fake= 0.093, g_loss 2.608, d_loss 0.163\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 343/390 d_loss_real= 0.186, d_loss_fake= 0.056, g_loss 2.946, d_loss 0.121\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 344/390 d_loss_real= 0.253, d_loss_fake= 0.073, g_loss 2.653, d_loss 0.163\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 345/390 d_loss_real= 0.001, d_loss_fake= 0.097, g_loss 2.763, d_loss 0.049\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 35 Batch 346/390 d_loss_real= 0.112, d_loss_fake= 0.070, g_loss 3.157, d_loss 0.091\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 347/390 d_loss_real= 0.137, d_loss_fake= 0.038, g_loss 3.531, d_loss 0.088\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 348/390 d_loss_real= 0.000, d_loss_fake= 0.029, g_loss 3.755, d_loss 0.014\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 35 Batch 349/390 d_loss_real= 0.146, d_loss_fake= 0.024, g_loss 3.807, d_loss 0.085\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 35 Batch 350/390 d_loss_real= 0.149, d_loss_fake= 0.023, g_loss 3.814, d_loss 0.086\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 35 Batch 351/390 d_loss_real= 0.130, d_loss_fake= 0.025, g_loss 3.743, d_loss 0.078\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 352/390 d_loss_real= 0.074, d_loss_fake= 0.027, g_loss 3.641, d_loss 0.050\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 35 Batch 353/390 d_loss_real= 0.071, d_loss_fake= 0.030, g_loss 3.529, d_loss 0.050\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 354/390 d_loss_real= 0.129, d_loss_fake= 0.034, g_loss 3.404, d_loss 0.081\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 35 Batch 355/390 d_loss_real= 0.148, d_loss_fake= 0.039, g_loss 3.313, d_loss 0.094\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 35 Batch 356/390 d_loss_real= 0.126, d_loss_fake= 0.044, g_loss 3.162, d_loss 0.085\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 357/390 d_loss_real= 0.289, d_loss_fake= 0.053, g_loss 3.116, d_loss 0.171\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 35 Batch 358/390 d_loss_real= 0.111, d_loss_fake= 0.051, g_loss 3.168, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 359/390 d_loss_real= 0.095, d_loss_fake= 0.043, g_loss 3.300, d_loss 0.069\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 360/390 d_loss_real= 0.076, d_loss_fake= 0.036, g_loss 3.446, d_loss 0.056\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 361/390 d_loss_real= 0.020, d_loss_fake= 0.034, g_loss 3.489, d_loss 0.027\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 362/390 d_loss_real= 0.103, d_loss_fake= 0.033, g_loss 3.491, d_loss 0.068\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 363/390 d_loss_real= 0.236, d_loss_fake= 0.034, g_loss 3.400, d_loss 0.135\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 364/390 d_loss_real= 0.105, d_loss_fake= 0.037, g_loss 3.363, d_loss 0.071\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 365/390 d_loss_real= 0.001, d_loss_fake= 0.038, g_loss 3.384, d_loss 0.020\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 366/390 d_loss_real= 0.158, d_loss_fake= 0.038, g_loss 3.376, d_loss 0.098\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 367/390 d_loss_real= 0.067, d_loss_fake= 0.036, g_loss 3.393, d_loss 0.051\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35 Batch 368/390 d_loss_real= 0.084, d_loss_fake= 0.035, g_loss 3.415, d_loss 0.059\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 35 Batch 369/390 d_loss_real= 0.247, d_loss_fake= 0.038, g_loss 3.369, d_loss 0.143\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 370/390 d_loss_real= 0.030, d_loss_fake= 0.040, g_loss 3.391, d_loss 0.035\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 371/390 d_loss_real= 0.133, d_loss_fake= 0.039, g_loss 3.419, d_loss 0.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 372/390 d_loss_real= 0.096, d_loss_fake= 0.036, g_loss 3.401, d_loss 0.066\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 35 Batch 373/390 d_loss_real= 0.103, d_loss_fake= 0.041, g_loss 3.250, d_loss 0.072\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 374/390 d_loss_real= 0.092, d_loss_fake= 0.046, g_loss 3.148, d_loss 0.069\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 375/390 d_loss_real= 0.115, d_loss_fake= 0.050, g_loss 3.180, d_loss 0.083\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 35 Batch 376/390 d_loss_real= 0.100, d_loss_fake= 0.053, g_loss 3.184, d_loss 0.076\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 35 Batch 377/390 d_loss_real= 0.001, d_loss_fake= 0.045, g_loss 3.308, d_loss 0.023\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 378/390 d_loss_real= 0.066, d_loss_fake= 0.041, g_loss 3.418, d_loss 0.053\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 35 Batch 379/390 d_loss_real= 0.000, d_loss_fake= 0.031, g_loss 3.581, d_loss 0.015\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 380/390 d_loss_real= 0.017, d_loss_fake= 0.028, g_loss 3.665, d_loss 0.022\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 35 Batch 381/390 d_loss_real= 0.230, d_loss_fake= 0.027, g_loss 3.689, d_loss 0.128\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 35 Batch 382/390 d_loss_real= 0.070, d_loss_fake= 0.028, g_loss 3.651, d_loss 0.049\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 35 Batch 383/390 d_loss_real= 0.178, d_loss_fake= 0.030, g_loss 3.621, d_loss 0.104\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 384/390 d_loss_real= 0.118, d_loss_fake= 0.029, g_loss 3.526, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 385/390 d_loss_real= 0.132, d_loss_fake= 0.033, g_loss 3.469, d_loss 0.083\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35 Batch 386/390 d_loss_real= 0.056, d_loss_fake= 0.034, g_loss 3.442, d_loss 0.045\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 387/390 d_loss_real= 0.050, d_loss_fake= 0.037, g_loss 3.452, d_loss 0.043\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35 Batch 388/390 d_loss_real= 0.149, d_loss_fake= 0.039, g_loss 3.303, d_loss 0.094\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 35 Batch 389/390 d_loss_real= 0.112, d_loss_fake= 0.045, g_loss 3.239, d_loss 0.079\n",
            "2/2 [==============================] - 0s 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35 Batch 390/390 d_loss_real= 0.006, d_loss_fake= 0.047, g_loss 3.194, d_loss 0.027\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 36 Batch 1/390 d_loss_real= 0.053, d_loss_fake= 0.044, g_loss 3.253, d_loss 0.048\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 2/390 d_loss_real= 0.173, d_loss_fake= 0.045, g_loss 3.249, d_loss 0.109\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 36 Batch 3/390 d_loss_real= 0.111, d_loss_fake= 0.041, g_loss 3.288, d_loss 0.076\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 36 Batch 4/390 d_loss_real= 0.111, d_loss_fake= 0.041, g_loss 3.293, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 5/390 d_loss_real= 0.075, d_loss_fake= 0.042, g_loss 3.236, d_loss 0.059\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 36 Batch 6/390 d_loss_real= 0.059, d_loss_fake= 0.043, g_loss 3.221, d_loss 0.051\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 7/390 d_loss_real= 0.098, d_loss_fake= 0.045, g_loss 3.191, d_loss 0.072\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 8/390 d_loss_real= 0.067, d_loss_fake= 0.047, g_loss 3.134, d_loss 0.057\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 36 Batch 9/390 d_loss_real= 0.000, d_loss_fake= 0.049, g_loss 3.173, d_loss 0.025\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 10/390 d_loss_real= 0.096, d_loss_fake= 0.048, g_loss 3.176, d_loss 0.072\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 36 Batch 11/390 d_loss_real= 0.162, d_loss_fake= 0.046, g_loss 3.175, d_loss 0.104\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 12/390 d_loss_real= 0.075, d_loss_fake= 0.046, g_loss 3.163, d_loss 0.061\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 13/390 d_loss_real= 0.121, d_loss_fake= 0.048, g_loss 3.167, d_loss 0.085\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 14/390 d_loss_real= 0.144, d_loss_fake= 0.048, g_loss 3.178, d_loss 0.096\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 15/390 d_loss_real= 0.064, d_loss_fake= 0.050, g_loss 3.091, d_loss 0.057\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 36 Batch 16/390 d_loss_real= 0.097, d_loss_fake= 0.050, g_loss 3.068, d_loss 0.074\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 36 Batch 17/390 d_loss_real= 0.082, d_loss_fake= 0.050, g_loss 3.024, d_loss 0.066\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 36 Batch 18/390 d_loss_real= 0.058, d_loss_fake= 0.056, g_loss 2.996, d_loss 0.057\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 19/390 d_loss_real= 0.016, d_loss_fake= 0.055, g_loss 2.976, d_loss 0.036\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 20/390 d_loss_real= 0.119, d_loss_fake= 0.052, g_loss 2.988, d_loss 0.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 21/390 d_loss_real= 0.039, d_loss_fake= 0.052, g_loss 3.052, d_loss 0.046\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36 Batch 22/390 d_loss_real= 0.192, d_loss_fake= 0.055, g_loss 3.021, d_loss 0.123\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 23/390 d_loss_real= 0.030, d_loss_fake= 0.056, g_loss 3.039, d_loss 0.043\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 24/390 d_loss_real= 0.131, d_loss_fake= 0.054, g_loss 3.046, d_loss 0.092\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36 Batch 25/390 d_loss_real= 0.037, d_loss_fake= 0.056, g_loss 3.143, d_loss 0.046\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 26/390 d_loss_real= 0.108, d_loss_fake= 0.045, g_loss 3.255, d_loss 0.076\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36 Batch 27/390 d_loss_real= 0.090, d_loss_fake= 0.039, g_loss 3.423, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 28/390 d_loss_real= 0.136, d_loss_fake= 0.037, g_loss 3.546, d_loss 0.087\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 36 Batch 29/390 d_loss_real= 0.161, d_loss_fake= 0.031, g_loss 3.558, d_loss 0.096\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 30/390 d_loss_real= 0.060, d_loss_fake= 0.037, g_loss 3.471, d_loss 0.048\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 36 Batch 31/390 d_loss_real= 0.121, d_loss_fake= 0.038, g_loss 3.497, d_loss 0.079\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 32/390 d_loss_real= 0.054, d_loss_fake= 0.040, g_loss 3.497, d_loss 0.047\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 36 Batch 33/390 d_loss_real= 0.104, d_loss_fake= 0.034, g_loss 3.459, d_loss 0.069\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 34/390 d_loss_real= 0.002, d_loss_fake= 0.036, g_loss 3.501, d_loss 0.019\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 35/390 d_loss_real= 0.005, d_loss_fake= 0.029, g_loss 3.696, d_loss 0.017\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 36/390 d_loss_real= 0.063, d_loss_fake= 0.027, g_loss 3.785, d_loss 0.045\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 36 Batch 37/390 d_loss_real= 0.135, d_loss_fake= 0.026, g_loss 3.741, d_loss 0.081\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 38/390 d_loss_real= 0.214, d_loss_fake= 0.027, g_loss 3.650, d_loss 0.120\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 36 Batch 39/390 d_loss_real= 0.003, d_loss_fake= 0.029, g_loss 3.653, d_loss 0.016\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 40/390 d_loss_real= 0.174, d_loss_fake= 0.032, g_loss 3.636, d_loss 0.103\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 36 Batch 41/390 d_loss_real= 0.132, d_loss_fake= 0.033, g_loss 3.543, d_loss 0.083\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 36 Batch 42/390 d_loss_real= 0.070, d_loss_fake= 0.030, g_loss 3.553, d_loss 0.050\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 36 Batch 43/390 d_loss_real= 0.379, d_loss_fake= 0.038, g_loss 3.372, d_loss 0.209\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 44/390 d_loss_real= 0.161, d_loss_fake= 0.049, g_loss 3.215, d_loss 0.105\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 36 Batch 45/390 d_loss_real= 0.026, d_loss_fake= 0.078, g_loss 3.124, d_loss 0.052\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 46/390 d_loss_real= 0.071, d_loss_fake= 0.050, g_loss 3.400, d_loss 0.061\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 47/390 d_loss_real= 0.257, d_loss_fake= 0.036, g_loss 3.572, d_loss 0.147\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 48/390 d_loss_real= 0.097, d_loss_fake= 0.030, g_loss 3.716, d_loss 0.063\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 36 Batch 49/390 d_loss_real= 0.114, d_loss_fake= 0.026, g_loss 3.865, d_loss 0.070\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 50/390 d_loss_real= 0.331, d_loss_fake= 0.025, g_loss 3.769, d_loss 0.178\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 51/390 d_loss_real= 0.147, d_loss_fake= 0.029, g_loss 3.695, d_loss 0.088\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 36 Batch 52/390 d_loss_real= 0.245, d_loss_fake= 0.030, g_loss 3.620, d_loss 0.137\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 53/390 d_loss_real= 0.071, d_loss_fake= 0.036, g_loss 3.489, d_loss 0.054\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 54/390 d_loss_real= 0.290, d_loss_fake= 0.036, g_loss 3.341, d_loss 0.163\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 55/390 d_loss_real= 0.011, d_loss_fake= 0.047, g_loss 3.158, d_loss 0.029\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 36 Batch 56/390 d_loss_real= 0.092, d_loss_fake= 0.054, g_loss 3.162, d_loss 0.073\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 36 Batch 57/390 d_loss_real= 0.090, d_loss_fake= 0.054, g_loss 3.039, d_loss 0.072\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 36 Batch 58/390 d_loss_real= 0.009, d_loss_fake= 0.058, g_loss 3.255, d_loss 0.034\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 36 Batch 59/390 d_loss_real= 0.001, d_loss_fake= 0.048, g_loss 3.419, d_loss 0.025\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 36 Batch 60/390 d_loss_real= 0.002, d_loss_fake= 0.034, g_loss 3.637, d_loss 0.018\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 36 Batch 61/390 d_loss_real= 0.221, d_loss_fake= 0.030, g_loss 3.768, d_loss 0.126\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 36 Batch 62/390 d_loss_real= 0.211, d_loss_fake= 0.028, g_loss 3.780, d_loss 0.120\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 36 Batch 63/390 d_loss_real= 0.125, d_loss_fake= 0.028, g_loss 3.699, d_loss 0.076\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 36 Batch 64/390 d_loss_real= 0.140, d_loss_fake= 0.027, g_loss 3.673, d_loss 0.084\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 36 Batch 65/390 d_loss_real= 0.053, d_loss_fake= 0.027, g_loss 3.582, d_loss 0.040\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 66/390 d_loss_real= 0.309, d_loss_fake= 0.030, g_loss 3.494, d_loss 0.169\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 36 Batch 67/390 d_loss_real= 0.071, d_loss_fake= 0.038, g_loss 3.282, d_loss 0.055\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 68/390 d_loss_real= 0.039, d_loss_fake= 0.045, g_loss 3.151, d_loss 0.042\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 69/390 d_loss_real= 0.126, d_loss_fake= 0.058, g_loss 3.015, d_loss 0.092\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 36 Batch 70/390 d_loss_real= 0.072, d_loss_fake= 0.055, g_loss 3.136, d_loss 0.064\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 36 Batch 71/390 d_loss_real= 0.117, d_loss_fake= 0.047, g_loss 3.278, d_loss 0.082\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 72/390 d_loss_real= 0.100, d_loss_fake= 0.039, g_loss 3.381, d_loss 0.069\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 73/390 d_loss_real= 0.152, d_loss_fake= 0.035, g_loss 3.455, d_loss 0.094\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 36 Batch 74/390 d_loss_real= 0.236, d_loss_fake= 0.035, g_loss 3.433, d_loss 0.136\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 36 Batch 75/390 d_loss_real= 0.128, d_loss_fake= 0.038, g_loss 3.325, d_loss 0.083\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 36 Batch 76/390 d_loss_real= 0.054, d_loss_fake= 0.042, g_loss 3.179, d_loss 0.048\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 77/390 d_loss_real= 0.070, d_loss_fake= 0.052, g_loss 3.046, d_loss 0.061\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 36 Batch 78/390 d_loss_real= 0.107, d_loss_fake= 0.046, g_loss 3.174, d_loss 0.076\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 36 Batch 79/390 d_loss_real= 0.120, d_loss_fake= 0.051, g_loss 3.195, d_loss 0.086\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 80/390 d_loss_real= 0.251, d_loss_fake= 0.062, g_loss 3.036, d_loss 0.157\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 81/390 d_loss_real= 0.091, d_loss_fake= 0.048, g_loss 3.214, d_loss 0.070\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 36 Batch 82/390 d_loss_real= 0.003, d_loss_fake= 0.037, g_loss 3.511, d_loss 0.020\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 36 Batch 83/390 d_loss_real= 0.121, d_loss_fake= 0.031, g_loss 3.561, d_loss 0.076\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 36 Batch 84/390 d_loss_real= 0.126, d_loss_fake= 0.029, g_loss 3.667, d_loss 0.077\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 85/390 d_loss_real= 0.001, d_loss_fake= 0.026, g_loss 3.765, d_loss 0.013\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 86/390 d_loss_real= 0.175, d_loss_fake= 0.026, g_loss 3.704, d_loss 0.101\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 87/390 d_loss_real= 0.063, d_loss_fake= 0.025, g_loss 3.627, d_loss 0.044\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 36 Batch 88/390 d_loss_real= 0.232, d_loss_fake= 0.034, g_loss 3.347, d_loss 0.133\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 89/390 d_loss_real= 0.178, d_loss_fake= 0.048, g_loss 2.993, d_loss 0.113\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 90/390 d_loss_real= 0.114, d_loss_fake= 0.090, g_loss 3.036, d_loss 0.102\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 91/390 d_loss_real= 0.203, d_loss_fake= 0.054, g_loss 3.315, d_loss 0.129\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 92/390 d_loss_real= 0.049, d_loss_fake= 0.035, g_loss 3.617, d_loss 0.042\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 36 Batch 93/390 d_loss_real= 0.141, d_loss_fake= 0.026, g_loss 3.802, d_loss 0.084\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 36 Batch 94/390 d_loss_real= 0.250, d_loss_fake= 0.024, g_loss 3.831, d_loss 0.137\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 95/390 d_loss_real= 0.209, d_loss_fake= 0.024, g_loss 3.732, d_loss 0.117\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 36 Batch 96/390 d_loss_real= 0.162, d_loss_fake= 0.028, g_loss 3.564, d_loss 0.095\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 36 Batch 97/390 d_loss_real= 0.035, d_loss_fake= 0.033, g_loss 3.391, d_loss 0.034\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 98/390 d_loss_real= 0.095, d_loss_fake= 0.039, g_loss 3.328, d_loss 0.067\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 36 Batch 99/390 d_loss_real= 0.111, d_loss_fake= 0.054, g_loss 3.107, d_loss 0.083\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 36 Batch 100/390 d_loss_real= 0.009, d_loss_fake= 0.055, g_loss 3.299, d_loss 0.032\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 101/390 d_loss_real= 0.128, d_loss_fake= 0.038, g_loss 3.473, d_loss 0.083\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36 Batch 102/390 d_loss_real= 0.069, d_loss_fake= 0.034, g_loss 3.635, d_loss 0.052\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 103/390 d_loss_real= 0.074, d_loss_fake= 0.026, g_loss 3.800, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 104/390 d_loss_real= 0.133, d_loss_fake= 0.024, g_loss 3.860, d_loss 0.078\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 105/390 d_loss_real= 0.123, d_loss_fake= 0.023, g_loss 3.832, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 106/390 d_loss_real= 0.151, d_loss_fake= 0.024, g_loss 3.775, d_loss 0.088\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 107/390 d_loss_real= 0.055, d_loss_fake= 0.025, g_loss 3.698, d_loss 0.040\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 36 Batch 108/390 d_loss_real= 0.152, d_loss_fake= 0.029, g_loss 3.572, d_loss 0.091\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 109/390 d_loss_real= 0.023, d_loss_fake= 0.034, g_loss 3.456, d_loss 0.028\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 110/390 d_loss_real= 0.066, d_loss_fake= 0.047, g_loss 3.272, d_loss 0.057\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 111/390 d_loss_real= 0.030, d_loss_fake= 0.033, g_loss 3.347, d_loss 0.032\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 112/390 d_loss_real= 0.054, d_loss_fake= 0.045, g_loss 3.297, d_loss 0.050\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 113/390 d_loss_real= 0.171, d_loss_fake= 0.054, g_loss 3.256, d_loss 0.113\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 114/390 d_loss_real= 0.083, d_loss_fake= 0.050, g_loss 3.457, d_loss 0.066\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 36 Batch 115/390 d_loss_real= 0.078, d_loss_fake= 0.042, g_loss 3.632, d_loss 0.060\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 116/390 d_loss_real= 0.143, d_loss_fake= 0.036, g_loss 3.768, d_loss 0.090\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 36 Batch 117/390 d_loss_real= 0.142, d_loss_fake= 0.023, g_loss 3.877, d_loss 0.083\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 118/390 d_loss_real= 0.094, d_loss_fake= 0.022, g_loss 3.925, d_loss 0.058\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 119/390 d_loss_real= 0.185, d_loss_fake= 0.024, g_loss 3.825, d_loss 0.104\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 36 Batch 120/390 d_loss_real= 0.048, d_loss_fake= 0.027, g_loss 3.629, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 121/390 d_loss_real= 0.252, d_loss_fake= 0.034, g_loss 3.485, d_loss 0.143\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 36 Batch 122/390 d_loss_real= 0.047, d_loss_fake= 0.050, g_loss 3.241, d_loss 0.049\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36 Batch 123/390 d_loss_real= 0.003, d_loss_fake= 0.052, g_loss 3.268, d_loss 0.028\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 36 Batch 124/390 d_loss_real= 0.152, d_loss_fake= 0.029, g_loss 3.667, d_loss 0.091\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 36 Batch 125/390 d_loss_real= 0.107, d_loss_fake= 0.029, g_loss 3.621, d_loss 0.068\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 36 Batch 126/390 d_loss_real= 0.030, d_loss_fake= 0.027, g_loss 3.758, d_loss 0.028\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 127/390 d_loss_real= 0.113, d_loss_fake= 0.028, g_loss 3.593, d_loss 0.070\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 128/390 d_loss_real= 0.169, d_loss_fake= 0.036, g_loss 3.396, d_loss 0.103\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 129/390 d_loss_real= 0.201, d_loss_fake= 0.053, g_loss 3.286, d_loss 0.127\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 130/390 d_loss_real= 0.115, d_loss_fake= 0.038, g_loss 3.423, d_loss 0.077\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 131/390 d_loss_real= 0.007, d_loss_fake= 0.033, g_loss 3.557, d_loss 0.020\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 36 Batch 132/390 d_loss_real= 0.168, d_loss_fake= 0.032, g_loss 3.599, d_loss 0.100\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 36 Batch 133/390 d_loss_real= 0.142, d_loss_fake= 0.029, g_loss 3.702, d_loss 0.086\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 134/390 d_loss_real= 0.161, d_loss_fake= 0.031, g_loss 3.494, d_loss 0.096\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 135/390 d_loss_real= 0.105, d_loss_fake= 0.033, g_loss 3.430, d_loss 0.069\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 36 Batch 136/390 d_loss_real= 0.092, d_loss_fake= 0.036, g_loss 3.430, d_loss 0.064\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 137/390 d_loss_real= 0.348, d_loss_fake= 0.040, g_loss 3.282, d_loss 0.194\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 138/390 d_loss_real= 0.114, d_loss_fake= 0.043, g_loss 3.273, d_loss 0.078\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 36 Batch 139/390 d_loss_real= 0.100, d_loss_fake= 0.045, g_loss 3.293, d_loss 0.073\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 36 Batch 140/390 d_loss_real= 0.316, d_loss_fake= 0.045, g_loss 3.307, d_loss 0.180\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 141/390 d_loss_real= 0.219, d_loss_fake= 0.049, g_loss 3.187, d_loss 0.134\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 142/390 d_loss_real= 0.117, d_loss_fake= 0.054, g_loss 3.112, d_loss 0.085\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 143/390 d_loss_real= 0.143, d_loss_fake= 0.065, g_loss 2.993, d_loss 0.104\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 36 Batch 144/390 d_loss_real= 0.036, d_loss_fake= 0.054, g_loss 3.099, d_loss 0.045\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 36 Batch 145/390 d_loss_real= 0.024, d_loss_fake= 0.043, g_loss 3.263, d_loss 0.034\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 146/390 d_loss_real= 0.093, d_loss_fake= 0.041, g_loss 3.322, d_loss 0.067\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 147/390 d_loss_real= 0.082, d_loss_fake= 0.039, g_loss 3.348, d_loss 0.060\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 36 Batch 148/390 d_loss_real= 0.154, d_loss_fake= 0.040, g_loss 3.307, d_loss 0.097\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 149/390 d_loss_real= 0.109, d_loss_fake= 0.044, g_loss 3.283, d_loss 0.077\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 36 Batch 150/390 d_loss_real= 0.233, d_loss_fake= 0.043, g_loss 3.211, d_loss 0.138\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 36 Batch 151/390 d_loss_real= 0.199, d_loss_fake= 0.054, g_loss 3.126, d_loss 0.126\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 36 Batch 152/390 d_loss_real= 0.117, d_loss_fake= 0.063, g_loss 3.015, d_loss 0.090\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 36 Batch 153/390 d_loss_real= 0.058, d_loss_fake= 0.063, g_loss 3.047, d_loss 0.060\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 36 Batch 154/390 d_loss_real= 0.049, d_loss_fake= 0.050, g_loss 3.197, d_loss 0.049\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 155/390 d_loss_real= 0.180, d_loss_fake= 0.043, g_loss 3.279, d_loss 0.112\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36 Batch 156/390 d_loss_real= 0.059, d_loss_fake= 0.038, g_loss 3.325, d_loss 0.048\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 36 Batch 157/390 d_loss_real= 0.142, d_loss_fake= 0.038, g_loss 3.252, d_loss 0.090\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "Epoch 36 Batch 158/390 d_loss_real= 0.167, d_loss_fake= 0.046, g_loss 3.146, d_loss 0.107\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 159/390 d_loss_real= 0.084, d_loss_fake= 0.053, g_loss 3.066, d_loss 0.068\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36 Batch 160/390 d_loss_real= 0.102, d_loss_fake= 0.064, g_loss 2.958, d_loss 0.083\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 161/390 d_loss_real= 0.106, d_loss_fake= 0.059, g_loss 3.134, d_loss 0.082\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 162/390 d_loss_real= 0.313, d_loss_fake= 0.048, g_loss 3.214, d_loss 0.181\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 163/390 d_loss_real= 0.033, d_loss_fake= 0.045, g_loss 3.307, d_loss 0.039\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 164/390 d_loss_real= 0.326, d_loss_fake= 0.039, g_loss 3.410, d_loss 0.183\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 165/390 d_loss_real= 0.107, d_loss_fake= 0.042, g_loss 3.373, d_loss 0.074\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 36 Batch 166/390 d_loss_real= 0.236, d_loss_fake= 0.041, g_loss 3.273, d_loss 0.138\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 167/390 d_loss_real= 0.204, d_loss_fake= 0.046, g_loss 3.102, d_loss 0.125\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 36 Batch 168/390 d_loss_real= 0.128, d_loss_fake= 0.049, g_loss 3.023, d_loss 0.088\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 36 Batch 169/390 d_loss_real= 0.058, d_loss_fake= 0.051, g_loss 3.031, d_loss 0.055\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 170/390 d_loss_real= 0.167, d_loss_fake= 0.056, g_loss 2.941, d_loss 0.112\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 36 Batch 171/390 d_loss_real= 0.195, d_loss_fake= 0.063, g_loss 2.829, d_loss 0.129\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 172/390 d_loss_real= 0.142, d_loss_fake= 0.070, g_loss 2.836, d_loss 0.106\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 173/390 d_loss_real= 0.095, d_loss_fake= 0.066, g_loss 2.927, d_loss 0.081\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 36 Batch 174/390 d_loss_real= 0.095, d_loss_fake= 0.058, g_loss 3.063, d_loss 0.077\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 175/390 d_loss_real= 0.003, d_loss_fake= 0.051, g_loss 3.217, d_loss 0.027\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 36 Batch 176/390 d_loss_real= 0.151, d_loss_fake= 0.043, g_loss 3.313, d_loss 0.097\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 36 Batch 177/390 d_loss_real= 0.141, d_loss_fake= 0.045, g_loss 3.257, d_loss 0.093\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 36 Batch 178/390 d_loss_real= 0.158, d_loss_fake= 0.044, g_loss 3.141, d_loss 0.101\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 36 Batch 179/390 d_loss_real= 0.108, d_loss_fake= 0.055, g_loss 2.895, d_loss 0.081\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36 Batch 180/390 d_loss_real= 0.137, d_loss_fake= 0.085, g_loss 2.645, d_loss 0.111\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 181/390 d_loss_real= 0.025, d_loss_fake= 0.079, g_loss 2.686, d_loss 0.052\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 36 Batch 182/390 d_loss_real= 0.028, d_loss_fake= 0.070, g_loss 3.052, d_loss 0.049\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 36 Batch 183/390 d_loss_real= 0.150, d_loss_fake= 0.047, g_loss 3.337, d_loss 0.099\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 36 Batch 184/390 d_loss_real= 0.108, d_loss_fake= 0.036, g_loss 3.523, d_loss 0.072\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 185/390 d_loss_real= 0.311, d_loss_fake= 0.036, g_loss 3.530, d_loss 0.173\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 186/390 d_loss_real= 0.176, d_loss_fake= 0.035, g_loss 3.450, d_loss 0.106\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 36 Batch 187/390 d_loss_real= 0.106, d_loss_fake= 0.037, g_loss 3.468, d_loss 0.072\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 188/390 d_loss_real= 0.085, d_loss_fake= 0.038, g_loss 3.305, d_loss 0.061\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 189/390 d_loss_real= 0.241, d_loss_fake= 0.044, g_loss 3.219, d_loss 0.142\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 190/390 d_loss_real= 0.134, d_loss_fake= 0.046, g_loss 3.059, d_loss 0.090\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36 Batch 191/390 d_loss_real= 0.002, d_loss_fake= 0.055, g_loss 2.956, d_loss 0.029\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 192/390 d_loss_real= 0.062, d_loss_fake= 0.063, g_loss 3.035, d_loss 0.062\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 193/390 d_loss_real= 0.073, d_loss_fake= 0.055, g_loss 3.162, d_loss 0.064\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 194/390 d_loss_real= 0.054, d_loss_fake= 0.045, g_loss 3.345, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 195/390 d_loss_real= 0.001, d_loss_fake= 0.035, g_loss 3.504, d_loss 0.018\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 36 Batch 196/390 d_loss_real= 0.155, d_loss_fake= 0.032, g_loss 3.570, d_loss 0.093\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 36 Batch 197/390 d_loss_real= 0.063, d_loss_fake= 0.031, g_loss 3.623, d_loss 0.047\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 198/390 d_loss_real= 0.105, d_loss_fake= 0.032, g_loss 3.504, d_loss 0.069\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 199/390 d_loss_real= 0.221, d_loss_fake= 0.032, g_loss 3.394, d_loss 0.127\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36 Batch 200/390 d_loss_real= 0.066, d_loss_fake= 0.039, g_loss 3.297, d_loss 0.052\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 201/390 d_loss_real= 0.083, d_loss_fake= 0.042, g_loss 3.095, d_loss 0.063\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 202/390 d_loss_real= 0.287, d_loss_fake= 0.070, g_loss 3.150, d_loss 0.179\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 36 Batch 203/390 d_loss_real= 0.151, d_loss_fake= 0.048, g_loss 3.259, d_loss 0.100\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 204/390 d_loss_real= 0.015, d_loss_fake= 0.037, g_loss 3.513, d_loss 0.026\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 205/390 d_loss_real= 0.051, d_loss_fake= 0.029, g_loss 3.651, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 206/390 d_loss_real= 0.061, d_loss_fake= 0.029, g_loss 3.744, d_loss 0.045\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 36 Batch 207/390 d_loss_real= 0.083, d_loss_fake= 0.026, g_loss 3.774, d_loss 0.054\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 36 Batch 208/390 d_loss_real= 0.142, d_loss_fake= 0.025, g_loss 3.800, d_loss 0.084\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 36 Batch 209/390 d_loss_real= 0.100, d_loss_fake= 0.026, g_loss 3.712, d_loss 0.063\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 210/390 d_loss_real= 0.208, d_loss_fake= 0.029, g_loss 3.510, d_loss 0.119\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 36 Batch 211/390 d_loss_real= 0.115, d_loss_fake= 0.035, g_loss 3.243, d_loss 0.075\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 36 Batch 212/390 d_loss_real= 0.000, d_loss_fake= 0.059, g_loss 2.986, d_loss 0.030\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 213/390 d_loss_real= 0.140, d_loss_fake= 0.052, g_loss 3.058, d_loss 0.096\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 36 Batch 214/390 d_loss_real= 0.026, d_loss_fake= 0.046, g_loss 3.330, d_loss 0.036\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 36 Batch 215/390 d_loss_real= 0.169, d_loss_fake= 0.048, g_loss 3.263, d_loss 0.109\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 216/390 d_loss_real= 0.034, d_loss_fake= 0.041, g_loss 3.457, d_loss 0.038\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 36 Batch 217/390 d_loss_real= 0.065, d_loss_fake= 0.032, g_loss 3.586, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 218/390 d_loss_real= 0.083, d_loss_fake= 0.033, g_loss 3.553, d_loss 0.058\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 219/390 d_loss_real= 0.266, d_loss_fake= 0.031, g_loss 3.450, d_loss 0.149\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 220/390 d_loss_real= 0.145, d_loss_fake= 0.043, g_loss 3.139, d_loss 0.094\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 221/390 d_loss_real= 0.109, d_loss_fake= 0.053, g_loss 3.276, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 222/390 d_loss_real= 0.138, d_loss_fake= 0.045, g_loss 3.282, d_loss 0.091\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 36 Batch 223/390 d_loss_real= 0.008, d_loss_fake= 0.041, g_loss 3.400, d_loss 0.025\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 36 Batch 224/390 d_loss_real= 0.005, d_loss_fake= 0.033, g_loss 3.695, d_loss 0.019\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 225/390 d_loss_real= 0.242, d_loss_fake= 0.028, g_loss 3.684, d_loss 0.135\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 226/390 d_loss_real= 0.134, d_loss_fake= 0.027, g_loss 3.658, d_loss 0.080\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 36 Batch 227/390 d_loss_real= 0.154, d_loss_fake= 0.028, g_loss 3.558, d_loss 0.091\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 228/390 d_loss_real= 0.121, d_loss_fake= 0.030, g_loss 3.565, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 229/390 d_loss_real= 0.083, d_loss_fake= 0.032, g_loss 3.480, d_loss 0.057\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36 Batch 230/390 d_loss_real= 0.112, d_loss_fake= 0.036, g_loss 3.374, d_loss 0.074\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36 Batch 231/390 d_loss_real= 0.063, d_loss_fake= 0.035, g_loss 3.390, d_loss 0.049\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 36 Batch 232/390 d_loss_real= 0.028, d_loss_fake= 0.043, g_loss 3.288, d_loss 0.035\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 233/390 d_loss_real= 0.161, d_loss_fake= 0.046, g_loss 3.236, d_loss 0.104\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 36 Batch 234/390 d_loss_real= 0.180, d_loss_fake= 0.039, g_loss 3.380, d_loss 0.109\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 36 Batch 235/390 d_loss_real= 0.331, d_loss_fake= 0.036, g_loss 3.393, d_loss 0.183\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 36 Batch 236/390 d_loss_real= 0.078, d_loss_fake= 0.037, g_loss 3.378, d_loss 0.058\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 36 Batch 237/390 d_loss_real= 0.125, d_loss_fake= 0.036, g_loss 3.375, d_loss 0.081\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 238/390 d_loss_real= 0.132, d_loss_fake= 0.038, g_loss 3.373, d_loss 0.085\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 239/390 d_loss_real= 0.026, d_loss_fake= 0.045, g_loss 3.221, d_loss 0.035\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 240/390 d_loss_real= 0.113, d_loss_fake= 0.050, g_loss 3.114, d_loss 0.081\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 36 Batch 241/390 d_loss_real= 0.128, d_loss_fake= 0.044, g_loss 3.247, d_loss 0.086\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 242/390 d_loss_real= 0.216, d_loss_fake= 0.042, g_loss 3.320, d_loss 0.129\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 243/390 d_loss_real= 0.090, d_loss_fake= 0.039, g_loss 3.408, d_loss 0.064\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 36 Batch 244/390 d_loss_real= 0.244, d_loss_fake= 0.037, g_loss 3.430, d_loss 0.140\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 245/390 d_loss_real= 0.043, d_loss_fake= 0.036, g_loss 3.426, d_loss 0.040\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 246/390 d_loss_real= 0.223, d_loss_fake= 0.037, g_loss 3.355, d_loss 0.130\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 36 Batch 247/390 d_loss_real= 0.148, d_loss_fake= 0.041, g_loss 3.262, d_loss 0.095\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 36 Batch 248/390 d_loss_real= 0.062, d_loss_fake= 0.045, g_loss 3.084, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 249/390 d_loss_real= 0.094, d_loss_fake= 0.054, g_loss 3.111, d_loss 0.074\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 36 Batch 250/390 d_loss_real= 0.212, d_loss_fake= 0.056, g_loss 3.083, d_loss 0.134\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36 Batch 251/390 d_loss_real= 0.210, d_loss_fake= 0.052, g_loss 3.090, d_loss 0.131\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 36 Batch 252/390 d_loss_real= 0.135, d_loss_fake= 0.048, g_loss 3.136, d_loss 0.092\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 36 Batch 253/390 d_loss_real= 0.002, d_loss_fake= 0.038, g_loss 3.377, d_loss 0.020\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 36 Batch 254/390 d_loss_real= 0.051, d_loss_fake= 0.035, g_loss 3.462, d_loss 0.043\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 255/390 d_loss_real= 0.031, d_loss_fake= 0.032, g_loss 3.538, d_loss 0.032\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 256/390 d_loss_real= 0.157, d_loss_fake= 0.030, g_loss 3.511, d_loss 0.094\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 257/390 d_loss_real= 0.084, d_loss_fake= 0.032, g_loss 3.526, d_loss 0.058\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 36 Batch 258/390 d_loss_real= 0.125, d_loss_fake= 0.036, g_loss 3.388, d_loss 0.080\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 259/390 d_loss_real= 0.105, d_loss_fake= 0.038, g_loss 3.301, d_loss 0.072\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36 Batch 260/390 d_loss_real= 0.292, d_loss_fake= 0.044, g_loss 3.225, d_loss 0.168\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 261/390 d_loss_real= 0.105, d_loss_fake= 0.043, g_loss 3.186, d_loss 0.074\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36 Batch 262/390 d_loss_real= 0.113, d_loss_fake= 0.044, g_loss 3.171, d_loss 0.079\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 263/390 d_loss_real= 0.075, d_loss_fake= 0.050, g_loss 3.141, d_loss 0.062\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 36 Batch 264/390 d_loss_real= 0.138, d_loss_fake= 0.057, g_loss 3.095, d_loss 0.097\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 265/390 d_loss_real= 0.033, d_loss_fake= 0.042, g_loss 3.332, d_loss 0.037\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 36 Batch 266/390 d_loss_real= 0.067, d_loss_fake= 0.037, g_loss 3.453, d_loss 0.052\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 267/390 d_loss_real= 0.043, d_loss_fake= 0.032, g_loss 3.529, d_loss 0.038\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 268/390 d_loss_real= 0.101, d_loss_fake= 0.030, g_loss 3.577, d_loss 0.066\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 36 Batch 269/390 d_loss_real= 0.000, d_loss_fake= 0.028, g_loss 3.647, d_loss 0.014\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 270/390 d_loss_real= 0.119, d_loss_fake= 0.029, g_loss 3.648, d_loss 0.074\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 271/390 d_loss_real= 0.050, d_loss_fake= 0.029, g_loss 3.601, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 272/390 d_loss_real= 0.143, d_loss_fake= 0.029, g_loss 3.499, d_loss 0.086\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 273/390 d_loss_real= 0.121, d_loss_fake= 0.034, g_loss 3.406, d_loss 0.078\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 36 Batch 274/390 d_loss_real= 0.120, d_loss_fake= 0.039, g_loss 3.324, d_loss 0.079\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 36 Batch 275/390 d_loss_real= 0.000, d_loss_fake= 0.043, g_loss 3.217, d_loss 0.022\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 276/390 d_loss_real= 0.249, d_loss_fake= 0.050, g_loss 3.038, d_loss 0.149\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 36 Batch 277/390 d_loss_real= 0.373, d_loss_fake= 0.064, g_loss 2.857, d_loss 0.218\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 278/390 d_loss_real= 0.000, d_loss_fake= 0.066, g_loss 2.798, d_loss 0.033\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36 Batch 279/390 d_loss_real= 0.083, d_loss_fake= 0.070, g_loss 2.844, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 280/390 d_loss_real= 0.051, d_loss_fake= 0.066, g_loss 2.987, d_loss 0.058\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 281/390 d_loss_real= 0.127, d_loss_fake= 0.055, g_loss 3.067, d_loss 0.091\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 282/390 d_loss_real= 0.195, d_loss_fake= 0.055, g_loss 3.010, d_loss 0.125\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36 Batch 283/390 d_loss_real= 0.115, d_loss_fake= 0.062, g_loss 3.065, d_loss 0.089\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 36 Batch 284/390 d_loss_real= 0.050, d_loss_fake= 0.056, g_loss 3.027, d_loss 0.053\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 36 Batch 285/390 d_loss_real= 0.016, d_loss_fake= 0.052, g_loss 3.147, d_loss 0.034\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 286/390 d_loss_real= 0.099, d_loss_fake= 0.052, g_loss 3.208, d_loss 0.075\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 36 Batch 287/390 d_loss_real= 0.162, d_loss_fake= 0.045, g_loss 3.286, d_loss 0.103\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 288/390 d_loss_real= 0.053, d_loss_fake= 0.044, g_loss 3.331, d_loss 0.048\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 289/390 d_loss_real= 0.226, d_loss_fake= 0.037, g_loss 3.376, d_loss 0.132\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 36 Batch 290/390 d_loss_real= 0.135, d_loss_fake= 0.040, g_loss 3.292, d_loss 0.087\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36 Batch 291/390 d_loss_real= 0.162, d_loss_fake= 0.046, g_loss 3.059, d_loss 0.104\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 292/390 d_loss_real= 0.058, d_loss_fake= 0.056, g_loss 3.054, d_loss 0.057\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 293/390 d_loss_real= 0.119, d_loss_fake= 0.058, g_loss 3.134, d_loss 0.088\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 294/390 d_loss_real= 0.133, d_loss_fake= 0.044, g_loss 3.281, d_loss 0.089\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 295/390 d_loss_real= 0.116, d_loss_fake= 0.037, g_loss 3.408, d_loss 0.077\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 36 Batch 296/390 d_loss_real= 0.088, d_loss_fake= 0.033, g_loss 3.488, d_loss 0.060\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 36 Batch 297/390 d_loss_real= 0.285, d_loss_fake= 0.033, g_loss 3.439, d_loss 0.159\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 298/390 d_loss_real= 0.066, d_loss_fake= 0.037, g_loss 3.369, d_loss 0.051\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 299/390 d_loss_real= 0.142, d_loss_fake= 0.039, g_loss 3.319, d_loss 0.090\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 36 Batch 300/390 d_loss_real= 0.079, d_loss_fake= 0.042, g_loss 3.199, d_loss 0.061\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 301/390 d_loss_real= 0.029, d_loss_fake= 0.047, g_loss 3.075, d_loss 0.038\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 302/390 d_loss_real= 0.074, d_loss_fake= 0.053, g_loss 3.044, d_loss 0.064\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 303/390 d_loss_real= 0.107, d_loss_fake= 0.053, g_loss 3.086, d_loss 0.080\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 36 Batch 304/390 d_loss_real= 0.011, d_loss_fake= 0.048, g_loss 3.156, d_loss 0.030\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 36 Batch 305/390 d_loss_real= 0.001, d_loss_fake= 0.042, g_loss 3.335, d_loss 0.022\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 36 Batch 306/390 d_loss_real= 0.078, d_loss_fake= 0.040, g_loss 3.271, d_loss 0.059\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 307/390 d_loss_real= 0.250, d_loss_fake= 0.049, g_loss 3.193, d_loss 0.149\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 36 Batch 308/390 d_loss_real= 0.001, d_loss_fake= 0.044, g_loss 3.366, d_loss 0.022\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 36 Batch 309/390 d_loss_real= 0.075, d_loss_fake= 0.039, g_loss 3.485, d_loss 0.057\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 310/390 d_loss_real= 0.103, d_loss_fake= 0.031, g_loss 3.597, d_loss 0.067\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36 Batch 311/390 d_loss_real= 0.149, d_loss_fake= 0.032, g_loss 3.517, d_loss 0.090\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 36 Batch 312/390 d_loss_real= 0.135, d_loss_fake= 0.033, g_loss 3.443, d_loss 0.084\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 313/390 d_loss_real= 0.235, d_loss_fake= 0.039, g_loss 3.372, d_loss 0.137\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 36 Batch 314/390 d_loss_real= 0.149, d_loss_fake= 0.041, g_loss 3.298, d_loss 0.095\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 315/390 d_loss_real= 0.066, d_loss_fake= 0.046, g_loss 3.353, d_loss 0.056\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 316/390 d_loss_real= 0.054, d_loss_fake= 0.038, g_loss 3.341, d_loss 0.046\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 317/390 d_loss_real= 0.198, d_loss_fake= 0.046, g_loss 3.328, d_loss 0.122\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 36 Batch 318/390 d_loss_real= 0.001, d_loss_fake= 0.036, g_loss 3.374, d_loss 0.019\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 36 Batch 319/390 d_loss_real= 0.258, d_loss_fake= 0.041, g_loss 3.369, d_loss 0.150\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 36 Batch 320/390 d_loss_real= 0.205, d_loss_fake= 0.053, g_loss 3.183, d_loss 0.129\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 36 Batch 321/390 d_loss_real= 0.006, d_loss_fake= 0.065, g_loss 3.230, d_loss 0.036\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 322/390 d_loss_real= 0.040, d_loss_fake= 0.063, g_loss 3.330, d_loss 0.052\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 323/390 d_loss_real= 0.002, d_loss_fake= 0.033, g_loss 3.607, d_loss 0.018\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36 Batch 324/390 d_loss_real= 0.136, d_loss_fake= 0.028, g_loss 3.843, d_loss 0.082\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 36 Batch 325/390 d_loss_real= 0.185, d_loss_fake= 0.024, g_loss 3.798, d_loss 0.105\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 36 Batch 326/390 d_loss_real= 0.006, d_loss_fake= 0.022, g_loss 3.846, d_loss 0.014\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36 Batch 327/390 d_loss_real= 0.385, d_loss_fake= 0.022, g_loss 3.854, d_loss 0.204\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 36 Batch 328/390 d_loss_real= 0.073, d_loss_fake= 0.026, g_loss 3.757, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 329/390 d_loss_real= 0.335, d_loss_fake= 0.027, g_loss 3.554, d_loss 0.181\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 36 Batch 330/390 d_loss_real= 0.000, d_loss_fake= 0.036, g_loss 3.408, d_loss 0.018\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 36 Batch 331/390 d_loss_real= 0.090, d_loss_fake= 0.037, g_loss 3.300, d_loss 0.063\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36 Batch 332/390 d_loss_real= 0.156, d_loss_fake= 0.046, g_loss 3.229, d_loss 0.101\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 333/390 d_loss_real= 0.084, d_loss_fake= 0.048, g_loss 3.240, d_loss 0.066\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 334/390 d_loss_real= 0.202, d_loss_fake= 0.049, g_loss 3.211, d_loss 0.126\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 36 Batch 335/390 d_loss_real= 0.117, d_loss_fake= 0.054, g_loss 3.211, d_loss 0.085\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 36 Batch 336/390 d_loss_real= 0.001, d_loss_fake= 0.044, g_loss 3.406, d_loss 0.022\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 337/390 d_loss_real= 0.077, d_loss_fake= 0.038, g_loss 3.510, d_loss 0.057\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 338/390 d_loss_real= 0.275, d_loss_fake= 0.035, g_loss 3.531, d_loss 0.155\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 36 Batch 339/390 d_loss_real= 0.127, d_loss_fake= 0.037, g_loss 3.408, d_loss 0.082\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 340/390 d_loss_real= 0.111, d_loss_fake= 0.042, g_loss 3.212, d_loss 0.076\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 341/390 d_loss_real= 0.057, d_loss_fake= 0.050, g_loss 3.304, d_loss 0.054\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 342/390 d_loss_real= 0.078, d_loss_fake= 0.053, g_loss 3.183, d_loss 0.066\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36 Batch 343/390 d_loss_real= 0.186, d_loss_fake= 0.044, g_loss 3.357, d_loss 0.115\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 344/390 d_loss_real= 0.003, d_loss_fake= 0.044, g_loss 3.403, d_loss 0.024\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 36 Batch 345/390 d_loss_real= 0.202, d_loss_fake= 0.041, g_loss 3.474, d_loss 0.121\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 36 Batch 346/390 d_loss_real= 0.088, d_loss_fake= 0.037, g_loss 3.451, d_loss 0.062\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 347/390 d_loss_real= 0.094, d_loss_fake= 0.032, g_loss 3.542, d_loss 0.063\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 348/390 d_loss_real= 0.054, d_loss_fake= 0.029, g_loss 3.707, d_loss 0.041\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 349/390 d_loss_real= 0.175, d_loss_fake= 0.031, g_loss 3.576, d_loss 0.103\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 36 Batch 350/390 d_loss_real= 0.000, d_loss_fake= 0.028, g_loss 3.675, d_loss 0.014\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 36 Batch 351/390 d_loss_real= 0.192, d_loss_fake= 0.027, g_loss 3.635, d_loss 0.110\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 36 Batch 352/390 d_loss_real= 0.083, d_loss_fake= 0.029, g_loss 3.556, d_loss 0.056\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 353/390 d_loss_real= 0.415, d_loss_fake= 0.033, g_loss 3.461, d_loss 0.224\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36 Batch 354/390 d_loss_real= 0.054, d_loss_fake= 0.040, g_loss 3.334, d_loss 0.047\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 36 Batch 355/390 d_loss_real= 0.076, d_loss_fake= 0.039, g_loss 3.314, d_loss 0.058\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 356/390 d_loss_real= 0.185, d_loss_fake= 0.048, g_loss 2.917, d_loss 0.116\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 357/390 d_loss_real= 0.183, d_loss_fake= 0.073, g_loss 2.890, d_loss 0.128\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36 Batch 358/390 d_loss_real= 0.123, d_loss_fake= 0.046, g_loss 3.268, d_loss 0.085\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 359/390 d_loss_real= 0.112, d_loss_fake= 0.051, g_loss 3.259, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 360/390 d_loss_real= 0.097, d_loss_fake= 0.041, g_loss 3.356, d_loss 0.069\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36 Batch 361/390 d_loss_real= 0.005, d_loss_fake= 0.032, g_loss 3.589, d_loss 0.018\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 362/390 d_loss_real= 0.145, d_loss_fake= 0.028, g_loss 3.660, d_loss 0.086\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 36 Batch 363/390 d_loss_real= 0.115, d_loss_fake= 0.030, g_loss 3.548, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 364/390 d_loss_real= 0.090, d_loss_fake= 0.032, g_loss 3.457, d_loss 0.061\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 365/390 d_loss_real= 0.003, d_loss_fake= 0.034, g_loss 3.501, d_loss 0.018\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 36 Batch 366/390 d_loss_real= 0.089, d_loss_fake= 0.033, g_loss 3.464, d_loss 0.061\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 36 Batch 367/390 d_loss_real= 0.105, d_loss_fake= 0.028, g_loss 3.626, d_loss 0.067\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 368/390 d_loss_real= 0.285, d_loss_fake= 0.035, g_loss 3.298, d_loss 0.160\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 36 Batch 369/390 d_loss_real= 0.146, d_loss_fake= 0.060, g_loss 3.017, d_loss 0.103\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 370/390 d_loss_real= 0.000, d_loss_fake= 0.050, g_loss 3.233, d_loss 0.025\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 371/390 d_loss_real= 0.148, d_loss_fake= 0.043, g_loss 3.319, d_loss 0.096\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 372/390 d_loss_real= 0.095, d_loss_fake= 0.044, g_loss 3.399, d_loss 0.069\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36 Batch 373/390 d_loss_real= 0.113, d_loss_fake= 0.033, g_loss 3.465, d_loss 0.073\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36 Batch 374/390 d_loss_real= 0.174, d_loss_fake= 0.030, g_loss 3.519, d_loss 0.102\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 375/390 d_loss_real= 0.296, d_loss_fake= 0.039, g_loss 3.233, d_loss 0.167\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 36 Batch 376/390 d_loss_real= 0.109, d_loss_fake= 0.050, g_loss 3.235, d_loss 0.080\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36 Batch 377/390 d_loss_real= 0.151, d_loss_fake= 0.053, g_loss 3.175, d_loss 0.102\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 378/390 d_loss_real= 0.131, d_loss_fake= 0.054, g_loss 3.262, d_loss 0.093\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 379/390 d_loss_real= 0.231, d_loss_fake= 0.041, g_loss 3.457, d_loss 0.136\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 380/390 d_loss_real= 0.119, d_loss_fake= 0.028, g_loss 3.742, d_loss 0.073\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 36 Batch 381/390 d_loss_real= 0.085, d_loss_fake= 0.025, g_loss 3.659, d_loss 0.055\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 382/390 d_loss_real= 0.068, d_loss_fake= 0.029, g_loss 3.585, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 383/390 d_loss_real= 0.203, d_loss_fake= 0.030, g_loss 3.501, d_loss 0.117\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 36 Batch 384/390 d_loss_real= 0.221, d_loss_fake= 0.033, g_loss 3.437, d_loss 0.127\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36 Batch 385/390 d_loss_real= 0.075, d_loss_fake= 0.037, g_loss 3.395, d_loss 0.056\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 386/390 d_loss_real= 0.074, d_loss_fake= 0.041, g_loss 3.248, d_loss 0.057\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36 Batch 387/390 d_loss_real= 0.166, d_loss_fake= 0.048, g_loss 3.120, d_loss 0.107\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36 Batch 388/390 d_loss_real= 0.160, d_loss_fake= 0.055, g_loss 3.058, d_loss 0.108\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 36 Batch 389/390 d_loss_real= 0.139, d_loss_fake= 0.051, g_loss 3.100, d_loss 0.095\n",
            "2/2 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36 Batch 390/390 d_loss_real= 0.059, d_loss_fake= 0.053, g_loss 3.160, d_loss 0.056\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 1/390 d_loss_real= 0.114, d_loss_fake= 0.045, g_loss 3.232, d_loss 0.079\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 37 Batch 2/390 d_loss_real= 0.019, d_loss_fake= 0.042, g_loss 3.339, d_loss 0.030\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 37 Batch 3/390 d_loss_real= 0.184, d_loss_fake= 0.037, g_loss 3.355, d_loss 0.111\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 4/390 d_loss_real= 0.082, d_loss_fake= 0.035, g_loss 3.411, d_loss 0.059\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 5/390 d_loss_real= 0.177, d_loss_fake= 0.036, g_loss 3.418, d_loss 0.107\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 6/390 d_loss_real= 0.000, d_loss_fake= 0.033, g_loss 3.489, d_loss 0.017\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 7/390 d_loss_real= 0.089, d_loss_fake= 0.033, g_loss 3.474, d_loss 0.061\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 8/390 d_loss_real= 0.144, d_loss_fake= 0.034, g_loss 3.454, d_loss 0.089\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 9/390 d_loss_real= 0.001, d_loss_fake= 0.034, g_loss 3.428, d_loss 0.018\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 10/390 d_loss_real= 0.135, d_loss_fake= 0.035, g_loss 3.337, d_loss 0.085\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 11/390 d_loss_real= 0.134, d_loss_fake= 0.044, g_loss 3.158, d_loss 0.089\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 12/390 d_loss_real= 0.060, d_loss_fake= 0.048, g_loss 3.122, d_loss 0.054\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 13/390 d_loss_real= 0.186, d_loss_fake= 0.051, g_loss 3.144, d_loss 0.119\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 14/390 d_loss_real= 0.116, d_loss_fake= 0.061, g_loss 2.991, d_loss 0.089\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 15/390 d_loss_real= 0.013, d_loss_fake= 0.056, g_loss 3.139, d_loss 0.035\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 37 Batch 16/390 d_loss_real= 0.152, d_loss_fake= 0.050, g_loss 3.146, d_loss 0.101\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 17/390 d_loss_real= 0.154, d_loss_fake= 0.049, g_loss 3.241, d_loss 0.101\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 18/390 d_loss_real= 0.178, d_loss_fake= 0.046, g_loss 3.226, d_loss 0.112\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 37 Batch 19/390 d_loss_real= 0.008, d_loss_fake= 0.043, g_loss 3.361, d_loss 0.025\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 37 Batch 20/390 d_loss_real= 0.122, d_loss_fake= 0.039, g_loss 3.391, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 21/390 d_loss_real= 0.081, d_loss_fake= 0.040, g_loss 3.345, d_loss 0.060\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 22/390 d_loss_real= 0.106, d_loss_fake= 0.042, g_loss 3.329, d_loss 0.074\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 37 Batch 23/390 d_loss_real= 0.133, d_loss_fake= 0.042, g_loss 3.162, d_loss 0.087\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 24/390 d_loss_real= 0.158, d_loss_fake= 0.043, g_loss 3.214, d_loss 0.100\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 37 Batch 25/390 d_loss_real= 0.114, d_loss_fake= 0.049, g_loss 3.194, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 26/390 d_loss_real= 0.027, d_loss_fake= 0.048, g_loss 3.196, d_loss 0.038\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 27/390 d_loss_real= 0.066, d_loss_fake= 0.044, g_loss 3.266, d_loss 0.055\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 28/390 d_loss_real= 0.059, d_loss_fake= 0.040, g_loss 3.360, d_loss 0.050\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 29/390 d_loss_real= 0.057, d_loss_fake= 0.032, g_loss 3.624, d_loss 0.045\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 30/390 d_loss_real= 0.140, d_loss_fake= 0.031, g_loss 3.586, d_loss 0.085\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 31/390 d_loss_real= 0.184, d_loss_fake= 0.034, g_loss 3.546, d_loss 0.109\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 32/390 d_loss_real= 0.115, d_loss_fake= 0.033, g_loss 3.495, d_loss 0.074\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 33/390 d_loss_real= 0.001, d_loss_fake= 0.037, g_loss 3.595, d_loss 0.019\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 34/390 d_loss_real= 0.246, d_loss_fake= 0.035, g_loss 3.568, d_loss 0.141\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 35/390 d_loss_real= 0.223, d_loss_fake= 0.033, g_loss 3.511, d_loss 0.128\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 36/390 d_loss_real= 0.071, d_loss_fake= 0.042, g_loss 3.345, d_loss 0.057\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 37 Batch 37/390 d_loss_real= 0.244, d_loss_fake= 0.069, g_loss 3.400, d_loss 0.157\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 38/390 d_loss_real= 0.112, d_loss_fake= 0.036, g_loss 3.560, d_loss 0.074\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 39/390 d_loss_real= 0.186, d_loss_fake= 0.031, g_loss 3.614, d_loss 0.109\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 37 Batch 40/390 d_loss_real= 0.241, d_loss_fake= 0.034, g_loss 3.428, d_loss 0.138\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 41/390 d_loss_real= 0.069, d_loss_fake= 0.043, g_loss 3.306, d_loss 0.056\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 42/390 d_loss_real= 0.086, d_loss_fake= 0.053, g_loss 3.350, d_loss 0.069\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 37 Batch 43/390 d_loss_real= 0.077, d_loss_fake= 0.043, g_loss 3.405, d_loss 0.060\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 44/390 d_loss_real= 0.042, d_loss_fake= 0.034, g_loss 3.630, d_loss 0.038\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 45/390 d_loss_real= 0.123, d_loss_fake= 0.028, g_loss 3.707, d_loss 0.076\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 46/390 d_loss_real= 0.139, d_loss_fake= 0.026, g_loss 3.754, d_loss 0.082\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 47/390 d_loss_real= 0.189, d_loss_fake= 0.026, g_loss 3.607, d_loss 0.108\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 48/390 d_loss_real= 0.336, d_loss_fake= 0.030, g_loss 3.429, d_loss 0.183\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 49/390 d_loss_real= 0.182, d_loss_fake= 0.039, g_loss 3.304, d_loss 0.110\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 50/390 d_loss_real= 0.135, d_loss_fake= 0.048, g_loss 3.191, d_loss 0.091\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 51/390 d_loss_real= 0.124, d_loss_fake= 0.049, g_loss 3.256, d_loss 0.087\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 37 Batch 52/390 d_loss_real= 0.214, d_loss_fake= 0.043, g_loss 3.215, d_loss 0.129\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 53/390 d_loss_real= 0.116, d_loss_fake= 0.045, g_loss 3.195, d_loss 0.080\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 37 Batch 54/390 d_loss_real= 0.112, d_loss_fake= 0.056, g_loss 3.224, d_loss 0.084\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 55/390 d_loss_real= 0.081, d_loss_fake= 0.043, g_loss 3.341, d_loss 0.062\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 56/390 d_loss_real= 0.000, d_loss_fake= 0.039, g_loss 3.535, d_loss 0.019\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 57/390 d_loss_real= 0.234, d_loss_fake= 0.031, g_loss 3.629, d_loss 0.132\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 58/390 d_loss_real= 0.077, d_loss_fake= 0.029, g_loss 3.631, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 59/390 d_loss_real= 0.137, d_loss_fake= 0.035, g_loss 3.559, d_loss 0.086\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 60/390 d_loss_real= 0.151, d_loss_fake= 0.037, g_loss 3.374, d_loss 0.094\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 61/390 d_loss_real= 0.156, d_loss_fake= 0.039, g_loss 3.278, d_loss 0.098\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 37 Batch 62/390 d_loss_real= 0.005, d_loss_fake= 0.040, g_loss 3.289, d_loss 0.022\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 63/390 d_loss_real= 0.000, d_loss_fake= 0.040, g_loss 3.459, d_loss 0.020\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 37 Batch 64/390 d_loss_real= 0.081, d_loss_fake= 0.037, g_loss 3.575, d_loss 0.059\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 65/390 d_loss_real= 0.005, d_loss_fake= 0.031, g_loss 3.711, d_loss 0.018\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 66/390 d_loss_real= 0.046, d_loss_fake= 0.025, g_loss 3.847, d_loss 0.035\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 67/390 d_loss_real= 0.114, d_loss_fake= 0.022, g_loss 3.914, d_loss 0.068\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 68/390 d_loss_real= 0.324, d_loss_fake= 0.022, g_loss 3.852, d_loss 0.173\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 69/390 d_loss_real= 0.122, d_loss_fake= 0.025, g_loss 3.758, d_loss 0.074\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 37 Batch 70/390 d_loss_real= 0.236, d_loss_fake= 0.030, g_loss 3.524, d_loss 0.133\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 71/390 d_loss_real= 0.116, d_loss_fake= 0.041, g_loss 3.081, d_loss 0.079\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 37 Batch 72/390 d_loss_real= 0.000, d_loss_fake= 0.073, g_loss 2.881, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 73/390 d_loss_real= 0.137, d_loss_fake= 0.068, g_loss 2.992, d_loss 0.103\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 74/390 d_loss_real= 0.099, d_loss_fake= 0.047, g_loss 3.277, d_loss 0.073\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 75/390 d_loss_real= 0.000, d_loss_fake= 0.038, g_loss 3.402, d_loss 0.019\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 76/390 d_loss_real= 0.106, d_loss_fake= 0.033, g_loss 3.461, d_loss 0.070\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 77/390 d_loss_real= 0.024, d_loss_fake= 0.033, g_loss 3.534, d_loss 0.028\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 78/390 d_loss_real= 0.192, d_loss_fake= 0.032, g_loss 3.500, d_loss 0.112\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 79/390 d_loss_real= 0.147, d_loss_fake= 0.033, g_loss 3.483, d_loss 0.090\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 80/390 d_loss_real= 0.191, d_loss_fake= 0.037, g_loss 3.368, d_loss 0.114\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 81/390 d_loss_real= 0.034, d_loss_fake= 0.043, g_loss 3.246, d_loss 0.038\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 82/390 d_loss_real= 0.005, d_loss_fake= 0.045, g_loss 3.208, d_loss 0.025\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 83/390 d_loss_real= 0.109, d_loss_fake= 0.048, g_loss 3.124, d_loss 0.079\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 84/390 d_loss_real= 0.144, d_loss_fake= 0.053, g_loss 3.112, d_loss 0.098\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 85/390 d_loss_real= 0.101, d_loss_fake= 0.055, g_loss 3.100, d_loss 0.078\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 37 Batch 86/390 d_loss_real= 0.172, d_loss_fake= 0.060, g_loss 2.984, d_loss 0.116\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 37 Batch 87/390 d_loss_real= 0.026, d_loss_fake= 0.077, g_loss 2.992, d_loss 0.051\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 37 Batch 88/390 d_loss_real= 0.055, d_loss_fake= 0.060, g_loss 3.258, d_loss 0.058\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 89/390 d_loss_real= 0.014, d_loss_fake= 0.043, g_loss 3.466, d_loss 0.029\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 90/390 d_loss_real= 0.060, d_loss_fake= 0.030, g_loss 3.673, d_loss 0.045\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 37 Batch 91/390 d_loss_real= 0.206, d_loss_fake= 0.031, g_loss 3.665, d_loss 0.119\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 92/390 d_loss_real= 0.000, d_loss_fake= 0.032, g_loss 3.558, d_loss 0.016\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 37 Batch 93/390 d_loss_real= 0.144, d_loss_fake= 0.034, g_loss 3.598, d_loss 0.089\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 94/390 d_loss_real= 0.061, d_loss_fake= 0.031, g_loss 3.632, d_loss 0.046\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 95/390 d_loss_real= 0.119, d_loss_fake= 0.028, g_loss 3.609, d_loss 0.074\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 96/390 d_loss_real= 0.054, d_loss_fake= 0.030, g_loss 3.662, d_loss 0.042\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 97/390 d_loss_real= 0.123, d_loss_fake= 0.026, g_loss 3.780, d_loss 0.075\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 98/390 d_loss_real= 0.117, d_loss_fake= 0.032, g_loss 3.628, d_loss 0.075\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 99/390 d_loss_real= 0.165, d_loss_fake= 0.036, g_loss 3.655, d_loss 0.101\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 100/390 d_loss_real= 0.004, d_loss_fake= 0.030, g_loss 3.719, d_loss 0.017\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 101/390 d_loss_real= 0.124, d_loss_fake= 0.020, g_loss 4.053, d_loss 0.072\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 102/390 d_loss_real= 0.016, d_loss_fake= 0.024, g_loss 3.897, d_loss 0.020\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 103/390 d_loss_real= 0.224, d_loss_fake= 0.023, g_loss 3.963, d_loss 0.124\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 37 Batch 104/390 d_loss_real= 0.054, d_loss_fake= 0.023, g_loss 3.827, d_loss 0.039\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 37 Batch 105/390 d_loss_real= 0.259, d_loss_fake= 0.031, g_loss 3.498, d_loss 0.145\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 106/390 d_loss_real= 0.030, d_loss_fake= 0.054, g_loss 3.394, d_loss 0.042\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 107/390 d_loss_real= 0.002, d_loss_fake= 0.034, g_loss 3.808, d_loss 0.018\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 37 Batch 108/390 d_loss_real= 0.144, d_loss_fake= 0.035, g_loss 3.472, d_loss 0.089\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 109/390 d_loss_real= 0.049, d_loss_fake= 0.027, g_loss 3.758, d_loss 0.038\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 110/390 d_loss_real= 0.185, d_loss_fake= 0.030, g_loss 3.761, d_loss 0.108\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 37 Batch 111/390 d_loss_real= 0.311, d_loss_fake= 0.027, g_loss 3.730, d_loss 0.169\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 112/390 d_loss_real= 0.009, d_loss_fake= 0.022, g_loss 3.901, d_loss 0.016\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 37 Batch 113/390 d_loss_real= 0.132, d_loss_fake= 0.027, g_loss 3.736, d_loss 0.079\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 114/390 d_loss_real= 0.213, d_loss_fake= 0.031, g_loss 3.520, d_loss 0.122\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 37 Batch 115/390 d_loss_real= 0.125, d_loss_fake= 0.037, g_loss 3.522, d_loss 0.081\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 37 Batch 116/390 d_loss_real= 0.182, d_loss_fake= 0.034, g_loss 3.549, d_loss 0.108\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 117/390 d_loss_real= 0.219, d_loss_fake= 0.035, g_loss 3.482, d_loss 0.127\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 37 Batch 118/390 d_loss_real= 0.195, d_loss_fake= 0.036, g_loss 3.552, d_loss 0.115\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 37 Batch 119/390 d_loss_real= 0.060, d_loss_fake= 0.032, g_loss 3.551, d_loss 0.046\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 120/390 d_loss_real= 0.266, d_loss_fake= 0.031, g_loss 3.539, d_loss 0.148\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 121/390 d_loss_real= 0.140, d_loss_fake= 0.034, g_loss 3.405, d_loss 0.087\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 37 Batch 122/390 d_loss_real= 0.028, d_loss_fake= 0.035, g_loss 3.385, d_loss 0.032\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 123/390 d_loss_real= 0.032, d_loss_fake= 0.035, g_loss 3.371, d_loss 0.033\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 124/390 d_loss_real= 0.140, d_loss_fake= 0.039, g_loss 3.275, d_loss 0.089\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 125/390 d_loss_real= 0.215, d_loss_fake= 0.044, g_loss 3.141, d_loss 0.130\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 37 Batch 126/390 d_loss_real= 0.044, d_loss_fake= 0.051, g_loss 3.063, d_loss 0.048\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 37 Batch 127/390 d_loss_real= 0.085, d_loss_fake= 0.050, g_loss 3.124, d_loss 0.067\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 128/390 d_loss_real= 0.168, d_loss_fake= 0.045, g_loss 3.239, d_loss 0.106\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 37 Batch 129/390 d_loss_real= 0.147, d_loss_fake= 0.044, g_loss 3.196, d_loss 0.096\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 37 Batch 130/390 d_loss_real= 0.051, d_loss_fake= 0.048, g_loss 3.208, d_loss 0.050\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 131/390 d_loss_real= 0.158, d_loss_fake= 0.046, g_loss 3.147, d_loss 0.102\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 132/390 d_loss_real= 0.050, d_loss_fake= 0.048, g_loss 3.232, d_loss 0.049\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 133/390 d_loss_real= 0.124, d_loss_fake= 0.041, g_loss 3.331, d_loss 0.083\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 37 Batch 134/390 d_loss_real= 0.280, d_loss_fake= 0.038, g_loss 3.304, d_loss 0.159\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 135/390 d_loss_real= 0.052, d_loss_fake= 0.042, g_loss 3.225, d_loss 0.047\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 136/390 d_loss_real= 0.199, d_loss_fake= 0.051, g_loss 2.942, d_loss 0.125\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 137/390 d_loss_real= 0.129, d_loss_fake= 0.064, g_loss 2.845, d_loss 0.096\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 138/390 d_loss_real= 0.098, d_loss_fake= 0.057, g_loss 3.021, d_loss 0.078\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 37 Batch 139/390 d_loss_real= 0.050, d_loss_fake= 0.046, g_loss 3.274, d_loss 0.048\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 140/390 d_loss_real= 0.144, d_loss_fake= 0.045, g_loss 3.267, d_loss 0.094\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 37 Batch 141/390 d_loss_real= 0.069, d_loss_fake= 0.041, g_loss 3.357, d_loss 0.055\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 142/390 d_loss_real= 0.061, d_loss_fake= 0.036, g_loss 3.434, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 143/390 d_loss_real= 0.000, d_loss_fake= 0.033, g_loss 3.537, d_loss 0.017\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 144/390 d_loss_real= 0.150, d_loss_fake= 0.033, g_loss 3.454, d_loss 0.092\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 145/390 d_loss_real= 0.102, d_loss_fake= 0.035, g_loss 3.371, d_loss 0.068\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 146/390 d_loss_real= 0.211, d_loss_fake= 0.040, g_loss 3.254, d_loss 0.126\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 147/390 d_loss_real= 0.176, d_loss_fake= 0.057, g_loss 2.960, d_loss 0.116\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 148/390 d_loss_real= 0.142, d_loss_fake= 0.085, g_loss 2.886, d_loss 0.113\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 149/390 d_loss_real= 0.169, d_loss_fake= 0.053, g_loss 3.204, d_loss 0.111\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 150/390 d_loss_real= 0.155, d_loss_fake= 0.043, g_loss 3.271, d_loss 0.099\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 37 Batch 151/390 d_loss_real= 0.000, d_loss_fake= 0.043, g_loss 3.356, d_loss 0.021\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 152/390 d_loss_real= 0.000, d_loss_fake= 0.037, g_loss 3.469, d_loss 0.019\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 37 Batch 153/390 d_loss_real= 0.097, d_loss_fake= 0.033, g_loss 3.530, d_loss 0.065\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 37 Batch 154/390 d_loss_real= 0.065, d_loss_fake= 0.031, g_loss 3.569, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 155/390 d_loss_real= 0.100, d_loss_fake= 0.031, g_loss 3.540, d_loss 0.065\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 156/390 d_loss_real= 0.241, d_loss_fake= 0.034, g_loss 3.433, d_loss 0.137\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 37 Batch 157/390 d_loss_real= 0.103, d_loss_fake= 0.036, g_loss 3.368, d_loss 0.070\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 158/390 d_loss_real= 0.042, d_loss_fake= 0.037, g_loss 3.384, d_loss 0.039\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 159/390 d_loss_real= 0.262, d_loss_fake= 0.039, g_loss 3.251, d_loss 0.150\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 160/390 d_loss_real= 0.115, d_loss_fake= 0.042, g_loss 3.218, d_loss 0.079\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 37 Batch 161/390 d_loss_real= 0.070, d_loss_fake= 0.048, g_loss 3.085, d_loss 0.059\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 162/390 d_loss_real= 0.059, d_loss_fake= 0.049, g_loss 3.060, d_loss 0.054\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 163/390 d_loss_real= 0.123, d_loss_fake= 0.054, g_loss 2.980, d_loss 0.089\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 164/390 d_loss_real= 0.059, d_loss_fake= 0.055, g_loss 2.974, d_loss 0.057\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 165/390 d_loss_real= 0.135, d_loss_fake= 0.059, g_loss 3.018, d_loss 0.097\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 166/390 d_loss_real= 0.134, d_loss_fake= 0.053, g_loss 3.078, d_loss 0.093\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 37 Batch 167/390 d_loss_real= 0.169, d_loss_fake= 0.048, g_loss 3.153, d_loss 0.109\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 37 Batch 168/390 d_loss_real= 0.150, d_loss_fake= 0.046, g_loss 3.227, d_loss 0.098\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 169/390 d_loss_real= 0.016, d_loss_fake= 0.041, g_loss 3.335, d_loss 0.028\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 170/390 d_loss_real= 0.090, d_loss_fake= 0.039, g_loss 3.357, d_loss 0.064\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 171/390 d_loss_real= 0.096, d_loss_fake= 0.038, g_loss 3.411, d_loss 0.067\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 172/390 d_loss_real= 0.009, d_loss_fake= 0.034, g_loss 3.492, d_loss 0.022\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 173/390 d_loss_real= 0.002, d_loss_fake= 0.032, g_loss 3.555, d_loss 0.017\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 174/390 d_loss_real= 0.023, d_loss_fake= 0.030, g_loss 3.606, d_loss 0.027\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 175/390 d_loss_real= 0.136, d_loss_fake= 0.028, g_loss 3.588, d_loss 0.082\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 37 Batch 176/390 d_loss_real= 0.050, d_loss_fake= 0.032, g_loss 3.490, d_loss 0.041\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 37 Batch 177/390 d_loss_real= 0.156, d_loss_fake= 0.035, g_loss 3.313, d_loss 0.096\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 178/390 d_loss_real= 0.062, d_loss_fake= 0.040, g_loss 3.273, d_loss 0.051\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 179/390 d_loss_real= 0.164, d_loss_fake= 0.041, g_loss 3.467, d_loss 0.102\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 180/390 d_loss_real= 0.144, d_loss_fake= 0.049, g_loss 3.297, d_loss 0.096\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 181/390 d_loss_real= 0.087, d_loss_fake= 0.046, g_loss 3.382, d_loss 0.066\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 182/390 d_loss_real= 0.022, d_loss_fake= 0.036, g_loss 3.562, d_loss 0.029\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 183/390 d_loss_real= 0.120, d_loss_fake= 0.030, g_loss 3.767, d_loss 0.075\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 184/390 d_loss_real= 0.057, d_loss_fake= 0.024, g_loss 3.870, d_loss 0.040\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 37 Batch 185/390 d_loss_real= 0.267, d_loss_fake= 0.023, g_loss 3.834, d_loss 0.145\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 37 Batch 186/390 d_loss_real= 0.215, d_loss_fake= 0.027, g_loss 3.666, d_loss 0.121\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 187/390 d_loss_real= 0.198, d_loss_fake= 0.032, g_loss 3.486, d_loss 0.115\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 188/390 d_loss_real= 0.117, d_loss_fake= 0.039, g_loss 3.319, d_loss 0.078\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 189/390 d_loss_real= 0.212, d_loss_fake= 0.046, g_loss 3.177, d_loss 0.129\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 190/390 d_loss_real= 0.180, d_loss_fake= 0.046, g_loss 3.224, d_loss 0.113\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 191/390 d_loss_real= 0.133, d_loss_fake= 0.052, g_loss 3.043, d_loss 0.093\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 192/390 d_loss_real= 0.033, d_loss_fake= 0.061, g_loss 2.988, d_loss 0.047\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 193/390 d_loss_real= 0.036, d_loss_fake= 0.055, g_loss 3.225, d_loss 0.045\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 37 Batch 194/390 d_loss_real= 0.184, d_loss_fake= 0.045, g_loss 3.316, d_loss 0.114\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 195/390 d_loss_real= 0.152, d_loss_fake= 0.041, g_loss 3.405, d_loss 0.097\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 37 Batch 196/390 d_loss_real= 0.009, d_loss_fake= 0.033, g_loss 3.588, d_loss 0.021\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 37 Batch 197/390 d_loss_real= 0.059, d_loss_fake= 0.028, g_loss 3.850, d_loss 0.044\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 198/390 d_loss_real= 0.003, d_loss_fake= 0.019, g_loss 4.068, d_loss 0.011\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 199/390 d_loss_real= 0.125, d_loss_fake= 0.019, g_loss 4.091, d_loss 0.072\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 200/390 d_loss_real= 0.021, d_loss_fake= 0.019, g_loss 3.989, d_loss 0.020\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 37 Batch 201/390 d_loss_real= 0.095, d_loss_fake= 0.021, g_loss 3.829, d_loss 0.058\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 37 Batch 202/390 d_loss_real= 0.294, d_loss_fake= 0.041, g_loss 3.165, d_loss 0.167\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 37 Batch 203/390 d_loss_real= 0.122, d_loss_fake= 0.103, g_loss 2.894, d_loss 0.112\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 37 Batch 204/390 d_loss_real= 0.198, d_loss_fake= 0.074, g_loss 3.551, d_loss 0.136\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 37 Batch 205/390 d_loss_real= 0.145, d_loss_fake= 0.019, g_loss 4.230, d_loss 0.082\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 206/390 d_loss_real= 0.130, d_loss_fake= 0.017, g_loss 4.225, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 207/390 d_loss_real= 0.003, d_loss_fake= 0.013, g_loss 4.376, d_loss 0.008\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 37 Batch 208/390 d_loss_real= 0.063, d_loss_fake= 0.014, g_loss 4.356, d_loss 0.038\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 37 Batch 209/390 d_loss_real= 0.076, d_loss_fake= 0.013, g_loss 4.314, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 210/390 d_loss_real= 0.274, d_loss_fake= 0.015, g_loss 4.152, d_loss 0.145\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 211/390 d_loss_real= 0.160, d_loss_fake= 0.018, g_loss 3.967, d_loss 0.089\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 212/390 d_loss_real= 0.113, d_loss_fake= 0.024, g_loss 3.721, d_loss 0.069\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 213/390 d_loss_real= 0.155, d_loss_fake= 0.029, g_loss 3.553, d_loss 0.092\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 214/390 d_loss_real= 0.098, d_loss_fake= 0.046, g_loss 3.244, d_loss 0.072\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 215/390 d_loss_real= 0.000, d_loss_fake= 0.061, g_loss 3.224, d_loss 0.030\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 37 Batch 216/390 d_loss_real= 0.060, d_loss_fake= 0.073, g_loss 3.346, d_loss 0.066\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 217/390 d_loss_real= 0.088, d_loss_fake= 0.068, g_loss 3.631, d_loss 0.078\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 218/390 d_loss_real= 0.103, d_loss_fake= 0.027, g_loss 3.917, d_loss 0.065\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 219/390 d_loss_real= 0.116, d_loss_fake= 0.021, g_loss 3.916, d_loss 0.069\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 37 Batch 220/390 d_loss_real= 0.109, d_loss_fake= 0.021, g_loss 3.913, d_loss 0.065\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 37 Batch 221/390 d_loss_real= 0.228, d_loss_fake= 0.022, g_loss 3.871, d_loss 0.125\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 222/390 d_loss_real= 0.016, d_loss_fake= 0.023, g_loss 3.778, d_loss 0.019\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 223/390 d_loss_real= 0.074, d_loss_fake= 0.026, g_loss 3.654, d_loss 0.050\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 224/390 d_loss_real= 0.013, d_loss_fake= 0.029, g_loss 3.551, d_loss 0.021\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 225/390 d_loss_real= 0.223, d_loss_fake= 0.035, g_loss 3.306, d_loss 0.129\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 37 Batch 226/390 d_loss_real= 0.063, d_loss_fake= 0.050, g_loss 3.143, d_loss 0.057\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 227/390 d_loss_real= 0.083, d_loss_fake= 0.053, g_loss 3.017, d_loss 0.068\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 37 Batch 228/390 d_loss_real= 0.136, d_loss_fake= 0.067, g_loss 3.092, d_loss 0.102\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 37 Batch 229/390 d_loss_real= 0.030, d_loss_fake= 0.056, g_loss 3.206, d_loss 0.043\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 230/390 d_loss_real= 0.137, d_loss_fake= 0.046, g_loss 3.322, d_loss 0.091\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 231/390 d_loss_real= 0.030, d_loss_fake= 0.039, g_loss 3.383, d_loss 0.034\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 232/390 d_loss_real= 0.266, d_loss_fake= 0.042, g_loss 3.326, d_loss 0.154\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 233/390 d_loss_real= 0.136, d_loss_fake= 0.045, g_loss 3.253, d_loss 0.090\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 234/390 d_loss_real= 0.025, d_loss_fake= 0.047, g_loss 3.172, d_loss 0.036\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 235/390 d_loss_real= 0.007, d_loss_fake= 0.055, g_loss 3.258, d_loss 0.031\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 236/390 d_loss_real= 0.225, d_loss_fake= 0.044, g_loss 3.400, d_loss 0.135\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 237/390 d_loss_real= 0.157, d_loss_fake= 0.037, g_loss 3.521, d_loss 0.097\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 238/390 d_loss_real= 0.147, d_loss_fake= 0.043, g_loss 3.287, d_loss 0.095\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 37 Batch 239/390 d_loss_real= 0.108, d_loss_fake= 0.049, g_loss 3.280, d_loss 0.078\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 240/390 d_loss_real= 0.148, d_loss_fake= 0.047, g_loss 3.271, d_loss 0.098\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 241/390 d_loss_real= 0.147, d_loss_fake= 0.039, g_loss 3.468, d_loss 0.093\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 242/390 d_loss_real= 0.053, d_loss_fake= 0.039, g_loss 3.367, d_loss 0.046\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 243/390 d_loss_real= 0.213, d_loss_fake= 0.046, g_loss 3.358, d_loss 0.129\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 244/390 d_loss_real= 0.131, d_loss_fake= 0.047, g_loss 3.426, d_loss 0.089\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 245/390 d_loss_real= 0.135, d_loss_fake= 0.041, g_loss 3.496, d_loss 0.088\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 37 Batch 246/390 d_loss_real= 0.066, d_loss_fake= 0.034, g_loss 3.675, d_loss 0.050\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 247/390 d_loss_real= 0.067, d_loss_fake= 0.026, g_loss 3.889, d_loss 0.047\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 248/390 d_loss_real= 0.134, d_loss_fake= 0.025, g_loss 3.829, d_loss 0.079\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 249/390 d_loss_real= 0.139, d_loss_fake= 0.024, g_loss 3.830, d_loss 0.082\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 250/390 d_loss_real= 0.189, d_loss_fake= 0.027, g_loss 3.625, d_loss 0.108\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 251/390 d_loss_real= 0.265, d_loss_fake= 0.032, g_loss 3.376, d_loss 0.149\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 252/390 d_loss_real= 0.064, d_loss_fake= 0.050, g_loss 3.168, d_loss 0.057\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 253/390 d_loss_real= 0.129, d_loss_fake= 0.050, g_loss 3.329, d_loss 0.090\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 254/390 d_loss_real= 0.098, d_loss_fake= 0.034, g_loss 3.571, d_loss 0.066\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 37 Batch 255/390 d_loss_real= 0.100, d_loss_fake= 0.031, g_loss 3.620, d_loss 0.065\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 256/390 d_loss_real= 0.100, d_loss_fake= 0.032, g_loss 3.598, d_loss 0.066\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 37 Batch 257/390 d_loss_real= 0.244, d_loss_fake= 0.034, g_loss 3.587, d_loss 0.139\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 37 Batch 258/390 d_loss_real= 0.000, d_loss_fake= 0.034, g_loss 3.578, d_loss 0.017\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 259/390 d_loss_real= 0.173, d_loss_fake= 0.028, g_loss 3.669, d_loss 0.101\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 260/390 d_loss_real= 0.092, d_loss_fake= 0.031, g_loss 3.553, d_loss 0.061\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 37 Batch 261/390 d_loss_real= 0.032, d_loss_fake= 0.030, g_loss 3.528, d_loss 0.031\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 262/390 d_loss_real= 0.118, d_loss_fake= 0.027, g_loss 3.648, d_loss 0.073\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 37 Batch 263/390 d_loss_real= 0.236, d_loss_fake= 0.036, g_loss 3.336, d_loss 0.136\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 264/390 d_loss_real= 0.266, d_loss_fake= 0.051, g_loss 3.168, d_loss 0.159\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 37 Batch 265/390 d_loss_real= 0.151, d_loss_fake= 0.071, g_loss 3.214, d_loss 0.111\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 37 Batch 266/390 d_loss_real= 0.043, d_loss_fake= 0.045, g_loss 3.512, d_loss 0.044\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 37 Batch 267/390 d_loss_real= 0.000, d_loss_fake= 0.028, g_loss 3.771, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 268/390 d_loss_real= 0.168, d_loss_fake= 0.024, g_loss 3.848, d_loss 0.096\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 269/390 d_loss_real= 0.147, d_loss_fake= 0.024, g_loss 3.791, d_loss 0.086\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 270/390 d_loss_real= 0.118, d_loss_fake= 0.025, g_loss 3.737, d_loss 0.072\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 37 Batch 271/390 d_loss_real= 0.122, d_loss_fake= 0.027, g_loss 3.634, d_loss 0.074\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 37 Batch 272/390 d_loss_real= 0.281, d_loss_fake= 0.033, g_loss 3.367, d_loss 0.157\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 37 Batch 273/390 d_loss_real= 0.007, d_loss_fake= 0.048, g_loss 3.085, d_loss 0.028\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 274/390 d_loss_real= 0.073, d_loss_fake= 0.066, g_loss 2.998, d_loss 0.070\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 37 Batch 275/390 d_loss_real= 0.049, d_loss_fake= 0.060, g_loss 3.239, d_loss 0.054\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 276/390 d_loss_real= 0.038, d_loss_fake= 0.037, g_loss 3.462, d_loss 0.038\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 37 Batch 277/390 d_loss_real= 0.013, d_loss_fake= 0.029, g_loss 3.688, d_loss 0.021\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 278/390 d_loss_real= 0.145, d_loss_fake= 0.028, g_loss 3.784, d_loss 0.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 279/390 d_loss_real= 0.121, d_loss_fake= 0.025, g_loss 3.772, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 280/390 d_loss_real= 0.075, d_loss_fake= 0.026, g_loss 3.698, d_loss 0.050\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 37 Batch 281/390 d_loss_real= 0.113, d_loss_fake= 0.032, g_loss 3.488, d_loss 0.072\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 282/390 d_loss_real= 0.300, d_loss_fake= 0.043, g_loss 3.410, d_loss 0.172\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 37 Batch 283/390 d_loss_real= 0.111, d_loss_fake= 0.055, g_loss 3.490, d_loss 0.083\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 37 Batch 284/390 d_loss_real= 0.141, d_loss_fake= 0.036, g_loss 3.603, d_loss 0.088\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 285/390 d_loss_real= 0.067, d_loss_fake= 0.029, g_loss 3.807, d_loss 0.048\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 286/390 d_loss_real= 0.078, d_loss_fake= 0.025, g_loss 3.940, d_loss 0.052\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 287/390 d_loss_real= 0.261, d_loss_fake= 0.025, g_loss 3.900, d_loss 0.143\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 288/390 d_loss_real= 0.157, d_loss_fake= 0.029, g_loss 3.761, d_loss 0.093\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 289/390 d_loss_real= 0.134, d_loss_fake= 0.031, g_loss 3.667, d_loss 0.083\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 290/390 d_loss_real= 0.001, d_loss_fake= 0.031, g_loss 3.695, d_loss 0.016\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 291/390 d_loss_real= 0.000, d_loss_fake= 0.031, g_loss 3.853, d_loss 0.016\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 292/390 d_loss_real= 0.134, d_loss_fake= 0.026, g_loss 3.839, d_loss 0.080\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 293/390 d_loss_real= 0.053, d_loss_fake= 0.025, g_loss 3.768, d_loss 0.039\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 37 Batch 294/390 d_loss_real= 0.016, d_loss_fake= 0.027, g_loss 3.753, d_loss 0.022\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 37 Batch 295/390 d_loss_real= 0.145, d_loss_fake= 0.032, g_loss 3.584, d_loss 0.089\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 37 Batch 296/390 d_loss_real= 0.192, d_loss_fake= 0.036, g_loss 3.643, d_loss 0.114\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 297/390 d_loss_real= 0.178, d_loss_fake= 0.032, g_loss 3.654, d_loss 0.105\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 37 Batch 298/390 d_loss_real= 0.238, d_loss_fake= 0.036, g_loss 3.596, d_loss 0.137\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 299/390 d_loss_real= 0.241, d_loss_fake= 0.034, g_loss 3.596, d_loss 0.137\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 300/390 d_loss_real= 0.066, d_loss_fake= 0.033, g_loss 3.524, d_loss 0.049\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 301/390 d_loss_real= 0.307, d_loss_fake= 0.042, g_loss 3.274, d_loss 0.174\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 37 Batch 302/390 d_loss_real= 0.011, d_loss_fake= 0.042, g_loss 3.305, d_loss 0.027\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 303/390 d_loss_real= 0.228, d_loss_fake= 0.047, g_loss 3.170, d_loss 0.137\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 304/390 d_loss_real= 0.127, d_loss_fake= 0.045, g_loss 3.257, d_loss 0.086\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 305/390 d_loss_real= 0.183, d_loss_fake= 0.069, g_loss 2.968, d_loss 0.126\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 37 Batch 306/390 d_loss_real= 0.101, d_loss_fake= 0.064, g_loss 3.079, d_loss 0.082\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 307/390 d_loss_real= 0.019, d_loss_fake= 0.054, g_loss 3.276, d_loss 0.037\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 308/390 d_loss_real= 0.015, d_loss_fake= 0.042, g_loss 3.488, d_loss 0.028\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 309/390 d_loss_real= 0.079, d_loss_fake= 0.034, g_loss 3.633, d_loss 0.057\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 37 Batch 310/390 d_loss_real= 0.049, d_loss_fake= 0.033, g_loss 3.733, d_loss 0.041\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 311/390 d_loss_real= 0.200, d_loss_fake= 0.035, g_loss 3.544, d_loss 0.117\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 312/390 d_loss_real= 0.099, d_loss_fake= 0.041, g_loss 3.407, d_loss 0.070\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 313/390 d_loss_real= 0.074, d_loss_fake= 0.048, g_loss 3.240, d_loss 0.061\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 37 Batch 314/390 d_loss_real= 0.214, d_loss_fake= 0.065, g_loss 2.880, d_loss 0.139\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 315/390 d_loss_real= 0.104, d_loss_fake= 0.173, g_loss 2.912, d_loss 0.139\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 316/390 d_loss_real= 0.167, d_loss_fake= 0.080, g_loss 3.682, d_loss 0.124\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 317/390 d_loss_real= 0.002, d_loss_fake= 0.020, g_loss 4.782, d_loss 0.011\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 318/390 d_loss_real= 0.076, d_loss_fake= 0.009, g_loss 5.284, d_loss 0.042\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 37 Batch 319/390 d_loss_real= 0.076, d_loss_fake= 0.007, g_loss 5.204, d_loss 0.041\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 37 Batch 320/390 d_loss_real= 0.366, d_loss_fake= 0.010, g_loss 5.251, d_loss 0.188\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 37 Batch 321/390 d_loss_real= 0.253, d_loss_fake= 0.011, g_loss 4.740, d_loss 0.132\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 322/390 d_loss_real= 0.221, d_loss_fake= 0.013, g_loss 4.253, d_loss 0.117\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 323/390 d_loss_real= 0.122, d_loss_fake= 0.132, g_loss 4.152, d_loss 0.127\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 324/390 d_loss_real= 0.310, d_loss_fake= 0.018, g_loss 4.123, d_loss 0.164\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 37 Batch 325/390 d_loss_real= 0.224, d_loss_fake= 0.023, g_loss 3.965, d_loss 0.124\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 37 Batch 326/390 d_loss_real= 0.098, d_loss_fake= 0.027, g_loss 3.765, d_loss 0.062\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 327/390 d_loss_real= 0.068, d_loss_fake= 0.032, g_loss 3.500, d_loss 0.050\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 328/390 d_loss_real= 0.286, d_loss_fake= 0.035, g_loss 3.379, d_loss 0.161\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 329/390 d_loss_real= 0.105, d_loss_fake= 0.044, g_loss 3.231, d_loss 0.074\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 330/390 d_loss_real= 0.064, d_loss_fake= 0.050, g_loss 3.143, d_loss 0.057\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 37 Batch 331/390 d_loss_real= 0.066, d_loss_fake= 0.052, g_loss 3.076, d_loss 0.059\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 332/390 d_loss_real= 0.011, d_loss_fake= 0.059, g_loss 3.010, d_loss 0.035\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 37 Batch 333/390 d_loss_real= 0.000, d_loss_fake= 0.060, g_loss 3.005, d_loss 0.030\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 334/390 d_loss_real= 0.004, d_loss_fake= 0.054, g_loss 3.026, d_loss 0.029\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 335/390 d_loss_real= 0.049, d_loss_fake= 0.055, g_loss 3.102, d_loss 0.052\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 37 Batch 336/390 d_loss_real= 0.024, d_loss_fake= 0.053, g_loss 3.064, d_loss 0.038\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 337/390 d_loss_real= 0.083, d_loss_fake= 0.053, g_loss 3.045, d_loss 0.068\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 338/390 d_loss_real= 0.052, d_loss_fake= 0.063, g_loss 2.988, d_loss 0.058\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 37 Batch 339/390 d_loss_real= 0.000, d_loss_fake= 0.842, g_loss 3.863, d_loss 0.421\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 340/390 d_loss_real= 0.249, d_loss_fake= 0.023, g_loss 4.056, d_loss 0.136\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 37 Batch 341/390 d_loss_real= 0.109, d_loss_fake= 0.015, g_loss 4.375, d_loss 0.062\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 342/390 d_loss_real= 0.787, d_loss_fake= 0.013, g_loss 4.432, d_loss 0.400\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 343/390 d_loss_real= 0.963, d_loss_fake= 0.016, g_loss 4.133, d_loss 0.490\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 344/390 d_loss_real= 0.848, d_loss_fake= 0.025, g_loss 3.597, d_loss 0.436\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37 Batch 345/390 d_loss_real= 0.336, d_loss_fake= 0.037, g_loss 3.183, d_loss 0.186\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 346/390 d_loss_real= 0.224, d_loss_fake= 0.054, g_loss 2.828, d_loss 0.139\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 347/390 d_loss_real= 0.207, d_loss_fake= 0.081, g_loss 2.549, d_loss 0.144\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 37 Batch 348/390 d_loss_real= 0.123, d_loss_fake= 0.102, g_loss 2.348, d_loss 0.112\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 349/390 d_loss_real= 0.090, d_loss_fake= 0.120, g_loss 2.209, d_loss 0.105\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 350/390 d_loss_real= 0.041, d_loss_fake= 0.206, g_loss 2.135, d_loss 0.124\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 351/390 d_loss_real= 0.041, d_loss_fake= 0.304, g_loss 2.115, d_loss 0.173\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 37 Batch 352/390 d_loss_real= 0.030, d_loss_fake= 0.215, g_loss 2.356, d_loss 0.123\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 353/390 d_loss_real= 0.047, d_loss_fake= 0.507, g_loss 2.754, d_loss 0.277\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 354/390 d_loss_real= 0.031, d_loss_fake= 0.061, g_loss 3.091, d_loss 0.046\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 355/390 d_loss_real= 0.219, d_loss_fake= 0.043, g_loss 3.312, d_loss 0.131\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 356/390 d_loss_real= 0.246, d_loss_fake= 0.034, g_loss 3.533, d_loss 0.140\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 357/390 d_loss_real= 0.540, d_loss_fake= 0.029, g_loss 3.598, d_loss 0.284\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 358/390 d_loss_real= 0.424, d_loss_fake= 0.029, g_loss 3.582, d_loss 0.226\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 359/390 d_loss_real= 0.575, d_loss_fake= 0.033, g_loss 3.363, d_loss 0.304\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 360/390 d_loss_real= 0.582, d_loss_fake= 0.042, g_loss 3.064, d_loss 0.312\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 361/390 d_loss_real= 0.619, d_loss_fake= 0.059, g_loss 2.733, d_loss 0.339\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 362/390 d_loss_real= 0.333, d_loss_fake= 0.080, g_loss 2.456, d_loss 0.207\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 37 Batch 363/390 d_loss_real= 0.126, d_loss_fake= 0.102, g_loss 2.252, d_loss 0.114\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 364/390 d_loss_real= 0.129, d_loss_fake= 0.131, g_loss 2.060, d_loss 0.130\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 37 Batch 365/390 d_loss_real= 0.104, d_loss_fake= 0.179, g_loss 1.942, d_loss 0.142\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 366/390 d_loss_real= 0.065, d_loss_fake= 0.195, g_loss 1.902, d_loss 0.130\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 367/390 d_loss_real= 0.042, d_loss_fake= 0.178, g_loss 1.968, d_loss 0.110\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 368/390 d_loss_real= 0.055, d_loss_fake= 0.162, g_loss 2.238, d_loss 0.108\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 369/390 d_loss_real= 0.017, d_loss_fake= 0.097, g_loss 2.618, d_loss 0.057\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 370/390 d_loss_real= 0.016, d_loss_fake= 0.066, g_loss 2.941, d_loss 0.041\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 37 Batch 371/390 d_loss_real= 0.051, d_loss_fake= 0.048, g_loss 3.192, d_loss 0.050\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37 Batch 372/390 d_loss_real= 0.061, d_loss_fake= 0.038, g_loss 3.404, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 373/390 d_loss_real= 0.044, d_loss_fake= 0.033, g_loss 3.543, d_loss 0.038\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37 Batch 374/390 d_loss_real= 0.011, d_loss_fake= 0.030, g_loss 3.643, d_loss 0.020\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 37 Batch 375/390 d_loss_real= 0.174, d_loss_fake= 0.028, g_loss 3.746, d_loss 0.101\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 376/390 d_loss_real= 0.058, d_loss_fake= 0.027, g_loss 3.680, d_loss 0.043\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 377/390 d_loss_real= 0.000, d_loss_fake= 0.032, g_loss 3.589, d_loss 0.016\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 37 Batch 378/390 d_loss_real= 0.043, d_loss_fake= 0.038, g_loss 3.417, d_loss 0.040\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 379/390 d_loss_real= 0.079, d_loss_fake= 0.049, g_loss 3.085, d_loss 0.064\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 37 Batch 380/390 d_loss_real= 0.094, d_loss_fake= 0.074, g_loss 2.670, d_loss 0.084\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 381/390 d_loss_real= 0.053, d_loss_fake= 0.132, g_loss 2.268, d_loss 0.093\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 37 Batch 382/390 d_loss_real= 0.080, d_loss_fake= 0.151, g_loss 2.430, d_loss 0.115\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 37 Batch 383/390 d_loss_real= 0.220, d_loss_fake= 0.129, g_loss 2.656, d_loss 0.174\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 37 Batch 384/390 d_loss_real= 0.046, d_loss_fake= 0.067, g_loss 3.288, d_loss 0.057\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37 Batch 385/390 d_loss_real= 0.128, d_loss_fake= 0.035, g_loss 3.881, d_loss 0.082\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 37 Batch 386/390 d_loss_real= 0.099, d_loss_fake= 0.020, g_loss 4.240, d_loss 0.060\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 37 Batch 387/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 4.118, d_loss 0.010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37 Batch 388/390 d_loss_real= 0.055, d_loss_fake= 0.020, g_loss 4.028, d_loss 0.037\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 37 Batch 389/390 d_loss_real= 0.135, d_loss_fake= 0.019, g_loss 4.119, d_loss 0.077\n",
            "2/2 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37 Batch 390/390 d_loss_real= 0.000, d_loss_fake= 0.018, g_loss 4.070, d_loss 0.009\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 1/390 d_loss_real= 0.061, d_loss_fake= 0.018, g_loss 4.090, d_loss 0.040\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 38 Batch 2/390 d_loss_real= 0.109, d_loss_fake= 0.018, g_loss 4.095, d_loss 0.064\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 38 Batch 3/390 d_loss_real= 0.007, d_loss_fake= 0.018, g_loss 4.037, d_loss 0.013\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 4/390 d_loss_real= 0.000, d_loss_fake= 0.022, g_loss 3.953, d_loss 0.011\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 5/390 d_loss_real= 0.108, d_loss_fake= 0.165, g_loss 4.192, d_loss 0.137\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 6/390 d_loss_real= 0.030, d_loss_fake= 0.010, g_loss 4.816, d_loss 0.020\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 7/390 d_loss_real= 0.157, d_loss_fake= 0.009, g_loss 4.733, d_loss 0.083\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 38 Batch 8/390 d_loss_real= 0.149, d_loss_fake= 0.009, g_loss 4.709, d_loss 0.079\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 9/390 d_loss_real= 0.340, d_loss_fake= 0.010, g_loss 4.672, d_loss 0.175\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 10/390 d_loss_real= 0.054, d_loss_fake= 0.010, g_loss 4.610, d_loss 0.032\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 38 Batch 11/390 d_loss_real= 0.140, d_loss_fake= 0.010, g_loss 4.584, d_loss 0.075\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 12/390 d_loss_real= 0.134, d_loss_fake= 0.011, g_loss 4.480, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 13/390 d_loss_real= 0.072, d_loss_fake= 0.012, g_loss 4.484, d_loss 0.042\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38 Batch 14/390 d_loss_real= 0.038, d_loss_fake= 0.013, g_loss 4.360, d_loss 0.026\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 15/390 d_loss_real= 0.057, d_loss_fake= 0.014, g_loss 4.306, d_loss 0.035\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 16/390 d_loss_real= 0.176, d_loss_fake= 0.014, g_loss 4.251, d_loss 0.095\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 17/390 d_loss_real= 0.149, d_loss_fake= 0.016, g_loss 4.176, d_loss 0.082\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 18/390 d_loss_real= 0.105, d_loss_fake= 0.017, g_loss 4.063, d_loss 0.061\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 38 Batch 19/390 d_loss_real= 0.089, d_loss_fake= 0.018, g_loss 3.949, d_loss 0.054\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 20/390 d_loss_real= 0.001, d_loss_fake= 0.020, g_loss 3.895, d_loss 0.010\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 38 Batch 21/390 d_loss_real= 0.000, d_loss_fake= 0.021, g_loss 3.841, d_loss 0.011\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 38 Batch 22/390 d_loss_real= 0.048, d_loss_fake= 0.022, g_loss 3.793, d_loss 0.035\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38 Batch 23/390 d_loss_real= 0.043, d_loss_fake= 0.023, g_loss 3.794, d_loss 0.033\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 38 Batch 24/390 d_loss_real= 0.113, d_loss_fake= 0.025, g_loss 3.730, d_loss 0.069\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 38 Batch 25/390 d_loss_real= 0.068, d_loss_fake= 0.026, g_loss 3.655, d_loss 0.047\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 38 Batch 26/390 d_loss_real= 0.000, d_loss_fake= 0.027, g_loss 3.603, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 27/390 d_loss_real= 0.043, d_loss_fake= 0.029, g_loss 3.537, d_loss 0.036\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 28/390 d_loss_real= 0.072, d_loss_fake= 0.039, g_loss 3.377, d_loss 0.056\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 29/390 d_loss_real= 0.000, d_loss_fake= 0.091, g_loss 3.296, d_loss 0.046\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 30/390 d_loss_real= 0.038, d_loss_fake= 0.046, g_loss 3.522, d_loss 0.042\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 38 Batch 31/390 d_loss_real= 0.067, d_loss_fake= 0.031, g_loss 3.707, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 32/390 d_loss_real= 0.145, d_loss_fake= 0.027, g_loss 3.761, d_loss 0.086\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 38 Batch 33/390 d_loss_real= 0.050, d_loss_fake= 0.025, g_loss 3.757, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 34/390 d_loss_real= 0.132, d_loss_fake= 0.026, g_loss 3.794, d_loss 0.079\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 38 Batch 35/390 d_loss_real= 0.131, d_loss_fake= 0.027, g_loss 3.724, d_loss 0.079\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 38 Batch 36/390 d_loss_real= 0.068, d_loss_fake= 0.032, g_loss 3.531, d_loss 0.050\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 38 Batch 37/390 d_loss_real= 0.000, d_loss_fake= 0.058, g_loss 3.381, d_loss 0.029\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 38/390 d_loss_real= 0.038, d_loss_fake= 0.112, g_loss 3.148, d_loss 0.075\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 39/390 d_loss_real= 0.044, d_loss_fake= 0.278, g_loss 3.161, d_loss 0.161\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 38 Batch 40/390 d_loss_real= 0.204, d_loss_fake= 0.965, g_loss 3.828, d_loss 0.584\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 38 Batch 41/390 d_loss_real= 0.432, d_loss_fake= 0.019, g_loss 4.335, d_loss 0.225\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 42/390 d_loss_real= 0.646, d_loss_fake= 0.016, g_loss 4.442, d_loss 0.331\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 43/390 d_loss_real= 0.634, d_loss_fake= 0.014, g_loss 4.465, d_loss 0.324\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 44/390 d_loss_real= 1.055, d_loss_fake= 0.017, g_loss 4.158, d_loss 0.536\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 38 Batch 45/390 d_loss_real= 0.856, d_loss_fake= 0.024, g_loss 3.857, d_loss 0.440\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 38 Batch 46/390 d_loss_real= 0.727, d_loss_fake= 0.032, g_loss 3.386, d_loss 0.380\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 47/390 d_loss_real= 0.338, d_loss_fake= 0.051, g_loss 3.042, d_loss 0.195\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 38 Batch 48/390 d_loss_real= 0.140, d_loss_fake= 0.064, g_loss 2.808, d_loss 0.102\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 38 Batch 49/390 d_loss_real= 0.147, d_loss_fake= 0.073, g_loss 2.723, d_loss 0.110\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 50/390 d_loss_real= 0.067, d_loss_fake= 0.075, g_loss 2.680, d_loss 0.071\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 38 Batch 51/390 d_loss_real= 0.078, d_loss_fake= 0.079, g_loss 2.626, d_loss 0.079\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 52/390 d_loss_real= 0.000, d_loss_fake= 0.080, g_loss 2.609, d_loss 0.040\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 53/390 d_loss_real= 0.017, d_loss_fake= 0.092, g_loss 2.517, d_loss 0.054\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 38 Batch 54/390 d_loss_real= 0.000, d_loss_fake= 0.186, g_loss 2.443, d_loss 0.093\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 55/390 d_loss_real= 0.065, d_loss_fake= 0.429, g_loss 2.631, d_loss 0.247\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 38 Batch 56/390 d_loss_real= 0.053, d_loss_fake= 0.071, g_loss 3.088, d_loss 0.062\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 57/390 d_loss_real= 0.127, d_loss_fake= 0.041, g_loss 3.311, d_loss 0.084\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 38 Batch 58/390 d_loss_real= 0.195, d_loss_fake= 0.036, g_loss 3.448, d_loss 0.116\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 59/390 d_loss_real= 0.138, d_loss_fake= 0.032, g_loss 3.452, d_loss 0.085\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 60/390 d_loss_real= 0.166, d_loss_fake= 0.032, g_loss 3.478, d_loss 0.099\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 61/390 d_loss_real= 0.326, d_loss_fake= 0.033, g_loss 3.455, d_loss 0.179\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 38 Batch 62/390 d_loss_real= 0.007, d_loss_fake= 0.034, g_loss 3.405, d_loss 0.021\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 63/390 d_loss_real= 0.102, d_loss_fake= 0.035, g_loss 3.367, d_loss 0.069\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 64/390 d_loss_real= 0.325, d_loss_fake= 0.037, g_loss 3.315, d_loss 0.181\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 65/390 d_loss_real= 0.018, d_loss_fake= 0.038, g_loss 3.236, d_loss 0.028\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 66/390 d_loss_real= 0.187, d_loss_fake= 0.042, g_loss 3.148, d_loss 0.115\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 38 Batch 67/390 d_loss_real= 0.266, d_loss_fake= 0.048, g_loss 3.104, d_loss 0.157\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 38 Batch 68/390 d_loss_real= 0.107, d_loss_fake= 0.051, g_loss 2.932, d_loss 0.079\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 38 Batch 69/390 d_loss_real= 0.115, d_loss_fake= 0.073, g_loss 2.834, d_loss 0.094\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 70/390 d_loss_real= 0.090, d_loss_fake= 0.066, g_loss 2.859, d_loss 0.078\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 38 Batch 71/390 d_loss_real= 0.181, d_loss_fake= 0.118, g_loss 2.915, d_loss 0.150\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 72/390 d_loss_real= 0.058, d_loss_fake= 0.055, g_loss 3.129, d_loss 0.056\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 73/390 d_loss_real= 0.140, d_loss_fake= 0.042, g_loss 3.301, d_loss 0.091\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 38 Batch 74/390 d_loss_real= 0.000, d_loss_fake= 0.037, g_loss 3.435, d_loss 0.018\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 75/390 d_loss_real= 0.110, d_loss_fake= 0.033, g_loss 3.526, d_loss 0.071\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 76/390 d_loss_real= 0.213, d_loss_fake= 0.030, g_loss 3.526, d_loss 0.121\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 38 Batch 77/390 d_loss_real= 0.138, d_loss_fake= 0.031, g_loss 3.552, d_loss 0.084\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 38 Batch 78/390 d_loss_real= 0.064, d_loss_fake= 0.030, g_loss 3.526, d_loss 0.047\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 79/390 d_loss_real= 0.115, d_loss_fake= 0.031, g_loss 3.530, d_loss 0.073\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 80/390 d_loss_real= 0.121, d_loss_fake= 0.033, g_loss 3.495, d_loss 0.077\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 38 Batch 81/390 d_loss_real= 0.112, d_loss_fake= 0.034, g_loss 3.435, d_loss 0.073\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38 Batch 82/390 d_loss_real= 0.134, d_loss_fake= 0.036, g_loss 3.361, d_loss 0.085\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38 Batch 83/390 d_loss_real= 0.030, d_loss_fake= 0.040, g_loss 3.274, d_loss 0.035\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 38 Batch 84/390 d_loss_real= 0.056, d_loss_fake= 0.043, g_loss 3.176, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 85/390 d_loss_real= 0.156, d_loss_fake= 0.051, g_loss 3.050, d_loss 0.103\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 86/390 d_loss_real= 0.138, d_loss_fake= 0.071, g_loss 2.954, d_loss 0.105\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 87/390 d_loss_real= 0.052, d_loss_fake= 0.073, g_loss 3.035, d_loss 0.062\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 88/390 d_loss_real= 0.163, d_loss_fake= 0.058, g_loss 3.406, d_loss 0.110\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 38 Batch 89/390 d_loss_real= 0.045, d_loss_fake= 0.032, g_loss 3.675, d_loss 0.038\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 90/390 d_loss_real= 0.138, d_loss_fake= 0.024, g_loss 3.818, d_loss 0.081\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 38 Batch 91/390 d_loss_real= 0.086, d_loss_fake= 0.023, g_loss 3.854, d_loss 0.054\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 92/390 d_loss_real= 0.065, d_loss_fake= 0.021, g_loss 3.886, d_loss 0.043\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 38 Batch 93/390 d_loss_real= 0.148, d_loss_fake= 0.023, g_loss 3.905, d_loss 0.085\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 94/390 d_loss_real= 0.068, d_loss_fake= 0.024, g_loss 3.895, d_loss 0.046\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 95/390 d_loss_real= 0.167, d_loss_fake= 0.025, g_loss 3.776, d_loss 0.096\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 96/390 d_loss_real= 0.002, d_loss_fake= 0.029, g_loss 3.692, d_loss 0.016\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 38 Batch 97/390 d_loss_real= 0.022, d_loss_fake= 0.028, g_loss 3.584, d_loss 0.025\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 38 Batch 98/390 d_loss_real= 0.101, d_loss_fake= 0.032, g_loss 3.515, d_loss 0.067\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 38 Batch 99/390 d_loss_real= 0.135, d_loss_fake= 0.037, g_loss 3.349, d_loss 0.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 100/390 d_loss_real= 0.237, d_loss_fake= 0.044, g_loss 3.118, d_loss 0.141\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 101/390 d_loss_real= 0.064, d_loss_fake= 0.057, g_loss 2.845, d_loss 0.061\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 102/390 d_loss_real= 0.000, d_loss_fake= 0.127, g_loss 2.718, d_loss 0.064\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 103/390 d_loss_real= 0.086, d_loss_fake= 0.114, g_loss 2.711, d_loss 0.100\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 104/390 d_loss_real= 0.107, d_loss_fake= 0.125, g_loss 2.776, d_loss 0.116\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 38 Batch 105/390 d_loss_real= 0.116, d_loss_fake= 0.075, g_loss 2.951, d_loss 0.095\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38 Batch 106/390 d_loss_real= 0.104, d_loss_fake= 0.065, g_loss 3.117, d_loss 0.084\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 107/390 d_loss_real= 0.014, d_loss_fake= 0.048, g_loss 3.249, d_loss 0.031\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 38 Batch 108/390 d_loss_real= 0.094, d_loss_fake= 0.040, g_loss 3.372, d_loss 0.067\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 109/390 d_loss_real= 0.204, d_loss_fake= 0.041, g_loss 3.440, d_loss 0.122\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 110/390 d_loss_real= 0.286, d_loss_fake= 0.038, g_loss 3.395, d_loss 0.162\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 38 Batch 111/390 d_loss_real= 0.223, d_loss_fake= 0.043, g_loss 3.364, d_loss 0.133\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38 Batch 112/390 d_loss_real= 0.225, d_loss_fake= 0.045, g_loss 3.262, d_loss 0.135\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 38 Batch 113/390 d_loss_real= 0.084, d_loss_fake= 0.048, g_loss 3.151, d_loss 0.066\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 38 Batch 114/390 d_loss_real= 0.024, d_loss_fake= 0.051, g_loss 3.031, d_loss 0.037\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 38 Batch 115/390 d_loss_real= 0.207, d_loss_fake= 0.070, g_loss 2.860, d_loss 0.139\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 38 Batch 116/390 d_loss_real= 0.134, d_loss_fake= 0.065, g_loss 2.903, d_loss 0.099\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 117/390 d_loss_real= 0.092, d_loss_fake= 0.065, g_loss 2.889, d_loss 0.078\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 38 Batch 118/390 d_loss_real= 0.079, d_loss_fake= 0.095, g_loss 2.498, d_loss 0.087\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 38 Batch 119/390 d_loss_real= 0.110, d_loss_fake= 0.066, g_loss 2.995, d_loss 0.088\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 120/390 d_loss_real= 0.103, d_loss_fake= 0.048, g_loss 3.214, d_loss 0.075\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 38 Batch 121/390 d_loss_real= 0.000, d_loss_fake= 0.054, g_loss 3.147, d_loss 0.027\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 38 Batch 122/390 d_loss_real= 0.134, d_loss_fake= 0.067, g_loss 3.131, d_loss 0.101\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 38 Batch 123/390 d_loss_real= 0.059, d_loss_fake= 0.058, g_loss 3.322, d_loss 0.059\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 124/390 d_loss_real= 0.063, d_loss_fake= 0.043, g_loss 3.412, d_loss 0.053\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 38 Batch 125/390 d_loss_real= 0.046, d_loss_fake= 0.041, g_loss 3.445, d_loss 0.044\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 38 Batch 126/390 d_loss_real= 0.079, d_loss_fake= 0.033, g_loss 3.737, d_loss 0.056\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 38 Batch 127/390 d_loss_real= 0.221, d_loss_fake= 0.026, g_loss 3.876, d_loss 0.124\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 128/390 d_loss_real= 0.156, d_loss_fake= 0.024, g_loss 3.884, d_loss 0.090\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 38 Batch 129/390 d_loss_real= 0.117, d_loss_fake= 0.029, g_loss 3.752, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 130/390 d_loss_real= 0.139, d_loss_fake= 0.033, g_loss 3.586, d_loss 0.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 131/390 d_loss_real= 0.036, d_loss_fake= 0.047, g_loss 3.527, d_loss 0.042\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38 Batch 132/390 d_loss_real= 0.022, d_loss_fake= 0.038, g_loss 3.636, d_loss 0.030\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 133/390 d_loss_real= 0.002, d_loss_fake= 0.033, g_loss 3.699, d_loss 0.018\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 38 Batch 134/390 d_loss_real= 0.074, d_loss_fake= 0.027, g_loss 3.922, d_loss 0.050\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 38 Batch 135/390 d_loss_real= 0.159, d_loss_fake= 0.023, g_loss 4.021, d_loss 0.091\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 38 Batch 136/390 d_loss_real= 0.087, d_loss_fake= 0.022, g_loss 4.058, d_loss 0.054\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 137/390 d_loss_real= 0.101, d_loss_fake= 0.029, g_loss 3.683, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 138/390 d_loss_real= 0.034, d_loss_fake= 0.033, g_loss 3.708, d_loss 0.033\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 38 Batch 139/390 d_loss_real= 0.168, d_loss_fake= 0.024, g_loss 3.952, d_loss 0.096\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 38 Batch 140/390 d_loss_real= 0.170, d_loss_fake= 0.034, g_loss 3.648, d_loss 0.102\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 38 Batch 141/390 d_loss_real= 0.123, d_loss_fake= 0.045, g_loss 3.528, d_loss 0.084\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 142/390 d_loss_real= 0.115, d_loss_fake= 0.042, g_loss 3.611, d_loss 0.078\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 38 Batch 143/390 d_loss_real= 0.043, d_loss_fake= 0.048, g_loss 3.539, d_loss 0.045\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 38 Batch 144/390 d_loss_real= 0.075, d_loss_fake= 0.028, g_loss 4.172, d_loss 0.051\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 38 Batch 145/390 d_loss_real= 0.052, d_loss_fake= 0.023, g_loss 4.137, d_loss 0.038\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 38 Batch 146/390 d_loss_real= 0.244, d_loss_fake= 0.018, g_loss 4.325, d_loss 0.131\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 38 Batch 147/390 d_loss_real= 0.334, d_loss_fake= 0.015, g_loss 4.251, d_loss 0.175\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 148/390 d_loss_real= 0.334, d_loss_fake= 0.026, g_loss 3.875, d_loss 0.180\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 149/390 d_loss_real= 0.187, d_loss_fake= 0.035, g_loss 3.565, d_loss 0.111\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 150/390 d_loss_real= 0.089, d_loss_fake= 0.031, g_loss 3.612, d_loss 0.060\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 38 Batch 151/390 d_loss_real= 0.150, d_loss_fake= 0.056, g_loss 3.451, d_loss 0.103\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 152/390 d_loss_real= 0.117, d_loss_fake= 0.050, g_loss 3.545, d_loss 0.083\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 153/390 d_loss_real= 0.074, d_loss_fake= 0.045, g_loss 4.024, d_loss 0.059\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 38 Batch 154/390 d_loss_real= 0.043, d_loss_fake= 0.020, g_loss 4.265, d_loss 0.031\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 155/390 d_loss_real= 0.171, d_loss_fake= 0.014, g_loss 4.513, d_loss 0.093\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 156/390 d_loss_real= 0.228, d_loss_fake= 0.011, g_loss 4.586, d_loss 0.120\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 157/390 d_loss_real= 0.099, d_loss_fake= 0.011, g_loss 4.612, d_loss 0.055\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 158/390 d_loss_real= 0.081, d_loss_fake= 0.010, g_loss 4.592, d_loss 0.045\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 38 Batch 159/390 d_loss_real= 0.166, d_loss_fake= 0.013, g_loss 4.279, d_loss 0.090\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 38 Batch 160/390 d_loss_real= 0.333, d_loss_fake= 0.018, g_loss 3.840, d_loss 0.175\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 38 Batch 161/390 d_loss_real= 0.045, d_loss_fake= 0.029, g_loss 3.611, d_loss 0.037\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 162/390 d_loss_real= 0.092, d_loss_fake= 0.049, g_loss 3.389, d_loss 0.070\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 163/390 d_loss_real= 0.173, d_loss_fake= 0.036, g_loss 3.659, d_loss 0.105\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 38 Batch 164/390 d_loss_real= 0.081, d_loss_fake= 0.046, g_loss 3.554, d_loss 0.064\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 165/390 d_loss_real= 0.323, d_loss_fake= 0.035, g_loss 3.708, d_loss 0.179\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 166/390 d_loss_real= 0.126, d_loss_fake= 0.023, g_loss 3.976, d_loss 0.074\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 38 Batch 167/390 d_loss_real= 0.057, d_loss_fake= 0.019, g_loss 4.130, d_loss 0.038\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 168/390 d_loss_real= 0.041, d_loss_fake= 0.017, g_loss 4.249, d_loss 0.029\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 38 Batch 169/390 d_loss_real= 0.230, d_loss_fake= 0.016, g_loss 4.246, d_loss 0.123\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 170/390 d_loss_real= 0.186, d_loss_fake= 0.016, g_loss 4.214, d_loss 0.101\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 171/390 d_loss_real= 0.232, d_loss_fake= 0.018, g_loss 3.989, d_loss 0.125\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38 Batch 172/390 d_loss_real= 0.180, d_loss_fake= 0.021, g_loss 3.754, d_loss 0.100\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 38 Batch 173/390 d_loss_real= 0.254, d_loss_fake= 0.035, g_loss 3.430, d_loss 0.144\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 174/390 d_loss_real= 0.040, d_loss_fake= 0.047, g_loss 3.261, d_loss 0.043\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 38 Batch 175/390 d_loss_real= 0.248, d_loss_fake= 0.042, g_loss 3.446, d_loss 0.145\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 38 Batch 176/390 d_loss_real= 0.085, d_loss_fake= 0.036, g_loss 3.380, d_loss 0.060\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 38 Batch 177/390 d_loss_real= 0.156, d_loss_fake= 0.039, g_loss 3.364, d_loss 0.098\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38 Batch 178/390 d_loss_real= 0.001, d_loss_fake= 0.035, g_loss 3.479, d_loss 0.018\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 179/390 d_loss_real= 0.000, d_loss_fake= 0.040, g_loss 3.548, d_loss 0.020\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 38 Batch 180/390 d_loss_real= 0.141, d_loss_fake= 0.027, g_loss 3.776, d_loss 0.084\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 181/390 d_loss_real= 0.195, d_loss_fake= 0.024, g_loss 3.795, d_loss 0.109\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 182/390 d_loss_real= 0.038, d_loss_fake= 0.024, g_loss 3.840, d_loss 0.031\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 183/390 d_loss_real= 0.152, d_loss_fake= 0.024, g_loss 3.745, d_loss 0.088\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 184/390 d_loss_real= 0.122, d_loss_fake= 0.025, g_loss 3.641, d_loss 0.074\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 38 Batch 185/390 d_loss_real= 0.099, d_loss_fake= 0.029, g_loss 3.481, d_loss 0.064\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 186/390 d_loss_real= 0.059, d_loss_fake= 0.035, g_loss 3.334, d_loss 0.047\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 187/390 d_loss_real= 0.144, d_loss_fake= 0.041, g_loss 3.195, d_loss 0.092\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 38 Batch 188/390 d_loss_real= 0.109, d_loss_fake= 0.048, g_loss 3.167, d_loss 0.078\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 189/390 d_loss_real= 0.003, d_loss_fake= 0.048, g_loss 3.176, d_loss 0.025\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 38 Batch 190/390 d_loss_real= 0.006, d_loss_fake= 0.043, g_loss 3.376, d_loss 0.024\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 191/390 d_loss_real= 0.090, d_loss_fake= 0.036, g_loss 3.468, d_loss 0.063\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 192/390 d_loss_real= 0.259, d_loss_fake= 0.034, g_loss 3.479, d_loss 0.146\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 38 Batch 193/390 d_loss_real= 0.080, d_loss_fake= 0.035, g_loss 3.360, d_loss 0.057\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 194/390 d_loss_real= 0.072, d_loss_fake= 0.038, g_loss 3.233, d_loss 0.055\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 38 Batch 195/390 d_loss_real= 0.047, d_loss_fake= 0.046, g_loss 3.154, d_loss 0.046\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 38 Batch 196/390 d_loss_real= 0.013, d_loss_fake= 0.048, g_loss 3.192, d_loss 0.030\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 197/390 d_loss_real= 0.056, d_loss_fake= 0.048, g_loss 3.248, d_loss 0.052\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38 Batch 198/390 d_loss_real= 0.068, d_loss_fake= 0.048, g_loss 3.309, d_loss 0.058\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 38 Batch 199/390 d_loss_real= 0.124, d_loss_fake= 0.045, g_loss 3.364, d_loss 0.085\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 38 Batch 200/390 d_loss_real= 0.095, d_loss_fake= 0.036, g_loss 3.440, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 201/390 d_loss_real= 0.067, d_loss_fake= 0.032, g_loss 3.585, d_loss 0.050\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38 Batch 202/390 d_loss_real= 0.164, d_loss_fake= 0.036, g_loss 3.451, d_loss 0.100\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 38 Batch 203/390 d_loss_real= 0.071, d_loss_fake= 0.033, g_loss 3.512, d_loss 0.052\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38 Batch 204/390 d_loss_real= 0.021, d_loss_fake= 0.045, g_loss 3.383, d_loss 0.033\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38 Batch 205/390 d_loss_real= 0.186, d_loss_fake= 0.058, g_loss 3.464, d_loss 0.122\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 206/390 d_loss_real= 0.057, d_loss_fake= 0.059, g_loss 3.484, d_loss 0.058\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 38 Batch 207/390 d_loss_real= 0.001, d_loss_fake= 0.043, g_loss 3.486, d_loss 0.022\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38 Batch 208/390 d_loss_real= 0.225, d_loss_fake= 0.042, g_loss 3.453, d_loss 0.133\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 38 Batch 209/390 d_loss_real= 0.250, d_loss_fake= 0.038, g_loss 3.435, d_loss 0.144\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 210/390 d_loss_real= 0.103, d_loss_fake= 0.044, g_loss 3.477, d_loss 0.073\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 211/390 d_loss_real= 0.149, d_loss_fake= 0.042, g_loss 3.330, d_loss 0.096\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38 Batch 212/390 d_loss_real= 0.243, d_loss_fake= 0.035, g_loss 3.347, d_loss 0.139\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 38 Batch 213/390 d_loss_real= 0.095, d_loss_fake= 0.043, g_loss 3.292, d_loss 0.069\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 38 Batch 214/390 d_loss_real= 0.084, d_loss_fake= 0.049, g_loss 3.166, d_loss 0.066\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 38 Batch 215/390 d_loss_real= 0.045, d_loss_fake= 0.044, g_loss 3.165, d_loss 0.044\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 38 Batch 216/390 d_loss_real= 0.145, d_loss_fake= 0.050, g_loss 3.124, d_loss 0.097\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 217/390 d_loss_real= 0.134, d_loss_fake= 0.051, g_loss 3.028, d_loss 0.093\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 38 Batch 218/390 d_loss_real= 0.064, d_loss_fake= 0.056, g_loss 3.028, d_loss 0.060\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 38 Batch 219/390 d_loss_real= 0.043, d_loss_fake= 0.053, g_loss 3.086, d_loss 0.048\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 220/390 d_loss_real= 0.158, d_loss_fake= 0.053, g_loss 3.003, d_loss 0.105\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 38 Batch 221/390 d_loss_real= 0.118, d_loss_fake= 0.055, g_loss 2.986, d_loss 0.087\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 38 Batch 222/390 d_loss_real= 0.195, d_loss_fake= 0.058, g_loss 2.917, d_loss 0.127\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 223/390 d_loss_real= 0.121, d_loss_fake= 0.073, g_loss 2.781, d_loss 0.097\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 224/390 d_loss_real= 0.134, d_loss_fake= 0.080, g_loss 2.706, d_loss 0.107\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 225/390 d_loss_real= 0.075, d_loss_fake= 0.084, g_loss 2.823, d_loss 0.079\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 226/390 d_loss_real= 0.216, d_loss_fake= 0.075, g_loss 2.795, d_loss 0.146\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 38 Batch 227/390 d_loss_real= 0.003, d_loss_fake= 0.067, g_loss 3.014, d_loss 0.035\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 228/390 d_loss_real= 0.019, d_loss_fake= 0.059, g_loss 3.173, d_loss 0.039\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 229/390 d_loss_real= 0.188, d_loss_fake= 0.043, g_loss 3.431, d_loss 0.116\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 38 Batch 230/390 d_loss_real= 0.143, d_loss_fake= 0.042, g_loss 3.467, d_loss 0.093\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 231/390 d_loss_real= 0.032, d_loss_fake= 0.039, g_loss 3.473, d_loss 0.036\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 232/390 d_loss_real= 0.198, d_loss_fake= 0.037, g_loss 3.436, d_loss 0.117\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 233/390 d_loss_real= 0.015, d_loss_fake= 0.042, g_loss 3.413, d_loss 0.028\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 38 Batch 234/390 d_loss_real= 0.192, d_loss_fake= 0.044, g_loss 3.313, d_loss 0.118\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 38 Batch 235/390 d_loss_real= 0.124, d_loss_fake= 0.061, g_loss 3.125, d_loss 0.092\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 236/390 d_loss_real= 0.109, d_loss_fake= 0.082, g_loss 2.967, d_loss 0.095\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 38 Batch 237/390 d_loss_real= 0.229, d_loss_fake= 0.072, g_loss 3.249, d_loss 0.151\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 38 Batch 238/390 d_loss_real= 0.140, d_loss_fake= 0.055, g_loss 3.591, d_loss 0.098\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 38 Batch 239/390 d_loss_real= 0.238, d_loss_fake= 0.032, g_loss 3.931, d_loss 0.135\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 38 Batch 240/390 d_loss_real= 0.289, d_loss_fake= 0.023, g_loss 3.917, d_loss 0.156\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 38 Batch 241/390 d_loss_real= 0.220, d_loss_fake= 0.022, g_loss 3.954, d_loss 0.121\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 38 Batch 242/390 d_loss_real= 0.182, d_loss_fake= 0.023, g_loss 3.919, d_loss 0.103\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 243/390 d_loss_real= 0.247, d_loss_fake= 0.024, g_loss 3.815, d_loss 0.135\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 38 Batch 244/390 d_loss_real= 0.159, d_loss_fake= 0.025, g_loss 3.757, d_loss 0.092\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 38 Batch 245/390 d_loss_real= 0.159, d_loss_fake= 0.029, g_loss 3.418, d_loss 0.094\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 246/390 d_loss_real= 0.106, d_loss_fake= 0.039, g_loss 3.224, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 247/390 d_loss_real= 0.107, d_loss_fake= 0.054, g_loss 3.083, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 248/390 d_loss_real= 0.068, d_loss_fake= 0.053, g_loss 3.226, d_loss 0.061\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 249/390 d_loss_real= 0.224, d_loss_fake= 0.042, g_loss 3.333, d_loss 0.133\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 250/390 d_loss_real= 0.054, d_loss_fake= 0.045, g_loss 3.270, d_loss 0.049\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 38 Batch 251/390 d_loss_real= 0.094, d_loss_fake= 0.044, g_loss 3.249, d_loss 0.069\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 252/390 d_loss_real= 0.080, d_loss_fake= 0.039, g_loss 3.349, d_loss 0.060\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 253/390 d_loss_real= 0.195, d_loss_fake= 0.039, g_loss 3.403, d_loss 0.117\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 254/390 d_loss_real= 0.073, d_loss_fake= 0.038, g_loss 3.377, d_loss 0.055\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 38 Batch 255/390 d_loss_real= 0.227, d_loss_fake= 0.038, g_loss 3.391, d_loss 0.132\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 256/390 d_loss_real= 0.071, d_loss_fake= 0.036, g_loss 3.462, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 257/390 d_loss_real= 0.049, d_loss_fake= 0.037, g_loss 3.392, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 258/390 d_loss_real= 0.144, d_loss_fake= 0.036, g_loss 3.413, d_loss 0.090\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 38 Batch 259/390 d_loss_real= 0.107, d_loss_fake= 0.041, g_loss 3.224, d_loss 0.074\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38 Batch 260/390 d_loss_real= 0.060, d_loss_fake= 0.053, g_loss 3.044, d_loss 0.056\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 261/390 d_loss_real= 0.147, d_loss_fake= 0.048, g_loss 3.154, d_loss 0.097\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 38 Batch 262/390 d_loss_real= 0.124, d_loss_fake= 0.057, g_loss 3.189, d_loss 0.090\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 38 Batch 263/390 d_loss_real= 0.016, d_loss_fake= 0.042, g_loss 3.301, d_loss 0.029\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 264/390 d_loss_real= 0.145, d_loss_fake= 0.038, g_loss 3.654, d_loss 0.092\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 38 Batch 265/390 d_loss_real= 0.123, d_loss_fake= 0.038, g_loss 3.401, d_loss 0.081\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 38 Batch 266/390 d_loss_real= 0.074, d_loss_fake= 0.030, g_loss 3.655, d_loss 0.052\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38 Batch 267/390 d_loss_real= 0.121, d_loss_fake= 0.026, g_loss 3.762, d_loss 0.074\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 268/390 d_loss_real= 0.198, d_loss_fake= 0.028, g_loss 3.633, d_loss 0.113\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 269/390 d_loss_real= 0.179, d_loss_fake= 0.032, g_loss 3.481, d_loss 0.105\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 270/390 d_loss_real= 0.100, d_loss_fake= 0.044, g_loss 3.293, d_loss 0.072\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38 Batch 271/390 d_loss_real= 0.081, d_loss_fake= 0.037, g_loss 3.417, d_loss 0.059\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 38 Batch 272/390 d_loss_real= 0.383, d_loss_fake= 0.037, g_loss 3.366, d_loss 0.210\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 38 Batch 273/390 d_loss_real= 0.068, d_loss_fake= 0.043, g_loss 3.323, d_loss 0.055\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 274/390 d_loss_real= 0.059, d_loss_fake= 0.047, g_loss 3.457, d_loss 0.053\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 38 Batch 275/390 d_loss_real= 0.065, d_loss_fake= 0.034, g_loss 3.696, d_loss 0.050\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 38 Batch 276/390 d_loss_real= 0.107, d_loss_fake= 0.025, g_loss 3.843, d_loss 0.066\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 277/390 d_loss_real= 0.127, d_loss_fake= 0.020, g_loss 4.020, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 278/390 d_loss_real= 0.152, d_loss_fake= 0.018, g_loss 4.151, d_loss 0.085\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 38 Batch 279/390 d_loss_real= 0.298, d_loss_fake= 0.019, g_loss 4.001, d_loss 0.158\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 280/390 d_loss_real= 0.038, d_loss_fake= 0.021, g_loss 3.833, d_loss 0.029\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 38 Batch 281/390 d_loss_real= 0.051, d_loss_fake= 0.025, g_loss 3.686, d_loss 0.038\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 282/390 d_loss_real= 0.058, d_loss_fake= 0.029, g_loss 3.600, d_loss 0.044\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 38 Batch 283/390 d_loss_real= 0.071, d_loss_fake= 0.034, g_loss 3.440, d_loss 0.052\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 284/390 d_loss_real= 0.162, d_loss_fake= 0.039, g_loss 3.409, d_loss 0.101\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 285/390 d_loss_real= 0.017, d_loss_fake= 0.044, g_loss 3.398, d_loss 0.030\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 38 Batch 286/390 d_loss_real= 0.089, d_loss_fake= 0.035, g_loss 3.562, d_loss 0.062\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 287/390 d_loss_real= 0.166, d_loss_fake= 0.042, g_loss 3.436, d_loss 0.104\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 38 Batch 288/390 d_loss_real= 0.107, d_loss_fake= 0.056, g_loss 3.283, d_loss 0.082\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 289/390 d_loss_real= 0.095, d_loss_fake= 0.040, g_loss 3.460, d_loss 0.067\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38 Batch 290/390 d_loss_real= 0.057, d_loss_fake= 0.033, g_loss 3.810, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 291/390 d_loss_real= 0.155, d_loss_fake= 0.023, g_loss 4.035, d_loss 0.089\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 38 Batch 292/390 d_loss_real= 0.086, d_loss_fake= 0.022, g_loss 4.059, d_loss 0.054\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38 Batch 293/390 d_loss_real= 0.023, d_loss_fake= 0.019, g_loss 4.183, d_loss 0.021\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 294/390 d_loss_real= 0.048, d_loss_fake= 0.018, g_loss 4.166, d_loss 0.033\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 295/390 d_loss_real= 0.120, d_loss_fake= 0.020, g_loss 4.077, d_loss 0.070\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 296/390 d_loss_real= 0.028, d_loss_fake= 0.026, g_loss 3.900, d_loss 0.027\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 38 Batch 297/390 d_loss_real= 0.076, d_loss_fake= 0.026, g_loss 3.771, d_loss 0.051\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38 Batch 298/390 d_loss_real= 0.183, d_loss_fake= 0.030, g_loss 3.709, d_loss 0.106\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 299/390 d_loss_real= 0.169, d_loss_fake= 0.043, g_loss 3.445, d_loss 0.106\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 300/390 d_loss_real= 0.100, d_loss_fake= 0.039, g_loss 3.345, d_loss 0.070\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 38 Batch 301/390 d_loss_real= 0.049, d_loss_fake= 0.031, g_loss 3.615, d_loss 0.040\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 38 Batch 302/390 d_loss_real= 0.111, d_loss_fake= 0.038, g_loss 3.527, d_loss 0.074\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 303/390 d_loss_real= 0.155, d_loss_fake= 0.042, g_loss 3.416, d_loss 0.098\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 38 Batch 304/390 d_loss_real= 0.087, d_loss_fake= 0.042, g_loss 3.469, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 305/390 d_loss_real= 0.177, d_loss_fake= 0.046, g_loss 3.368, d_loss 0.111\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 306/390 d_loss_real= 0.037, d_loss_fake= 0.052, g_loss 3.279, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 307/390 d_loss_real= 0.061, d_loss_fake= 0.038, g_loss 3.505, d_loss 0.049\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 38 Batch 308/390 d_loss_real= 0.061, d_loss_fake= 0.032, g_loss 3.732, d_loss 0.046\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 38 Batch 309/390 d_loss_real= 0.145, d_loss_fake= 0.032, g_loss 3.644, d_loss 0.088\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 310/390 d_loss_real= 0.112, d_loss_fake= 0.032, g_loss 3.726, d_loss 0.072\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 311/390 d_loss_real= 0.001, d_loss_fake= 0.030, g_loss 3.726, d_loss 0.016\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 38 Batch 312/390 d_loss_real= 0.190, d_loss_fake= 0.031, g_loss 3.729, d_loss 0.110\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 38 Batch 313/390 d_loss_real= 0.039, d_loss_fake= 0.036, g_loss 3.449, d_loss 0.037\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38 Batch 314/390 d_loss_real= 0.130, d_loss_fake= 0.041, g_loss 3.375, d_loss 0.085\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 315/390 d_loss_real= 0.025, d_loss_fake= 0.047, g_loss 3.290, d_loss 0.036\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38 Batch 316/390 d_loss_real= 0.079, d_loss_fake= 0.049, g_loss 3.342, d_loss 0.064\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 38 Batch 317/390 d_loss_real= 0.015, d_loss_fake= 0.044, g_loss 3.383, d_loss 0.029\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 38 Batch 318/390 d_loss_real= 0.130, d_loss_fake= 0.048, g_loss 3.209, d_loss 0.089\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 319/390 d_loss_real= 0.219, d_loss_fake= 0.047, g_loss 3.208, d_loss 0.133\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 320/390 d_loss_real= 0.076, d_loss_fake= 0.058, g_loss 3.103, d_loss 0.067\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 321/390 d_loss_real= 0.000, d_loss_fake= 0.059, g_loss 3.245, d_loss 0.030\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 38 Batch 322/390 d_loss_real= 0.025, d_loss_fake= 0.048, g_loss 3.339, d_loss 0.036\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 38 Batch 323/390 d_loss_real= 0.238, d_loss_fake= 0.040, g_loss 3.512, d_loss 0.139\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 38 Batch 324/390 d_loss_real= 0.098, d_loss_fake= 0.042, g_loss 3.637, d_loss 0.070\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 38 Batch 325/390 d_loss_real= 0.000, d_loss_fake= 0.040, g_loss 3.616, d_loss 0.020\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 326/390 d_loss_real= 0.057, d_loss_fake= 0.046, g_loss 3.567, d_loss 0.051\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38 Batch 327/390 d_loss_real= 0.049, d_loss_fake= 0.042, g_loss 3.493, d_loss 0.045\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 38 Batch 328/390 d_loss_real= 0.187, d_loss_fake= 0.050, g_loss 3.549, d_loss 0.119\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 329/390 d_loss_real= 0.141, d_loss_fake= 0.040, g_loss 3.393, d_loss 0.090\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 38 Batch 330/390 d_loss_real= 0.001, d_loss_fake= 0.046, g_loss 3.146, d_loss 0.023\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 38 Batch 331/390 d_loss_real= 0.158, d_loss_fake= 0.066, g_loss 3.054, d_loss 0.112\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 332/390 d_loss_real= 0.060, d_loss_fake= 0.081, g_loss 3.154, d_loss 0.070\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 333/390 d_loss_real= 0.178, d_loss_fake= 0.056, g_loss 3.328, d_loss 0.117\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 334/390 d_loss_real= 0.071, d_loss_fake= 0.058, g_loss 3.335, d_loss 0.065\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 38 Batch 335/390 d_loss_real= 0.159, d_loss_fake= 0.044, g_loss 3.456, d_loss 0.101\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 336/390 d_loss_real= 0.095, d_loss_fake= 0.039, g_loss 3.429, d_loss 0.067\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 337/390 d_loss_real= 0.134, d_loss_fake= 0.045, g_loss 3.453, d_loss 0.090\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 38 Batch 338/390 d_loss_real= 0.155, d_loss_fake= 0.044, g_loss 3.495, d_loss 0.099\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38 Batch 339/390 d_loss_real= 0.007, d_loss_fake= 0.038, g_loss 3.616, d_loss 0.023\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 340/390 d_loss_real= 0.055, d_loss_fake= 0.030, g_loss 3.863, d_loss 0.043\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 38 Batch 341/390 d_loss_real= 0.267, d_loss_fake= 0.025, g_loss 3.781, d_loss 0.146\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38 Batch 342/390 d_loss_real= 0.170, d_loss_fake= 0.034, g_loss 3.376, d_loss 0.102\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 343/390 d_loss_real= 0.138, d_loss_fake= 0.045, g_loss 3.453, d_loss 0.092\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 344/390 d_loss_real= 0.035, d_loss_fake= 0.047, g_loss 3.460, d_loss 0.041\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 38 Batch 345/390 d_loss_real= 0.259, d_loss_fake= 0.054, g_loss 3.480, d_loss 0.156\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 38 Batch 346/390 d_loss_real= 0.040, d_loss_fake= 0.042, g_loss 3.477, d_loss 0.041\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 38 Batch 347/390 d_loss_real= 0.003, d_loss_fake= 0.031, g_loss 3.756, d_loss 0.017\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 348/390 d_loss_real= 0.070, d_loss_fake= 0.027, g_loss 3.633, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 349/390 d_loss_real= 0.131, d_loss_fake= 0.031, g_loss 3.676, d_loss 0.081\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38 Batch 350/390 d_loss_real= 0.170, d_loss_fake= 0.029, g_loss 3.822, d_loss 0.100\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 351/390 d_loss_real= 0.033, d_loss_fake= 0.023, g_loss 3.876, d_loss 0.028\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 352/390 d_loss_real= 0.328, d_loss_fake= 0.027, g_loss 3.620, d_loss 0.178\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 353/390 d_loss_real= 0.070, d_loss_fake= 0.036, g_loss 3.430, d_loss 0.053\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 38 Batch 354/390 d_loss_real= 0.268, d_loss_fake= 0.039, g_loss 3.390, d_loss 0.153\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 38 Batch 355/390 d_loss_real= 0.110, d_loss_fake= 0.052, g_loss 3.280, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 356/390 d_loss_real= 0.057, d_loss_fake= 0.040, g_loss 3.544, d_loss 0.049\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 357/390 d_loss_real= 0.116, d_loss_fake= 0.045, g_loss 3.400, d_loss 0.081\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 38 Batch 358/390 d_loss_real= 0.131, d_loss_fake= 0.033, g_loss 3.639, d_loss 0.082\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 359/390 d_loss_real= 0.139, d_loss_fake= 0.025, g_loss 3.823, d_loss 0.082\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 38 Batch 360/390 d_loss_real= 0.218, d_loss_fake= 0.027, g_loss 3.748, d_loss 0.122\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 38 Batch 361/390 d_loss_real= 0.189, d_loss_fake= 0.029, g_loss 3.676, d_loss 0.109\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 362/390 d_loss_real= 0.048, d_loss_fake= 0.032, g_loss 3.548, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 363/390 d_loss_real= 0.151, d_loss_fake= 0.036, g_loss 3.370, d_loss 0.094\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 38 Batch 364/390 d_loss_real= 0.028, d_loss_fake= 0.045, g_loss 3.288, d_loss 0.036\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 38 Batch 365/390 d_loss_real= 0.251, d_loss_fake= 0.044, g_loss 3.201, d_loss 0.148\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 366/390 d_loss_real= 0.110, d_loss_fake= 0.052, g_loss 3.145, d_loss 0.081\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 38 Batch 367/390 d_loss_real= 0.120, d_loss_fake= 0.052, g_loss 3.346, d_loss 0.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 368/390 d_loss_real= 0.231, d_loss_fake= 0.044, g_loss 3.329, d_loss 0.137\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 38 Batch 369/390 d_loss_real= 0.105, d_loss_fake= 0.041, g_loss 3.375, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 370/390 d_loss_real= 0.113, d_loss_fake= 0.043, g_loss 3.234, d_loss 0.078\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 38 Batch 371/390 d_loss_real= 0.174, d_loss_fake= 0.059, g_loss 3.113, d_loss 0.117\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 38 Batch 372/390 d_loss_real= 0.003, d_loss_fake= 0.062, g_loss 3.265, d_loss 0.032\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 373/390 d_loss_real= 0.129, d_loss_fake= 0.041, g_loss 3.452, d_loss 0.085\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 38 Batch 374/390 d_loss_real= 0.189, d_loss_fake= 0.033, g_loss 3.533, d_loss 0.111\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 38 Batch 375/390 d_loss_real= 0.174, d_loss_fake= 0.032, g_loss 3.525, d_loss 0.103\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 38 Batch 376/390 d_loss_real= 0.316, d_loss_fake= 0.031, g_loss 3.566, d_loss 0.174\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38 Batch 377/390 d_loss_real= 0.267, d_loss_fake= 0.032, g_loss 3.455, d_loss 0.150\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 378/390 d_loss_real= 0.124, d_loss_fake= 0.042, g_loss 3.051, d_loss 0.083\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38 Batch 379/390 d_loss_real= 0.150, d_loss_fake= 0.072, g_loss 2.863, d_loss 0.111\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 38 Batch 380/390 d_loss_real= 0.186, d_loss_fake= 0.051, g_loss 3.104, d_loss 0.118\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 381/390 d_loss_real= 0.072, d_loss_fake= 0.066, g_loss 2.926, d_loss 0.069\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38 Batch 382/390 d_loss_real= 0.147, d_loss_fake= 0.050, g_loss 3.224, d_loss 0.098\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 38 Batch 383/390 d_loss_real= 0.072, d_loss_fake= 0.042, g_loss 3.374, d_loss 0.057\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 384/390 d_loss_real= 0.002, d_loss_fake= 0.035, g_loss 3.541, d_loss 0.018\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 38 Batch 385/390 d_loss_real= 0.198, d_loss_fake= 0.033, g_loss 3.518, d_loss 0.115\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 386/390 d_loss_real= 0.259, d_loss_fake= 0.033, g_loss 3.484, d_loss 0.146\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38 Batch 387/390 d_loss_real= 0.136, d_loss_fake= 0.032, g_loss 3.519, d_loss 0.084\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38 Batch 388/390 d_loss_real= 0.043, d_loss_fake= 0.032, g_loss 3.462, d_loss 0.038\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 38 Batch 389/390 d_loss_real= 0.155, d_loss_fake= 0.032, g_loss 3.400, d_loss 0.093\n",
            "2/2 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38 Batch 390/390 d_loss_real= 0.167, d_loss_fake= 0.041, g_loss 3.274, d_loss 0.104\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 1/390 d_loss_real= 0.153, d_loss_fake= 0.051, g_loss 3.104, d_loss 0.102\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 2/390 d_loss_real= 0.056, d_loss_fake= 0.060, g_loss 3.086, d_loss 0.058\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 3/390 d_loss_real= 0.169, d_loss_fake= 0.055, g_loss 3.096, d_loss 0.112\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 39 Batch 4/390 d_loss_real= 0.102, d_loss_fake= 0.051, g_loss 3.208, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 5/390 d_loss_real= 0.057, d_loss_fake= 0.046, g_loss 3.359, d_loss 0.051\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 39 Batch 6/390 d_loss_real= 0.157, d_loss_fake= 0.040, g_loss 3.415, d_loss 0.098\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 7/390 d_loss_real= 0.001, d_loss_fake= 0.033, g_loss 3.548, d_loss 0.017\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 8/390 d_loss_real= 0.094, d_loss_fake= 0.029, g_loss 3.642, d_loss 0.062\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 9/390 d_loss_real= 0.135, d_loss_fake= 0.027, g_loss 3.673, d_loss 0.081\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 10/390 d_loss_real= 0.127, d_loss_fake= 0.027, g_loss 3.671, d_loss 0.077\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 11/390 d_loss_real= 0.047, d_loss_fake= 0.029, g_loss 3.634, d_loss 0.038\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 12/390 d_loss_real= 0.098, d_loss_fake= 0.031, g_loss 3.532, d_loss 0.065\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 39 Batch 13/390 d_loss_real= 0.078, d_loss_fake= 0.034, g_loss 3.441, d_loss 0.056\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 14/390 d_loss_real= 0.000, d_loss_fake= 0.031, g_loss 3.473, d_loss 0.016\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 15/390 d_loss_real= 0.064, d_loss_fake= 0.035, g_loss 3.431, d_loss 0.050\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 39 Batch 16/390 d_loss_real= 0.054, d_loss_fake= 0.035, g_loss 3.567, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 17/390 d_loss_real= 0.080, d_loss_fake= 0.031, g_loss 3.610, d_loss 0.056\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 18/390 d_loss_real= 0.092, d_loss_fake= 0.033, g_loss 3.530, d_loss 0.062\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 19/390 d_loss_real= 0.083, d_loss_fake= 0.033, g_loss 3.546, d_loss 0.058\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 39 Batch 20/390 d_loss_real= 0.222, d_loss_fake= 0.031, g_loss 3.515, d_loss 0.126\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 21/390 d_loss_real= 0.051, d_loss_fake= 0.032, g_loss 3.583, d_loss 0.041\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 39 Batch 22/390 d_loss_real= 0.078, d_loss_fake= 0.035, g_loss 3.412, d_loss 0.056\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 39 Batch 23/390 d_loss_real= 0.121, d_loss_fake= 0.046, g_loss 3.273, d_loss 0.083\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 39 Batch 24/390 d_loss_real= 0.000, d_loss_fake= 0.034, g_loss 3.554, d_loss 0.017\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 39 Batch 25/390 d_loss_real= 0.018, d_loss_fake= 0.038, g_loss 3.513, d_loss 0.028\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 39 Batch 26/390 d_loss_real= 0.058, d_loss_fake= 0.027, g_loss 3.844, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 27/390 d_loss_real= 0.152, d_loss_fake= 0.027, g_loss 3.781, d_loss 0.090\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 39 Batch 28/390 d_loss_real= 0.122, d_loss_fake= 0.024, g_loss 3.925, d_loss 0.073\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 29/390 d_loss_real= 0.002, d_loss_fake= 0.021, g_loss 4.009, d_loss 0.011\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 30/390 d_loss_real= 0.208, d_loss_fake= 0.022, g_loss 3.845, d_loss 0.115\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 39 Batch 31/390 d_loss_real= 0.212, d_loss_fake= 0.022, g_loss 3.786, d_loss 0.117\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 32/390 d_loss_real= 0.035, d_loss_fake= 0.026, g_loss 3.778, d_loss 0.031\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 33/390 d_loss_real= 0.204, d_loss_fake= 0.033, g_loss 3.513, d_loss 0.119\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 34/390 d_loss_real= 0.031, d_loss_fake= 0.024, g_loss 3.742, d_loss 0.028\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 39 Batch 35/390 d_loss_real= 0.139, d_loss_fake= 0.086, g_loss 3.342, d_loss 0.113\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 36/390 d_loss_real= 0.085, d_loss_fake= 0.033, g_loss 3.703, d_loss 0.059\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 37/390 d_loss_real= 0.083, d_loss_fake= 0.020, g_loss 4.035, d_loss 0.052\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 38/390 d_loss_real= 0.223, d_loss_fake= 0.022, g_loss 3.944, d_loss 0.123\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 39 Batch 39/390 d_loss_real= 0.101, d_loss_fake= 0.030, g_loss 3.727, d_loss 0.065\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 39 Batch 40/390 d_loss_real= 0.187, d_loss_fake= 0.033, g_loss 3.605, d_loss 0.110\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 41/390 d_loss_real= 0.209, d_loss_fake= 0.038, g_loss 3.493, d_loss 0.123\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 42/390 d_loss_real= 0.184, d_loss_fake= 0.041, g_loss 3.400, d_loss 0.112\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 43/390 d_loss_real= 0.114, d_loss_fake= 0.046, g_loss 3.345, d_loss 0.080\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 39 Batch 44/390 d_loss_real= 0.108, d_loss_fake= 0.050, g_loss 3.309, d_loss 0.079\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 45/390 d_loss_real= 0.084, d_loss_fake= 0.038, g_loss 3.372, d_loss 0.061\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 39 Batch 46/390 d_loss_real= 0.087, d_loss_fake= 0.035, g_loss 3.445, d_loss 0.061\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 39 Batch 47/390 d_loss_real= 0.065, d_loss_fake= 0.041, g_loss 3.336, d_loss 0.053\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 48/390 d_loss_real= 0.113, d_loss_fake= 0.038, g_loss 3.344, d_loss 0.075\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 49/390 d_loss_real= 0.244, d_loss_fake= 0.047, g_loss 3.128, d_loss 0.145\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 39 Batch 50/390 d_loss_real= 0.048, d_loss_fake= 0.059, g_loss 3.028, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 51/390 d_loss_real= 0.047, d_loss_fake= 0.047, g_loss 3.207, d_loss 0.047\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 39 Batch 52/390 d_loss_real= 0.039, d_loss_fake= 0.043, g_loss 3.399, d_loss 0.041\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 53/390 d_loss_real= 0.087, d_loss_fake= 0.040, g_loss 3.352, d_loss 0.063\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 54/390 d_loss_real= 0.091, d_loss_fake= 0.042, g_loss 3.315, d_loss 0.067\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 39 Batch 55/390 d_loss_real= 0.199, d_loss_fake= 0.045, g_loss 3.218, d_loss 0.122\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 39 Batch 56/390 d_loss_real= 0.056, d_loss_fake= 0.051, g_loss 3.181, d_loss 0.053\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 39 Batch 57/390 d_loss_real= 0.071, d_loss_fake= 0.051, g_loss 3.133, d_loss 0.061\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 39 Batch 58/390 d_loss_real= 0.081, d_loss_fake= 0.054, g_loss 3.117, d_loss 0.067\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 39 Batch 59/390 d_loss_real= 0.051, d_loss_fake= 0.046, g_loss 3.244, d_loss 0.049\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 39 Batch 60/390 d_loss_real= 0.056, d_loss_fake= 0.041, g_loss 3.428, d_loss 0.049\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 39 Batch 61/390 d_loss_real= 0.000, d_loss_fake= 0.038, g_loss 3.534, d_loss 0.019\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 62/390 d_loss_real= 0.061, d_loss_fake= 0.031, g_loss 3.654, d_loss 0.046\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 63/390 d_loss_real= 0.050, d_loss_fake= 0.032, g_loss 3.735, d_loss 0.041\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 39 Batch 64/390 d_loss_real= 0.178, d_loss_fake= 0.028, g_loss 3.687, d_loss 0.103\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 65/390 d_loss_real= 0.148, d_loss_fake= 0.031, g_loss 3.598, d_loss 0.090\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 39 Batch 66/390 d_loss_real= 0.222, d_loss_fake= 0.036, g_loss 3.453, d_loss 0.129\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 67/390 d_loss_real= 0.203, d_loss_fake= 0.046, g_loss 3.362, d_loss 0.124\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 68/390 d_loss_real= 0.063, d_loss_fake= 0.094, g_loss 3.169, d_loss 0.078\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 69/390 d_loss_real= 0.001, d_loss_fake= 0.033, g_loss 3.723, d_loss 0.017\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 70/390 d_loss_real= 0.063, d_loss_fake= 0.027, g_loss 3.778, d_loss 0.045\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 39 Batch 71/390 d_loss_real= 0.103, d_loss_fake= 0.025, g_loss 3.840, d_loss 0.064\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 39 Batch 72/390 d_loss_real= 0.059, d_loss_fake= 0.028, g_loss 3.774, d_loss 0.043\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 73/390 d_loss_real= 0.090, d_loss_fake= 0.029, g_loss 3.591, d_loss 0.060\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 39 Batch 74/390 d_loss_real= 0.133, d_loss_fake= 0.033, g_loss 3.458, d_loss 0.083\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 39 Batch 75/390 d_loss_real= 0.277, d_loss_fake= 0.035, g_loss 3.438, d_loss 0.156\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 39 Batch 76/390 d_loss_real= 0.038, d_loss_fake= 0.048, g_loss 3.192, d_loss 0.043\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 77/390 d_loss_real= 0.307, d_loss_fake= 0.052, g_loss 3.220, d_loss 0.180\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 78/390 d_loss_real= 0.105, d_loss_fake= 0.043, g_loss 3.367, d_loss 0.074\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 79/390 d_loss_real= 0.000, d_loss_fake= 0.035, g_loss 3.553, d_loss 0.018\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 80/390 d_loss_real= 0.117, d_loss_fake= 0.030, g_loss 3.634, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 81/390 d_loss_real= 0.090, d_loss_fake= 0.027, g_loss 3.772, d_loss 0.058\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 39 Batch 82/390 d_loss_real= 0.279, d_loss_fake= 0.030, g_loss 3.595, d_loss 0.154\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 39 Batch 83/390 d_loss_real= 0.174, d_loss_fake= 0.034, g_loss 3.436, d_loss 0.104\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 84/390 d_loss_real= 0.111, d_loss_fake= 0.043, g_loss 3.267, d_loss 0.077\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 85/390 d_loss_real= 0.132, d_loss_fake= 0.049, g_loss 3.145, d_loss 0.091\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 39 Batch 86/390 d_loss_real= 0.111, d_loss_fake= 0.054, g_loss 3.270, d_loss 0.082\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 39 Batch 87/390 d_loss_real= 0.079, d_loss_fake= 0.038, g_loss 3.461, d_loss 0.058\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 88/390 d_loss_real= 0.049, d_loss_fake= 0.044, g_loss 3.525, d_loss 0.046\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 89/390 d_loss_real= 0.013, d_loss_fake= 0.029, g_loss 3.753, d_loss 0.021\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 39 Batch 90/390 d_loss_real= 0.051, d_loss_fake= 0.024, g_loss 3.857, d_loss 0.038\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 91/390 d_loss_real= 0.102, d_loss_fake= 0.023, g_loss 3.913, d_loss 0.062\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 39 Batch 92/390 d_loss_real= 0.058, d_loss_fake= 0.023, g_loss 3.889, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 93/390 d_loss_real= 0.210, d_loss_fake= 0.024, g_loss 3.772, d_loss 0.117\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 39 Batch 94/390 d_loss_real= 0.250, d_loss_fake= 0.026, g_loss 3.598, d_loss 0.138\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 39 Batch 95/390 d_loss_real= 0.228, d_loss_fake= 0.033, g_loss 3.439, d_loss 0.131\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 96/390 d_loss_real= 0.009, d_loss_fake= 0.037, g_loss 3.329, d_loss 0.023\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 39 Batch 97/390 d_loss_real= 0.075, d_loss_fake= 0.042, g_loss 3.302, d_loss 0.058\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 39 Batch 98/390 d_loss_real= 0.123, d_loss_fake= 0.039, g_loss 3.290, d_loss 0.081\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 39 Batch 99/390 d_loss_real= 0.006, d_loss_fake= 0.038, g_loss 3.386, d_loss 0.022\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 100/390 d_loss_real= 0.001, d_loss_fake= 0.034, g_loss 3.536, d_loss 0.017\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 101/390 d_loss_real= 0.115, d_loss_fake= 0.030, g_loss 3.607, d_loss 0.072\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 102/390 d_loss_real= 0.073, d_loss_fake= 0.027, g_loss 3.736, d_loss 0.050\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 103/390 d_loss_real= 0.003, d_loss_fake= 0.025, g_loss 3.762, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 104/390 d_loss_real= 0.213, d_loss_fake= 0.026, g_loss 3.728, d_loss 0.119\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 39 Batch 105/390 d_loss_real= 0.000, d_loss_fake= 0.025, g_loss 3.752, d_loss 0.013\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 39 Batch 106/390 d_loss_real= 0.059, d_loss_fake= 0.026, g_loss 3.747, d_loss 0.043\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 39 Batch 107/390 d_loss_real= 0.057, d_loss_fake= 0.025, g_loss 3.750, d_loss 0.041\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 108/390 d_loss_real= 0.125, d_loss_fake= 0.026, g_loss 3.720, d_loss 0.075\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 39 Batch 109/390 d_loss_real= 0.036, d_loss_fake= 0.029, g_loss 3.557, d_loss 0.033\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 110/390 d_loss_real= 0.091, d_loss_fake= 0.035, g_loss 3.352, d_loss 0.063\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 111/390 d_loss_real= 0.027, d_loss_fake= 0.042, g_loss 3.139, d_loss 0.035\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 39 Batch 112/390 d_loss_real= 0.072, d_loss_fake= 0.061, g_loss 3.057, d_loss 0.067\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 113/390 d_loss_real= 0.029, d_loss_fake= 0.062, g_loss 3.281, d_loss 0.046\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 114/390 d_loss_real= 0.171, d_loss_fake= 0.043, g_loss 3.477, d_loss 0.107\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 115/390 d_loss_real= 0.066, d_loss_fake= 0.029, g_loss 3.801, d_loss 0.047\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 39 Batch 116/390 d_loss_real= 0.079, d_loss_fake= 0.023, g_loss 3.880, d_loss 0.051\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 117/390 d_loss_real= 0.121, d_loss_fake= 0.021, g_loss 3.917, d_loss 0.071\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 39 Batch 118/390 d_loss_real= 0.079, d_loss_fake= 0.021, g_loss 3.930, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 119/390 d_loss_real= 0.178, d_loss_fake= 0.021, g_loss 3.861, d_loss 0.099\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 39 Batch 120/390 d_loss_real= 0.156, d_loss_fake= 0.024, g_loss 3.725, d_loss 0.090\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 121/390 d_loss_real= 0.289, d_loss_fake= 0.029, g_loss 3.525, d_loss 0.159\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 39 Batch 122/390 d_loss_real= 0.125, d_loss_fake= 0.034, g_loss 3.387, d_loss 0.080\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 123/390 d_loss_real= 0.162, d_loss_fake= 0.040, g_loss 3.221, d_loss 0.101\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 39 Batch 124/390 d_loss_real= 0.091, d_loss_fake= 0.051, g_loss 3.114, d_loss 0.071\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 125/390 d_loss_real= 0.090, d_loss_fake= 0.051, g_loss 3.227, d_loss 0.070\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 39 Batch 126/390 d_loss_real= 0.029, d_loss_fake= 0.057, g_loss 3.321, d_loss 0.043\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 39 Batch 127/390 d_loss_real= 0.188, d_loss_fake= 0.040, g_loss 3.371, d_loss 0.114\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 39 Batch 128/390 d_loss_real= 0.255, d_loss_fake= 0.038, g_loss 3.341, d_loss 0.147\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 39 Batch 129/390 d_loss_real= 0.082, d_loss_fake= 0.043, g_loss 3.277, d_loss 0.062\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 39 Batch 130/390 d_loss_real= 0.144, d_loss_fake= 0.045, g_loss 3.286, d_loss 0.095\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 131/390 d_loss_real= 0.010, d_loss_fake= 0.041, g_loss 3.368, d_loss 0.025\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 39 Batch 132/390 d_loss_real= 0.185, d_loss_fake= 0.037, g_loss 3.424, d_loss 0.111\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 39 Batch 133/390 d_loss_real= 0.127, d_loss_fake= 0.036, g_loss 3.432, d_loss 0.082\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 134/390 d_loss_real= 0.128, d_loss_fake= 0.036, g_loss 3.429, d_loss 0.082\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 135/390 d_loss_real= 0.121, d_loss_fake= 0.038, g_loss 3.317, d_loss 0.080\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 136/390 d_loss_real= 0.035, d_loss_fake= 0.044, g_loss 3.229, d_loss 0.039\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 39 Batch 137/390 d_loss_real= 0.001, d_loss_fake= 0.042, g_loss 3.280, d_loss 0.022\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 39 Batch 138/390 d_loss_real= 0.005, d_loss_fake= 0.041, g_loss 3.395, d_loss 0.023\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 39 Batch 139/390 d_loss_real= 0.122, d_loss_fake= 0.034, g_loss 3.542, d_loss 0.078\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 140/390 d_loss_real= 0.122, d_loss_fake= 0.029, g_loss 3.642, d_loss 0.076\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 141/390 d_loss_real= 0.122, d_loss_fake= 0.028, g_loss 3.674, d_loss 0.075\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 39 Batch 142/390 d_loss_real= 0.117, d_loss_fake= 0.027, g_loss 3.732, d_loss 0.072\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 39 Batch 143/390 d_loss_real= 0.148, d_loss_fake= 0.026, g_loss 3.672, d_loss 0.087\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 144/390 d_loss_real= 0.072, d_loss_fake= 0.029, g_loss 3.558, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 145/390 d_loss_real= 0.107, d_loss_fake= 0.032, g_loss 3.479, d_loss 0.069\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 39 Batch 146/390 d_loss_real= 0.061, d_loss_fake= 0.035, g_loss 3.390, d_loss 0.048\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 39 Batch 147/390 d_loss_real= 0.139, d_loss_fake= 0.040, g_loss 3.298, d_loss 0.090\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 148/390 d_loss_real= 0.083, d_loss_fake= 0.045, g_loss 3.184, d_loss 0.064\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 149/390 d_loss_real= 0.102, d_loss_fake= 0.049, g_loss 3.175, d_loss 0.076\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 39 Batch 150/390 d_loss_real= 0.058, d_loss_fake= 0.048, g_loss 3.279, d_loss 0.053\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 39 Batch 151/390 d_loss_real= 0.043, d_loss_fake= 0.039, g_loss 3.456, d_loss 0.041\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 152/390 d_loss_real= 0.109, d_loss_fake= 0.036, g_loss 3.555, d_loss 0.072\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 39 Batch 153/390 d_loss_real= 0.119, d_loss_fake= 0.029, g_loss 3.670, d_loss 0.074\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 39 Batch 154/390 d_loss_real= 0.100, d_loss_fake= 0.026, g_loss 3.727, d_loss 0.063\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 39 Batch 155/390 d_loss_real= 0.073, d_loss_fake= 0.025, g_loss 3.799, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 156/390 d_loss_real= 0.194, d_loss_fake= 0.024, g_loss 3.770, d_loss 0.109\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 39 Batch 157/390 d_loss_real= 0.220, d_loss_fake= 0.025, g_loss 3.728, d_loss 0.122\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 158/390 d_loss_real= 0.097, d_loss_fake= 0.029, g_loss 3.566, d_loss 0.063\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 39 Batch 159/390 d_loss_real= 0.115, d_loss_fake= 0.034, g_loss 3.395, d_loss 0.074\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 160/390 d_loss_real= 0.059, d_loss_fake= 0.043, g_loss 3.227, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 161/390 d_loss_real= 0.175, d_loss_fake= 0.048, g_loss 3.098, d_loss 0.112\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 39 Batch 162/390 d_loss_real= 0.080, d_loss_fake= 0.079, g_loss 2.943, d_loss 0.079\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 39 Batch 163/390 d_loss_real= 0.217, d_loss_fake= 0.077, g_loss 2.940, d_loss 0.147\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 39 Batch 164/390 d_loss_real= 0.113, d_loss_fake= 0.042, g_loss 3.477, d_loss 0.077\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 165/390 d_loss_real= 0.116, d_loss_fake= 0.038, g_loss 3.533, d_loss 0.077\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 166/390 d_loss_real= 0.061, d_loss_fake= 0.031, g_loss 3.761, d_loss 0.046\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 39 Batch 167/390 d_loss_real= 0.014, d_loss_fake= 0.025, g_loss 3.837, d_loss 0.020\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 168/390 d_loss_real= 0.053, d_loss_fake= 0.022, g_loss 3.889, d_loss 0.038\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 169/390 d_loss_real= 0.133, d_loss_fake= 0.021, g_loss 3.952, d_loss 0.077\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 39 Batch 170/390 d_loss_real= 0.079, d_loss_fake= 0.022, g_loss 3.918, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 171/390 d_loss_real= 0.127, d_loss_fake= 0.022, g_loss 3.816, d_loss 0.074\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 172/390 d_loss_real= 0.106, d_loss_fake= 0.026, g_loss 3.679, d_loss 0.066\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 39 Batch 173/390 d_loss_real= 0.131, d_loss_fake= 0.033, g_loss 3.372, d_loss 0.082\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 39 Batch 174/390 d_loss_real= 0.083, d_loss_fake= 0.046, g_loss 3.194, d_loss 0.065\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 39 Batch 175/390 d_loss_real= 0.084, d_loss_fake= 0.057, g_loss 3.207, d_loss 0.070\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 176/390 d_loss_real= 0.061, d_loss_fake= 0.053, g_loss 3.345, d_loss 0.057\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 39 Batch 177/390 d_loss_real= 0.105, d_loss_fake= 0.042, g_loss 3.602, d_loss 0.074\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 39 Batch 178/390 d_loss_real= 0.098, d_loss_fake= 0.026, g_loss 3.903, d_loss 0.062\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 179/390 d_loss_real= 0.067, d_loss_fake= 0.023, g_loss 3.981, d_loss 0.045\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 39 Batch 180/390 d_loss_real= 0.002, d_loss_fake= 0.020, g_loss 4.170, d_loss 0.011\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 39 Batch 181/390 d_loss_real= 0.184, d_loss_fake= 0.018, g_loss 4.112, d_loss 0.101\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 182/390 d_loss_real= 0.186, d_loss_fake= 0.020, g_loss 4.122, d_loss 0.103\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 39 Batch 183/390 d_loss_real= 0.152, d_loss_fake= 0.022, g_loss 3.965, d_loss 0.087\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 39 Batch 184/390 d_loss_real= 0.203, d_loss_fake= 0.025, g_loss 3.737, d_loss 0.114\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 185/390 d_loss_real= 0.013, d_loss_fake= 0.035, g_loss 3.613, d_loss 0.024\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 39 Batch 186/390 d_loss_real= 0.039, d_loss_fake= 0.041, g_loss 3.531, d_loss 0.040\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 39 Batch 187/390 d_loss_real= 0.168, d_loss_fake= 0.033, g_loss 3.585, d_loss 0.100\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 188/390 d_loss_real= 0.028, d_loss_fake= 0.034, g_loss 3.635, d_loss 0.031\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 189/390 d_loss_real= 0.000, d_loss_fake= 0.031, g_loss 3.691, d_loss 0.016\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 39 Batch 190/390 d_loss_real= 0.120, d_loss_fake= 0.029, g_loss 3.793, d_loss 0.074\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 191/390 d_loss_real= 0.126, d_loss_fake= 0.025, g_loss 3.741, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 192/390 d_loss_real= 0.188, d_loss_fake= 0.023, g_loss 3.807, d_loss 0.106\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 193/390 d_loss_real= 0.175, d_loss_fake= 0.024, g_loss 3.745, d_loss 0.100\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 39 Batch 194/390 d_loss_real= 0.194, d_loss_fake= 0.030, g_loss 3.655, d_loss 0.112\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 195/390 d_loss_real= 0.055, d_loss_fake= 0.032, g_loss 3.612, d_loss 0.044\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 196/390 d_loss_real= 0.167, d_loss_fake= 0.037, g_loss 3.397, d_loss 0.102\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 39 Batch 197/390 d_loss_real= 0.114, d_loss_fake= 0.039, g_loss 3.333, d_loss 0.077\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 198/390 d_loss_real= 0.160, d_loss_fake= 0.042, g_loss 3.294, d_loss 0.101\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 39 Batch 199/390 d_loss_real= 0.063, d_loss_fake= 0.040, g_loss 3.401, d_loss 0.051\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 39 Batch 200/390 d_loss_real= 0.186, d_loss_fake= 0.043, g_loss 3.271, d_loss 0.115\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 201/390 d_loss_real= 0.023, d_loss_fake= 0.042, g_loss 3.368, d_loss 0.033\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 39 Batch 202/390 d_loss_real= 0.054, d_loss_fake= 0.031, g_loss 3.644, d_loss 0.042\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 203/390 d_loss_real= 0.080, d_loss_fake= 0.029, g_loss 3.646, d_loss 0.054\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 39 Batch 204/390 d_loss_real= 0.002, d_loss_fake= 0.027, g_loss 3.700, d_loss 0.015\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 39 Batch 205/390 d_loss_real= 0.214, d_loss_fake= 0.027, g_loss 3.653, d_loss 0.120\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 39 Batch 206/390 d_loss_real= 0.099, d_loss_fake= 0.035, g_loss 3.477, d_loss 0.067\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 207/390 d_loss_real= 0.110, d_loss_fake= 0.061, g_loss 3.224, d_loss 0.086\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 208/390 d_loss_real= 0.056, d_loss_fake= 0.052, g_loss 3.586, d_loss 0.054\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 39 Batch 209/390 d_loss_real= 0.140, d_loss_fake= 0.039, g_loss 3.669, d_loss 0.089\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 39 Batch 210/390 d_loss_real= 0.043, d_loss_fake= 0.030, g_loss 3.882, d_loss 0.036\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 39 Batch 211/390 d_loss_real= 0.184, d_loss_fake= 0.025, g_loss 4.100, d_loss 0.105\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 39 Batch 212/390 d_loss_real= 0.078, d_loss_fake= 0.021, g_loss 4.167, d_loss 0.049\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 213/390 d_loss_real= 0.233, d_loss_fake= 0.018, g_loss 4.209, d_loss 0.125\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 39 Batch 214/390 d_loss_real= 0.199, d_loss_fake= 0.018, g_loss 4.109, d_loss 0.108\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 39 Batch 215/390 d_loss_real= 0.092, d_loss_fake= 0.019, g_loss 4.047, d_loss 0.056\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 216/390 d_loss_real= 0.290, d_loss_fake= 0.024, g_loss 3.703, d_loss 0.157\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 217/390 d_loss_real= 0.072, d_loss_fake= 0.032, g_loss 3.418, d_loss 0.052\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 218/390 d_loss_real= 0.128, d_loss_fake= 0.034, g_loss 3.404, d_loss 0.081\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 219/390 d_loss_real= 0.311, d_loss_fake= 0.084, g_loss 2.823, d_loss 0.198\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 220/390 d_loss_real= 0.089, d_loss_fake= 0.076, g_loss 3.255, d_loss 0.083\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 221/390 d_loss_real= 0.042, d_loss_fake= 0.024, g_loss 4.144, d_loss 0.033\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 39 Batch 222/390 d_loss_real= 0.002, d_loss_fake= 0.018, g_loss 4.195, d_loss 0.010\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 39 Batch 223/390 d_loss_real= 0.002, d_loss_fake= 0.017, g_loss 4.200, d_loss 0.009\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 224/390 d_loss_real= 0.137, d_loss_fake= 0.017, g_loss 4.162, d_loss 0.077\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 39 Batch 225/390 d_loss_real= 0.000, d_loss_fake= 0.017, g_loss 4.083, d_loss 0.009\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 39 Batch 226/390 d_loss_real= 0.178, d_loss_fake= 0.018, g_loss 4.020, d_loss 0.098\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 227/390 d_loss_real= 0.082, d_loss_fake= 0.022, g_loss 3.940, d_loss 0.052\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 228/390 d_loss_real= 0.167, d_loss_fake= 0.024, g_loss 3.810, d_loss 0.095\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 39 Batch 229/390 d_loss_real= 0.110, d_loss_fake= 0.026, g_loss 3.714, d_loss 0.068\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 39 Batch 230/390 d_loss_real= 0.046, d_loss_fake= 0.029, g_loss 3.574, d_loss 0.037\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 39 Batch 231/390 d_loss_real= 0.124, d_loss_fake= 0.034, g_loss 3.413, d_loss 0.079\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 232/390 d_loss_real= 0.043, d_loss_fake= 0.040, g_loss 3.213, d_loss 0.041\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 233/390 d_loss_real= 0.068, d_loss_fake= 0.082, g_loss 3.047, d_loss 0.075\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 39 Batch 234/390 d_loss_real= 0.243, d_loss_fake= 0.138, g_loss 3.257, d_loss 0.191\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 39 Batch 235/390 d_loss_real= 0.142, d_loss_fake= 0.039, g_loss 3.611, d_loss 0.091\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 236/390 d_loss_real= 0.044, d_loss_fake= 0.028, g_loss 3.763, d_loss 0.036\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 39 Batch 237/390 d_loss_real= 0.128, d_loss_fake= 0.027, g_loss 3.825, d_loss 0.077\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 238/390 d_loss_real= 0.149, d_loss_fake= 0.024, g_loss 3.820, d_loss 0.086\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 239/390 d_loss_real= 0.213, d_loss_fake= 0.028, g_loss 3.762, d_loss 0.121\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 240/390 d_loss_real= 0.269, d_loss_fake= 0.030, g_loss 3.617, d_loss 0.150\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 39 Batch 241/390 d_loss_real= 0.075, d_loss_fake= 0.033, g_loss 3.462, d_loss 0.054\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 242/390 d_loss_real= 0.103, d_loss_fake= 0.041, g_loss 3.315, d_loss 0.072\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 39 Batch 243/390 d_loss_real= 0.136, d_loss_fake= 0.051, g_loss 3.063, d_loss 0.094\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 244/390 d_loss_real= 0.153, d_loss_fake= 0.059, g_loss 2.928, d_loss 0.106\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 245/390 d_loss_real= 0.042, d_loss_fake= 0.072, g_loss 2.829, d_loss 0.057\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 39 Batch 246/390 d_loss_real= 0.094, d_loss_fake= 0.085, g_loss 2.781, d_loss 0.089\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 247/390 d_loss_real= 0.070, d_loss_fake= 0.074, g_loss 2.896, d_loss 0.072\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 248/390 d_loss_real= 0.051, d_loss_fake= 0.071, g_loss 3.141, d_loss 0.061\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 249/390 d_loss_real= 0.143, d_loss_fake= 0.051, g_loss 3.280, d_loss 0.097\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 39 Batch 250/390 d_loss_real= 0.118, d_loss_fake= 0.045, g_loss 3.397, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 251/390 d_loss_real= 0.151, d_loss_fake= 0.038, g_loss 3.490, d_loss 0.094\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 252/390 d_loss_real= 0.001, d_loss_fake= 0.037, g_loss 3.548, d_loss 0.019\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 253/390 d_loss_real= 0.126, d_loss_fake= 0.032, g_loss 3.606, d_loss 0.079\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 254/390 d_loss_real= 0.150, d_loss_fake= 0.031, g_loss 3.636, d_loss 0.090\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 255/390 d_loss_real= 0.089, d_loss_fake= 0.034, g_loss 3.623, d_loss 0.061\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 39 Batch 256/390 d_loss_real= 0.086, d_loss_fake= 0.035, g_loss 3.643, d_loss 0.061\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 39 Batch 257/390 d_loss_real= 0.215, d_loss_fake= 0.031, g_loss 3.565, d_loss 0.123\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 258/390 d_loss_real= 0.173, d_loss_fake= 0.046, g_loss 3.569, d_loss 0.110\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 39 Batch 259/390 d_loss_real= 0.266, d_loss_fake= 0.050, g_loss 3.638, d_loss 0.158\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 260/390 d_loss_real= 0.074, d_loss_fake= 0.029, g_loss 3.896, d_loss 0.051\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 261/390 d_loss_real= 0.092, d_loss_fake= 0.031, g_loss 3.969, d_loss 0.061\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 262/390 d_loss_real= 0.150, d_loss_fake= 0.024, g_loss 3.913, d_loss 0.087\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 39 Batch 263/390 d_loss_real= 0.144, d_loss_fake= 0.026, g_loss 3.855, d_loss 0.085\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 39 Batch 264/390 d_loss_real= 0.070, d_loss_fake= 0.032, g_loss 3.870, d_loss 0.051\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 39 Batch 265/390 d_loss_real= 0.052, d_loss_fake= 0.030, g_loss 3.974, d_loss 0.041\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 266/390 d_loss_real= 0.141, d_loss_fake= 0.019, g_loss 4.096, d_loss 0.080\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 39 Batch 267/390 d_loss_real= 0.059, d_loss_fake= 0.021, g_loss 3.982, d_loss 0.040\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 268/390 d_loss_real= 0.247, d_loss_fake= 0.028, g_loss 3.857, d_loss 0.137\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 269/390 d_loss_real= 0.101, d_loss_fake= 0.039, g_loss 3.661, d_loss 0.070\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 39 Batch 270/390 d_loss_real= 0.165, d_loss_fake= 0.031, g_loss 3.717, d_loss 0.098\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 271/390 d_loss_real= 0.093, d_loss_fake= 0.038, g_loss 3.581, d_loss 0.066\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 39 Batch 272/390 d_loss_real= 0.000, d_loss_fake= 0.037, g_loss 3.838, d_loss 0.018\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 273/390 d_loss_real= 0.081, d_loss_fake= 0.022, g_loss 4.073, d_loss 0.052\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 39 Batch 274/390 d_loss_real= 0.052, d_loss_fake= 0.018, g_loss 4.159, d_loss 0.035\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 39 Batch 275/390 d_loss_real= 0.002, d_loss_fake= 0.015, g_loss 4.309, d_loss 0.009\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 39 Batch 276/390 d_loss_real= 0.117, d_loss_fake= 0.015, g_loss 4.270, d_loss 0.066\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 39 Batch 277/390 d_loss_real= 0.303, d_loss_fake= 0.016, g_loss 4.124, d_loss 0.160\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 278/390 d_loss_real= 0.105, d_loss_fake= 0.020, g_loss 3.921, d_loss 0.063\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 279/390 d_loss_real= 0.181, d_loss_fake= 0.024, g_loss 3.722, d_loss 0.103\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 39 Batch 280/390 d_loss_real= 0.005, d_loss_fake= 0.034, g_loss 3.608, d_loss 0.020\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 39 Batch 281/390 d_loss_real= 0.001, d_loss_fake= 0.037, g_loss 3.665, d_loss 0.019\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 39 Batch 282/390 d_loss_real= 0.003, d_loss_fake= 0.029, g_loss 3.798, d_loss 0.016\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 283/390 d_loss_real= 0.090, d_loss_fake= 0.023, g_loss 3.952, d_loss 0.056\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 284/390 d_loss_real= 0.001, d_loss_fake= 0.026, g_loss 3.941, d_loss 0.014\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 285/390 d_loss_real= 0.155, d_loss_fake= 0.023, g_loss 3.955, d_loss 0.089\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 39 Batch 286/390 d_loss_real= 0.290, d_loss_fake= 0.027, g_loss 3.674, d_loss 0.159\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 39 Batch 287/390 d_loss_real= 0.082, d_loss_fake= 0.032, g_loss 3.319, d_loss 0.057\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 288/390 d_loss_real= 0.074, d_loss_fake= 0.055, g_loss 3.133, d_loss 0.065\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 39 Batch 289/390 d_loss_real= 0.066, d_loss_fake= 0.050, g_loss 3.225, d_loss 0.058\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 290/390 d_loss_real= 0.075, d_loss_fake= 0.049, g_loss 3.316, d_loss 0.062\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 291/390 d_loss_real= 0.139, d_loss_fake= 0.038, g_loss 3.631, d_loss 0.088\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 292/390 d_loss_real= 0.075, d_loss_fake= 0.031, g_loss 3.821, d_loss 0.053\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 293/390 d_loss_real= 0.136, d_loss_fake= 0.022, g_loss 3.990, d_loss 0.079\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 294/390 d_loss_real= 0.166, d_loss_fake= 0.021, g_loss 3.948, d_loss 0.093\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 295/390 d_loss_real= 0.078, d_loss_fake= 0.022, g_loss 3.926, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 296/390 d_loss_real= 0.154, d_loss_fake= 0.025, g_loss 3.654, d_loss 0.089\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 297/390 d_loss_real= 0.038, d_loss_fake= 0.046, g_loss 3.386, d_loss 0.042\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 298/390 d_loss_real= 0.128, d_loss_fake= 0.039, g_loss 3.501, d_loss 0.084\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 299/390 d_loss_real= 0.000, d_loss_fake= 0.074, g_loss 3.481, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 300/390 d_loss_real= 0.001, d_loss_fake= 0.041, g_loss 3.837, d_loss 0.021\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 301/390 d_loss_real= 0.053, d_loss_fake= 0.023, g_loss 4.083, d_loss 0.038\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 302/390 d_loss_real= 0.266, d_loss_fake= 0.019, g_loss 4.181, d_loss 0.142\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 39 Batch 303/390 d_loss_real= 0.200, d_loss_fake= 0.018, g_loss 4.192, d_loss 0.109\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 304/390 d_loss_real= 0.278, d_loss_fake= 0.017, g_loss 4.136, d_loss 0.147\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 305/390 d_loss_real= 0.107, d_loss_fake= 0.017, g_loss 4.093, d_loss 0.062\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 306/390 d_loss_real= 0.082, d_loss_fake= 0.024, g_loss 3.768, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 307/390 d_loss_real= 0.223, d_loss_fake= 0.038, g_loss 3.669, d_loss 0.131\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 308/390 d_loss_real= 0.196, d_loss_fake= 0.038, g_loss 3.431, d_loss 0.117\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 39 Batch 309/390 d_loss_real= 0.002, d_loss_fake= 0.064, g_loss 3.362, d_loss 0.033\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 310/390 d_loss_real= 0.030, d_loss_fake= 0.122, g_loss 3.545, d_loss 0.076\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 311/390 d_loss_real= 0.031, d_loss_fake= 0.026, g_loss 4.017, d_loss 0.028\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 312/390 d_loss_real= 0.026, d_loss_fake= 0.018, g_loss 4.176, d_loss 0.022\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 313/390 d_loss_real= 0.121, d_loss_fake= 0.016, g_loss 4.237, d_loss 0.069\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 39 Batch 314/390 d_loss_real= 0.224, d_loss_fake= 0.017, g_loss 4.159, d_loss 0.120\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 315/390 d_loss_real= 0.034, d_loss_fake= 0.018, g_loss 4.044, d_loss 0.026\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 316/390 d_loss_real= 0.328, d_loss_fake= 0.019, g_loss 3.999, d_loss 0.173\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 317/390 d_loss_real= 0.181, d_loss_fake= 0.020, g_loss 3.943, d_loss 0.100\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 39 Batch 318/390 d_loss_real= 0.116, d_loss_fake= 0.022, g_loss 3.852, d_loss 0.069\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 39 Batch 319/390 d_loss_real= 0.039, d_loss_fake= 0.023, g_loss 3.811, d_loss 0.031\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 39 Batch 320/390 d_loss_real= 0.058, d_loss_fake= 0.024, g_loss 3.723, d_loss 0.041\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 321/390 d_loss_real= 0.069, d_loss_fake= 0.024, g_loss 3.777, d_loss 0.046\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 322/390 d_loss_real= 0.228, d_loss_fake= 0.025, g_loss 3.696, d_loss 0.127\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 39 Batch 323/390 d_loss_real= 0.056, d_loss_fake= 0.028, g_loss 3.617, d_loss 0.042\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 39 Batch 324/390 d_loss_real= 0.018, d_loss_fake= 0.034, g_loss 3.533, d_loss 0.026\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 325/390 d_loss_real= 0.060, d_loss_fake= 0.041, g_loss 3.361, d_loss 0.050\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 39 Batch 326/390 d_loss_real= 0.000, d_loss_fake= 0.039, g_loss 3.293, d_loss 0.020\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 39 Batch 327/390 d_loss_real= 0.106, d_loss_fake= 0.063, g_loss 3.255, d_loss 0.085\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 328/390 d_loss_real= 0.068, d_loss_fake= 0.059, g_loss 3.537, d_loss 0.063\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 329/390 d_loss_real= 0.130, d_loss_fake= 0.034, g_loss 3.757, d_loss 0.082\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 330/390 d_loss_real= 0.151, d_loss_fake= 0.028, g_loss 3.861, d_loss 0.089\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 331/390 d_loss_real= 0.114, d_loss_fake= 0.031, g_loss 3.857, d_loss 0.073\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 332/390 d_loss_real= 0.001, d_loss_fake= 0.023, g_loss 4.068, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 333/390 d_loss_real= 0.098, d_loss_fake= 0.021, g_loss 4.067, d_loss 0.059\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 334/390 d_loss_real= 0.088, d_loss_fake= 0.021, g_loss 3.955, d_loss 0.055\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 39 Batch 335/390 d_loss_real= 0.090, d_loss_fake= 0.025, g_loss 3.907, d_loss 0.058\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 336/390 d_loss_real= 0.200, d_loss_fake= 0.029, g_loss 3.555, d_loss 0.114\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 39 Batch 337/390 d_loss_real= 0.018, d_loss_fake= 0.037, g_loss 3.390, d_loss 0.027\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 39 Batch 338/390 d_loss_real= 0.017, d_loss_fake= 0.058, g_loss 2.954, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 339/390 d_loss_real= 0.088, d_loss_fake= 0.084, g_loss 3.056, d_loss 0.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 340/390 d_loss_real= 0.051, d_loss_fake= 0.063, g_loss 3.359, d_loss 0.057\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 341/390 d_loss_real= 0.168, d_loss_fake= 0.040, g_loss 3.550, d_loss 0.104\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 39 Batch 342/390 d_loss_real= 0.122, d_loss_fake= 0.037, g_loss 3.473, d_loss 0.080\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 39 Batch 343/390 d_loss_real= 0.061, d_loss_fake= 0.037, g_loss 3.562, d_loss 0.049\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 39 Batch 344/390 d_loss_real= 0.117, d_loss_fake= 0.034, g_loss 3.541, d_loss 0.076\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 39 Batch 345/390 d_loss_real= 0.023, d_loss_fake= 0.032, g_loss 3.631, d_loss 0.028\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 346/390 d_loss_real= 0.230, d_loss_fake= 0.029, g_loss 3.674, d_loss 0.129\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 347/390 d_loss_real= 0.000, d_loss_fake= 0.028, g_loss 3.758, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 348/390 d_loss_real= 0.123, d_loss_fake= 0.031, g_loss 3.687, d_loss 0.077\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 39 Batch 349/390 d_loss_real= 0.170, d_loss_fake= 0.030, g_loss 3.681, d_loss 0.100\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 39 Batch 350/390 d_loss_real= 0.020, d_loss_fake= 0.031, g_loss 3.645, d_loss 0.026\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 351/390 d_loss_real= 0.057, d_loss_fake= 0.030, g_loss 3.618, d_loss 0.044\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 352/390 d_loss_real= 0.051, d_loss_fake= 0.029, g_loss 3.641, d_loss 0.040\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 353/390 d_loss_real= 0.059, d_loss_fake= 0.035, g_loss 3.447, d_loss 0.047\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 354/390 d_loss_real= 0.076, d_loss_fake= 0.033, g_loss 3.500, d_loss 0.055\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 355/390 d_loss_real= 0.106, d_loss_fake= 0.030, g_loss 3.853, d_loss 0.068\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 39 Batch 356/390 d_loss_real= 0.027, d_loss_fake= 0.041, g_loss 3.428, d_loss 0.034\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 39 Batch 357/390 d_loss_real= 0.000, d_loss_fake= 0.027, g_loss 3.824, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 358/390 d_loss_real= 0.187, d_loss_fake= 0.040, g_loss 3.606, d_loss 0.113\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 359/390 d_loss_real= 0.058, d_loss_fake= 0.063, g_loss 3.716, d_loss 0.060\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 360/390 d_loss_real= 0.112, d_loss_fake= 0.027, g_loss 4.212, d_loss 0.070\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 361/390 d_loss_real= 0.156, d_loss_fake= 0.018, g_loss 4.288, d_loss 0.087\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 362/390 d_loss_real= 0.217, d_loss_fake= 0.017, g_loss 4.333, d_loss 0.117\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 363/390 d_loss_real= 0.057, d_loss_fake= 0.018, g_loss 4.333, d_loss 0.038\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 364/390 d_loss_real= 0.043, d_loss_fake= 0.022, g_loss 4.358, d_loss 0.032\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 39 Batch 365/390 d_loss_real= 0.294, d_loss_fake= 0.021, g_loss 4.163, d_loss 0.158\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 39 Batch 366/390 d_loss_real= 0.168, d_loss_fake= 0.025, g_loss 4.018, d_loss 0.097\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 367/390 d_loss_real= 0.075, d_loss_fake= 0.024, g_loss 3.815, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 368/390 d_loss_real= 0.070, d_loss_fake= 0.027, g_loss 3.711, d_loss 0.048\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 39 Batch 369/390 d_loss_real= 0.165, d_loss_fake= 0.032, g_loss 3.632, d_loss 0.099\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 39 Batch 370/390 d_loss_real= 0.177, d_loss_fake= 0.035, g_loss 3.532, d_loss 0.106\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 39 Batch 371/390 d_loss_real= 0.140, d_loss_fake= 0.037, g_loss 3.400, d_loss 0.088\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 372/390 d_loss_real= 0.087, d_loss_fake= 0.050, g_loss 3.335, d_loss 0.068\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 373/390 d_loss_real= 0.152, d_loss_fake= 0.050, g_loss 3.479, d_loss 0.101\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 374/390 d_loss_real= 0.048, d_loss_fake= 0.030, g_loss 3.745, d_loss 0.039\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 375/390 d_loss_real= 0.063, d_loss_fake= 0.024, g_loss 3.806, d_loss 0.044\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 376/390 d_loss_real= 0.403, d_loss_fake= 0.026, g_loss 3.577, d_loss 0.215\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 39 Batch 377/390 d_loss_real= 0.090, d_loss_fake= 0.035, g_loss 3.269, d_loss 0.063\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 39 Batch 378/390 d_loss_real= 0.050, d_loss_fake= 0.061, g_loss 3.227, d_loss 0.056\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 39 Batch 379/390 d_loss_real= 0.135, d_loss_fake= 0.056, g_loss 3.255, d_loss 0.096\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 380/390 d_loss_real= 0.004, d_loss_fake= 0.039, g_loss 3.484, d_loss 0.021\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 39 Batch 381/390 d_loss_real= 0.058, d_loss_fake= 0.030, g_loss 3.706, d_loss 0.044\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39 Batch 382/390 d_loss_real= 0.114, d_loss_fake= 0.025, g_loss 3.794, d_loss 0.070\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 383/390 d_loss_real= 0.144, d_loss_fake= 0.023, g_loss 3.849, d_loss 0.083\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 384/390 d_loss_real= 0.140, d_loss_fake= 0.024, g_loss 3.883, d_loss 0.082\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 385/390 d_loss_real= 0.048, d_loss_fake= 0.024, g_loss 3.841, d_loss 0.036\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 386/390 d_loss_real= 0.076, d_loss_fake= 0.025, g_loss 3.763, d_loss 0.050\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39 Batch 387/390 d_loss_real= 0.352, d_loss_fake= 0.026, g_loss 3.653, d_loss 0.189\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39 Batch 388/390 d_loss_real= 0.152, d_loss_fake= 0.030, g_loss 3.479, d_loss 0.091\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 39 Batch 389/390 d_loss_real= 0.059, d_loss_fake= 0.034, g_loss 3.321, d_loss 0.046\n",
            "2/2 [==============================] - 0s 10ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39 Batch 390/390 d_loss_real= 0.033, d_loss_fake= 0.046, g_loss 3.260, d_loss 0.039\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 1/390 d_loss_real= 0.046, d_loss_fake= 0.056, g_loss 3.050, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 2/390 d_loss_real= 0.131, d_loss_fake= 0.059, g_loss 3.162, d_loss 0.095\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 3/390 d_loss_real= 0.002, d_loss_fake= 0.050, g_loss 3.307, d_loss 0.026\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 40 Batch 4/390 d_loss_real= 0.276, d_loss_fake= 0.046, g_loss 3.443, d_loss 0.161\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 5/390 d_loss_real= 0.103, d_loss_fake= 0.035, g_loss 3.529, d_loss 0.069\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 40 Batch 6/390 d_loss_real= 0.101, d_loss_fake= 0.033, g_loss 3.554, d_loss 0.067\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 7/390 d_loss_real= 0.031, d_loss_fake= 0.031, g_loss 3.542, d_loss 0.031\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 40 Batch 8/390 d_loss_real= 0.008, d_loss_fake= 0.032, g_loss 3.573, d_loss 0.020\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 40 Batch 9/390 d_loss_real= 0.041, d_loss_fake= 0.034, g_loss 3.518, d_loss 0.037\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 10/390 d_loss_real= 0.049, d_loss_fake= 0.035, g_loss 3.495, d_loss 0.042\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 40 Batch 11/390 d_loss_real= 0.057, d_loss_fake= 0.035, g_loss 3.534, d_loss 0.046\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40 Batch 12/390 d_loss_real= 0.110, d_loss_fake= 0.036, g_loss 3.392, d_loss 0.073\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 13/390 d_loss_real= 0.035, d_loss_fake= 0.042, g_loss 3.542, d_loss 0.039\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 14/390 d_loss_real= 0.127, d_loss_fake= 0.033, g_loss 3.684, d_loss 0.080\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 15/390 d_loss_real= 0.018, d_loss_fake= 0.025, g_loss 3.808, d_loss 0.021\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 16/390 d_loss_real= 0.089, d_loss_fake= 0.023, g_loss 3.922, d_loss 0.056\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 17/390 d_loss_real= 0.121, d_loss_fake= 0.025, g_loss 3.720, d_loss 0.073\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 40 Batch 18/390 d_loss_real= 0.009, d_loss_fake= 0.034, g_loss 3.583, d_loss 0.022\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40 Batch 19/390 d_loss_real= 0.046, d_loss_fake= 0.043, g_loss 3.523, d_loss 0.044\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 20/390 d_loss_real= 0.124, d_loss_fake= 0.059, g_loss 3.559, d_loss 0.092\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 40 Batch 21/390 d_loss_real= 0.038, d_loss_fake= 0.035, g_loss 3.881, d_loss 0.037\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 22/390 d_loss_real= 0.036, d_loss_fake= 0.021, g_loss 4.070, d_loss 0.029\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 23/390 d_loss_real= 0.001, d_loss_fake= 0.017, g_loss 4.278, d_loss 0.009\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40 Batch 24/390 d_loss_real= 0.121, d_loss_fake= 0.016, g_loss 4.349, d_loss 0.068\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40 Batch 25/390 d_loss_real= 0.000, d_loss_fake= 0.015, g_loss 4.455, d_loss 0.007\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 40 Batch 26/390 d_loss_real= 0.407, d_loss_fake= 0.014, g_loss 4.332, d_loss 0.211\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 40 Batch 27/390 d_loss_real= 0.352, d_loss_fake= 0.016, g_loss 4.206, d_loss 0.184\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 40 Batch 28/390 d_loss_real= 0.301, d_loss_fake= 0.020, g_loss 3.798, d_loss 0.161\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 29/390 d_loss_real= 0.092, d_loss_fake= 0.038, g_loss 3.368, d_loss 0.065\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 30/390 d_loss_real= 0.033, d_loss_fake= 0.086, g_loss 3.370, d_loss 0.059\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 40 Batch 31/390 d_loss_real= 0.149, d_loss_fake= 0.032, g_loss 3.672, d_loss 0.091\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 40 Batch 32/390 d_loss_real= 0.053, d_loss_fake= 0.028, g_loss 3.785, d_loss 0.041\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 33/390 d_loss_real= 0.167, d_loss_fake= 0.025, g_loss 3.828, d_loss 0.096\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 34/390 d_loss_real= 0.097, d_loss_fake= 0.025, g_loss 3.775, d_loss 0.061\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 35/390 d_loss_real= 0.050, d_loss_fake= 0.026, g_loss 3.735, d_loss 0.038\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 40 Batch 36/390 d_loss_real= 0.186, d_loss_fake= 0.029, g_loss 3.545, d_loss 0.107\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 37/390 d_loss_real= 0.058, d_loss_fake= 0.032, g_loss 3.473, d_loss 0.045\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 40 Batch 38/390 d_loss_real= 0.063, d_loss_fake= 0.038, g_loss 3.368, d_loss 0.050\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 39/390 d_loss_real= 0.212, d_loss_fake= 0.040, g_loss 3.295, d_loss 0.126\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 40 Batch 40/390 d_loss_real= 0.016, d_loss_fake= 0.041, g_loss 3.266, d_loss 0.029\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 41/390 d_loss_real= 0.000, d_loss_fake= 0.038, g_loss 3.499, d_loss 0.019\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40 Batch 42/390 d_loss_real= 0.058, d_loss_fake= 0.044, g_loss 3.331, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 43/390 d_loss_real= 0.028, d_loss_fake= 0.038, g_loss 3.579, d_loss 0.033\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 40 Batch 44/390 d_loss_real= 0.115, d_loss_fake= 0.036, g_loss 3.509, d_loss 0.076\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 45/390 d_loss_real= 0.131, d_loss_fake= 0.042, g_loss 3.414, d_loss 0.087\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 40 Batch 46/390 d_loss_real= 0.207, d_loss_fake= 0.041, g_loss 3.542, d_loss 0.124\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40 Batch 47/390 d_loss_real= 0.152, d_loss_fake= 0.041, g_loss 3.531, d_loss 0.097\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40 Batch 48/390 d_loss_real= 0.047, d_loss_fake= 0.031, g_loss 3.829, d_loss 0.039\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 49/390 d_loss_real= 0.120, d_loss_fake= 0.028, g_loss 3.806, d_loss 0.074\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 50/390 d_loss_real= 0.130, d_loss_fake= 0.021, g_loss 4.036, d_loss 0.075\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 40 Batch 51/390 d_loss_real= 0.273, d_loss_fake= 0.021, g_loss 4.068, d_loss 0.147\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40 Batch 52/390 d_loss_real= 0.126, d_loss_fake= 0.023, g_loss 3.797, d_loss 0.075\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 53/390 d_loss_real= 0.057, d_loss_fake= 0.028, g_loss 3.608, d_loss 0.042\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 40 Batch 54/390 d_loss_real= 0.189, d_loss_fake= 0.042, g_loss 3.518, d_loss 0.115\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 40 Batch 55/390 d_loss_real= 0.080, d_loss_fake= 0.049, g_loss 3.384, d_loss 0.065\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 40 Batch 56/390 d_loss_real= 0.000, d_loss_fake= 0.036, g_loss 3.631, d_loss 0.018\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 40 Batch 57/390 d_loss_real= 0.120, d_loss_fake= 0.029, g_loss 3.689, d_loss 0.075\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 40 Batch 58/390 d_loss_real= 0.171, d_loss_fake= 0.028, g_loss 3.716, d_loss 0.100\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 40 Batch 59/390 d_loss_real= 0.078, d_loss_fake= 0.027, g_loss 3.684, d_loss 0.053\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 40 Batch 60/390 d_loss_real= 0.174, d_loss_fake= 0.027, g_loss 3.694, d_loss 0.100\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 61/390 d_loss_real= 0.080, d_loss_fake= 0.030, g_loss 3.556, d_loss 0.055\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 62/390 d_loss_real= 0.109, d_loss_fake= 0.032, g_loss 3.438, d_loss 0.071\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 40 Batch 63/390 d_loss_real= 0.053, d_loss_fake= 0.033, g_loss 3.531, d_loss 0.043\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 40 Batch 64/390 d_loss_real= 0.067, d_loss_fake= 0.035, g_loss 3.495, d_loss 0.051\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 40 Batch 65/390 d_loss_real= 0.020, d_loss_fake= 0.050, g_loss 3.318, d_loss 0.035\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 40 Batch 66/390 d_loss_real= 0.102, d_loss_fake= 0.039, g_loss 3.457, d_loss 0.071\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 40 Batch 67/390 d_loss_real= 0.037, d_loss_fake= 0.033, g_loss 3.614, d_loss 0.035\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 40 Batch 68/390 d_loss_real= 0.121, d_loss_fake= 0.034, g_loss 3.560, d_loss 0.077\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 69/390 d_loss_real= 0.186, d_loss_fake= 0.029, g_loss 3.639, d_loss 0.107\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 70/390 d_loss_real= 0.151, d_loss_fake= 0.029, g_loss 3.712, d_loss 0.090\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 71/390 d_loss_real= 0.068, d_loss_fake= 0.029, g_loss 3.705, d_loss 0.049\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40 Batch 72/390 d_loss_real= 0.056, d_loss_fake= 0.026, g_loss 3.725, d_loss 0.041\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 40 Batch 73/390 d_loss_real= 0.153, d_loss_fake= 0.029, g_loss 3.772, d_loss 0.091\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 74/390 d_loss_real= 0.181, d_loss_fake= 0.027, g_loss 3.673, d_loss 0.104\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 40 Batch 75/390 d_loss_real= 0.070, d_loss_fake= 0.028, g_loss 3.710, d_loss 0.049\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 40 Batch 76/390 d_loss_real= 0.000, d_loss_fake= 0.028, g_loss 3.701, d_loss 0.014\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 40 Batch 77/390 d_loss_real= 0.114, d_loss_fake= 0.028, g_loss 3.755, d_loss 0.071\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 40 Batch 78/390 d_loss_real= 0.180, d_loss_fake= 0.031, g_loss 3.623, d_loss 0.106\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 79/390 d_loss_real= 0.227, d_loss_fake= 0.034, g_loss 3.500, d_loss 0.131\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 40 Batch 80/390 d_loss_real= 0.148, d_loss_fake= 0.040, g_loss 3.390, d_loss 0.094\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 40 Batch 81/390 d_loss_real= 0.149, d_loss_fake= 0.045, g_loss 3.213, d_loss 0.097\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 40 Batch 82/390 d_loss_real= 0.000, d_loss_fake= 0.052, g_loss 3.081, d_loss 0.026\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 83/390 d_loss_real= 0.001, d_loss_fake= 0.056, g_loss 3.196, d_loss 0.029\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 40 Batch 84/390 d_loss_real= 0.113, d_loss_fake= 0.050, g_loss 3.283, d_loss 0.081\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 40 Batch 85/390 d_loss_real= 0.016, d_loss_fake= 0.046, g_loss 3.413, d_loss 0.031\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 40 Batch 86/390 d_loss_real= 0.097, d_loss_fake= 0.041, g_loss 3.442, d_loss 0.069\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40 Batch 87/390 d_loss_real= 0.086, d_loss_fake= 0.039, g_loss 3.555, d_loss 0.063\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 88/390 d_loss_real= 0.033, d_loss_fake= 0.031, g_loss 3.576, d_loss 0.032\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 40 Batch 89/390 d_loss_real= 0.191, d_loss_fake= 0.033, g_loss 3.566, d_loss 0.112\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 40 Batch 90/390 d_loss_real= 0.337, d_loss_fake= 0.035, g_loss 3.412, d_loss 0.186\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 91/390 d_loss_real= 0.013, d_loss_fake= 0.035, g_loss 3.314, d_loss 0.024\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 92/390 d_loss_real= 0.075, d_loss_fake= 0.043, g_loss 3.232, d_loss 0.059\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 40 Batch 93/390 d_loss_real= 0.056, d_loss_fake= 0.055, g_loss 3.231, d_loss 0.056\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 40 Batch 94/390 d_loss_real= 0.092, d_loss_fake= 0.061, g_loss 3.370, d_loss 0.077\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 95/390 d_loss_real= 0.143, d_loss_fake= 0.036, g_loss 3.609, d_loss 0.089\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 40 Batch 96/390 d_loss_real= 0.083, d_loss_fake= 0.027, g_loss 3.818, d_loss 0.055\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 97/390 d_loss_real= 0.069, d_loss_fake= 0.023, g_loss 3.889, d_loss 0.046\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 40 Batch 98/390 d_loss_real= 0.063, d_loss_fake= 0.022, g_loss 3.933, d_loss 0.042\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 40 Batch 99/390 d_loss_real= 0.052, d_loss_fake= 0.020, g_loss 3.945, d_loss 0.036\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 40 Batch 100/390 d_loss_real= 0.167, d_loss_fake= 0.021, g_loss 3.920, d_loss 0.094\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 101/390 d_loss_real= 0.058, d_loss_fake= 0.021, g_loss 3.863, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 102/390 d_loss_real= 0.173, d_loss_fake= 0.025, g_loss 3.754, d_loss 0.099\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 103/390 d_loss_real= 0.122, d_loss_fake= 0.028, g_loss 3.643, d_loss 0.075\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 40 Batch 104/390 d_loss_real= 0.116, d_loss_fake= 0.036, g_loss 3.378, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 105/390 d_loss_real= 0.100, d_loss_fake= 0.045, g_loss 3.305, d_loss 0.073\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 106/390 d_loss_real= 0.166, d_loss_fake= 0.051, g_loss 3.328, d_loss 0.109\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40 Batch 107/390 d_loss_real= 0.061, d_loss_fake= 0.046, g_loss 3.608, d_loss 0.054\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 40 Batch 108/390 d_loss_real= 0.068, d_loss_fake= 0.027, g_loss 3.913, d_loss 0.047\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 40 Batch 109/390 d_loss_real= 0.088, d_loss_fake= 0.020, g_loss 4.088, d_loss 0.054\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 110/390 d_loss_real= 0.068, d_loss_fake= 0.017, g_loss 4.204, d_loss 0.042\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 40 Batch 111/390 d_loss_real= 0.071, d_loss_fake= 0.016, g_loss 4.234, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 112/390 d_loss_real= 0.055, d_loss_fake= 0.015, g_loss 4.175, d_loss 0.035\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 40 Batch 113/390 d_loss_real= 0.129, d_loss_fake= 0.017, g_loss 4.107, d_loss 0.073\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 114/390 d_loss_real= 0.076, d_loss_fake= 0.017, g_loss 3.969, d_loss 0.047\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 40 Batch 115/390 d_loss_real= 0.246, d_loss_fake= 0.022, g_loss 3.724, d_loss 0.134\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 116/390 d_loss_real= 0.064, d_loss_fake= 0.029, g_loss 3.520, d_loss 0.047\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 117/390 d_loss_real= 0.111, d_loss_fake= 0.036, g_loss 3.442, d_loss 0.074\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 118/390 d_loss_real= 0.178, d_loss_fake= 0.041, g_loss 3.433, d_loss 0.110\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 40 Batch 119/390 d_loss_real= 0.191, d_loss_fake= 0.034, g_loss 3.581, d_loss 0.113\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 40 Batch 120/390 d_loss_real= 0.048, d_loss_fake= 0.029, g_loss 3.665, d_loss 0.039\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 121/390 d_loss_real= 0.001, d_loss_fake= 0.026, g_loss 3.792, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 122/390 d_loss_real= 0.008, d_loss_fake= 0.023, g_loss 3.895, d_loss 0.015\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 40 Batch 123/390 d_loss_real= 0.111, d_loss_fake= 0.021, g_loss 3.895, d_loss 0.066\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 40 Batch 124/390 d_loss_real= 0.216, d_loss_fake= 0.021, g_loss 3.838, d_loss 0.119\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 125/390 d_loss_real= 0.080, d_loss_fake= 0.023, g_loss 3.783, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 126/390 d_loss_real= 0.129, d_loss_fake= 0.026, g_loss 3.720, d_loss 0.077\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 127/390 d_loss_real= 0.129, d_loss_fake= 0.027, g_loss 3.713, d_loss 0.078\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 128/390 d_loss_real= 0.168, d_loss_fake= 0.030, g_loss 3.472, d_loss 0.099\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 40 Batch 129/390 d_loss_real= 0.148, d_loss_fake= 0.043, g_loss 3.229, d_loss 0.096\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 130/390 d_loss_real= 0.000, d_loss_fake= 0.051, g_loss 3.304, d_loss 0.026\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 131/390 d_loss_real= 0.109, d_loss_fake= 0.045, g_loss 3.290, d_loss 0.077\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 132/390 d_loss_real= 0.029, d_loss_fake= 0.039, g_loss 3.454, d_loss 0.034\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 133/390 d_loss_real= 0.210, d_loss_fake= 0.036, g_loss 3.497, d_loss 0.123\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40 Batch 134/390 d_loss_real= 0.009, d_loss_fake= 0.035, g_loss 3.528, d_loss 0.022\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 40 Batch 135/390 d_loss_real= 0.040, d_loss_fake= 0.030, g_loss 3.602, d_loss 0.035\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 136/390 d_loss_real= 0.114, d_loss_fake= 0.035, g_loss 3.425, d_loss 0.074\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 40 Batch 137/390 d_loss_real= 0.115, d_loss_fake= 0.048, g_loss 3.433, d_loss 0.082\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 138/390 d_loss_real= 0.110, d_loss_fake= 0.037, g_loss 3.479, d_loss 0.074\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 139/390 d_loss_real= 0.169, d_loss_fake= 0.037, g_loss 3.574, d_loss 0.103\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 140/390 d_loss_real= 0.005, d_loss_fake= 0.034, g_loss 3.729, d_loss 0.019\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 141/390 d_loss_real= 0.063, d_loss_fake= 0.025, g_loss 3.879, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 142/390 d_loss_real= 0.059, d_loss_fake= 0.021, g_loss 4.005, d_loss 0.040\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 40 Batch 143/390 d_loss_real= 0.065, d_loss_fake= 0.018, g_loss 4.083, d_loss 0.042\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 144/390 d_loss_real= 0.097, d_loss_fake= 0.018, g_loss 4.060, d_loss 0.058\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 40 Batch 145/390 d_loss_real= 0.184, d_loss_fake= 0.019, g_loss 4.003, d_loss 0.102\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 40 Batch 146/390 d_loss_real= 0.064, d_loss_fake= 0.019, g_loss 3.950, d_loss 0.042\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 147/390 d_loss_real= 0.215, d_loss_fake= 0.021, g_loss 3.832, d_loss 0.118\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 40 Batch 148/390 d_loss_real= 0.127, d_loss_fake= 0.023, g_loss 3.757, d_loss 0.075\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 40 Batch 149/390 d_loss_real= 0.295, d_loss_fake= 0.026, g_loss 3.631, d_loss 0.161\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 150/390 d_loss_real= 0.000, d_loss_fake= 0.029, g_loss 3.552, d_loss 0.015\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 151/390 d_loss_real= 0.081, d_loss_fake= 0.032, g_loss 3.442, d_loss 0.057\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 152/390 d_loss_real= 0.042, d_loss_fake= 0.036, g_loss 3.391, d_loss 0.039\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 153/390 d_loss_real= 0.000, d_loss_fake= 0.042, g_loss 3.317, d_loss 0.021\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 40 Batch 154/390 d_loss_real= 0.187, d_loss_fake= 0.044, g_loss 3.313, d_loss 0.116\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 40 Batch 155/390 d_loss_real= 0.115, d_loss_fake= 0.043, g_loss 3.296, d_loss 0.079\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40 Batch 156/390 d_loss_real= 0.000, d_loss_fake= 0.037, g_loss 3.417, d_loss 0.018\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 157/390 d_loss_real= 0.187, d_loss_fake= 0.035, g_loss 3.450, d_loss 0.111\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 158/390 d_loss_real= 0.000, d_loss_fake= 0.035, g_loss 3.536, d_loss 0.018\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40 Batch 159/390 d_loss_real= 0.162, d_loss_fake= 0.033, g_loss 3.511, d_loss 0.098\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 160/390 d_loss_real= 0.128, d_loss_fake= 0.036, g_loss 3.349, d_loss 0.082\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 40 Batch 161/390 d_loss_real= 0.112, d_loss_fake= 0.042, g_loss 3.246, d_loss 0.077\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 162/390 d_loss_real= 0.198, d_loss_fake= 0.047, g_loss 3.219, d_loss 0.123\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 40 Batch 163/390 d_loss_real= 0.341, d_loss_fake= 0.055, g_loss 3.261, d_loss 0.198\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 40 Batch 164/390 d_loss_real= 0.248, d_loss_fake= 0.048, g_loss 3.246, d_loss 0.148\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 40 Batch 165/390 d_loss_real= 0.025, d_loss_fake= 0.067, g_loss 3.258, d_loss 0.046\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 166/390 d_loss_real= 0.046, d_loss_fake= 0.035, g_loss 3.602, d_loss 0.040\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40 Batch 167/390 d_loss_real= 0.089, d_loss_fake= 0.032, g_loss 3.697, d_loss 0.060\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 40 Batch 168/390 d_loss_real= 0.110, d_loss_fake= 0.030, g_loss 3.717, d_loss 0.070\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 169/390 d_loss_real= 0.097, d_loss_fake= 0.028, g_loss 3.779, d_loss 0.063\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 170/390 d_loss_real= 0.059, d_loss_fake= 0.028, g_loss 3.685, d_loss 0.044\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40 Batch 171/390 d_loss_real= 0.000, d_loss_fake= 0.031, g_loss 3.722, d_loss 0.015\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 40 Batch 172/390 d_loss_real= 0.112, d_loss_fake= 0.040, g_loss 3.579, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 173/390 d_loss_real= 0.037, d_loss_fake= 0.056, g_loss 3.577, d_loss 0.046\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 174/390 d_loss_real= 0.140, d_loss_fake= 0.055, g_loss 3.765, d_loss 0.098\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 175/390 d_loss_real= 0.134, d_loss_fake= 0.030, g_loss 4.003, d_loss 0.082\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 40 Batch 176/390 d_loss_real= 0.062, d_loss_fake= 0.022, g_loss 4.334, d_loss 0.042\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 40 Batch 177/390 d_loss_real= 0.260, d_loss_fake= 0.015, g_loss 4.402, d_loss 0.138\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 40 Batch 178/390 d_loss_real= 0.075, d_loss_fake= 0.015, g_loss 4.367, d_loss 0.045\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 179/390 d_loss_real= 0.168, d_loss_fake= 0.021, g_loss 3.996, d_loss 0.095\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 40 Batch 180/390 d_loss_real= 0.005, d_loss_fake= 0.040, g_loss 3.891, d_loss 0.022\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 40 Batch 181/390 d_loss_real= 0.085, d_loss_fake= 0.040, g_loss 4.132, d_loss 0.062\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 182/390 d_loss_real= 0.073, d_loss_fake= 0.018, g_loss 4.406, d_loss 0.045\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 40 Batch 183/390 d_loss_real= 0.216, d_loss_fake= 0.015, g_loss 4.374, d_loss 0.116\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 184/390 d_loss_real= 0.173, d_loss_fake= 0.023, g_loss 4.250, d_loss 0.098\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 40 Batch 185/390 d_loss_real= 0.101, d_loss_fake= 0.032, g_loss 3.940, d_loss 0.067\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 40 Batch 186/390 d_loss_real= 0.040, d_loss_fake= 0.048, g_loss 3.835, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 187/390 d_loss_real= 0.094, d_loss_fake= 0.049, g_loss 3.892, d_loss 0.071\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 40 Batch 188/390 d_loss_real= 0.028, d_loss_fake= 0.035, g_loss 4.048, d_loss 0.031\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 40 Batch 189/390 d_loss_real= 0.060, d_loss_fake= 0.039, g_loss 3.902, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 190/390 d_loss_real= 0.135, d_loss_fake= 0.028, g_loss 3.864, d_loss 0.082\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 191/390 d_loss_real= 0.046, d_loss_fake= 0.025, g_loss 3.892, d_loss 0.035\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 40 Batch 192/390 d_loss_real= 0.173, d_loss_fake= 0.029, g_loss 3.689, d_loss 0.101\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 193/390 d_loss_real= 0.198, d_loss_fake= 0.035, g_loss 3.441, d_loss 0.117\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 40 Batch 194/390 d_loss_real= 0.099, d_loss_fake= 0.046, g_loss 3.323, d_loss 0.072\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 40 Batch 195/390 d_loss_real= 0.289, d_loss_fake= 0.055, g_loss 3.087, d_loss 0.172\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 40 Batch 196/390 d_loss_real= 0.000, d_loss_fake= 0.069, g_loss 2.838, d_loss 0.035\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40 Batch 197/390 d_loss_real= 0.007, d_loss_fake= 0.082, g_loss 2.752, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 198/390 d_loss_real= 0.047, d_loss_fake= 0.103, g_loss 2.922, d_loss 0.075\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 40 Batch 199/390 d_loss_real= 0.200, d_loss_fake= 0.090, g_loss 3.093, d_loss 0.145\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 40 Batch 200/390 d_loss_real= 0.033, d_loss_fake= 0.116, g_loss 3.811, d_loss 0.074\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 201/390 d_loss_real= 0.008, d_loss_fake= 0.024, g_loss 4.435, d_loss 0.016\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 40 Batch 202/390 d_loss_real= 0.197, d_loss_fake= 0.015, g_loss 4.559, d_loss 0.106\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 40 Batch 203/390 d_loss_real= 0.189, d_loss_fake= 0.014, g_loss 4.664, d_loss 0.101\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 204/390 d_loss_real= 0.291, d_loss_fake= 0.012, g_loss 4.556, d_loss 0.151\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 40 Batch 205/390 d_loss_real= 0.448, d_loss_fake= 0.015, g_loss 4.365, d_loss 0.232\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 206/390 d_loss_real= 0.139, d_loss_fake= 0.016, g_loss 4.126, d_loss 0.077\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 207/390 d_loss_real= 0.135, d_loss_fake= 0.019, g_loss 3.976, d_loss 0.077\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 208/390 d_loss_real= 0.226, d_loss_fake= 0.025, g_loss 3.710, d_loss 0.126\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 209/390 d_loss_real= 0.167, d_loss_fake= 0.029, g_loss 3.326, d_loss 0.098\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 40 Batch 210/390 d_loss_real= 0.077, d_loss_fake= 0.536, g_loss 3.553, d_loss 0.306\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40 Batch 211/390 d_loss_real= 0.226, d_loss_fake= 0.023, g_loss 3.882, d_loss 0.124\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 212/390 d_loss_real= 0.148, d_loss_fake= 0.021, g_loss 3.940, d_loss 0.085\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 213/390 d_loss_real= 0.188, d_loss_fake= 0.022, g_loss 3.895, d_loss 0.105\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 214/390 d_loss_real= 0.233, d_loss_fake= 0.023, g_loss 3.792, d_loss 0.128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 215/390 d_loss_real= 0.262, d_loss_fake= 0.026, g_loss 3.652, d_loss 0.144\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 40 Batch 216/390 d_loss_real= 0.313, d_loss_fake= 0.032, g_loss 3.406, d_loss 0.172\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 217/390 d_loss_real= 0.226, d_loss_fake= 0.039, g_loss 3.217, d_loss 0.133\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 218/390 d_loss_real= 0.184, d_loss_fake= 0.049, g_loss 2.997, d_loss 0.117\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 40 Batch 219/390 d_loss_real= 0.123, d_loss_fake= 0.061, g_loss 2.748, d_loss 0.092\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 220/390 d_loss_real= 0.102, d_loss_fake= 0.093, g_loss 2.430, d_loss 0.097\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40 Batch 221/390 d_loss_real= 0.107, d_loss_fake= 0.482, g_loss 2.432, d_loss 0.295\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 222/390 d_loss_real= 0.112, d_loss_fake= 0.100, g_loss 2.765, d_loss 0.106\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 223/390 d_loss_real= 0.213, d_loss_fake= 0.063, g_loss 2.938, d_loss 0.138\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 40 Batch 224/390 d_loss_real= 0.347, d_loss_fake= 0.055, g_loss 3.033, d_loss 0.201\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 40 Batch 225/390 d_loss_real= 0.201, d_loss_fake= 0.056, g_loss 2.993, d_loss 0.129\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 40 Batch 226/390 d_loss_real= 0.099, d_loss_fake= 0.054, g_loss 3.026, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 227/390 d_loss_real= 0.153, d_loss_fake= 0.053, g_loss 3.040, d_loss 0.103\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 228/390 d_loss_real= 0.173, d_loss_fake= 0.053, g_loss 3.033, d_loss 0.113\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40 Batch 229/390 d_loss_real= 0.214, d_loss_fake= 0.051, g_loss 2.996, d_loss 0.133\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 230/390 d_loss_real= 0.201, d_loss_fake= 0.055, g_loss 3.001, d_loss 0.128\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 231/390 d_loss_real= 0.082, d_loss_fake= 0.055, g_loss 2.989, d_loss 0.068\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 232/390 d_loss_real= 0.041, d_loss_fake= 0.057, g_loss 2.931, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 233/390 d_loss_real= 0.015, d_loss_fake= 0.059, g_loss 2.983, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 234/390 d_loss_real= 0.006, d_loss_fake= 0.060, g_loss 2.945, d_loss 0.033\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 40 Batch 235/390 d_loss_real= 0.018, d_loss_fake= 0.068, g_loss 2.822, d_loss 0.043\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 236/390 d_loss_real= 0.000, d_loss_fake= 0.194, g_loss 2.977, d_loss 0.097\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 237/390 d_loss_real= 0.024, d_loss_fake= 0.087, g_loss 3.486, d_loss 0.056\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 40 Batch 238/390 d_loss_real= 0.010, d_loss_fake= 0.023, g_loss 4.199, d_loss 0.017\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 239/390 d_loss_real= 0.057, d_loss_fake= 0.015, g_loss 4.418, d_loss 0.036\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 240/390 d_loss_real= 0.215, d_loss_fake= 0.015, g_loss 4.341, d_loss 0.115\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 40 Batch 241/390 d_loss_real= 0.068, d_loss_fake= 0.016, g_loss 4.272, d_loss 0.042\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 242/390 d_loss_real= 0.148, d_loss_fake= 0.016, g_loss 4.241, d_loss 0.082\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 243/390 d_loss_real= 0.107, d_loss_fake= 0.016, g_loss 4.240, d_loss 0.061\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 40 Batch 244/390 d_loss_real= 0.111, d_loss_fake= 0.017, g_loss 4.143, d_loss 0.064\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 40 Batch 245/390 d_loss_real= 0.360, d_loss_fake= 0.019, g_loss 4.010, d_loss 0.189\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 40 Batch 246/390 d_loss_real= 0.067, d_loss_fake= 0.020, g_loss 3.946, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 247/390 d_loss_real= 0.281, d_loss_fake= 0.022, g_loss 3.794, d_loss 0.152\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 40 Batch 248/390 d_loss_real= 0.135, d_loss_fake= 0.026, g_loss 3.672, d_loss 0.080\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 249/390 d_loss_real= 0.176, d_loss_fake= 0.031, g_loss 3.489, d_loss 0.104\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 40 Batch 250/390 d_loss_real= 0.000, d_loss_fake= 0.036, g_loss 3.348, d_loss 0.018\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 40 Batch 251/390 d_loss_real= 0.045, d_loss_fake= 0.041, g_loss 3.349, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 252/390 d_loss_real= 0.028, d_loss_fake= 0.047, g_loss 3.211, d_loss 0.038\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40 Batch 253/390 d_loss_real= 0.010, d_loss_fake= 0.048, g_loss 3.145, d_loss 0.029\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 254/390 d_loss_real= 0.044, d_loss_fake= 0.047, g_loss 3.044, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 255/390 d_loss_real= 0.000, d_loss_fake= 0.063, g_loss 3.063, d_loss 0.032\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 40 Batch 256/390 d_loss_real= 0.049, d_loss_fake= 0.071, g_loss 2.885, d_loss 0.060\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 40 Batch 257/390 d_loss_real= 0.055, d_loss_fake= 0.075, g_loss 2.809, d_loss 0.065\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 40 Batch 258/390 d_loss_real= 0.000, d_loss_fake= 0.070, g_loss 2.881, d_loss 0.035\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 259/390 d_loss_real= 0.000, d_loss_fake= 0.089, g_loss 3.117, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 260/390 d_loss_real= 0.074, d_loss_fake= 0.066, g_loss 3.219, d_loss 0.070\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 261/390 d_loss_real= 0.125, d_loss_fake= 0.061, g_loss 3.331, d_loss 0.093\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 40 Batch 262/390 d_loss_real= 0.070, d_loss_fake= 0.043, g_loss 3.484, d_loss 0.056\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 40 Batch 263/390 d_loss_real= 0.010, d_loss_fake= 0.032, g_loss 3.683, d_loss 0.021\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 40 Batch 264/390 d_loss_real= 0.108, d_loss_fake= 0.032, g_loss 3.829, d_loss 0.070\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 40 Batch 265/390 d_loss_real= 0.119, d_loss_fake= 0.033, g_loss 3.895, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 266/390 d_loss_real= 0.145, d_loss_fake= 0.031, g_loss 3.800, d_loss 0.088\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 40 Batch 267/390 d_loss_real= 0.068, d_loss_fake= 0.030, g_loss 4.073, d_loss 0.049\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40 Batch 268/390 d_loss_real= 0.360, d_loss_fake= 0.024, g_loss 3.851, d_loss 0.192\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 40 Batch 269/390 d_loss_real= 0.212, d_loss_fake= 0.040, g_loss 3.889, d_loss 0.126\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 270/390 d_loss_real= 0.289, d_loss_fake= 0.053, g_loss 3.704, d_loss 0.171\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 271/390 d_loss_real= 0.045, d_loss_fake= 0.053, g_loss 3.700, d_loss 0.049\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 40 Batch 272/390 d_loss_real= 0.139, d_loss_fake= 0.033, g_loss 3.951, d_loss 0.086\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 40 Batch 273/390 d_loss_real= 0.185, d_loss_fake= 0.032, g_loss 3.953, d_loss 0.109\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 274/390 d_loss_real= 0.000, d_loss_fake= 0.030, g_loss 4.051, d_loss 0.015\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 275/390 d_loss_real= 0.183, d_loss_fake= 0.019, g_loss 4.143, d_loss 0.101\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 276/390 d_loss_real= 0.099, d_loss_fake= 0.022, g_loss 4.210, d_loss 0.061\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 40 Batch 277/390 d_loss_real= 0.287, d_loss_fake= 0.019, g_loss 4.246, d_loss 0.153\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 40 Batch 278/390 d_loss_real= 0.126, d_loss_fake= 0.017, g_loss 4.187, d_loss 0.072\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 279/390 d_loss_real= 0.077, d_loss_fake= 0.014, g_loss 4.278, d_loss 0.046\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40 Batch 280/390 d_loss_real= 0.142, d_loss_fake= 0.019, g_loss 3.973, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 281/390 d_loss_real= 0.001, d_loss_fake= 0.021, g_loss 3.999, d_loss 0.011\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 40 Batch 282/390 d_loss_real= 0.259, d_loss_fake= 0.023, g_loss 3.691, d_loss 0.141\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 283/390 d_loss_real= 0.104, d_loss_fake= 0.062, g_loss 3.323, d_loss 0.083\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 284/390 d_loss_real= 0.128, d_loss_fake= 0.062, g_loss 3.601, d_loss 0.095\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 285/390 d_loss_real= 0.105, d_loss_fake= 0.050, g_loss 3.659, d_loss 0.078\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 40 Batch 286/390 d_loss_real= 0.076, d_loss_fake= 0.030, g_loss 3.762, d_loss 0.053\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 40 Batch 287/390 d_loss_real= 0.225, d_loss_fake= 0.022, g_loss 4.081, d_loss 0.123\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 40 Batch 288/390 d_loss_real= 0.144, d_loss_fake= 0.019, g_loss 4.025, d_loss 0.082\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 40 Batch 289/390 d_loss_real= 0.184, d_loss_fake= 0.019, g_loss 4.000, d_loss 0.102\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 40 Batch 290/390 d_loss_real= 0.170, d_loss_fake= 0.022, g_loss 3.877, d_loss 0.096\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 40 Batch 291/390 d_loss_real= 0.138, d_loss_fake= 0.028, g_loss 3.787, d_loss 0.083\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 40 Batch 292/390 d_loss_real= 0.079, d_loss_fake= 0.038, g_loss 3.629, d_loss 0.058\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 40 Batch 293/390 d_loss_real= 0.325, d_loss_fake= 0.047, g_loss 3.448, d_loss 0.186\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 294/390 d_loss_real= 0.161, d_loss_fake= 0.078, g_loss 3.284, d_loss 0.119\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 40 Batch 295/390 d_loss_real= 0.143, d_loss_fake= 0.071, g_loss 3.335, d_loss 0.107\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40 Batch 296/390 d_loss_real= 0.292, d_loss_fake= 0.041, g_loss 3.580, d_loss 0.166\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 297/390 d_loss_real= 0.182, d_loss_fake= 0.031, g_loss 3.767, d_loss 0.107\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 298/390 d_loss_real= 0.113, d_loss_fake= 0.025, g_loss 3.824, d_loss 0.069\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 40 Batch 299/390 d_loss_real= 0.162, d_loss_fake= 0.024, g_loss 3.798, d_loss 0.093\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 40 Batch 300/390 d_loss_real= 0.074, d_loss_fake= 0.024, g_loss 3.799, d_loss 0.049\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 301/390 d_loss_real= 0.346, d_loss_fake= 0.025, g_loss 3.728, d_loss 0.185\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 40 Batch 302/390 d_loss_real= 0.043, d_loss_fake= 0.027, g_loss 3.599, d_loss 0.035\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 303/390 d_loss_real= 0.221, d_loss_fake= 0.031, g_loss 3.420, d_loss 0.126\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 304/390 d_loss_real= 0.280, d_loss_fake= 0.040, g_loss 3.158, d_loss 0.160\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 40 Batch 305/390 d_loss_real= 0.056, d_loss_fake= 0.054, g_loss 3.068, d_loss 0.055\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 40 Batch 306/390 d_loss_real= 0.046, d_loss_fake= 0.054, g_loss 3.085, d_loss 0.050\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 307/390 d_loss_real= 0.029, d_loss_fake= 0.050, g_loss 3.188, d_loss 0.040\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 40 Batch 308/390 d_loss_real= 0.007, d_loss_fake= 0.044, g_loss 3.411, d_loss 0.025\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 309/390 d_loss_real= 0.070, d_loss_fake= 0.035, g_loss 3.502, d_loss 0.052\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 40 Batch 310/390 d_loss_real= 0.060, d_loss_fake= 0.031, g_loss 3.656, d_loss 0.045\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 311/390 d_loss_real= 0.058, d_loss_fake= 0.027, g_loss 3.796, d_loss 0.042\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 312/390 d_loss_real= 0.061, d_loss_fake= 0.025, g_loss 3.828, d_loss 0.043\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40 Batch 313/390 d_loss_real= 0.047, d_loss_fake= 0.024, g_loss 3.959, d_loss 0.035\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 314/390 d_loss_real= 0.061, d_loss_fake= 0.022, g_loss 3.899, d_loss 0.042\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 315/390 d_loss_real= 0.181, d_loss_fake= 0.023, g_loss 3.914, d_loss 0.102\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 40 Batch 316/390 d_loss_real= 0.000, d_loss_fake= 0.025, g_loss 3.852, d_loss 0.013\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 40 Batch 317/390 d_loss_real= 0.086, d_loss_fake= 0.027, g_loss 3.744, d_loss 0.057\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 40 Batch 318/390 d_loss_real= 0.006, d_loss_fake= 0.028, g_loss 3.759, d_loss 0.017\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 40 Batch 319/390 d_loss_real= 0.103, d_loss_fake= 0.032, g_loss 3.666, d_loss 0.067\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 40 Batch 320/390 d_loss_real= 0.099, d_loss_fake= 0.033, g_loss 3.625, d_loss 0.066\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 321/390 d_loss_real= 0.163, d_loss_fake= 0.037, g_loss 3.625, d_loss 0.100\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 40 Batch 322/390 d_loss_real= 0.087, d_loss_fake= 0.034, g_loss 3.536, d_loss 0.060\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 323/390 d_loss_real= 0.144, d_loss_fake= 0.036, g_loss 3.532, d_loss 0.090\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 324/390 d_loss_real= 0.116, d_loss_fake= 0.037, g_loss 3.544, d_loss 0.076\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 40 Batch 325/390 d_loss_real= 0.096, d_loss_fake= 0.038, g_loss 3.576, d_loss 0.067\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 326/390 d_loss_real= 0.029, d_loss_fake= 0.036, g_loss 3.557, d_loss 0.032\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 327/390 d_loss_real= 0.230, d_loss_fake= 0.033, g_loss 3.507, d_loss 0.132\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 40 Batch 328/390 d_loss_real= 0.048, d_loss_fake= 0.032, g_loss 3.495, d_loss 0.040\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 40 Batch 329/390 d_loss_real= 0.001, d_loss_fake= 0.036, g_loss 3.516, d_loss 0.018\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 330/390 d_loss_real= 0.093, d_loss_fake= 0.035, g_loss 3.467, d_loss 0.064\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 40 Batch 331/390 d_loss_real= 0.011, d_loss_fake= 0.034, g_loss 3.513, d_loss 0.022\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 332/390 d_loss_real= 0.003, d_loss_fake= 0.035, g_loss 3.477, d_loss 0.019\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 333/390 d_loss_real= 0.070, d_loss_fake= 0.035, g_loss 3.562, d_loss 0.053\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 334/390 d_loss_real= 0.118, d_loss_fake= 0.030, g_loss 3.541, d_loss 0.074\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40 Batch 335/390 d_loss_real= 0.055, d_loss_fake= 0.037, g_loss 3.505, d_loss 0.046\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 336/390 d_loss_real= 0.126, d_loss_fake= 0.032, g_loss 3.419, d_loss 0.079\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40 Batch 337/390 d_loss_real= 0.035, d_loss_fake= 0.038, g_loss 3.429, d_loss 0.037\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40 Batch 338/390 d_loss_real= 0.084, d_loss_fake= 0.041, g_loss 3.286, d_loss 0.063\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 40 Batch 339/390 d_loss_real= 0.183, d_loss_fake= 0.048, g_loss 3.257, d_loss 0.116\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 340/390 d_loss_real= 0.000, d_loss_fake= 0.056, g_loss 3.296, d_loss 0.028\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 40 Batch 341/390 d_loss_real= 0.048, d_loss_fake= 0.045, g_loss 3.443, d_loss 0.046\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 342/390 d_loss_real= 0.070, d_loss_fake= 0.040, g_loss 3.559, d_loss 0.055\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 40 Batch 343/390 d_loss_real= 0.129, d_loss_fake= 0.033, g_loss 3.770, d_loss 0.081\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 344/390 d_loss_real= 0.162, d_loss_fake= 0.027, g_loss 3.869, d_loss 0.095\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 345/390 d_loss_real= 0.122, d_loss_fake= 0.024, g_loss 3.753, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 346/390 d_loss_real= 0.000, d_loss_fake= 0.027, g_loss 3.725, d_loss 0.014\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 40 Batch 347/390 d_loss_real= 0.073, d_loss_fake= 0.031, g_loss 3.829, d_loss 0.052\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 40 Batch 348/390 d_loss_real= 0.100, d_loss_fake= 0.029, g_loss 3.602, d_loss 0.064\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 40 Batch 349/390 d_loss_real= 0.121, d_loss_fake= 0.029, g_loss 3.700, d_loss 0.075\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 40 Batch 350/390 d_loss_real= 0.196, d_loss_fake= 0.035, g_loss 3.750, d_loss 0.116\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 40 Batch 351/390 d_loss_real= 0.177, d_loss_fake= 0.036, g_loss 3.700, d_loss 0.106\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 352/390 d_loss_real= 0.004, d_loss_fake= 0.021, g_loss 3.889, d_loss 0.012\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 353/390 d_loss_real= 0.180, d_loss_fake= 0.019, g_loss 4.061, d_loss 0.100\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 354/390 d_loss_real= 0.102, d_loss_fake= 0.021, g_loss 4.015, d_loss 0.062\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 40 Batch 355/390 d_loss_real= 0.085, d_loss_fake= 0.023, g_loss 3.884, d_loss 0.054\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 356/390 d_loss_real= 0.299, d_loss_fake= 0.037, g_loss 3.703, d_loss 0.168\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 357/390 d_loss_real= 0.062, d_loss_fake= 0.049, g_loss 3.597, d_loss 0.056\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 40 Batch 358/390 d_loss_real= 0.079, d_loss_fake= 0.045, g_loss 3.634, d_loss 0.062\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 359/390 d_loss_real= 0.205, d_loss_fake= 0.036, g_loss 3.825, d_loss 0.121\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 360/390 d_loss_real= 0.066, d_loss_fake= 0.022, g_loss 3.969, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 361/390 d_loss_real= 0.121, d_loss_fake= 0.020, g_loss 4.008, d_loss 0.070\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 362/390 d_loss_real= 0.264, d_loss_fake= 0.021, g_loss 3.833, d_loss 0.143\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 40 Batch 363/390 d_loss_real= 0.156, d_loss_fake= 0.027, g_loss 3.673, d_loss 0.092\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 364/390 d_loss_real= 0.066, d_loss_fake= 0.032, g_loss 3.489, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 365/390 d_loss_real= 0.011, d_loss_fake= 0.033, g_loss 3.630, d_loss 0.022\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 366/390 d_loss_real= 0.108, d_loss_fake= 0.052, g_loss 3.604, d_loss 0.080\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 40 Batch 367/390 d_loss_real= 0.120, d_loss_fake= 0.027, g_loss 3.840, d_loss 0.074\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 40 Batch 368/390 d_loss_real= 0.161, d_loss_fake= 0.021, g_loss 3.897, d_loss 0.091\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 369/390 d_loss_real= 0.265, d_loss_fake= 0.023, g_loss 3.916, d_loss 0.144\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 370/390 d_loss_real= 0.152, d_loss_fake= 0.024, g_loss 3.924, d_loss 0.088\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 40 Batch 371/390 d_loss_real= 0.149, d_loss_fake= 0.023, g_loss 3.763, d_loss 0.086\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 40 Batch 372/390 d_loss_real= 0.165, d_loss_fake= 0.030, g_loss 3.577, d_loss 0.098\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 373/390 d_loss_real= 0.184, d_loss_fake= 0.033, g_loss 3.463, d_loss 0.108\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 374/390 d_loss_real= 0.106, d_loss_fake= 0.043, g_loss 3.322, d_loss 0.074\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 375/390 d_loss_real= 0.066, d_loss_fake= 0.050, g_loss 3.293, d_loss 0.058\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 376/390 d_loss_real= 0.065, d_loss_fake= 0.045, g_loss 3.431, d_loss 0.055\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 40 Batch 377/390 d_loss_real= 0.001, d_loss_fake= 0.039, g_loss 3.523, d_loss 0.020\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 40 Batch 378/390 d_loss_real= 0.059, d_loss_fake= 0.030, g_loss 3.691, d_loss 0.044\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 40 Batch 379/390 d_loss_real= 0.225, d_loss_fake= 0.033, g_loss 3.840, d_loss 0.129\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 380/390 d_loss_real= 0.161, d_loss_fake= 0.029, g_loss 3.611, d_loss 0.095\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 40 Batch 381/390 d_loss_real= 0.122, d_loss_fake= 0.030, g_loss 3.672, d_loss 0.076\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 40 Batch 382/390 d_loss_real= 0.245, d_loss_fake= 0.034, g_loss 3.626, d_loss 0.139\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 383/390 d_loss_real= 0.061, d_loss_fake= 0.036, g_loss 3.477, d_loss 0.049\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40 Batch 384/390 d_loss_real= 0.278, d_loss_fake= 0.044, g_loss 3.390, d_loss 0.161\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 385/390 d_loss_real= 0.077, d_loss_fake= 0.047, g_loss 3.307, d_loss 0.062\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 40 Batch 386/390 d_loss_real= 0.082, d_loss_fake= 0.067, g_loss 3.214, d_loss 0.074\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40 Batch 387/390 d_loss_real= 0.099, d_loss_fake= 0.047, g_loss 3.373, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 388/390 d_loss_real= 0.098, d_loss_fake= 0.037, g_loss 3.653, d_loss 0.067\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40 Batch 389/390 d_loss_real= 0.090, d_loss_fake= 0.030, g_loss 3.721, d_loss 0.060\n",
            "2/2 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40 Batch 390/390 d_loss_real= 0.115, d_loss_fake= 0.030, g_loss 3.743, d_loss 0.073\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 41 Batch 1/390 d_loss_real= 0.138, d_loss_fake= 0.024, g_loss 3.818, d_loss 0.081\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 2/390 d_loss_real= 0.068, d_loss_fake= 0.023, g_loss 3.918, d_loss 0.046\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 3/390 d_loss_real= 0.019, d_loss_fake= 0.024, g_loss 3.924, d_loss 0.021\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 41 Batch 4/390 d_loss_real= 0.309, d_loss_fake= 0.023, g_loss 3.902, d_loss 0.166\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 41 Batch 5/390 d_loss_real= 0.123, d_loss_fake= 0.026, g_loss 3.724, d_loss 0.075\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 41 Batch 6/390 d_loss_real= 0.009, d_loss_fake= 0.026, g_loss 3.694, d_loss 0.018\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 7/390 d_loss_real= 0.149, d_loss_fake= 0.030, g_loss 3.676, d_loss 0.090\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 8/390 d_loss_real= 0.278, d_loss_fake= 0.036, g_loss 3.469, d_loss 0.157\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 9/390 d_loss_real= 0.183, d_loss_fake= 0.034, g_loss 3.415, d_loss 0.108\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 41 Batch 10/390 d_loss_real= 0.023, d_loss_fake= 0.042, g_loss 3.296, d_loss 0.032\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 11/390 d_loss_real= 0.057, d_loss_fake= 0.048, g_loss 3.217, d_loss 0.052\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 12/390 d_loss_real= 0.168, d_loss_fake= 0.044, g_loss 3.258, d_loss 0.106\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 41 Batch 13/390 d_loss_real= 0.054, d_loss_fake= 0.049, g_loss 3.302, d_loss 0.052\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 14/390 d_loss_real= 0.067, d_loss_fake= 0.040, g_loss 3.466, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 15/390 d_loss_real= 0.020, d_loss_fake= 0.035, g_loss 3.662, d_loss 0.027\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 41 Batch 16/390 d_loss_real= 0.078, d_loss_fake= 0.035, g_loss 3.754, d_loss 0.056\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 17/390 d_loss_real= 0.204, d_loss_fake= 0.030, g_loss 3.617, d_loss 0.117\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 18/390 d_loss_real= 0.109, d_loss_fake= 0.034, g_loss 3.472, d_loss 0.071\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 19/390 d_loss_real= 0.121, d_loss_fake= 0.040, g_loss 3.440, d_loss 0.081\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 20/390 d_loss_real= 0.074, d_loss_fake= 0.040, g_loss 3.307, d_loss 0.057\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 21/390 d_loss_real= 0.025, d_loss_fake= 0.052, g_loss 3.322, d_loss 0.038\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 22/390 d_loss_real= 0.081, d_loss_fake= 0.038, g_loss 3.442, d_loss 0.059\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 23/390 d_loss_real= 0.062, d_loss_fake= 0.037, g_loss 3.510, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 24/390 d_loss_real= 0.210, d_loss_fake= 0.037, g_loss 3.392, d_loss 0.124\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 25/390 d_loss_real= 0.009, d_loss_fake= 0.044, g_loss 3.330, d_loss 0.027\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 26/390 d_loss_real= 0.000, d_loss_fake= 0.041, g_loss 3.459, d_loss 0.021\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 27/390 d_loss_real= 0.070, d_loss_fake= 0.031, g_loss 3.787, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 28/390 d_loss_real= 0.146, d_loss_fake= 0.026, g_loss 3.743, d_loss 0.086\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41 Batch 29/390 d_loss_real= 0.243, d_loss_fake= 0.033, g_loss 3.453, d_loss 0.138\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 30/390 d_loss_real= 0.070, d_loss_fake= 0.041, g_loss 3.392, d_loss 0.055\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 31/390 d_loss_real= 0.063, d_loss_fake= 0.044, g_loss 3.413, d_loss 0.053\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 32/390 d_loss_real= 0.102, d_loss_fake= 0.031, g_loss 3.726, d_loss 0.066\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 33/390 d_loss_real= 0.061, d_loss_fake= 0.025, g_loss 3.864, d_loss 0.043\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 34/390 d_loss_real= 0.133, d_loss_fake= 0.020, g_loss 3.991, d_loss 0.077\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41 Batch 35/390 d_loss_real= 0.112, d_loss_fake= 0.018, g_loss 4.178, d_loss 0.065\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41 Batch 36/390 d_loss_real= 0.118, d_loss_fake= 0.017, g_loss 4.036, d_loss 0.068\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41 Batch 37/390 d_loss_real= 0.118, d_loss_fake= 0.020, g_loss 4.115, d_loss 0.069\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 38/390 d_loss_real= 0.080, d_loss_fake= 0.019, g_loss 3.993, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 39/390 d_loss_real= 0.001, d_loss_fake= 0.021, g_loss 3.980, d_loss 0.011\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 40/390 d_loss_real= 0.360, d_loss_fake= 0.023, g_loss 3.869, d_loss 0.191\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 41/390 d_loss_real= 0.073, d_loss_fake= 0.023, g_loss 3.799, d_loss 0.048\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 42/390 d_loss_real= 0.115, d_loss_fake= 0.026, g_loss 3.691, d_loss 0.071\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 43/390 d_loss_real= 0.149, d_loss_fake= 0.039, g_loss 3.329, d_loss 0.094\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 44/390 d_loss_real= 0.163, d_loss_fake= 0.077, g_loss 3.193, d_loss 0.120\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 41 Batch 45/390 d_loss_real= 0.104, d_loss_fake= 0.052, g_loss 3.431, d_loss 0.078\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41 Batch 46/390 d_loss_real= 0.127, d_loss_fake= 0.036, g_loss 3.623, d_loss 0.081\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 47/390 d_loss_real= 0.098, d_loss_fake= 0.025, g_loss 3.821, d_loss 0.062\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 41 Batch 48/390 d_loss_real= 0.119, d_loss_fake= 0.023, g_loss 3.880, d_loss 0.071\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 41 Batch 49/390 d_loss_real= 0.193, d_loss_fake= 0.024, g_loss 3.797, d_loss 0.108\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 50/390 d_loss_real= 0.000, d_loss_fake= 0.024, g_loss 3.803, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 51/390 d_loss_real= 0.000, d_loss_fake= 0.023, g_loss 3.802, d_loss 0.012\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 52/390 d_loss_real= 0.102, d_loss_fake= 0.024, g_loss 3.781, d_loss 0.063\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 41 Batch 53/390 d_loss_real= 0.062, d_loss_fake= 0.025, g_loss 3.724, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 54/390 d_loss_real= 0.074, d_loss_fake= 0.027, g_loss 3.662, d_loss 0.050\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41 Batch 55/390 d_loss_real= 0.147, d_loss_fake= 0.029, g_loss 3.565, d_loss 0.088\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 56/390 d_loss_real= 0.092, d_loss_fake= 0.032, g_loss 3.478, d_loss 0.062\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 57/390 d_loss_real= 0.202, d_loss_fake= 0.036, g_loss 3.275, d_loss 0.119\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41 Batch 58/390 d_loss_real= 0.194, d_loss_fake= 0.047, g_loss 3.071, d_loss 0.121\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 41 Batch 59/390 d_loss_real= 0.183, d_loss_fake= 0.058, g_loss 2.938, d_loss 0.120\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 60/390 d_loss_real= 0.164, d_loss_fake= 0.103, g_loss 3.273, d_loss 0.133\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 41 Batch 61/390 d_loss_real= 0.057, d_loss_fake= 0.035, g_loss 3.593, d_loss 0.046\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 62/390 d_loss_real= 0.121, d_loss_fake= 0.028, g_loss 3.758, d_loss 0.074\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 63/390 d_loss_real= 0.218, d_loss_fake= 0.027, g_loss 3.726, d_loss 0.122\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 41 Batch 64/390 d_loss_real= 0.265, d_loss_fake= 0.028, g_loss 3.674, d_loss 0.146\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 65/390 d_loss_real= 0.214, d_loss_fake= 0.032, g_loss 3.499, d_loss 0.123\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 66/390 d_loss_real= 0.198, d_loss_fake= 0.038, g_loss 3.224, d_loss 0.118\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41 Batch 67/390 d_loss_real= 0.062, d_loss_fake= 0.048, g_loss 2.955, d_loss 0.055\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 68/390 d_loss_real= 0.045, d_loss_fake= 0.066, g_loss 2.666, d_loss 0.055\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 69/390 d_loss_real= 0.000, d_loss_fake= 0.111, g_loss 2.512, d_loss 0.055\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 41 Batch 70/390 d_loss_real= 0.006, d_loss_fake= 0.137, g_loss 2.873, d_loss 0.072\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 71/390 d_loss_real= 0.093, d_loss_fake= 0.050, g_loss 3.391, d_loss 0.071\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 72/390 d_loss_real= 0.105, d_loss_fake= 0.031, g_loss 3.701, d_loss 0.068\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 73/390 d_loss_real= 0.126, d_loss_fake= 0.026, g_loss 3.864, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 74/390 d_loss_real= 0.063, d_loss_fake= 0.023, g_loss 3.862, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 75/390 d_loss_real= 0.278, d_loss_fake= 0.023, g_loss 3.891, d_loss 0.150\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 41 Batch 76/390 d_loss_real= 0.327, d_loss_fake= 0.023, g_loss 3.767, d_loss 0.175\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 77/390 d_loss_real= 0.131, d_loss_fake= 0.027, g_loss 3.694, d_loss 0.079\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 41 Batch 78/390 d_loss_real= 0.114, d_loss_fake= 0.030, g_loss 3.630, d_loss 0.072\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 79/390 d_loss_real= 0.088, d_loss_fake= 0.029, g_loss 3.485, d_loss 0.059\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 80/390 d_loss_real= 0.041, d_loss_fake= 0.033, g_loss 3.418, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 81/390 d_loss_real= 0.123, d_loss_fake= 0.038, g_loss 3.263, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 82/390 d_loss_real= 0.063, d_loss_fake= 0.045, g_loss 3.100, d_loss 0.054\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41 Batch 83/390 d_loss_real= 0.024, d_loss_fake= 0.053, g_loss 2.963, d_loss 0.039\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 84/390 d_loss_real= 0.000, d_loss_fake= 0.072, g_loss 2.756, d_loss 0.036\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 85/390 d_loss_real= 0.121, d_loss_fake= 0.100, g_loss 2.968, d_loss 0.111\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 86/390 d_loss_real= 0.000, d_loss_fake= 0.053, g_loss 3.272, d_loss 0.027\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 87/390 d_loss_real= 0.131, d_loss_fake= 0.033, g_loss 3.606, d_loss 0.082\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 41 Batch 88/390 d_loss_real= 0.131, d_loss_fake= 0.026, g_loss 3.814, d_loss 0.078\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 89/390 d_loss_real= 0.060, d_loss_fake= 0.022, g_loss 3.959, d_loss 0.041\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 90/390 d_loss_real= 0.028, d_loss_fake= 0.020, g_loss 4.021, d_loss 0.024\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 41 Batch 91/390 d_loss_real= 0.129, d_loss_fake= 0.017, g_loss 4.082, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 92/390 d_loss_real= 0.267, d_loss_fake= 0.018, g_loss 4.017, d_loss 0.143\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 93/390 d_loss_real= 0.292, d_loss_fake= 0.020, g_loss 3.891, d_loss 0.156\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 94/390 d_loss_real= 0.060, d_loss_fake= 0.023, g_loss 3.818, d_loss 0.041\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 95/390 d_loss_real= 0.037, d_loss_fake= 0.025, g_loss 3.661, d_loss 0.031\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 96/390 d_loss_real= 0.172, d_loss_fake= 0.029, g_loss 3.487, d_loss 0.101\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 97/390 d_loss_real= 0.000, d_loss_fake= 0.033, g_loss 3.453, d_loss 0.016\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 98/390 d_loss_real= 0.030, d_loss_fake= 0.040, g_loss 3.310, d_loss 0.035\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 99/390 d_loss_real= 0.000, d_loss_fake= 0.047, g_loss 3.390, d_loss 0.024\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 41 Batch 100/390 d_loss_real= 0.000, d_loss_fake= 0.038, g_loss 3.487, d_loss 0.019\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 101/390 d_loss_real= 0.108, d_loss_fake= 0.033, g_loss 3.616, d_loss 0.071\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 102/390 d_loss_real= 0.074, d_loss_fake= 0.026, g_loss 3.745, d_loss 0.050\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 103/390 d_loss_real= 0.099, d_loss_fake= 0.026, g_loss 3.738, d_loss 0.062\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 104/390 d_loss_real= 0.000, d_loss_fake= 0.026, g_loss 3.773, d_loss 0.013\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 105/390 d_loss_real= 0.035, d_loss_fake= 0.026, g_loss 3.717, d_loss 0.031\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 106/390 d_loss_real= 0.065, d_loss_fake= 0.030, g_loss 3.765, d_loss 0.047\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 107/390 d_loss_real= 0.011, d_loss_fake= 0.028, g_loss 3.649, d_loss 0.020\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 108/390 d_loss_real= 0.121, d_loss_fake= 0.025, g_loss 3.699, d_loss 0.073\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 41 Batch 109/390 d_loss_real= 0.059, d_loss_fake= 0.032, g_loss 3.568, d_loss 0.045\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 110/390 d_loss_real= 0.098, d_loss_fake= 0.032, g_loss 3.544, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 111/390 d_loss_real= 0.118, d_loss_fake= 0.039, g_loss 3.608, d_loss 0.079\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 41 Batch 112/390 d_loss_real= 0.233, d_loss_fake= 0.038, g_loss 3.685, d_loss 0.135\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 113/390 d_loss_real= 0.187, d_loss_fake= 0.037, g_loss 3.491, d_loss 0.112\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 41 Batch 114/390 d_loss_real= 0.163, d_loss_fake= 0.059, g_loss 3.500, d_loss 0.111\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 115/390 d_loss_real= 0.044, d_loss_fake= 0.034, g_loss 3.543, d_loss 0.039\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 41 Batch 116/390 d_loss_real= 0.098, d_loss_fake= 0.040, g_loss 3.587, d_loss 0.069\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 117/390 d_loss_real= 0.130, d_loss_fake= 0.032, g_loss 3.702, d_loss 0.081\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 118/390 d_loss_real= 0.059, d_loss_fake= 0.031, g_loss 3.724, d_loss 0.045\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 119/390 d_loss_real= 0.236, d_loss_fake= 0.035, g_loss 3.620, d_loss 0.136\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 120/390 d_loss_real= 0.116, d_loss_fake= 0.040, g_loss 3.376, d_loss 0.078\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 121/390 d_loss_real= 0.020, d_loss_fake= 0.051, g_loss 3.421, d_loss 0.036\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 122/390 d_loss_real= 0.000, d_loss_fake= 0.037, g_loss 3.626, d_loss 0.019\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 123/390 d_loss_real= 0.164, d_loss_fake= 0.026, g_loss 3.847, d_loss 0.095\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 124/390 d_loss_real= 0.109, d_loss_fake= 0.023, g_loss 3.912, d_loss 0.066\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 125/390 d_loss_real= 0.080, d_loss_fake= 0.021, g_loss 3.957, d_loss 0.051\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 126/390 d_loss_real= 0.076, d_loss_fake= 0.021, g_loss 3.939, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 127/390 d_loss_real= 0.001, d_loss_fake= 0.022, g_loss 3.928, d_loss 0.011\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41 Batch 128/390 d_loss_real= 0.000, d_loss_fake= 0.021, g_loss 3.924, d_loss 0.010\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41 Batch 129/390 d_loss_real= 0.071, d_loss_fake= 0.020, g_loss 3.959, d_loss 0.046\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 130/390 d_loss_real= 0.053, d_loss_fake= 0.021, g_loss 3.844, d_loss 0.037\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41 Batch 131/390 d_loss_real= 0.188, d_loss_fake= 0.026, g_loss 3.750, d_loss 0.107\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 132/390 d_loss_real= 0.183, d_loss_fake= 0.035, g_loss 3.498, d_loss 0.109\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 133/390 d_loss_real= 0.137, d_loss_fake= 0.057, g_loss 3.334, d_loss 0.097\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 41 Batch 134/390 d_loss_real= 0.060, d_loss_fake= 0.043, g_loss 3.433, d_loss 0.052\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 41 Batch 135/390 d_loss_real= 0.046, d_loss_fake= 0.031, g_loss 3.641, d_loss 0.039\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 41 Batch 136/390 d_loss_real= 0.087, d_loss_fake= 0.027, g_loss 3.709, d_loss 0.057\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 137/390 d_loss_real= 0.064, d_loss_fake= 0.025, g_loss 3.775, d_loss 0.044\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 138/390 d_loss_real= 0.214, d_loss_fake= 0.024, g_loss 3.699, d_loss 0.119\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 139/390 d_loss_real= 0.182, d_loss_fake= 0.028, g_loss 3.652, d_loss 0.105\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 140/390 d_loss_real= 0.086, d_loss_fake= 0.029, g_loss 3.572, d_loss 0.057\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 41 Batch 141/390 d_loss_real= 0.138, d_loss_fake= 0.033, g_loss 3.427, d_loss 0.086\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 142/390 d_loss_real= 0.006, d_loss_fake= 0.036, g_loss 3.404, d_loss 0.021\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41 Batch 143/390 d_loss_real= 0.059, d_loss_fake= 0.039, g_loss 3.280, d_loss 0.049\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 41 Batch 144/390 d_loss_real= 0.138, d_loss_fake= 0.043, g_loss 3.318, d_loss 0.090\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 145/390 d_loss_real= 0.254, d_loss_fake= 0.042, g_loss 3.195, d_loss 0.148\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 41 Batch 146/390 d_loss_real= 0.131, d_loss_fake= 0.048, g_loss 3.197, d_loss 0.089\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 147/390 d_loss_real= 0.165, d_loss_fake= 0.049, g_loss 3.199, d_loss 0.107\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 148/390 d_loss_real= 0.000, d_loss_fake= 0.045, g_loss 3.253, d_loss 0.023\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 149/390 d_loss_real= 0.001, d_loss_fake= 0.035, g_loss 3.514, d_loss 0.018\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 41 Batch 150/390 d_loss_real= 0.031, d_loss_fake= 0.031, g_loss 3.617, d_loss 0.031\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 151/390 d_loss_real= 0.068, d_loss_fake= 0.030, g_loss 3.661, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 152/390 d_loss_real= 0.021, d_loss_fake= 0.027, g_loss 3.727, d_loss 0.024\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 153/390 d_loss_real= 0.196, d_loss_fake= 0.027, g_loss 3.703, d_loss 0.112\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 154/390 d_loss_real= 0.131, d_loss_fake= 0.029, g_loss 3.582, d_loss 0.080\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 155/390 d_loss_real= 0.131, d_loss_fake= 0.032, g_loss 3.323, d_loss 0.082\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 156/390 d_loss_real= 0.055, d_loss_fake= 0.039, g_loss 3.238, d_loss 0.047\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 41 Batch 157/390 d_loss_real= 0.062, d_loss_fake= 0.053, g_loss 3.150, d_loss 0.058\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 158/390 d_loss_real= 0.021, d_loss_fake= 0.055, g_loss 3.290, d_loss 0.038\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 159/390 d_loss_real= 0.172, d_loss_fake= 0.035, g_loss 3.493, d_loss 0.103\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 160/390 d_loss_real= 0.058, d_loss_fake= 0.030, g_loss 3.644, d_loss 0.044\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 161/390 d_loss_real= 0.186, d_loss_fake= 0.028, g_loss 3.745, d_loss 0.107\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 162/390 d_loss_real= 0.034, d_loss_fake= 0.025, g_loss 3.784, d_loss 0.030\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 163/390 d_loss_real= 0.110, d_loss_fake= 0.024, g_loss 3.812, d_loss 0.067\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 164/390 d_loss_real= 0.001, d_loss_fake= 0.024, g_loss 3.811, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 165/390 d_loss_real= 0.036, d_loss_fake= 0.024, g_loss 3.759, d_loss 0.030\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 166/390 d_loss_real= 0.154, d_loss_fake= 0.026, g_loss 3.681, d_loss 0.090\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 167/390 d_loss_real= 0.007, d_loss_fake= 0.029, g_loss 3.584, d_loss 0.018\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 168/390 d_loss_real= 0.070, d_loss_fake= 0.033, g_loss 3.403, d_loss 0.052\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 169/390 d_loss_real= 0.056, d_loss_fake= 0.038, g_loss 3.332, d_loss 0.047\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 170/390 d_loss_real= 0.070, d_loss_fake= 0.033, g_loss 3.548, d_loss 0.051\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41 Batch 171/390 d_loss_real= 0.116, d_loss_fake= 0.040, g_loss 3.264, d_loss 0.078\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 41 Batch 172/390 d_loss_real= 0.000, d_loss_fake= 0.045, g_loss 3.319, d_loss 0.023\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 173/390 d_loss_real= 0.106, d_loss_fake= 0.049, g_loss 3.451, d_loss 0.077\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 174/390 d_loss_real= 0.138, d_loss_fake= 0.034, g_loss 3.670, d_loss 0.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 175/390 d_loss_real= 0.000, d_loss_fake= 0.024, g_loss 3.961, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 176/390 d_loss_real= 0.156, d_loss_fake= 0.022, g_loss 3.892, d_loss 0.089\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 177/390 d_loss_real= 0.063, d_loss_fake= 0.023, g_loss 3.937, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 178/390 d_loss_real= 0.066, d_loss_fake= 0.018, g_loss 4.090, d_loss 0.042\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 179/390 d_loss_real= 0.093, d_loss_fake= 0.020, g_loss 4.051, d_loss 0.056\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 180/390 d_loss_real= 0.065, d_loss_fake= 0.018, g_loss 4.046, d_loss 0.041\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 181/390 d_loss_real= 0.079, d_loss_fake= 0.020, g_loss 4.009, d_loss 0.049\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 182/390 d_loss_real= 0.132, d_loss_fake= 0.023, g_loss 3.830, d_loss 0.078\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 41 Batch 183/390 d_loss_real= 0.072, d_loss_fake= 0.029, g_loss 3.684, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 184/390 d_loss_real= 0.156, d_loss_fake= 0.033, g_loss 3.532, d_loss 0.095\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 185/390 d_loss_real= 0.033, d_loss_fake= 0.036, g_loss 3.606, d_loss 0.035\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 41 Batch 186/390 d_loss_real= 0.089, d_loss_fake= 0.035, g_loss 3.732, d_loss 0.062\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 187/390 d_loss_real= 0.002, d_loss_fake= 0.023, g_loss 3.946, d_loss 0.013\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 41 Batch 188/390 d_loss_real= 0.278, d_loss_fake= 0.021, g_loss 3.941, d_loss 0.149\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 189/390 d_loss_real= 0.069, d_loss_fake= 0.020, g_loss 4.015, d_loss 0.044\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41 Batch 190/390 d_loss_real= 0.003, d_loss_fake= 0.020, g_loss 4.029, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 191/390 d_loss_real= 0.241, d_loss_fake= 0.020, g_loss 4.017, d_loss 0.131\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 192/390 d_loss_real= 0.007, d_loss_fake= 0.020, g_loss 3.967, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 193/390 d_loss_real= 0.067, d_loss_fake= 0.019, g_loss 3.939, d_loss 0.043\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 41 Batch 194/390 d_loss_real= 0.027, d_loss_fake= 0.022, g_loss 3.890, d_loss 0.025\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 195/390 d_loss_real= 0.055, d_loss_fake= 0.025, g_loss 3.720, d_loss 0.040\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 196/390 d_loss_real= 0.004, d_loss_fake= 0.025, g_loss 3.692, d_loss 0.015\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 197/390 d_loss_real= 0.069, d_loss_fake= 0.025, g_loss 3.852, d_loss 0.047\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 198/390 d_loss_real= 0.179, d_loss_fake= 0.025, g_loss 3.710, d_loss 0.102\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 199/390 d_loss_real= 0.106, d_loss_fake= 0.031, g_loss 3.577, d_loss 0.068\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 200/390 d_loss_real= 0.092, d_loss_fake= 0.040, g_loss 3.447, d_loss 0.066\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 201/390 d_loss_real= 0.000, d_loss_fake= 0.029, g_loss 3.707, d_loss 0.015\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 202/390 d_loss_real= 0.046, d_loss_fake= 0.028, g_loss 3.818, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 203/390 d_loss_real= 0.006, d_loss_fake= 0.027, g_loss 3.814, d_loss 0.017\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 204/390 d_loss_real= 0.205, d_loss_fake= 0.024, g_loss 3.893, d_loss 0.114\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 205/390 d_loss_real= 0.124, d_loss_fake= 0.024, g_loss 3.929, d_loss 0.074\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 41 Batch 206/390 d_loss_real= 0.075, d_loss_fake= 0.021, g_loss 3.891, d_loss 0.048\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 207/390 d_loss_real= 0.004, d_loss_fake= 0.020, g_loss 3.956, d_loss 0.012\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 208/390 d_loss_real= 0.087, d_loss_fake= 0.023, g_loss 3.870, d_loss 0.055\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 41 Batch 209/390 d_loss_real= 0.076, d_loss_fake= 0.022, g_loss 3.857, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 210/390 d_loss_real= 0.151, d_loss_fake= 0.025, g_loss 3.730, d_loss 0.088\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 211/390 d_loss_real= 0.072, d_loss_fake= 0.029, g_loss 3.682, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 212/390 d_loss_real= 0.127, d_loss_fake= 0.036, g_loss 3.627, d_loss 0.082\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41 Batch 213/390 d_loss_real= 0.092, d_loss_fake= 0.039, g_loss 3.663, d_loss 0.065\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41 Batch 214/390 d_loss_real= 0.112, d_loss_fake= 0.037, g_loss 3.625, d_loss 0.074\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41 Batch 215/390 d_loss_real= 0.183, d_loss_fake= 0.034, g_loss 3.746, d_loss 0.109\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 41 Batch 216/390 d_loss_real= 0.053, d_loss_fake= 0.032, g_loss 3.790, d_loss 0.042\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 217/390 d_loss_real= 0.133, d_loss_fake= 0.029, g_loss 3.687, d_loss 0.081\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 218/390 d_loss_real= 0.178, d_loss_fake= 0.036, g_loss 3.609, d_loss 0.107\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 219/390 d_loss_real= 0.051, d_loss_fake= 0.026, g_loss 3.879, d_loss 0.038\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 220/390 d_loss_real= 0.063, d_loss_fake= 0.037, g_loss 3.693, d_loss 0.050\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 221/390 d_loss_real= 0.118, d_loss_fake= 0.021, g_loss 4.038, d_loss 0.070\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 222/390 d_loss_real= 0.073, d_loss_fake= 0.024, g_loss 3.866, d_loss 0.049\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 223/390 d_loss_real= 0.054, d_loss_fake= 0.031, g_loss 3.658, d_loss 0.043\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 41 Batch 224/390 d_loss_real= 0.142, d_loss_fake= 0.029, g_loss 3.636, d_loss 0.085\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 225/390 d_loss_real= 0.049, d_loss_fake= 0.026, g_loss 3.776, d_loss 0.038\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41 Batch 226/390 d_loss_real= 0.178, d_loss_fake= 0.052, g_loss 3.291, d_loss 0.115\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 227/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 4.224, d_loss 0.010\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 228/390 d_loss_real= 0.085, d_loss_fake= 0.022, g_loss 4.075, d_loss 0.054\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 229/390 d_loss_real= 0.339, d_loss_fake= 0.022, g_loss 3.836, d_loss 0.181\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 41 Batch 230/390 d_loss_real= 0.006, d_loss_fake= 0.031, g_loss 3.578, d_loss 0.019\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 231/390 d_loss_real= 0.054, d_loss_fake= 0.039, g_loss 3.534, d_loss 0.047\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 41 Batch 232/390 d_loss_real= 0.045, d_loss_fake= 0.034, g_loss 3.650, d_loss 0.040\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 233/390 d_loss_real= 0.128, d_loss_fake= 0.033, g_loss 3.537, d_loss 0.081\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 234/390 d_loss_real= 0.001, d_loss_fake= 0.037, g_loss 3.718, d_loss 0.019\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 235/390 d_loss_real= 0.178, d_loss_fake= 0.033, g_loss 3.768, d_loss 0.105\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 236/390 d_loss_real= 0.024, d_loss_fake= 0.028, g_loss 3.764, d_loss 0.026\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 41 Batch 237/390 d_loss_real= 0.109, d_loss_fake= 0.028, g_loss 3.876, d_loss 0.069\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 238/390 d_loss_real= 0.339, d_loss_fake= 0.026, g_loss 3.814, d_loss 0.182\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 41 Batch 239/390 d_loss_real= 0.069, d_loss_fake= 0.032, g_loss 3.649, d_loss 0.051\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 240/390 d_loss_real= 0.081, d_loss_fake= 0.045, g_loss 3.432, d_loss 0.063\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 241/390 d_loss_real= 0.064, d_loss_fake= 0.043, g_loss 3.534, d_loss 0.054\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 242/390 d_loss_real= 0.145, d_loss_fake= 0.032, g_loss 3.694, d_loss 0.089\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 243/390 d_loss_real= 0.147, d_loss_fake= 0.029, g_loss 3.748, d_loss 0.088\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 244/390 d_loss_real= 0.097, d_loss_fake= 0.027, g_loss 3.723, d_loss 0.062\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 245/390 d_loss_real= 0.171, d_loss_fake= 0.031, g_loss 3.801, d_loss 0.101\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 41 Batch 246/390 d_loss_real= 0.125, d_loss_fake= 0.028, g_loss 3.968, d_loss 0.076\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 247/390 d_loss_real= 0.240, d_loss_fake= 0.030, g_loss 3.698, d_loss 0.135\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 248/390 d_loss_real= 0.152, d_loss_fake= 0.026, g_loss 3.796, d_loss 0.089\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 249/390 d_loss_real= 0.111, d_loss_fake= 0.024, g_loss 3.849, d_loss 0.067\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 250/390 d_loss_real= 0.071, d_loss_fake= 0.034, g_loss 3.630, d_loss 0.052\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 251/390 d_loss_real= 0.130, d_loss_fake= 0.059, g_loss 3.246, d_loss 0.094\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 41 Batch 252/390 d_loss_real= 0.063, d_loss_fake= 0.039, g_loss 3.797, d_loss 0.051\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 253/390 d_loss_real= 0.144, d_loss_fake= 0.022, g_loss 3.902, d_loss 0.083\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 254/390 d_loss_real= 0.136, d_loss_fake= 0.024, g_loss 4.067, d_loss 0.080\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 255/390 d_loss_real= 0.087, d_loss_fake= 0.022, g_loss 4.007, d_loss 0.055\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 256/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 4.017, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 257/390 d_loss_real= 0.099, d_loss_fake= 0.024, g_loss 3.799, d_loss 0.062\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 258/390 d_loss_real= 0.000, d_loss_fake= 0.026, g_loss 3.760, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 259/390 d_loss_real= 0.051, d_loss_fake= 0.027, g_loss 3.786, d_loss 0.039\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 41 Batch 260/390 d_loss_real= 0.136, d_loss_fake= 0.029, g_loss 3.607, d_loss 0.083\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 261/390 d_loss_real= 0.136, d_loss_fake= 0.030, g_loss 3.599, d_loss 0.083\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41 Batch 262/390 d_loss_real= 0.034, d_loss_fake= 0.032, g_loss 3.629, d_loss 0.033\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 263/390 d_loss_real= 0.196, d_loss_fake= 0.057, g_loss 3.282, d_loss 0.126\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 264/390 d_loss_real= 0.013, d_loss_fake= 0.056, g_loss 3.562, d_loss 0.035\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 265/390 d_loss_real= 0.102, d_loss_fake= 0.026, g_loss 3.938, d_loss 0.064\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 266/390 d_loss_real= 0.142, d_loss_fake= 0.023, g_loss 4.084, d_loss 0.083\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 41 Batch 267/390 d_loss_real= 0.209, d_loss_fake= 0.022, g_loss 3.977, d_loss 0.116\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41 Batch 268/390 d_loss_real= 0.068, d_loss_fake= 0.025, g_loss 3.820, d_loss 0.047\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 41 Batch 269/390 d_loss_real= 0.039, d_loss_fake= 0.025, g_loss 3.882, d_loss 0.032\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 270/390 d_loss_real= 0.115, d_loss_fake= 0.026, g_loss 3.658, d_loss 0.070\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 41 Batch 271/390 d_loss_real= 0.191, d_loss_fake= 0.031, g_loss 3.450, d_loss 0.111\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 272/390 d_loss_real= 0.087, d_loss_fake= 0.042, g_loss 3.373, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 273/390 d_loss_real= 0.006, d_loss_fake= 0.044, g_loss 3.336, d_loss 0.025\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 274/390 d_loss_real= 0.072, d_loss_fake= 0.043, g_loss 3.642, d_loss 0.058\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 41 Batch 275/390 d_loss_real= 0.065, d_loss_fake= 0.033, g_loss 3.622, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 276/390 d_loss_real= 0.060, d_loss_fake= 0.029, g_loss 3.698, d_loss 0.045\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 277/390 d_loss_real= 0.092, d_loss_fake= 0.027, g_loss 3.693, d_loss 0.059\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 278/390 d_loss_real= 0.057, d_loss_fake= 0.025, g_loss 3.751, d_loss 0.041\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 279/390 d_loss_real= 0.105, d_loss_fake= 0.029, g_loss 3.702, d_loss 0.067\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 280/390 d_loss_real= 0.110, d_loss_fake= 0.029, g_loss 3.702, d_loss 0.070\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 281/390 d_loss_real= 0.105, d_loss_fake= 0.031, g_loss 3.691, d_loss 0.068\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 282/390 d_loss_real= 0.302, d_loss_fake= 0.034, g_loss 3.454, d_loss 0.168\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 283/390 d_loss_real= 0.129, d_loss_fake= 0.036, g_loss 3.353, d_loss 0.083\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 41 Batch 284/390 d_loss_real= 0.163, d_loss_fake= 0.050, g_loss 3.194, d_loss 0.107\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 285/390 d_loss_real= 0.052, d_loss_fake= 0.047, g_loss 3.362, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 286/390 d_loss_real= 0.109, d_loss_fake= 0.037, g_loss 3.407, d_loss 0.073\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 41 Batch 287/390 d_loss_real= 0.000, d_loss_fake= 0.036, g_loss 3.570, d_loss 0.018\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 288/390 d_loss_real= 0.185, d_loss_fake= 0.033, g_loss 3.517, d_loss 0.109\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 289/390 d_loss_real= 0.115, d_loss_fake= 0.037, g_loss 3.492, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 290/390 d_loss_real= 0.199, d_loss_fake= 0.039, g_loss 3.343, d_loss 0.119\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 291/390 d_loss_real= 0.072, d_loss_fake= 0.043, g_loss 3.222, d_loss 0.058\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 292/390 d_loss_real= 0.070, d_loss_fake= 0.052, g_loss 3.127, d_loss 0.061\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 293/390 d_loss_real= 0.059, d_loss_fake= 0.050, g_loss 3.122, d_loss 0.055\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 294/390 d_loss_real= 0.219, d_loss_fake= 0.051, g_loss 3.094, d_loss 0.135\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 41 Batch 295/390 d_loss_real= 0.116, d_loss_fake= 0.051, g_loss 3.119, d_loss 0.083\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 296/390 d_loss_real= 0.057, d_loss_fake= 0.047, g_loss 3.278, d_loss 0.052\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 297/390 d_loss_real= 0.038, d_loss_fake= 0.045, g_loss 3.296, d_loss 0.041\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41 Batch 298/390 d_loss_real= 0.058, d_loss_fake= 0.040, g_loss 3.422, d_loss 0.049\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 299/390 d_loss_real= 0.019, d_loss_fake= 0.037, g_loss 3.467, d_loss 0.028\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 300/390 d_loss_real= 0.188, d_loss_fake= 0.037, g_loss 3.474, d_loss 0.112\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 301/390 d_loss_real= 0.006, d_loss_fake= 0.032, g_loss 3.534, d_loss 0.019\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 41 Batch 302/390 d_loss_real= 0.072, d_loss_fake= 0.032, g_loss 3.691, d_loss 0.052\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 41 Batch 303/390 d_loss_real= 0.057, d_loss_fake= 0.025, g_loss 3.898, d_loss 0.041\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41 Batch 304/390 d_loss_real= 0.110, d_loss_fake= 0.019, g_loss 4.169, d_loss 0.065\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 41 Batch 305/390 d_loss_real= 0.106, d_loss_fake= 0.016, g_loss 4.318, d_loss 0.061\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41 Batch 306/390 d_loss_real= 0.056, d_loss_fake= 0.015, g_loss 4.314, d_loss 0.035\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 307/390 d_loss_real= 0.077, d_loss_fake= 0.014, g_loss 4.376, d_loss 0.046\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41 Batch 308/390 d_loss_real= 0.000, d_loss_fake= 0.014, g_loss 4.405, d_loss 0.007\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 309/390 d_loss_real= 0.168, d_loss_fake= 0.015, g_loss 4.151, d_loss 0.091\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 41 Batch 310/390 d_loss_real= 0.046, d_loss_fake= 0.019, g_loss 3.977, d_loss 0.032\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41 Batch 311/390 d_loss_real= 0.225, d_loss_fake= 0.027, g_loss 3.632, d_loss 0.126\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 312/390 d_loss_real= 0.068, d_loss_fake= 0.053, g_loss 3.486, d_loss 0.060\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41 Batch 313/390 d_loss_real= 0.016, d_loss_fake= 0.036, g_loss 3.646, d_loss 0.026\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 41 Batch 314/390 d_loss_real= 0.082, d_loss_fake= 0.030, g_loss 3.725, d_loss 0.056\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 315/390 d_loss_real= 0.086, d_loss_fake= 0.036, g_loss 3.499, d_loss 0.061\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 316/390 d_loss_real= 0.010, d_loss_fake= 0.037, g_loss 3.514, d_loss 0.023\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 41 Batch 317/390 d_loss_real= 0.036, d_loss_fake= 0.042, g_loss 3.353, d_loss 0.039\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 41 Batch 318/390 d_loss_real= 0.029, d_loss_fake= 0.039, g_loss 3.493, d_loss 0.034\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 41 Batch 319/390 d_loss_real= 0.000, d_loss_fake= 0.035, g_loss 3.567, d_loss 0.018\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 320/390 d_loss_real= 0.148, d_loss_fake= 0.035, g_loss 3.647, d_loss 0.092\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 321/390 d_loss_real= 0.128, d_loss_fake= 0.033, g_loss 3.588, d_loss 0.081\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 322/390 d_loss_real= 0.057, d_loss_fake= 0.037, g_loss 3.549, d_loss 0.047\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 323/390 d_loss_real= 0.135, d_loss_fake= 0.038, g_loss 3.502, d_loss 0.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 324/390 d_loss_real= 0.001, d_loss_fake= 0.035, g_loss 3.572, d_loss 0.018\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 325/390 d_loss_real= 0.119, d_loss_fake= 0.034, g_loss 3.611, d_loss 0.077\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 326/390 d_loss_real= 0.192, d_loss_fake= 0.034, g_loss 3.523, d_loss 0.113\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 327/390 d_loss_real= 0.011, d_loss_fake= 0.038, g_loss 3.435, d_loss 0.025\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 41 Batch 328/390 d_loss_real= 0.154, d_loss_fake= 0.049, g_loss 3.334, d_loss 0.101\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 41 Batch 329/390 d_loss_real= 0.181, d_loss_fake= 0.049, g_loss 3.405, d_loss 0.115\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 330/390 d_loss_real= 0.071, d_loss_fake= 0.036, g_loss 3.589, d_loss 0.054\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 331/390 d_loss_real= 0.021, d_loss_fake= 0.036, g_loss 3.706, d_loss 0.029\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 41 Batch 332/390 d_loss_real= 0.141, d_loss_fake= 0.027, g_loss 3.909, d_loss 0.084\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 333/390 d_loss_real= 0.001, d_loss_fake= 0.025, g_loss 3.989, d_loss 0.013\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 41 Batch 334/390 d_loss_real= 0.384, d_loss_fake= 0.027, g_loss 3.791, d_loss 0.206\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 335/390 d_loss_real= 0.053, d_loss_fake= 0.025, g_loss 4.024, d_loss 0.039\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 41 Batch 336/390 d_loss_real= 0.077, d_loss_fake= 0.011, g_loss 4.857, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 337/390 d_loss_real= 0.221, d_loss_fake= 0.104, g_loss 3.456, d_loss 0.163\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 338/390 d_loss_real= 0.098, d_loss_fake= 0.005, g_loss 5.585, d_loss 0.051\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 339/390 d_loss_real= 0.103, d_loss_fake= 0.006, g_loss 5.172, d_loss 0.055\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 41 Batch 340/390 d_loss_real= 0.127, d_loss_fake= 0.010, g_loss 4.605, d_loss 0.069\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 41 Batch 341/390 d_loss_real= 0.000, d_loss_fake= 0.017, g_loss 4.211, d_loss 0.008\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 41 Batch 342/390 d_loss_real= 0.170, d_loss_fake= 0.094, g_loss 3.734, d_loss 0.132\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 41 Batch 343/390 d_loss_real= 0.065, d_loss_fake= 0.079, g_loss 4.169, d_loss 0.072\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 344/390 d_loss_real= 0.023, d_loss_fake= 0.016, g_loss 4.255, d_loss 0.020\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 345/390 d_loss_real= 0.177, d_loss_fake= 0.017, g_loss 4.305, d_loss 0.097\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 41 Batch 346/390 d_loss_real= 0.127, d_loss_fake= 0.018, g_loss 4.097, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 347/390 d_loss_real= 0.241, d_loss_fake= 0.017, g_loss 4.005, d_loss 0.129\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 41 Batch 348/390 d_loss_real= 0.260, d_loss_fake= 0.025, g_loss 3.783, d_loss 0.142\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 41 Batch 349/390 d_loss_real= 0.368, d_loss_fake= 0.032, g_loss 3.541, d_loss 0.200\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 41 Batch 350/390 d_loss_real= 0.069, d_loss_fake= 0.042, g_loss 3.252, d_loss 0.056\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 41 Batch 351/390 d_loss_real= 0.083, d_loss_fake= 0.054, g_loss 3.001, d_loss 0.069\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 352/390 d_loss_real= 0.077, d_loss_fake= 0.085, g_loss 2.639, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 353/390 d_loss_real= 0.074, d_loss_fake= 0.159, g_loss 2.734, d_loss 0.117\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 354/390 d_loss_real= 0.071, d_loss_fake= 0.069, g_loss 3.434, d_loss 0.070\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 355/390 d_loss_real= 0.049, d_loss_fake= 0.027, g_loss 3.993, d_loss 0.038\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 41 Batch 356/390 d_loss_real= 0.155, d_loss_fake= 0.018, g_loss 4.345, d_loss 0.086\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 357/390 d_loss_real= 0.099, d_loss_fake= 0.014, g_loss 4.343, d_loss 0.057\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41 Batch 358/390 d_loss_real= 0.190, d_loss_fake= 0.014, g_loss 4.358, d_loss 0.102\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 359/390 d_loss_real= 0.150, d_loss_fake= 0.013, g_loss 4.393, d_loss 0.081\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 360/390 d_loss_real= 0.002, d_loss_fake= 0.014, g_loss 4.323, d_loss 0.008\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 361/390 d_loss_real= 0.000, d_loss_fake= 0.015, g_loss 4.298, d_loss 0.007\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 41 Batch 362/390 d_loss_real= 0.090, d_loss_fake= 0.016, g_loss 4.127, d_loss 0.053\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 41 Batch 363/390 d_loss_real= 0.103, d_loss_fake= 0.022, g_loss 3.726, d_loss 0.063\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 364/390 d_loss_real= 0.118, d_loss_fake= 0.093, g_loss 3.806, d_loss 0.106\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 41 Batch 365/390 d_loss_real= 0.001, d_loss_fake= 0.016, g_loss 4.555, d_loss 0.009\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 366/390 d_loss_real= 0.007, d_loss_fake= 0.012, g_loss 4.576, d_loss 0.009\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 367/390 d_loss_real= 0.000, d_loss_fake= 0.010, g_loss 4.679, d_loss 0.005\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 368/390 d_loss_real= 0.021, d_loss_fake= 0.011, g_loss 4.607, d_loss 0.016\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 369/390 d_loss_real= 0.090, d_loss_fake= 0.011, g_loss 4.526, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 370/390 d_loss_real= 0.215, d_loss_fake= 0.012, g_loss 4.502, d_loss 0.113\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 371/390 d_loss_real= 0.099, d_loss_fake= 0.013, g_loss 4.416, d_loss 0.056\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 41 Batch 372/390 d_loss_real= 0.179, d_loss_fake= 0.015, g_loss 4.216, d_loss 0.097\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 373/390 d_loss_real= 0.026, d_loss_fake= 0.016, g_loss 4.194, d_loss 0.021\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 374/390 d_loss_real= 0.057, d_loss_fake= 0.019, g_loss 4.109, d_loss 0.038\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 375/390 d_loss_real= 0.141, d_loss_fake= 0.018, g_loss 3.993, d_loss 0.080\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 41 Batch 376/390 d_loss_real= 0.106, d_loss_fake= 0.021, g_loss 3.867, d_loss 0.064\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 377/390 d_loss_real= 0.061, d_loss_fake= 0.025, g_loss 3.687, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41 Batch 378/390 d_loss_real= 0.105, d_loss_fake= 0.028, g_loss 3.552, d_loss 0.067\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41 Batch 379/390 d_loss_real= 0.000, d_loss_fake= 0.046, g_loss 3.307, d_loss 0.023\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 380/390 d_loss_real= 0.051, d_loss_fake= 0.162, g_loss 3.333, d_loss 0.106\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41 Batch 381/390 d_loss_real= 0.012, d_loss_fake= 0.035, g_loss 3.535, d_loss 0.023\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 382/390 d_loss_real= 0.115, d_loss_fake= 0.033, g_loss 3.608, d_loss 0.074\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 383/390 d_loss_real= 0.057, d_loss_fake= 0.035, g_loss 3.531, d_loss 0.046\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 41 Batch 384/390 d_loss_real= 0.124, d_loss_fake= 0.037, g_loss 3.443, d_loss 0.080\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41 Batch 385/390 d_loss_real= 0.044, d_loss_fake= 0.039, g_loss 3.357, d_loss 0.042\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 386/390 d_loss_real= 0.122, d_loss_fake= 0.042, g_loss 3.272, d_loss 0.082\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 41 Batch 387/390 d_loss_real= 0.102, d_loss_fake= 0.044, g_loss 3.244, d_loss 0.073\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 41 Batch 388/390 d_loss_real= 0.090, d_loss_fake= 0.043, g_loss 3.255, d_loss 0.067\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41 Batch 389/390 d_loss_real= 0.022, d_loss_fake= 0.045, g_loss 3.257, d_loss 0.033\n",
            "2/2 [==============================] - 0s 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41 Batch 390/390 d_loss_real= 0.189, d_loss_fake= 0.042, g_loss 3.301, d_loss 0.115\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42 Batch 1/390 d_loss_real= 0.168, d_loss_fake= 0.039, g_loss 3.340, d_loss 0.104\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 42 Batch 2/390 d_loss_real= 0.067, d_loss_fake= 0.037, g_loss 3.392, d_loss 0.052\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 3/390 d_loss_real= 0.026, d_loss_fake= 0.036, g_loss 3.404, d_loss 0.031\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 4/390 d_loss_real= 0.104, d_loss_fake= 0.035, g_loss 3.396, d_loss 0.070\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 5/390 d_loss_real= 0.053, d_loss_fake= 0.038, g_loss 3.367, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 6/390 d_loss_real= 0.000, d_loss_fake= 0.040, g_loss 3.336, d_loss 0.020\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 42 Batch 7/390 d_loss_real= 0.107, d_loss_fake= 0.064, g_loss 3.228, d_loss 0.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 8/390 d_loss_real= 0.046, d_loss_fake= 0.103, g_loss 3.204, d_loss 0.075\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42 Batch 9/390 d_loss_real= 0.002, d_loss_fake= 0.069, g_loss 3.772, d_loss 0.035\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 10/390 d_loss_real= 0.003, d_loss_fake= 0.022, g_loss 4.232, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 11/390 d_loss_real= 0.060, d_loss_fake= 0.016, g_loss 4.357, d_loss 0.038\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 12/390 d_loss_real= 0.201, d_loss_fake= 0.014, g_loss 4.423, d_loss 0.108\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 42 Batch 13/390 d_loss_real= 0.151, d_loss_fake= 0.015, g_loss 4.422, d_loss 0.083\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 42 Batch 14/390 d_loss_real= 0.053, d_loss_fake= 0.015, g_loss 4.272, d_loss 0.034\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 42 Batch 15/390 d_loss_real= 0.129, d_loss_fake= 0.018, g_loss 4.027, d_loss 0.073\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 16/390 d_loss_real= 0.166, d_loss_fake= 0.026, g_loss 3.701, d_loss 0.096\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 42 Batch 17/390 d_loss_real= 0.042, d_loss_fake= 0.132, g_loss 3.494, d_loss 0.087\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 18/390 d_loss_real= 0.061, d_loss_fake= 0.112, g_loss 3.881, d_loss 0.087\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 19/390 d_loss_real= 0.143, d_loss_fake= 0.029, g_loss 4.839, d_loss 0.086\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 20/390 d_loss_real= 0.026, d_loss_fake= 0.009, g_loss 5.252, d_loss 0.017\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 21/390 d_loss_real= 0.344, d_loss_fake= 0.006, g_loss 5.311, d_loss 0.175\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 42 Batch 22/390 d_loss_real= 0.098, d_loss_fake= 0.006, g_loss 5.273, d_loss 0.052\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 42 Batch 23/390 d_loss_real= 0.198, d_loss_fake= 0.007, g_loss 5.001, d_loss 0.103\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 24/390 d_loss_real= 0.136, d_loss_fake= 0.009, g_loss 4.854, d_loss 0.072\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 42 Batch 25/390 d_loss_real= 0.048, d_loss_fake= 0.011, g_loss 4.497, d_loss 0.029\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 42 Batch 26/390 d_loss_real= 0.062, d_loss_fake= 0.016, g_loss 4.140, d_loss 0.039\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 27/390 d_loss_real= 0.005, d_loss_fake= 0.032, g_loss 3.379, d_loss 0.018\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 28/390 d_loss_real= 0.107, d_loss_fake= 0.881, g_loss 4.696, d_loss 0.494\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 29/390 d_loss_real= 0.005, d_loss_fake= 0.007, g_loss 5.370, d_loss 0.006\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 30/390 d_loss_real= 0.201, d_loss_fake= 0.004, g_loss 5.587, d_loss 0.103\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42 Batch 31/390 d_loss_real= 0.991, d_loss_fake= 0.004, g_loss 5.550, d_loss 0.497\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 32/390 d_loss_real= 1.280, d_loss_fake= 0.005, g_loss 5.176, d_loss 0.642\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 33/390 d_loss_real= 0.814, d_loss_fake= 0.007, g_loss 4.720, d_loss 0.411\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 34/390 d_loss_real= 0.512, d_loss_fake= 0.012, g_loss 4.323, d_loss 0.262\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 42 Batch 35/390 d_loss_real= 0.400, d_loss_fake= 0.018, g_loss 3.880, d_loss 0.209\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42 Batch 36/390 d_loss_real= 0.215, d_loss_fake= 0.026, g_loss 3.479, d_loss 0.120\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 37/390 d_loss_real= 0.176, d_loss_fake= 0.039, g_loss 3.228, d_loss 0.108\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 42 Batch 38/390 d_loss_real= 0.046, d_loss_fake= 0.052, g_loss 2.850, d_loss 0.049\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42 Batch 39/390 d_loss_real= 0.050, d_loss_fake= 0.126, g_loss 2.672, d_loss 0.088\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 42 Batch 40/390 d_loss_real= 0.000, d_loss_fake= 0.145, g_loss 2.457, d_loss 0.072\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 41/390 d_loss_real= 0.095, d_loss_fake= 0.650, g_loss 2.730, d_loss 0.373\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 42/390 d_loss_real= 0.024, d_loss_fake= 0.099, g_loss 3.219, d_loss 0.061\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 42 Batch 43/390 d_loss_real= 0.020, d_loss_fake= 0.037, g_loss 3.474, d_loss 0.028\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 44/390 d_loss_real= 0.110, d_loss_fake= 0.031, g_loss 3.576, d_loss 0.071\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 45/390 d_loss_real= 0.308, d_loss_fake= 0.030, g_loss 3.600, d_loss 0.169\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 46/390 d_loss_real= 0.330, d_loss_fake= 0.029, g_loss 3.535, d_loss 0.179\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 42 Batch 47/390 d_loss_real= 0.141, d_loss_fake= 0.032, g_loss 3.472, d_loss 0.086\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 48/390 d_loss_real= 0.314, d_loss_fake= 0.035, g_loss 3.364, d_loss 0.174\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 49/390 d_loss_real= 0.268, d_loss_fake= 0.040, g_loss 3.213, d_loss 0.154\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 50/390 d_loss_real= 0.460, d_loss_fake= 0.047, g_loss 3.017, d_loss 0.253\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 51/390 d_loss_real= 0.233, d_loss_fake= 0.057, g_loss 2.847, d_loss 0.145\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 52/390 d_loss_real= 0.252, d_loss_fake= 0.067, g_loss 2.678, d_loss 0.159\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 53/390 d_loss_real= 0.130, d_loss_fake= 0.078, g_loss 2.550, d_loss 0.104\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 42 Batch 54/390 d_loss_real= 0.047, d_loss_fake= 0.088, g_loss 2.450, d_loss 0.067\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 55/390 d_loss_real= 0.088, d_loss_fake= 0.098, g_loss 2.420, d_loss 0.093\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 56/390 d_loss_real= 0.120, d_loss_fake= 0.099, g_loss 2.409, d_loss 0.109\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 42 Batch 57/390 d_loss_real= 0.000, d_loss_fake= 0.102, g_loss 2.448, d_loss 0.051\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 42 Batch 58/390 d_loss_real= 0.001, d_loss_fake= 0.085, g_loss 2.596, d_loss 0.043\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 42 Batch 59/390 d_loss_real= 0.109, d_loss_fake= 0.074, g_loss 2.770, d_loss 0.091\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42 Batch 60/390 d_loss_real= 0.055, d_loss_fake= 0.061, g_loss 2.921, d_loss 0.058\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 42 Batch 61/390 d_loss_real= 0.013, d_loss_fake= 0.050, g_loss 3.118, d_loss 0.031\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 62/390 d_loss_real= 0.024, d_loss_fake= 0.042, g_loss 3.293, d_loss 0.033\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 42 Batch 63/390 d_loss_real= 0.104, d_loss_fake= 0.036, g_loss 3.415, d_loss 0.070\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 64/390 d_loss_real= 0.015, d_loss_fake= 0.032, g_loss 3.535, d_loss 0.024\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42 Batch 65/390 d_loss_real= 0.074, d_loss_fake= 0.029, g_loss 3.609, d_loss 0.052\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 66/390 d_loss_real= 0.144, d_loss_fake= 0.028, g_loss 3.652, d_loss 0.086\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42 Batch 67/390 d_loss_real= 0.106, d_loss_fake= 0.028, g_loss 3.646, d_loss 0.067\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 68/390 d_loss_real= 0.000, d_loss_fake= 0.028, g_loss 3.659, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 69/390 d_loss_real= 0.037, d_loss_fake= 0.027, g_loss 3.680, d_loss 0.032\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 42 Batch 70/390 d_loss_real= 0.059, d_loss_fake= 0.029, g_loss 3.622, d_loss 0.044\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 71/390 d_loss_real= 0.056, d_loss_fake= 0.027, g_loss 3.629, d_loss 0.042\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 72/390 d_loss_real= 0.060, d_loss_fake= 0.030, g_loss 3.571, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 73/390 d_loss_real= 0.066, d_loss_fake= 0.030, g_loss 3.540, d_loss 0.048\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 42 Batch 74/390 d_loss_real= 0.000, d_loss_fake= 0.034, g_loss 3.489, d_loss 0.017\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 42 Batch 75/390 d_loss_real= 0.036, d_loss_fake= 0.032, g_loss 3.446, d_loss 0.034\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 76/390 d_loss_real= 0.139, d_loss_fake= 0.037, g_loss 3.359, d_loss 0.088\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42 Batch 77/390 d_loss_real= 0.001, d_loss_fake= 0.039, g_loss 3.319, d_loss 0.020\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 42 Batch 78/390 d_loss_real= 0.017, d_loss_fake= 0.044, g_loss 3.251, d_loss 0.031\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 79/390 d_loss_real= 0.040, d_loss_fake= 0.052, g_loss 3.243, d_loss 0.046\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 42 Batch 80/390 d_loss_real= 0.032, d_loss_fake= 0.050, g_loss 3.212, d_loss 0.041\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 81/390 d_loss_real= 0.080, d_loss_fake= 0.052, g_loss 3.172, d_loss 0.066\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 82/390 d_loss_real= 0.000, d_loss_fake= 0.053, g_loss 3.233, d_loss 0.027\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42 Batch 83/390 d_loss_real= 0.074, d_loss_fake= 0.048, g_loss 3.276, d_loss 0.061\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 42 Batch 84/390 d_loss_real= 0.121, d_loss_fake= 0.044, g_loss 3.294, d_loss 0.082\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 85/390 d_loss_real= 0.098, d_loss_fake= 0.040, g_loss 3.299, d_loss 0.069\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 86/390 d_loss_real= 0.054, d_loss_fake= 0.042, g_loss 3.336, d_loss 0.048\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 87/390 d_loss_real= 0.064, d_loss_fake= 0.041, g_loss 3.332, d_loss 0.052\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 88/390 d_loss_real= 0.000, d_loss_fake= 0.037, g_loss 3.449, d_loss 0.018\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 89/390 d_loss_real= 0.134, d_loss_fake= 0.035, g_loss 3.529, d_loss 0.085\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 42 Batch 90/390 d_loss_real= 0.120, d_loss_fake= 0.030, g_loss 3.590, d_loss 0.075\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 91/390 d_loss_real= 0.000, d_loss_fake= 0.031, g_loss 3.663, d_loss 0.015\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42 Batch 92/390 d_loss_real= 0.061, d_loss_fake= 0.032, g_loss 3.684, d_loss 0.046\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 93/390 d_loss_real= 0.058, d_loss_fake= 0.028, g_loss 3.705, d_loss 0.043\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 42 Batch 94/390 d_loss_real= 0.010, d_loss_fake= 0.030, g_loss 3.761, d_loss 0.020\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 42 Batch 95/390 d_loss_real= 0.122, d_loss_fake= 0.029, g_loss 3.706, d_loss 0.075\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 96/390 d_loss_real= 0.062, d_loss_fake= 0.028, g_loss 3.664, d_loss 0.045\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42 Batch 97/390 d_loss_real= 0.000, d_loss_fake= 0.028, g_loss 3.782, d_loss 0.014\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 98/390 d_loss_real= 0.059, d_loss_fake= 0.028, g_loss 3.713, d_loss 0.044\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 42 Batch 99/390 d_loss_real= 0.213, d_loss_fake= 0.029, g_loss 3.583, d_loss 0.121\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 42 Batch 100/390 d_loss_real= 0.186, d_loss_fake= 0.041, g_loss 3.391, d_loss 0.113\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 42 Batch 101/390 d_loss_real= 0.001, d_loss_fake= 0.048, g_loss 3.180, d_loss 0.024\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 102/390 d_loss_real= 0.072, d_loss_fake= 0.080, g_loss 3.211, d_loss 0.076\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 103/390 d_loss_real= 0.168, d_loss_fake= 0.085, g_loss 3.165, d_loss 0.127\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 104/390 d_loss_real= 0.145, d_loss_fake= 0.055, g_loss 3.523, d_loss 0.100\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 42 Batch 105/390 d_loss_real= 0.026, d_loss_fake= 0.033, g_loss 3.829, d_loss 0.029\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 106/390 d_loss_real= 0.098, d_loss_fake= 0.024, g_loss 3.944, d_loss 0.061\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 107/390 d_loss_real= 0.106, d_loss_fake= 0.023, g_loss 3.994, d_loss 0.064\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 108/390 d_loss_real= 0.220, d_loss_fake= 0.021, g_loss 3.945, d_loss 0.121\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 42 Batch 109/390 d_loss_real= 0.163, d_loss_fake= 0.024, g_loss 3.825, d_loss 0.093\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 42 Batch 110/390 d_loss_real= 0.128, d_loss_fake= 0.028, g_loss 3.565, d_loss 0.078\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 111/390 d_loss_real= 0.083, d_loss_fake= 0.048, g_loss 3.277, d_loss 0.065\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 112/390 d_loss_real= 0.173, d_loss_fake= 0.056, g_loss 3.154, d_loss 0.114\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 113/390 d_loss_real= 0.187, d_loss_fake= 0.058, g_loss 3.379, d_loss 0.122\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 42 Batch 114/390 d_loss_real= 0.199, d_loss_fake= 0.028, g_loss 3.866, d_loss 0.113\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 42 Batch 115/390 d_loss_real= 0.087, d_loss_fake= 0.031, g_loss 3.757, d_loss 0.059\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42 Batch 116/390 d_loss_real= 0.117, d_loss_fake= 0.022, g_loss 3.990, d_loss 0.069\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42 Batch 117/390 d_loss_real= 0.134, d_loss_fake= 0.020, g_loss 4.046, d_loss 0.077\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 118/390 d_loss_real= 0.001, d_loss_fake= 0.020, g_loss 4.062, d_loss 0.011\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42 Batch 119/390 d_loss_real= 0.070, d_loss_fake= 0.018, g_loss 4.171, d_loss 0.044\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 42 Batch 120/390 d_loss_real= 0.361, d_loss_fake= 0.018, g_loss 4.026, d_loss 0.189\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 121/390 d_loss_real= 0.082, d_loss_fake= 0.022, g_loss 3.895, d_loss 0.052\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 122/390 d_loss_real= 0.350, d_loss_fake= 0.030, g_loss 3.348, d_loss 0.190\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 123/390 d_loss_real= 0.215, d_loss_fake= 0.052, g_loss 3.062, d_loss 0.134\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 42 Batch 124/390 d_loss_real= 0.069, d_loss_fake= 0.037, g_loss 3.599, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 125/390 d_loss_real= 0.071, d_loss_fake= 0.026, g_loss 3.794, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 126/390 d_loss_real= 0.251, d_loss_fake= 0.030, g_loss 3.591, d_loss 0.141\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42 Batch 127/390 d_loss_real= 0.000, d_loss_fake= 0.052, g_loss 3.396, d_loss 0.026\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42 Batch 128/390 d_loss_real= 0.147, d_loss_fake= 0.030, g_loss 3.922, d_loss 0.088\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42 Batch 129/390 d_loss_real= 0.060, d_loss_fake= 0.021, g_loss 4.173, d_loss 0.040\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 130/390 d_loss_real= 0.070, d_loss_fake= 0.014, g_loss 4.436, d_loss 0.042\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 42 Batch 131/390 d_loss_real= 0.085, d_loss_fake= 0.012, g_loss 4.492, d_loss 0.049\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42 Batch 132/390 d_loss_real= 0.111, d_loss_fake= 0.012, g_loss 4.583, d_loss 0.061\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42 Batch 133/390 d_loss_real= 0.145, d_loss_fake= 0.012, g_loss 4.536, d_loss 0.078\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 134/390 d_loss_real= 0.179, d_loss_fake= 0.012, g_loss 4.462, d_loss 0.095\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 135/390 d_loss_real= 0.107, d_loss_fake= 0.014, g_loss 4.363, d_loss 0.061\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 136/390 d_loss_real= 0.063, d_loss_fake= 0.014, g_loss 4.300, d_loss 0.038\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42 Batch 137/390 d_loss_real= 0.090, d_loss_fake= 0.015, g_loss 4.181, d_loss 0.052\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 138/390 d_loss_real= 0.195, d_loss_fake= 0.016, g_loss 4.106, d_loss 0.106\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42 Batch 139/390 d_loss_real= 0.001, d_loss_fake= 0.021, g_loss 3.964, d_loss 0.011\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 42 Batch 140/390 d_loss_real= 0.052, d_loss_fake= 0.022, g_loss 3.921, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 141/390 d_loss_real= 0.044, d_loss_fake= 0.023, g_loss 3.958, d_loss 0.033\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 142/390 d_loss_real= 0.106, d_loss_fake= 0.021, g_loss 3.975, d_loss 0.063\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 42 Batch 143/390 d_loss_real= 0.084, d_loss_fake= 0.024, g_loss 3.927, d_loss 0.054\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 42 Batch 144/390 d_loss_real= 0.082, d_loss_fake= 0.023, g_loss 4.017, d_loss 0.053\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 42 Batch 145/390 d_loss_real= 0.052, d_loss_fake= 0.025, g_loss 4.043, d_loss 0.038\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42 Batch 146/390 d_loss_real= 0.076, d_loss_fake= 0.023, g_loss 4.077, d_loss 0.049\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 42 Batch 147/390 d_loss_real= 0.109, d_loss_fake= 0.020, g_loss 4.193, d_loss 0.065\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42 Batch 148/390 d_loss_real= 0.121, d_loss_fake= 0.020, g_loss 4.334, d_loss 0.071\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 149/390 d_loss_real= 0.018, d_loss_fake= 0.018, g_loss 4.271, d_loss 0.018\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 42 Batch 150/390 d_loss_real= 0.018, d_loss_fake= 0.022, g_loss 4.290, d_loss 0.020\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 151/390 d_loss_real= 0.001, d_loss_fake= 0.022, g_loss 4.158, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 152/390 d_loss_real= 0.000, d_loss_fake= 0.017, g_loss 4.202, d_loss 0.009\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 42 Batch 153/390 d_loss_real= 0.033, d_loss_fake= 0.024, g_loss 4.186, d_loss 0.028\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 154/390 d_loss_real= 0.067, d_loss_fake= 0.025, g_loss 4.092, d_loss 0.046\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 155/390 d_loss_real= 0.121, d_loss_fake= 0.028, g_loss 3.900, d_loss 0.074\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 42 Batch 156/390 d_loss_real= 0.036, d_loss_fake= 0.039, g_loss 3.716, d_loss 0.037\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 157/390 d_loss_real= 0.074, d_loss_fake= 0.037, g_loss 3.582, d_loss 0.055\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 158/390 d_loss_real= 0.063, d_loss_fake= 0.053, g_loss 3.545, d_loss 0.058\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 159/390 d_loss_real= 0.093, d_loss_fake= 0.070, g_loss 3.216, d_loss 0.082\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 42 Batch 160/390 d_loss_real= 0.064, d_loss_fake= 0.065, g_loss 3.235, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 161/390 d_loss_real= 0.009, d_loss_fake= 0.074, g_loss 3.447, d_loss 0.041\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 162/390 d_loss_real= 0.060, d_loss_fake= 0.054, g_loss 3.440, d_loss 0.057\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 163/390 d_loss_real= 0.070, d_loss_fake= 0.050, g_loss 3.407, d_loss 0.060\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 164/390 d_loss_real= 0.000, d_loss_fake= 0.055, g_loss 3.342, d_loss 0.027\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 165/390 d_loss_real= 0.067, d_loss_fake= 0.052, g_loss 3.422, d_loss 0.060\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 166/390 d_loss_real= 0.079, d_loss_fake= 0.050, g_loss 3.238, d_loss 0.064\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42 Batch 167/390 d_loss_real= 0.004, d_loss_fake= 0.052, g_loss 3.412, d_loss 0.028\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 42 Batch 168/390 d_loss_real= 0.174, d_loss_fake= 0.047, g_loss 3.423, d_loss 0.110\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 169/390 d_loss_real= 0.064, d_loss_fake= 0.041, g_loss 3.520, d_loss 0.052\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 42 Batch 170/390 d_loss_real= 0.102, d_loss_fake= 0.038, g_loss 3.618, d_loss 0.070\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 171/390 d_loss_real= 0.063, d_loss_fake= 0.033, g_loss 3.688, d_loss 0.048\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 172/390 d_loss_real= 0.039, d_loss_fake= 0.028, g_loss 3.791, d_loss 0.033\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42 Batch 173/390 d_loss_real= 0.046, d_loss_fake= 0.026, g_loss 3.838, d_loss 0.036\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42 Batch 174/390 d_loss_real= 0.190, d_loss_fake= 0.026, g_loss 3.775, d_loss 0.108\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42 Batch 175/390 d_loss_real= 0.176, d_loss_fake= 0.027, g_loss 3.662, d_loss 0.101\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 176/390 d_loss_real= 0.196, d_loss_fake= 0.035, g_loss 3.387, d_loss 0.116\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 177/390 d_loss_real= 0.014, d_loss_fake= 0.050, g_loss 3.369, d_loss 0.032\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 42 Batch 178/390 d_loss_real= 0.041, d_loss_fake= 0.051, g_loss 3.222, d_loss 0.046\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 42 Batch 179/390 d_loss_real= 0.024, d_loss_fake= 0.059, g_loss 3.290, d_loss 0.042\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 180/390 d_loss_real= 0.252, d_loss_fake= 0.050, g_loss 3.474, d_loss 0.151\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 181/390 d_loss_real= 0.122, d_loss_fake= 0.042, g_loss 3.533, d_loss 0.082\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 42 Batch 182/390 d_loss_real= 0.077, d_loss_fake= 0.034, g_loss 3.745, d_loss 0.055\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 42 Batch 183/390 d_loss_real= 0.119, d_loss_fake= 0.024, g_loss 3.860, d_loss 0.072\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42 Batch 184/390 d_loss_real= 0.160, d_loss_fake= 0.022, g_loss 3.836, d_loss 0.091\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 42 Batch 185/390 d_loss_real= 0.079, d_loss_fake= 0.024, g_loss 3.837, d_loss 0.052\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 186/390 d_loss_real= 0.083, d_loss_fake= 0.028, g_loss 3.891, d_loss 0.056\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 42 Batch 187/390 d_loss_real= 0.148, d_loss_fake= 0.023, g_loss 3.784, d_loss 0.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 188/390 d_loss_real= 0.081, d_loss_fake= 0.030, g_loss 3.782, d_loss 0.055\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 42 Batch 189/390 d_loss_real= 0.078, d_loss_fake= 0.028, g_loss 3.868, d_loss 0.053\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 42 Batch 190/390 d_loss_real= 0.103, d_loss_fake= 0.024, g_loss 3.851, d_loss 0.063\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 191/390 d_loss_real= 0.179, d_loss_fake= 0.022, g_loss 3.886, d_loss 0.100\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42 Batch 192/390 d_loss_real= 0.004, d_loss_fake= 0.021, g_loss 3.956, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 193/390 d_loss_real= 0.009, d_loss_fake= 0.023, g_loss 3.873, d_loss 0.016\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 194/390 d_loss_real= 0.164, d_loss_fake= 0.024, g_loss 3.761, d_loss 0.094\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 195/390 d_loss_real= 0.125, d_loss_fake= 0.055, g_loss 3.362, d_loss 0.090\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 42 Batch 196/390 d_loss_real= 0.108, d_loss_fake= 0.066, g_loss 3.468, d_loss 0.087\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 197/390 d_loss_real= 0.088, d_loss_fake= 0.044, g_loss 3.544, d_loss 0.066\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 42 Batch 198/390 d_loss_real= 0.183, d_loss_fake= 0.024, g_loss 3.886, d_loss 0.103\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 199/390 d_loss_real= 0.339, d_loss_fake= 0.025, g_loss 3.827, d_loss 0.182\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 42 Batch 200/390 d_loss_real= 0.196, d_loss_fake= 0.027, g_loss 3.827, d_loss 0.111\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 201/390 d_loss_real= 0.161, d_loss_fake= 0.023, g_loss 3.819, d_loss 0.092\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 42 Batch 202/390 d_loss_real= 0.117, d_loss_fake= 0.032, g_loss 3.612, d_loss 0.074\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 203/390 d_loss_real= 0.112, d_loss_fake= 0.035, g_loss 3.498, d_loss 0.073\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 204/390 d_loss_real= 0.066, d_loss_fake= 0.029, g_loss 3.645, d_loss 0.047\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 205/390 d_loss_real= 0.145, d_loss_fake= 0.039, g_loss 3.534, d_loss 0.092\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 206/390 d_loss_real= 0.216, d_loss_fake= 0.031, g_loss 3.608, d_loss 0.124\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42 Batch 207/390 d_loss_real= 0.264, d_loss_fake= 0.035, g_loss 3.520, d_loss 0.150\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 42 Batch 208/390 d_loss_real= 0.162, d_loss_fake= 0.037, g_loss 3.517, d_loss 0.099\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 209/390 d_loss_real= 0.135, d_loss_fake= 0.035, g_loss 3.583, d_loss 0.085\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42 Batch 210/390 d_loss_real= 0.121, d_loss_fake= 0.032, g_loss 3.640, d_loss 0.077\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 211/390 d_loss_real= 0.245, d_loss_fake= 0.030, g_loss 3.512, d_loss 0.138\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42 Batch 212/390 d_loss_real= 0.055, d_loss_fake= 0.032, g_loss 3.550, d_loss 0.044\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 213/390 d_loss_real= 0.121, d_loss_fake= 0.030, g_loss 3.570, d_loss 0.075\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 214/390 d_loss_real= 0.088, d_loss_fake= 0.031, g_loss 3.462, d_loss 0.060\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 42 Batch 215/390 d_loss_real= 0.057, d_loss_fake= 0.035, g_loss 3.406, d_loss 0.046\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 216/390 d_loss_real= 0.019, d_loss_fake= 0.040, g_loss 3.388, d_loss 0.029\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42 Batch 217/390 d_loss_real= 0.140, d_loss_fake= 0.036, g_loss 3.356, d_loss 0.088\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42 Batch 218/390 d_loss_real= 0.019, d_loss_fake= 0.038, g_loss 3.490, d_loss 0.028\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42 Batch 219/390 d_loss_real= 0.297, d_loss_fake= 0.033, g_loss 3.511, d_loss 0.165\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 42 Batch 220/390 d_loss_real= 0.176, d_loss_fake= 0.037, g_loss 3.379, d_loss 0.107\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 42 Batch 221/390 d_loss_real= 0.248, d_loss_fake= 0.049, g_loss 3.255, d_loss 0.149\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 42 Batch 222/390 d_loss_real= 0.001, d_loss_fake= 0.043, g_loss 3.299, d_loss 0.022\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 42 Batch 223/390 d_loss_real= 0.185, d_loss_fake= 0.050, g_loss 3.370, d_loss 0.117\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 224/390 d_loss_real= 0.139, d_loss_fake= 0.050, g_loss 3.384, d_loss 0.094\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 42 Batch 225/390 d_loss_real= 0.075, d_loss_fake= 0.049, g_loss 3.259, d_loss 0.062\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 226/390 d_loss_real= 0.004, d_loss_fake= 0.044, g_loss 3.341, d_loss 0.024\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 227/390 d_loss_real= 0.070, d_loss_fake= 0.037, g_loss 3.464, d_loss 0.054\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 228/390 d_loss_real= 0.196, d_loss_fake= 0.038, g_loss 3.547, d_loss 0.117\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 229/390 d_loss_real= 0.243, d_loss_fake= 0.031, g_loss 3.524, d_loss 0.137\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 230/390 d_loss_real= 0.071, d_loss_fake= 0.032, g_loss 3.504, d_loss 0.052\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 231/390 d_loss_real= 0.209, d_loss_fake= 0.031, g_loss 3.549, d_loss 0.120\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 232/390 d_loss_real= 0.025, d_loss_fake= 0.034, g_loss 3.491, d_loss 0.029\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 233/390 d_loss_real= 0.073, d_loss_fake= 0.028, g_loss 3.737, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 234/390 d_loss_real= 0.000, d_loss_fake= 0.028, g_loss 3.749, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 235/390 d_loss_real= 0.179, d_loss_fake= 0.023, g_loss 3.833, d_loss 0.101\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42 Batch 236/390 d_loss_real= 0.164, d_loss_fake= 0.024, g_loss 3.824, d_loss 0.094\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 42 Batch 237/390 d_loss_real= 0.137, d_loss_fake= 0.023, g_loss 3.787, d_loss 0.080\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 42 Batch 238/390 d_loss_real= 0.194, d_loss_fake= 0.026, g_loss 3.691, d_loss 0.110\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 239/390 d_loss_real= 0.271, d_loss_fake= 0.030, g_loss 3.479, d_loss 0.150\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 240/390 d_loss_real= 0.095, d_loss_fake= 0.043, g_loss 3.250, d_loss 0.069\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 241/390 d_loss_real= 0.102, d_loss_fake= 0.049, g_loss 3.181, d_loss 0.075\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 42 Batch 242/390 d_loss_real= 0.003, d_loss_fake= 0.069, g_loss 3.272, d_loss 0.036\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 42 Batch 243/390 d_loss_real= 0.037, d_loss_fake= 0.050, g_loss 3.584, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 244/390 d_loss_real= 0.380, d_loss_fake= 0.039, g_loss 3.594, d_loss 0.210\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 245/390 d_loss_real= 0.131, d_loss_fake= 0.027, g_loss 3.788, d_loss 0.079\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 246/390 d_loss_real= 0.147, d_loss_fake= 0.027, g_loss 3.706, d_loss 0.087\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42 Batch 247/390 d_loss_real= 0.189, d_loss_fake= 0.028, g_loss 3.647, d_loss 0.108\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 248/390 d_loss_real= 0.020, d_loss_fake= 0.027, g_loss 3.703, d_loss 0.023\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 42 Batch 249/390 d_loss_real= 0.079, d_loss_fake= 0.026, g_loss 3.699, d_loss 0.052\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 250/390 d_loss_real= 0.042, d_loss_fake= 0.030, g_loss 3.611, d_loss 0.036\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 251/390 d_loss_real= 0.212, d_loss_fake= 0.034, g_loss 3.498, d_loss 0.123\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42 Batch 252/390 d_loss_real= 0.000, d_loss_fake= 0.031, g_loss 3.609, d_loss 0.015\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 253/390 d_loss_real= 0.013, d_loss_fake= 0.033, g_loss 3.603, d_loss 0.023\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 254/390 d_loss_real= 0.062, d_loss_fake= 0.030, g_loss 3.701, d_loss 0.046\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 42 Batch 255/390 d_loss_real= 0.285, d_loss_fake= 0.028, g_loss 3.567, d_loss 0.157\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 42 Batch 256/390 d_loss_real= 0.045, d_loss_fake= 0.029, g_loss 3.562, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 257/390 d_loss_real= 0.063, d_loss_fake= 0.030, g_loss 3.699, d_loss 0.046\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42 Batch 258/390 d_loss_real= 0.008, d_loss_fake= 0.029, g_loss 3.581, d_loss 0.019\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 42 Batch 259/390 d_loss_real= 0.005, d_loss_fake= 0.027, g_loss 3.767, d_loss 0.016\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42 Batch 260/390 d_loss_real= 0.212, d_loss_fake= 0.024, g_loss 3.744, d_loss 0.118\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 261/390 d_loss_real= 0.129, d_loss_fake= 0.028, g_loss 3.717, d_loss 0.078\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42 Batch 262/390 d_loss_real= 0.065, d_loss_fake= 0.022, g_loss 3.842, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 263/390 d_loss_real= 0.061, d_loss_fake= 0.023, g_loss 3.886, d_loss 0.042\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 264/390 d_loss_real= 0.010, d_loss_fake= 0.022, g_loss 3.944, d_loss 0.016\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 265/390 d_loss_real= 0.133, d_loss_fake= 0.020, g_loss 4.025, d_loss 0.077\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 42 Batch 266/390 d_loss_real= 0.140, d_loss_fake= 0.020, g_loss 4.024, d_loss 0.080\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 267/390 d_loss_real= 0.128, d_loss_fake= 0.020, g_loss 3.995, d_loss 0.074\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 42 Batch 268/390 d_loss_real= 0.106, d_loss_fake= 0.020, g_loss 3.906, d_loss 0.063\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 269/390 d_loss_real= 0.092, d_loss_fake= 0.025, g_loss 3.832, d_loss 0.058\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 42 Batch 270/390 d_loss_real= 0.183, d_loss_fake= 0.027, g_loss 3.545, d_loss 0.105\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 42 Batch 271/390 d_loss_real= 0.084, d_loss_fake= 0.051, g_loss 3.525, d_loss 0.067\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 272/390 d_loss_real= 0.154, d_loss_fake= 0.043, g_loss 3.719, d_loss 0.098\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42 Batch 273/390 d_loss_real= 0.176, d_loss_fake= 0.027, g_loss 3.815, d_loss 0.101\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 274/390 d_loss_real= 0.117, d_loss_fake= 0.023, g_loss 3.840, d_loss 0.070\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 275/390 d_loss_real= 0.032, d_loss_fake= 0.022, g_loss 3.861, d_loss 0.027\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 42 Batch 276/390 d_loss_real= 0.076, d_loss_fake= 0.023, g_loss 3.821, d_loss 0.049\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 42 Batch 277/390 d_loss_real= 0.130, d_loss_fake= 0.026, g_loss 3.712, d_loss 0.078\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 278/390 d_loss_real= 0.073, d_loss_fake= 0.026, g_loss 3.663, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 279/390 d_loss_real= 0.260, d_loss_fake= 0.033, g_loss 3.548, d_loss 0.146\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 280/390 d_loss_real= 0.131, d_loss_fake= 0.039, g_loss 3.410, d_loss 0.085\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 281/390 d_loss_real= 0.065, d_loss_fake= 0.042, g_loss 3.382, d_loss 0.054\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 282/390 d_loss_real= 0.173, d_loss_fake= 0.034, g_loss 3.584, d_loss 0.104\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42 Batch 283/390 d_loss_real= 0.132, d_loss_fake= 0.029, g_loss 3.669, d_loss 0.080\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 284/390 d_loss_real= 0.022, d_loss_fake= 0.026, g_loss 3.760, d_loss 0.024\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 42 Batch 285/390 d_loss_real= 0.210, d_loss_fake= 0.027, g_loss 3.695, d_loss 0.118\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42 Batch 286/390 d_loss_real= 0.001, d_loss_fake= 0.028, g_loss 3.667, d_loss 0.015\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 42 Batch 287/390 d_loss_real= 0.018, d_loss_fake= 0.028, g_loss 3.634, d_loss 0.023\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 42 Batch 288/390 d_loss_real= 0.064, d_loss_fake= 0.027, g_loss 3.671, d_loss 0.045\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42 Batch 289/390 d_loss_real= 0.061, d_loss_fake= 0.025, g_loss 3.795, d_loss 0.043\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 42 Batch 290/390 d_loss_real= 0.105, d_loss_fake= 0.023, g_loss 3.843, d_loss 0.064\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 291/390 d_loss_real= 0.038, d_loss_fake= 0.021, g_loss 3.927, d_loss 0.030\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 292/390 d_loss_real= 0.009, d_loss_fake= 0.021, g_loss 3.963, d_loss 0.015\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 293/390 d_loss_real= 0.072, d_loss_fake= 0.020, g_loss 3.984, d_loss 0.046\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42 Batch 294/390 d_loss_real= 0.000, d_loss_fake= 0.019, g_loss 4.014, d_loss 0.010\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 42 Batch 295/390 d_loss_real= 0.092, d_loss_fake= 0.019, g_loss 4.011, d_loss 0.055\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42 Batch 296/390 d_loss_real= 0.110, d_loss_fake= 0.019, g_loss 3.989, d_loss 0.065\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 42 Batch 297/390 d_loss_real= 0.066, d_loss_fake= 0.020, g_loss 3.971, d_loss 0.043\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 42 Batch 298/390 d_loss_real= 0.116, d_loss_fake= 0.020, g_loss 3.931, d_loss 0.068\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 299/390 d_loss_real= 0.034, d_loss_fake= 0.021, g_loss 3.903, d_loss 0.028\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42 Batch 300/390 d_loss_real= 0.226, d_loss_fake= 0.024, g_loss 3.650, d_loss 0.125\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 42 Batch 301/390 d_loss_real= 0.000, d_loss_fake= 0.029, g_loss 3.420, d_loss 0.015\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42 Batch 302/390 d_loss_real= 0.090, d_loss_fake= 0.037, g_loss 3.352, d_loss 0.064\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 42 Batch 303/390 d_loss_real= 0.107, d_loss_fake= 0.041, g_loss 3.337, d_loss 0.074\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 304/390 d_loss_real= 0.062, d_loss_fake= 0.037, g_loss 3.451, d_loss 0.050\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 42 Batch 305/390 d_loss_real= 0.069, d_loss_fake= 0.031, g_loss 3.593, d_loss 0.050\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 306/390 d_loss_real= 0.229, d_loss_fake= 0.028, g_loss 3.703, d_loss 0.128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 307/390 d_loss_real= 0.035, d_loss_fake= 0.026, g_loss 3.685, d_loss 0.030\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42 Batch 308/390 d_loss_real= 0.081, d_loss_fake= 0.027, g_loss 3.708, d_loss 0.054\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 42 Batch 309/390 d_loss_real= 0.063, d_loss_fake= 0.026, g_loss 3.717, d_loss 0.045\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 42 Batch 310/390 d_loss_real= 0.004, d_loss_fake= 0.025, g_loss 3.738, d_loss 0.014\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 42 Batch 311/390 d_loss_real= 0.165, d_loss_fake= 0.024, g_loss 3.788, d_loss 0.095\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 312/390 d_loss_real= 0.006, d_loss_fake= 0.024, g_loss 3.784, d_loss 0.015\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 313/390 d_loss_real= 0.233, d_loss_fake= 0.024, g_loss 3.705, d_loss 0.128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 314/390 d_loss_real= 0.167, d_loss_fake= 0.027, g_loss 3.612, d_loss 0.097\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 315/390 d_loss_real= 0.063, d_loss_fake= 0.031, g_loss 3.488, d_loss 0.047\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 316/390 d_loss_real= 0.042, d_loss_fake= 0.035, g_loss 3.349, d_loss 0.039\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42 Batch 317/390 d_loss_real= 0.048, d_loss_fake= 0.041, g_loss 3.341, d_loss 0.044\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 42 Batch 318/390 d_loss_real= 0.071, d_loss_fake= 0.047, g_loss 3.225, d_loss 0.059\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 42 Batch 319/390 d_loss_real= 0.062, d_loss_fake= 0.045, g_loss 3.311, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 320/390 d_loss_real= 0.074, d_loss_fake= 0.038, g_loss 3.460, d_loss 0.056\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 321/390 d_loss_real= 0.007, d_loss_fake= 0.031, g_loss 3.611, d_loss 0.019\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 322/390 d_loss_real= 0.038, d_loss_fake= 0.027, g_loss 3.838, d_loss 0.032\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 42 Batch 323/390 d_loss_real= 0.166, d_loss_fake= 0.024, g_loss 3.798, d_loss 0.095\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 324/390 d_loss_real= 0.058, d_loss_fake= 0.024, g_loss 3.861, d_loss 0.041\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 325/390 d_loss_real= 0.179, d_loss_fake= 0.022, g_loss 3.883, d_loss 0.101\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 42 Batch 326/390 d_loss_real= 0.001, d_loss_fake= 0.024, g_loss 3.825, d_loss 0.013\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42 Batch 327/390 d_loss_real= 0.076, d_loss_fake= 0.023, g_loss 3.764, d_loss 0.050\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42 Batch 328/390 d_loss_real= 0.135, d_loss_fake= 0.025, g_loss 3.779, d_loss 0.080\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 329/390 d_loss_real= 0.108, d_loss_fake= 0.025, g_loss 3.687, d_loss 0.067\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 330/390 d_loss_real= 0.106, d_loss_fake= 0.027, g_loss 3.678, d_loss 0.066\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42 Batch 331/390 d_loss_real= 0.147, d_loss_fake= 0.028, g_loss 3.652, d_loss 0.087\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 42 Batch 332/390 d_loss_real= 0.068, d_loss_fake= 0.030, g_loss 3.692, d_loss 0.049\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 333/390 d_loss_real= 0.000, d_loss_fake= 0.029, g_loss 3.712, d_loss 0.015\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 42 Batch 334/390 d_loss_real= 0.131, d_loss_fake= 0.028, g_loss 3.713, d_loss 0.079\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 335/390 d_loss_real= 0.055, d_loss_fake= 0.026, g_loss 3.805, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 336/390 d_loss_real= 0.091, d_loss_fake= 0.023, g_loss 3.797, d_loss 0.057\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 337/390 d_loss_real= 0.052, d_loss_fake= 0.024, g_loss 3.824, d_loss 0.038\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 42 Batch 338/390 d_loss_real= 0.101, d_loss_fake= 0.023, g_loss 3.826, d_loss 0.062\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 339/390 d_loss_real= 0.138, d_loss_fake= 0.023, g_loss 3.793, d_loss 0.081\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 42 Batch 340/390 d_loss_real= 0.109, d_loss_fake= 0.027, g_loss 3.636, d_loss 0.068\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 42 Batch 341/390 d_loss_real= 0.094, d_loss_fake= 0.031, g_loss 3.572, d_loss 0.063\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42 Batch 342/390 d_loss_real= 0.064, d_loss_fake= 0.032, g_loss 3.548, d_loss 0.048\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 343/390 d_loss_real= 0.139, d_loss_fake= 0.035, g_loss 3.499, d_loss 0.087\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 42 Batch 344/390 d_loss_real= 0.003, d_loss_fake= 0.037, g_loss 3.532, d_loss 0.020\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42 Batch 345/390 d_loss_real= 0.068, d_loss_fake= 0.030, g_loss 3.557, d_loss 0.049\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42 Batch 346/390 d_loss_real= 0.002, d_loss_fake= 0.029, g_loss 3.619, d_loss 0.016\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 42 Batch 347/390 d_loss_real= 0.138, d_loss_fake= 0.032, g_loss 3.554, d_loss 0.085\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 42 Batch 348/390 d_loss_real= 0.097, d_loss_fake= 0.031, g_loss 3.456, d_loss 0.064\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 349/390 d_loss_real= 0.118, d_loss_fake= 0.035, g_loss 3.506, d_loss 0.077\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 350/390 d_loss_real= 0.000, d_loss_fake= 0.033, g_loss 3.585, d_loss 0.017\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 42 Batch 351/390 d_loss_real= 0.000, d_loss_fake= 0.029, g_loss 3.690, d_loss 0.015\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 352/390 d_loss_real= 0.069, d_loss_fake= 0.026, g_loss 3.752, d_loss 0.048\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 353/390 d_loss_real= 0.103, d_loss_fake= 0.025, g_loss 3.747, d_loss 0.064\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 354/390 d_loss_real= 0.183, d_loss_fake= 0.027, g_loss 3.711, d_loss 0.105\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 355/390 d_loss_real= 0.000, d_loss_fake= 0.027, g_loss 3.717, d_loss 0.013\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 42 Batch 356/390 d_loss_real= 0.033, d_loss_fake= 0.026, g_loss 3.689, d_loss 0.029\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 357/390 d_loss_real= 0.123, d_loss_fake= 0.028, g_loss 3.636, d_loss 0.075\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 42 Batch 358/390 d_loss_real= 0.134, d_loss_fake= 0.030, g_loss 3.521, d_loss 0.082\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 359/390 d_loss_real= 0.210, d_loss_fake= 0.034, g_loss 3.354, d_loss 0.122\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 360/390 d_loss_real= 0.109, d_loss_fake= 0.040, g_loss 3.272, d_loss 0.074\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 42 Batch 361/390 d_loss_real= 0.098, d_loss_fake= 0.042, g_loss 3.217, d_loss 0.070\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 362/390 d_loss_real= 0.054, d_loss_fake= 0.043, g_loss 3.268, d_loss 0.049\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42 Batch 363/390 d_loss_real= 0.179, d_loss_fake= 0.042, g_loss 3.234, d_loss 0.110\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 364/390 d_loss_real= 0.048, d_loss_fake= 0.049, g_loss 3.191, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 365/390 d_loss_real= 0.077, d_loss_fake= 0.049, g_loss 3.199, d_loss 0.063\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 366/390 d_loss_real= 0.174, d_loss_fake= 0.045, g_loss 3.170, d_loss 0.110\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 367/390 d_loss_real= 0.149, d_loss_fake= 0.047, g_loss 3.226, d_loss 0.098\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 368/390 d_loss_real= 0.103, d_loss_fake= 0.042, g_loss 3.306, d_loss 0.073\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 42 Batch 369/390 d_loss_real= 0.118, d_loss_fake= 0.040, g_loss 3.336, d_loss 0.079\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 370/390 d_loss_real= 0.133, d_loss_fake= 0.043, g_loss 3.320, d_loss 0.088\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 371/390 d_loss_real= 0.110, d_loss_fake= 0.040, g_loss 3.353, d_loss 0.075\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 372/390 d_loss_real= 0.010, d_loss_fake= 0.039, g_loss 3.398, d_loss 0.025\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 373/390 d_loss_real= 0.053, d_loss_fake= 0.036, g_loss 3.388, d_loss 0.045\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 374/390 d_loss_real= 0.000, d_loss_fake= 0.036, g_loss 3.447, d_loss 0.018\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 42 Batch 375/390 d_loss_real= 0.085, d_loss_fake= 0.033, g_loss 3.470, d_loss 0.059\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 376/390 d_loss_real= 0.000, d_loss_fake= 0.033, g_loss 3.480, d_loss 0.017\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 42 Batch 377/390 d_loss_real= 0.185, d_loss_fake= 0.032, g_loss 3.582, d_loss 0.109\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42 Batch 378/390 d_loss_real= 0.084, d_loss_fake= 0.030, g_loss 3.610, d_loss 0.057\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 42 Batch 379/390 d_loss_real= 0.037, d_loss_fake= 0.030, g_loss 3.616, d_loss 0.034\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 42 Batch 380/390 d_loss_real= 0.084, d_loss_fake= 0.029, g_loss 3.570, d_loss 0.056\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42 Batch 381/390 d_loss_real= 0.056, d_loss_fake= 0.032, g_loss 3.552, d_loss 0.044\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 382/390 d_loss_real= 0.049, d_loss_fake= 0.037, g_loss 3.449, d_loss 0.043\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 42 Batch 383/390 d_loss_real= 0.062, d_loss_fake= 0.047, g_loss 3.271, d_loss 0.055\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42 Batch 384/390 d_loss_real= 0.000, d_loss_fake= 0.046, g_loss 3.457, d_loss 0.023\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 42 Batch 385/390 d_loss_real= 0.253, d_loss_fake= 0.042, g_loss 3.527, d_loss 0.148\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 42 Batch 386/390 d_loss_real= 0.014, d_loss_fake= 0.039, g_loss 3.586, d_loss 0.026\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 42 Batch 387/390 d_loss_real= 0.105, d_loss_fake= 0.041, g_loss 3.555, d_loss 0.073\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 42 Batch 388/390 d_loss_real= 0.178, d_loss_fake= 0.039, g_loss 3.539, d_loss 0.109\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42 Batch 389/390 d_loss_real= 0.146, d_loss_fake= 0.032, g_loss 3.657, d_loss 0.089\n",
            "2/2 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42 Batch 390/390 d_loss_real= 0.155, d_loss_fake= 0.033, g_loss 3.688, d_loss 0.094\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 43 Batch 1/390 d_loss_real= 0.096, d_loss_fake= 0.036, g_loss 3.536, d_loss 0.066\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 2/390 d_loss_real= 0.011, d_loss_fake= 0.035, g_loss 3.583, d_loss 0.023\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 43 Batch 3/390 d_loss_real= 0.001, d_loss_fake= 0.030, g_loss 3.771, d_loss 0.016\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 43 Batch 4/390 d_loss_real= 0.135, d_loss_fake= 0.031, g_loss 3.798, d_loss 0.083\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 43 Batch 5/390 d_loss_real= 0.131, d_loss_fake= 0.027, g_loss 3.820, d_loss 0.079\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 6/390 d_loss_real= 0.129, d_loss_fake= 0.023, g_loss 3.915, d_loss 0.076\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 7/390 d_loss_real= 0.194, d_loss_fake= 0.024, g_loss 3.912, d_loss 0.109\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 8/390 d_loss_real= 0.036, d_loss_fake= 0.020, g_loss 3.903, d_loss 0.028\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 9/390 d_loss_real= 0.310, d_loss_fake= 0.024, g_loss 3.855, d_loss 0.167\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 10/390 d_loss_real= 0.189, d_loss_fake= 0.029, g_loss 3.674, d_loss 0.109\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 11/390 d_loss_real= 0.160, d_loss_fake= 0.032, g_loss 3.532, d_loss 0.096\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 12/390 d_loss_real= 0.029, d_loss_fake= 0.034, g_loss 3.500, d_loss 0.032\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 13/390 d_loss_real= 0.005, d_loss_fake= 0.031, g_loss 3.548, d_loss 0.018\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 14/390 d_loss_real= 0.094, d_loss_fake= 0.033, g_loss 3.508, d_loss 0.063\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 15/390 d_loss_real= 0.137, d_loss_fake= 0.043, g_loss 3.379, d_loss 0.090\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 16/390 d_loss_real= 0.084, d_loss_fake= 0.042, g_loss 3.480, d_loss 0.063\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 17/390 d_loss_real= 0.178, d_loss_fake= 0.034, g_loss 3.549, d_loss 0.106\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 18/390 d_loss_real= 0.066, d_loss_fake= 0.030, g_loss 3.665, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 19/390 d_loss_real= 0.087, d_loss_fake= 0.025, g_loss 3.795, d_loss 0.056\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 43 Batch 20/390 d_loss_real= 0.056, d_loss_fake= 0.024, g_loss 3.794, d_loss 0.040\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 43 Batch 21/390 d_loss_real= 0.000, d_loss_fake= 0.023, g_loss 3.891, d_loss 0.011\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 43 Batch 22/390 d_loss_real= 0.000, d_loss_fake= 0.023, g_loss 3.992, d_loss 0.011\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 43 Batch 23/390 d_loss_real= 0.009, d_loss_fake= 0.019, g_loss 4.044, d_loss 0.014\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 43 Batch 24/390 d_loss_real= 0.071, d_loss_fake= 0.018, g_loss 4.124, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 25/390 d_loss_real= 0.051, d_loss_fake= 0.016, g_loss 4.148, d_loss 0.034\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 26/390 d_loss_real= 0.078, d_loss_fake= 0.017, g_loss 4.087, d_loss 0.048\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 43 Batch 27/390 d_loss_real= 0.185, d_loss_fake= 0.018, g_loss 3.969, d_loss 0.102\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 28/390 d_loss_real= 0.123, d_loss_fake= 0.021, g_loss 3.875, d_loss 0.072\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 29/390 d_loss_real= 0.000, d_loss_fake= 0.022, g_loss 3.835, d_loss 0.011\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 30/390 d_loss_real= 0.001, d_loss_fake= 0.022, g_loss 3.854, d_loss 0.011\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 43 Batch 31/390 d_loss_real= 0.090, d_loss_fake= 0.021, g_loss 3.770, d_loss 0.056\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 43 Batch 32/390 d_loss_real= 0.259, d_loss_fake= 0.028, g_loss 3.618, d_loss 0.143\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 33/390 d_loss_real= 0.001, d_loss_fake= 0.042, g_loss 3.530, d_loss 0.022\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 34/390 d_loss_real= 0.226, d_loss_fake= 0.034, g_loss 3.694, d_loss 0.130\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 43 Batch 35/390 d_loss_real= 0.081, d_loss_fake= 0.032, g_loss 3.742, d_loss 0.056\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 43 Batch 36/390 d_loss_real= 0.121, d_loss_fake= 0.025, g_loss 3.792, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 37/390 d_loss_real= 0.194, d_loss_fake= 0.025, g_loss 3.858, d_loss 0.109\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 43 Batch 38/390 d_loss_real= 0.060, d_loss_fake= 0.023, g_loss 3.921, d_loss 0.041\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 39/390 d_loss_real= 0.179, d_loss_fake= 0.020, g_loss 3.937, d_loss 0.100\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 43 Batch 40/390 d_loss_real= 0.299, d_loss_fake= 0.022, g_loss 3.891, d_loss 0.160\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 43 Batch 41/390 d_loss_real= 0.245, d_loss_fake= 0.026, g_loss 3.708, d_loss 0.135\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 42/390 d_loss_real= 0.060, d_loss_fake= 0.029, g_loss 3.524, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 43/390 d_loss_real= 0.054, d_loss_fake= 0.035, g_loss 3.417, d_loss 0.045\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 44/390 d_loss_real= 0.060, d_loss_fake= 0.037, g_loss 3.396, d_loss 0.048\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 45/390 d_loss_real= 0.050, d_loss_fake= 0.035, g_loss 3.414, d_loss 0.042\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 43 Batch 46/390 d_loss_real= 0.052, d_loss_fake= 0.038, g_loss 3.339, d_loss 0.045\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 47/390 d_loss_real= 0.044, d_loss_fake= 0.044, g_loss 3.266, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 48/390 d_loss_real= 0.056, d_loss_fake= 0.042, g_loss 3.243, d_loss 0.049\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 49/390 d_loss_real= 0.008, d_loss_fake= 0.043, g_loss 3.317, d_loss 0.025\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 43 Batch 50/390 d_loss_real= 0.107, d_loss_fake= 0.038, g_loss 3.428, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 51/390 d_loss_real= 0.001, d_loss_fake= 0.034, g_loss 3.537, d_loss 0.017\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 52/390 d_loss_real= 0.295, d_loss_fake= 0.034, g_loss 3.517, d_loss 0.164\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 53/390 d_loss_real= 0.201, d_loss_fake= 0.037, g_loss 3.420, d_loss 0.119\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 54/390 d_loss_real= 0.050, d_loss_fake= 0.039, g_loss 3.338, d_loss 0.044\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 55/390 d_loss_real= 0.002, d_loss_fake= 0.035, g_loss 3.445, d_loss 0.019\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 56/390 d_loss_real= 0.089, d_loss_fake= 0.039, g_loss 3.316, d_loss 0.064\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 43 Batch 57/390 d_loss_real= 0.121, d_loss_fake= 0.054, g_loss 3.096, d_loss 0.088\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 58/390 d_loss_real= 0.095, d_loss_fake= 0.056, g_loss 3.141, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 59/390 d_loss_real= 0.107, d_loss_fake= 0.040, g_loss 3.333, d_loss 0.074\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 43 Batch 60/390 d_loss_real= 0.013, d_loss_fake= 0.037, g_loss 3.427, d_loss 0.025\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 43 Batch 61/390 d_loss_real= 0.022, d_loss_fake= 0.036, g_loss 3.506, d_loss 0.029\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 62/390 d_loss_real= 0.023, d_loss_fake= 0.032, g_loss 3.607, d_loss 0.027\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 63/390 d_loss_real= 0.173, d_loss_fake= 0.030, g_loss 3.580, d_loss 0.102\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 64/390 d_loss_real= 0.107, d_loss_fake= 0.033, g_loss 3.588, d_loss 0.070\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 65/390 d_loss_real= 0.037, d_loss_fake= 0.028, g_loss 3.679, d_loss 0.033\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 66/390 d_loss_real= 0.051, d_loss_fake= 0.029, g_loss 3.679, d_loss 0.040\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 43 Batch 67/390 d_loss_real= 0.113, d_loss_fake= 0.030, g_loss 3.718, d_loss 0.071\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 68/390 d_loss_real= 0.046, d_loss_fake= 0.028, g_loss 3.749, d_loss 0.037\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 43 Batch 69/390 d_loss_real= 0.052, d_loss_fake= 0.025, g_loss 3.807, d_loss 0.038\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 43 Batch 70/390 d_loss_real= 0.064, d_loss_fake= 0.023, g_loss 3.860, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 71/390 d_loss_real= 0.000, d_loss_fake= 0.021, g_loss 4.075, d_loss 0.010\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 72/390 d_loss_real= 0.104, d_loss_fake= 0.022, g_loss 3.972, d_loss 0.063\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 73/390 d_loss_real= 0.168, d_loss_fake= 0.022, g_loss 3.881, d_loss 0.095\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 74/390 d_loss_real= 0.091, d_loss_fake= 0.024, g_loss 3.683, d_loss 0.058\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 43 Batch 75/390 d_loss_real= 0.000, d_loss_fake= 0.029, g_loss 3.610, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 76/390 d_loss_real= 0.017, d_loss_fake= 0.033, g_loss 3.560, d_loss 0.025\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 77/390 d_loss_real= 0.072, d_loss_fake= 0.030, g_loss 3.771, d_loss 0.051\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 43 Batch 78/390 d_loss_real= 0.235, d_loss_fake= 0.040, g_loss 3.662, d_loss 0.137\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 79/390 d_loss_real= 0.034, d_loss_fake= 0.027, g_loss 3.825, d_loss 0.030\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 80/390 d_loss_real= 0.001, d_loss_fake= 0.022, g_loss 4.023, d_loss 0.012\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 43 Batch 81/390 d_loss_real= 0.142, d_loss_fake= 0.022, g_loss 4.028, d_loss 0.082\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 43 Batch 82/390 d_loss_real= 0.002, d_loss_fake= 0.017, g_loss 4.247, d_loss 0.010\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 83/390 d_loss_real= 0.306, d_loss_fake= 0.019, g_loss 4.109, d_loss 0.162\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 84/390 d_loss_real= 0.064, d_loss_fake= 0.019, g_loss 4.018, d_loss 0.041\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 85/390 d_loss_real= 0.000, d_loss_fake= 0.023, g_loss 4.097, d_loss 0.011\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 43 Batch 86/390 d_loss_real= 0.078, d_loss_fake= 0.019, g_loss 4.020, d_loss 0.048\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 43 Batch 87/390 d_loss_real= 0.001, d_loss_fake= 0.021, g_loss 4.112, d_loss 0.011\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 43 Batch 88/390 d_loss_real= 0.270, d_loss_fake= 0.019, g_loss 4.027, d_loss 0.145\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 43 Batch 89/390 d_loss_real= 0.131, d_loss_fake= 0.025, g_loss 3.913, d_loss 0.078\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 90/390 d_loss_real= 0.139, d_loss_fake= 0.024, g_loss 3.854, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 91/390 d_loss_real= 0.175, d_loss_fake= 0.032, g_loss 3.643, d_loss 0.104\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 92/390 d_loss_real= 0.229, d_loss_fake= 0.038, g_loss 3.696, d_loss 0.133\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 93/390 d_loss_real= 0.114, d_loss_fake= 0.037, g_loss 3.724, d_loss 0.076\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 94/390 d_loss_real= 0.076, d_loss_fake= 0.028, g_loss 3.838, d_loss 0.052\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 43 Batch 95/390 d_loss_real= 0.016, d_loss_fake= 0.020, g_loss 4.092, d_loss 0.018\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 96/390 d_loss_real= 0.274, d_loss_fake= 0.023, g_loss 3.887, d_loss 0.149\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 43 Batch 97/390 d_loss_real= 0.256, d_loss_fake= 0.027, g_loss 3.592, d_loss 0.142\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 98/390 d_loss_real= 0.070, d_loss_fake= 0.026, g_loss 3.730, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 99/390 d_loss_real= 0.184, d_loss_fake= 0.043, g_loss 3.287, d_loss 0.113\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 43 Batch 100/390 d_loss_real= 0.113, d_loss_fake= 0.048, g_loss 3.386, d_loss 0.080\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 101/390 d_loss_real= 0.022, d_loss_fake= 0.036, g_loss 3.601, d_loss 0.029\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 102/390 d_loss_real= 0.058, d_loss_fake= 0.032, g_loss 3.765, d_loss 0.045\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 103/390 d_loss_real= 0.105, d_loss_fake= 0.025, g_loss 3.933, d_loss 0.065\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 43 Batch 104/390 d_loss_real= 0.156, d_loss_fake= 0.024, g_loss 3.766, d_loss 0.090\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 105/390 d_loss_real= 0.122, d_loss_fake= 0.037, g_loss 3.458, d_loss 0.080\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 106/390 d_loss_real= 0.272, d_loss_fake= 0.046, g_loss 3.194, d_loss 0.159\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 43 Batch 107/390 d_loss_real= 0.172, d_loss_fake= 0.044, g_loss 3.439, d_loss 0.108\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 108/390 d_loss_real= 0.134, d_loss_fake= 0.043, g_loss 3.487, d_loss 0.088\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 109/390 d_loss_real= 0.171, d_loss_fake= 0.060, g_loss 3.357, d_loss 0.116\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 110/390 d_loss_real= 0.009, d_loss_fake= 0.035, g_loss 3.564, d_loss 0.022\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 111/390 d_loss_real= 0.032, d_loss_fake= 0.029, g_loss 3.813, d_loss 0.030\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 112/390 d_loss_real= 0.136, d_loss_fake= 0.026, g_loss 3.829, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 113/390 d_loss_real= 0.019, d_loss_fake= 0.026, g_loss 3.858, d_loss 0.023\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 114/390 d_loss_real= 0.072, d_loss_fake= 0.023, g_loss 3.917, d_loss 0.048\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 115/390 d_loss_real= 0.015, d_loss_fake= 0.022, g_loss 3.899, d_loss 0.018\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 116/390 d_loss_real= 0.113, d_loss_fake= 0.026, g_loss 3.780, d_loss 0.070\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 117/390 d_loss_real= 0.023, d_loss_fake= 0.026, g_loss 3.777, d_loss 0.025\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 118/390 d_loss_real= 0.124, d_loss_fake= 0.031, g_loss 3.668, d_loss 0.077\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 43 Batch 119/390 d_loss_real= 0.140, d_loss_fake= 0.027, g_loss 3.818, d_loss 0.083\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 120/390 d_loss_real= 0.137, d_loss_fake= 0.034, g_loss 3.697, d_loss 0.086\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 121/390 d_loss_real= 0.145, d_loss_fake= 0.029, g_loss 3.866, d_loss 0.087\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 122/390 d_loss_real= 0.050, d_loss_fake= 0.022, g_loss 3.934, d_loss 0.036\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 123/390 d_loss_real= 0.101, d_loss_fake= 0.023, g_loss 3.803, d_loss 0.062\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 43 Batch 124/390 d_loss_real= 0.080, d_loss_fake= 0.028, g_loss 3.634, d_loss 0.054\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 125/390 d_loss_real= 0.038, d_loss_fake= 0.027, g_loss 3.715, d_loss 0.033\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 126/390 d_loss_real= 0.197, d_loss_fake= 0.028, g_loss 3.733, d_loss 0.113\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 127/390 d_loss_real= 0.180, d_loss_fake= 0.027, g_loss 3.663, d_loss 0.103\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 128/390 d_loss_real= 0.147, d_loss_fake= 0.033, g_loss 3.539, d_loss 0.090\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 129/390 d_loss_real= 0.134, d_loss_fake= 0.039, g_loss 3.507, d_loss 0.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 130/390 d_loss_real= 0.122, d_loss_fake= 0.030, g_loss 3.667, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 131/390 d_loss_real= 0.125, d_loss_fake= 0.029, g_loss 3.696, d_loss 0.077\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 132/390 d_loss_real= 0.000, d_loss_fake= 0.026, g_loss 3.841, d_loss 0.013\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 133/390 d_loss_real= 0.099, d_loss_fake= 0.022, g_loss 3.915, d_loss 0.061\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 134/390 d_loss_real= 0.000, d_loss_fake= 0.021, g_loss 3.966, d_loss 0.011\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 135/390 d_loss_real= 0.214, d_loss_fake= 0.022, g_loss 3.877, d_loss 0.118\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 43 Batch 136/390 d_loss_real= 0.070, d_loss_fake= 0.022, g_loss 3.793, d_loss 0.046\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 43 Batch 137/390 d_loss_real= 0.001, d_loss_fake= 0.025, g_loss 3.762, d_loss 0.013\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 43 Batch 138/390 d_loss_real= 0.002, d_loss_fake= 0.025, g_loss 3.756, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 139/390 d_loss_real= 0.204, d_loss_fake= 0.025, g_loss 3.679, d_loss 0.115\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 43 Batch 140/390 d_loss_real= 0.081, d_loss_fake= 0.027, g_loss 3.650, d_loss 0.054\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 141/390 d_loss_real= 0.208, d_loss_fake= 0.029, g_loss 3.533, d_loss 0.118\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 142/390 d_loss_real= 0.243, d_loss_fake= 0.035, g_loss 3.254, d_loss 0.139\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 143/390 d_loss_real= 0.120, d_loss_fake= 0.044, g_loss 3.151, d_loss 0.082\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 144/390 d_loss_real= 0.056, d_loss_fake= 0.052, g_loss 3.060, d_loss 0.054\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 145/390 d_loss_real= 0.135, d_loss_fake= 0.071, g_loss 3.199, d_loss 0.103\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 146/390 d_loss_real= 0.038, d_loss_fake= 0.037, g_loss 3.590, d_loss 0.037\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 43 Batch 147/390 d_loss_real= 0.066, d_loss_fake= 0.026, g_loss 3.868, d_loss 0.046\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 148/390 d_loss_real= 0.129, d_loss_fake= 0.024, g_loss 3.873, d_loss 0.076\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 43 Batch 149/390 d_loss_real= 0.243, d_loss_fake= 0.025, g_loss 3.885, d_loss 0.134\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 43 Batch 150/390 d_loss_real= 0.114, d_loss_fake= 0.026, g_loss 3.787, d_loss 0.070\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 151/390 d_loss_real= 0.219, d_loss_fake= 0.029, g_loss 3.713, d_loss 0.124\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 152/390 d_loss_real= 0.068, d_loss_fake= 0.028, g_loss 3.588, d_loss 0.048\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 153/390 d_loss_real= 0.040, d_loss_fake= 0.034, g_loss 3.482, d_loss 0.037\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 154/390 d_loss_real= 0.093, d_loss_fake= 0.037, g_loss 3.357, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 155/390 d_loss_real= 0.023, d_loss_fake= 0.038, g_loss 3.412, d_loss 0.031\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 43 Batch 156/390 d_loss_real= 0.081, d_loss_fake= 0.043, g_loss 3.270, d_loss 0.062\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 43 Batch 157/390 d_loss_real= 0.097, d_loss_fake= 0.031, g_loss 3.663, d_loss 0.064\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 158/390 d_loss_real= 0.023, d_loss_fake= 0.028, g_loss 3.684, d_loss 0.025\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 159/390 d_loss_real= 0.065, d_loss_fake= 0.032, g_loss 3.548, d_loss 0.049\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 160/390 d_loss_real= 0.106, d_loss_fake= 0.037, g_loss 3.573, d_loss 0.071\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 161/390 d_loss_real= 0.135, d_loss_fake= 0.028, g_loss 3.720, d_loss 0.082\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 43 Batch 162/390 d_loss_real= 0.106, d_loss_fake= 0.030, g_loss 3.716, d_loss 0.068\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 163/390 d_loss_real= 0.162, d_loss_fake= 0.027, g_loss 3.774, d_loss 0.094\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 164/390 d_loss_real= 0.022, d_loss_fake= 0.023, g_loss 3.860, d_loss 0.022\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 165/390 d_loss_real= 0.089, d_loss_fake= 0.028, g_loss 3.762, d_loss 0.059\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 166/390 d_loss_real= 0.091, d_loss_fake= 0.031, g_loss 3.523, d_loss 0.061\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 167/390 d_loss_real= 0.117, d_loss_fake= 0.025, g_loss 3.762, d_loss 0.071\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 168/390 d_loss_real= 0.112, d_loss_fake= 0.035, g_loss 3.624, d_loss 0.074\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 43 Batch 169/390 d_loss_real= 0.203, d_loss_fake= 0.043, g_loss 3.595, d_loss 0.123\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 43 Batch 170/390 d_loss_real= 0.030, d_loss_fake= 0.033, g_loss 3.698, d_loss 0.031\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 171/390 d_loss_real= 0.299, d_loss_fake= 0.031, g_loss 3.702, d_loss 0.165\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 172/390 d_loss_real= 0.112, d_loss_fake= 0.023, g_loss 3.952, d_loss 0.067\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 173/390 d_loss_real= 0.006, d_loss_fake= 0.022, g_loss 4.136, d_loss 0.014\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 43 Batch 174/390 d_loss_real= 0.077, d_loss_fake= 0.021, g_loss 4.094, d_loss 0.049\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 43 Batch 175/390 d_loss_real= 0.047, d_loss_fake= 0.020, g_loss 4.143, d_loss 0.033\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 176/390 d_loss_real= 0.005, d_loss_fake= 0.019, g_loss 4.144, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 177/390 d_loss_real= 0.000, d_loss_fake= 0.016, g_loss 4.318, d_loss 0.008\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 43 Batch 178/390 d_loss_real= 0.167, d_loss_fake= 0.020, g_loss 4.196, d_loss 0.094\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 43 Batch 179/390 d_loss_real= 0.071, d_loss_fake= 0.019, g_loss 4.176, d_loss 0.045\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 180/390 d_loss_real= 0.112, d_loss_fake= 0.020, g_loss 4.139, d_loss 0.066\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 181/390 d_loss_real= 0.073, d_loss_fake= 0.018, g_loss 4.108, d_loss 0.046\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 43 Batch 182/390 d_loss_real= 0.003, d_loss_fake= 0.024, g_loss 3.965, d_loss 0.014\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 183/390 d_loss_real= 0.068, d_loss_fake= 0.020, g_loss 3.973, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 184/390 d_loss_real= 0.075, d_loss_fake= 0.023, g_loss 3.918, d_loss 0.049\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 43 Batch 185/390 d_loss_real= 0.142, d_loss_fake= 0.025, g_loss 3.738, d_loss 0.083\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 186/390 d_loss_real= 0.000, d_loss_fake= 0.027, g_loss 3.851, d_loss 0.013\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 43 Batch 187/390 d_loss_real= 0.145, d_loss_fake= 0.028, g_loss 3.869, d_loss 0.086\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 43 Batch 188/390 d_loss_real= 0.001, d_loss_fake= 0.028, g_loss 3.720, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 189/390 d_loss_real= 0.160, d_loss_fake= 0.027, g_loss 3.689, d_loss 0.093\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 190/390 d_loss_real= 0.010, d_loss_fake= 0.028, g_loss 3.579, d_loss 0.019\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 191/390 d_loss_real= 0.102, d_loss_fake= 0.035, g_loss 3.506, d_loss 0.069\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 192/390 d_loss_real= 0.080, d_loss_fake= 0.032, g_loss 3.750, d_loss 0.056\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 193/390 d_loss_real= 0.022, d_loss_fake= 0.026, g_loss 3.832, d_loss 0.024\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 194/390 d_loss_real= 0.078, d_loss_fake= 0.033, g_loss 3.711, d_loss 0.056\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 195/390 d_loss_real= 0.121, d_loss_fake= 0.029, g_loss 3.748, d_loss 0.075\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 43 Batch 196/390 d_loss_real= 0.109, d_loss_fake= 0.026, g_loss 3.842, d_loss 0.068\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 43 Batch 197/390 d_loss_real= 0.158, d_loss_fake= 0.028, g_loss 3.736, d_loss 0.093\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 198/390 d_loss_real= 0.085, d_loss_fake= 0.024, g_loss 3.758, d_loss 0.054\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 43 Batch 199/390 d_loss_real= 0.177, d_loss_fake= 0.025, g_loss 3.773, d_loss 0.101\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 43 Batch 200/390 d_loss_real= 0.020, d_loss_fake= 0.025, g_loss 3.709, d_loss 0.023\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 43 Batch 201/390 d_loss_real= 0.065, d_loss_fake= 0.028, g_loss 3.705, d_loss 0.047\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 43 Batch 202/390 d_loss_real= 0.094, d_loss_fake= 0.029, g_loss 3.727, d_loss 0.061\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 203/390 d_loss_real= 0.194, d_loss_fake= 0.040, g_loss 3.419, d_loss 0.117\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 204/390 d_loss_real= 0.068, d_loss_fake= 0.047, g_loss 3.427, d_loss 0.057\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 205/390 d_loss_real= 0.072, d_loss_fake= 0.035, g_loss 3.654, d_loss 0.054\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 43 Batch 206/390 d_loss_real= 0.117, d_loss_fake= 0.035, g_loss 3.484, d_loss 0.076\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 43 Batch 207/390 d_loss_real= 0.128, d_loss_fake= 0.033, g_loss 3.667, d_loss 0.080\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 208/390 d_loss_real= 0.073, d_loss_fake= 0.032, g_loss 3.622, d_loss 0.053\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 209/390 d_loss_real= 0.184, d_loss_fake= 0.036, g_loss 3.388, d_loss 0.110\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 43 Batch 210/390 d_loss_real= 0.090, d_loss_fake= 0.047, g_loss 3.346, d_loss 0.069\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 43 Batch 211/390 d_loss_real= 0.107, d_loss_fake= 0.047, g_loss 3.433, d_loss 0.077\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 43 Batch 212/390 d_loss_real= 0.000, d_loss_fake= 0.044, g_loss 3.537, d_loss 0.022\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 43 Batch 213/390 d_loss_real= 0.161, d_loss_fake= 0.034, g_loss 3.638, d_loss 0.097\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 214/390 d_loss_real= 0.100, d_loss_fake= 0.033, g_loss 3.667, d_loss 0.066\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 43 Batch 215/390 d_loss_real= 0.055, d_loss_fake= 0.030, g_loss 3.728, d_loss 0.043\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 43 Batch 216/390 d_loss_real= 0.185, d_loss_fake= 0.028, g_loss 3.783, d_loss 0.106\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 217/390 d_loss_real= 0.002, d_loss_fake= 0.027, g_loss 3.831, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 218/390 d_loss_real= 0.001, d_loss_fake= 0.023, g_loss 3.852, d_loss 0.012\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 219/390 d_loss_real= 0.111, d_loss_fake= 0.024, g_loss 3.964, d_loss 0.067\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 220/390 d_loss_real= 0.132, d_loss_fake= 0.025, g_loss 3.908, d_loss 0.078\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 221/390 d_loss_real= 0.250, d_loss_fake= 0.026, g_loss 3.848, d_loss 0.138\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 222/390 d_loss_real= 0.187, d_loss_fake= 0.027, g_loss 3.761, d_loss 0.107\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 223/390 d_loss_real= 0.003, d_loss_fake= 0.029, g_loss 3.634, d_loss 0.016\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 43 Batch 224/390 d_loss_real= 0.071, d_loss_fake= 0.029, g_loss 3.601, d_loss 0.050\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 225/390 d_loss_real= 0.086, d_loss_fake= 0.031, g_loss 3.555, d_loss 0.059\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 43 Batch 226/390 d_loss_real= 0.179, d_loss_fake= 0.038, g_loss 3.362, d_loss 0.109\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 227/390 d_loss_real= 0.097, d_loss_fake= 0.038, g_loss 3.498, d_loss 0.068\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 43 Batch 228/390 d_loss_real= 0.107, d_loss_fake= 0.036, g_loss 3.545, d_loss 0.071\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 229/390 d_loss_real= 0.227, d_loss_fake= 0.027, g_loss 3.699, d_loss 0.127\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 230/390 d_loss_real= 0.081, d_loss_fake= 0.025, g_loss 3.782, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 231/390 d_loss_real= 0.125, d_loss_fake= 0.025, g_loss 3.761, d_loss 0.075\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 232/390 d_loss_real= 0.081, d_loss_fake= 0.024, g_loss 3.839, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 233/390 d_loss_real= 0.111, d_loss_fake= 0.025, g_loss 3.760, d_loss 0.068\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 43 Batch 234/390 d_loss_real= 0.105, d_loss_fake= 0.026, g_loss 3.778, d_loss 0.066\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 43 Batch 235/390 d_loss_real= 0.160, d_loss_fake= 0.030, g_loss 3.663, d_loss 0.095\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 236/390 d_loss_real= 0.102, d_loss_fake= 0.039, g_loss 3.462, d_loss 0.071\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 43 Batch 237/390 d_loss_real= 0.000, d_loss_fake= 0.050, g_loss 3.501, d_loss 0.025\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 43 Batch 238/390 d_loss_real= 0.043, d_loss_fake= 0.038, g_loss 3.695, d_loss 0.041\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 239/390 d_loss_real= 0.102, d_loss_fake= 0.026, g_loss 3.810, d_loss 0.064\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 240/390 d_loss_real= 0.000, d_loss_fake= 0.022, g_loss 4.019, d_loss 0.011\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 241/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 4.158, d_loss 0.010\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 242/390 d_loss_real= 0.051, d_loss_fake= 0.019, g_loss 4.123, d_loss 0.035\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 243/390 d_loss_real= 0.215, d_loss_fake= 0.020, g_loss 4.054, d_loss 0.117\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 244/390 d_loss_real= 0.305, d_loss_fake= 0.021, g_loss 3.922, d_loss 0.163\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 245/390 d_loss_real= 0.071, d_loss_fake= 0.028, g_loss 3.689, d_loss 0.050\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 246/390 d_loss_real= 0.208, d_loss_fake= 0.041, g_loss 3.399, d_loss 0.124\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 247/390 d_loss_real= 0.108, d_loss_fake= 0.049, g_loss 3.312, d_loss 0.078\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 248/390 d_loss_real= 0.041, d_loss_fake= 0.054, g_loss 3.290, d_loss 0.048\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 249/390 d_loss_real= 0.123, d_loss_fake= 0.044, g_loss 3.330, d_loss 0.084\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 43 Batch 250/390 d_loss_real= 0.066, d_loss_fake= 0.044, g_loss 3.377, d_loss 0.055\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 43 Batch 251/390 d_loss_real= 0.124, d_loss_fake= 0.039, g_loss 3.354, d_loss 0.082\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 43 Batch 252/390 d_loss_real= 0.151, d_loss_fake= 0.042, g_loss 3.314, d_loss 0.096\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 43 Batch 253/390 d_loss_real= 0.163, d_loss_fake= 0.047, g_loss 3.227, d_loss 0.105\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 254/390 d_loss_real= 0.076, d_loss_fake= 0.053, g_loss 3.161, d_loss 0.064\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 255/390 d_loss_real= 0.079, d_loss_fake= 0.050, g_loss 3.143, d_loss 0.064\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 256/390 d_loss_real= 0.277, d_loss_fake= 0.054, g_loss 3.260, d_loss 0.165\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 257/390 d_loss_real= 0.064, d_loss_fake= 0.051, g_loss 3.397, d_loss 0.058\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 258/390 d_loss_real= 0.140, d_loss_fake= 0.032, g_loss 3.589, d_loss 0.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 259/390 d_loss_real= 0.081, d_loss_fake= 0.027, g_loss 3.711, d_loss 0.054\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 260/390 d_loss_real= 0.025, d_loss_fake= 0.026, g_loss 3.729, d_loss 0.025\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 261/390 d_loss_real= 0.110, d_loss_fake= 0.025, g_loss 3.735, d_loss 0.068\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 262/390 d_loss_real= 0.080, d_loss_fake= 0.026, g_loss 3.680, d_loss 0.053\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 263/390 d_loss_real= 0.064, d_loss_fake= 0.026, g_loss 3.698, d_loss 0.045\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 264/390 d_loss_real= 0.020, d_loss_fake= 0.028, g_loss 3.667, d_loss 0.024\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 265/390 d_loss_real= 0.009, d_loss_fake= 0.028, g_loss 3.733, d_loss 0.018\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 266/390 d_loss_real= 0.224, d_loss_fake= 0.029, g_loss 3.559, d_loss 0.126\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 43 Batch 267/390 d_loss_real= 0.060, d_loss_fake= 0.041, g_loss 3.592, d_loss 0.051\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 43 Batch 268/390 d_loss_real= 0.102, d_loss_fake= 0.031, g_loss 3.639, d_loss 0.066\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 269/390 d_loss_real= 0.068, d_loss_fake= 0.030, g_loss 3.680, d_loss 0.049\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 270/390 d_loss_real= 0.146, d_loss_fake= 0.028, g_loss 3.679, d_loss 0.087\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 43 Batch 271/390 d_loss_real= 0.116, d_loss_fake= 0.030, g_loss 3.520, d_loss 0.073\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 272/390 d_loss_real= 0.053, d_loss_fake= 0.039, g_loss 3.456, d_loss 0.046\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 273/390 d_loss_real= 0.000, d_loss_fake= 0.044, g_loss 3.596, d_loss 0.022\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 274/390 d_loss_real= 0.202, d_loss_fake= 0.038, g_loss 3.796, d_loss 0.120\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 275/390 d_loss_real= 0.093, d_loss_fake= 0.024, g_loss 3.875, d_loss 0.058\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 276/390 d_loss_real= 0.039, d_loss_fake= 0.024, g_loss 3.917, d_loss 0.032\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 43 Batch 277/390 d_loss_real= 0.000, d_loss_fake= 0.023, g_loss 3.918, d_loss 0.011\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 278/390 d_loss_real= 0.071, d_loss_fake= 0.021, g_loss 4.120, d_loss 0.046\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 279/390 d_loss_real= 0.065, d_loss_fake= 0.020, g_loss 4.051, d_loss 0.042\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 280/390 d_loss_real= 0.003, d_loss_fake= 0.021, g_loss 4.020, d_loss 0.012\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 281/390 d_loss_real= 0.162, d_loss_fake= 0.021, g_loss 3.970, d_loss 0.091\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 43 Batch 282/390 d_loss_real= 0.130, d_loss_fake= 0.024, g_loss 3.996, d_loss 0.077\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 43 Batch 283/390 d_loss_real= 0.005, d_loss_fake= 0.032, g_loss 3.950, d_loss 0.019\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 284/390 d_loss_real= 0.124, d_loss_fake= 0.024, g_loss 4.180, d_loss 0.074\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 285/390 d_loss_real= 0.083, d_loss_fake= 0.019, g_loss 4.169, d_loss 0.051\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 286/390 d_loss_real= 0.128, d_loss_fake= 0.020, g_loss 3.972, d_loss 0.074\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 287/390 d_loss_real= 0.203, d_loss_fake= 0.027, g_loss 3.722, d_loss 0.115\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 288/390 d_loss_real= 0.000, d_loss_fake= 0.031, g_loss 3.598, d_loss 0.016\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 289/390 d_loss_real= 0.199, d_loss_fake= 0.029, g_loss 3.690, d_loss 0.114\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 290/390 d_loss_real= 0.002, d_loss_fake= 0.031, g_loss 3.650, d_loss 0.017\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 43 Batch 291/390 d_loss_real= 0.063, d_loss_fake= 0.038, g_loss 3.551, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 292/390 d_loss_real= 0.156, d_loss_fake= 0.033, g_loss 3.728, d_loss 0.094\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 293/390 d_loss_real= 0.139, d_loss_fake= 0.032, g_loss 3.794, d_loss 0.086\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 294/390 d_loss_real= 0.180, d_loss_fake= 0.029, g_loss 3.837, d_loss 0.105\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 295/390 d_loss_real= 0.160, d_loss_fake= 0.027, g_loss 3.916, d_loss 0.093\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 43 Batch 296/390 d_loss_real= 0.093, d_loss_fake= 0.023, g_loss 4.044, d_loss 0.058\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 297/390 d_loss_real= 0.236, d_loss_fake= 0.024, g_loss 3.795, d_loss 0.130\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 298/390 d_loss_real= 0.105, d_loss_fake= 0.028, g_loss 3.559, d_loss 0.067\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 299/390 d_loss_real= 0.140, d_loss_fake= 0.046, g_loss 3.140, d_loss 0.093\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 43 Batch 300/390 d_loss_real= 0.022, d_loss_fake= 0.097, g_loss 3.421, d_loss 0.060\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 43 Batch 301/390 d_loss_real= 0.059, d_loss_fake= 0.024, g_loss 4.159, d_loss 0.041\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 302/390 d_loss_real= 0.070, d_loss_fake= 0.016, g_loss 4.380, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 303/390 d_loss_real= 0.211, d_loss_fake= 0.012, g_loss 4.500, d_loss 0.111\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 304/390 d_loss_real= 0.061, d_loss_fake= 0.015, g_loss 4.601, d_loss 0.038\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 305/390 d_loss_real= 0.063, d_loss_fake= 0.014, g_loss 4.493, d_loss 0.038\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 306/390 d_loss_real= 0.090, d_loss_fake= 0.017, g_loss 4.402, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 307/390 d_loss_real= 0.134, d_loss_fake= 0.017, g_loss 4.257, d_loss 0.075\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 43 Batch 308/390 d_loss_real= 0.032, d_loss_fake= 0.020, g_loss 4.030, d_loss 0.026\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 309/390 d_loss_real= 0.116, d_loss_fake= 0.027, g_loss 3.600, d_loss 0.071\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 43 Batch 310/390 d_loss_real= 0.068, d_loss_fake= 0.057, g_loss 3.420, d_loss 0.063\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 311/390 d_loss_real= 0.000, d_loss_fake= 0.050, g_loss 3.296, d_loss 0.025\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 312/390 d_loss_real= 0.000, d_loss_fake= 0.039, g_loss 3.617, d_loss 0.019\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 313/390 d_loss_real= 0.056, d_loss_fake= 0.031, g_loss 3.811, d_loss 0.043\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 43 Batch 314/390 d_loss_real= 0.008, d_loss_fake= 0.031, g_loss 3.910, d_loss 0.019\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 315/390 d_loss_real= 0.210, d_loss_fake= 0.092, g_loss 3.750, d_loss 0.151\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 316/390 d_loss_real= 0.005, d_loss_fake= 0.056, g_loss 4.041, d_loss 0.030\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 43 Batch 317/390 d_loss_real= 0.187, d_loss_fake= 0.022, g_loss 4.346, d_loss 0.105\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 318/390 d_loss_real= 0.177, d_loss_fake= 0.016, g_loss 4.604, d_loss 0.097\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 43 Batch 319/390 d_loss_real= 0.059, d_loss_fake= 0.012, g_loss 4.743, d_loss 0.036\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 320/390 d_loss_real= 0.228, d_loss_fake= 0.011, g_loss 4.771, d_loss 0.120\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 321/390 d_loss_real= 0.161, d_loss_fake= 0.011, g_loss 4.690, d_loss 0.086\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 322/390 d_loss_real= 0.121, d_loss_fake= 0.013, g_loss 4.652, d_loss 0.067\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 323/390 d_loss_real= 0.007, d_loss_fake= 0.014, g_loss 4.446, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 324/390 d_loss_real= 0.046, d_loss_fake= 0.017, g_loss 4.173, d_loss 0.031\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 325/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 3.883, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 326/390 d_loss_real= 0.000, d_loss_fake= 0.027, g_loss 3.666, d_loss 0.014\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 327/390 d_loss_real= 0.056, d_loss_fake= 0.044, g_loss 3.556, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 328/390 d_loss_real= 0.177, d_loss_fake= 0.037, g_loss 3.644, d_loss 0.107\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 329/390 d_loss_real= 0.013, d_loss_fake= 0.032, g_loss 3.797, d_loss 0.022\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 43 Batch 330/390 d_loss_real= 0.140, d_loss_fake= 0.026, g_loss 3.875, d_loss 0.083\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 43 Batch 331/390 d_loss_real= 0.000, d_loss_fake= 0.024, g_loss 3.832, d_loss 0.012\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 332/390 d_loss_real= 0.019, d_loss_fake= 0.024, g_loss 3.828, d_loss 0.021\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 333/390 d_loss_real= 0.125, d_loss_fake= 0.025, g_loss 3.700, d_loss 0.075\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 334/390 d_loss_real= 0.140, d_loss_fake= 0.026, g_loss 3.803, d_loss 0.083\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 335/390 d_loss_real= 0.062, d_loss_fake= 0.029, g_loss 3.611, d_loss 0.045\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 336/390 d_loss_real= 0.071, d_loss_fake= 0.032, g_loss 3.627, d_loss 0.052\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 337/390 d_loss_real= 0.073, d_loss_fake= 0.035, g_loss 3.530, d_loss 0.054\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 338/390 d_loss_real= 0.013, d_loss_fake= 0.035, g_loss 3.463, d_loss 0.024\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 43 Batch 339/390 d_loss_real= 0.162, d_loss_fake= 0.034, g_loss 3.409, d_loss 0.098\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 340/390 d_loss_real= 0.086, d_loss_fake= 0.038, g_loss 3.398, d_loss 0.062\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 43 Batch 341/390 d_loss_real= 0.000, d_loss_fake= 0.037, g_loss 3.396, d_loss 0.019\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 342/390 d_loss_real= 0.216, d_loss_fake= 0.049, g_loss 3.349, d_loss 0.132\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 343/390 d_loss_real= 0.059, d_loss_fake= 0.048, g_loss 3.246, d_loss 0.054\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 344/390 d_loss_real= 0.006, d_loss_fake= 0.061, g_loss 3.393, d_loss 0.033\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 345/390 d_loss_real= 0.105, d_loss_fake= 0.041, g_loss 3.664, d_loss 0.073\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 346/390 d_loss_real= 0.138, d_loss_fake= 0.024, g_loss 3.893, d_loss 0.081\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 347/390 d_loss_real= 0.172, d_loss_fake= 0.021, g_loss 3.978, d_loss 0.097\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 348/390 d_loss_real= 0.250, d_loss_fake= 0.021, g_loss 3.905, d_loss 0.135\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 43 Batch 349/390 d_loss_real= 0.064, d_loss_fake= 0.021, g_loss 3.878, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 350/390 d_loss_real= 0.139, d_loss_fake= 0.021, g_loss 3.840, d_loss 0.080\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 351/390 d_loss_real= 0.138, d_loss_fake= 0.025, g_loss 3.718, d_loss 0.082\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 352/390 d_loss_real= 0.168, d_loss_fake= 0.031, g_loss 3.544, d_loss 0.100\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 353/390 d_loss_real= 0.002, d_loss_fake= 0.037, g_loss 3.548, d_loss 0.020\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 354/390 d_loss_real= 0.012, d_loss_fake= 0.054, g_loss 3.571, d_loss 0.033\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 355/390 d_loss_real= 0.075, d_loss_fake= 0.029, g_loss 3.730, d_loss 0.052\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 356/390 d_loss_real= 0.069, d_loss_fake= 0.023, g_loss 3.916, d_loss 0.046\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 43 Batch 357/390 d_loss_real= 0.021, d_loss_fake= 0.021, g_loss 3.983, d_loss 0.021\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 358/390 d_loss_real= 0.186, d_loss_fake= 0.020, g_loss 3.988, d_loss 0.103\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 359/390 d_loss_real= 0.144, d_loss_fake= 0.020, g_loss 4.000, d_loss 0.082\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 43 Batch 360/390 d_loss_real= 0.000, d_loss_fake= 0.021, g_loss 3.919, d_loss 0.010\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 361/390 d_loss_real= 0.019, d_loss_fake= 0.023, g_loss 3.878, d_loss 0.021\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 362/390 d_loss_real= 0.041, d_loss_fake= 0.024, g_loss 3.829, d_loss 0.032\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 363/390 d_loss_real= 0.000, d_loss_fake= 0.023, g_loss 3.828, d_loss 0.012\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 43 Batch 364/390 d_loss_real= 0.057, d_loss_fake= 0.025, g_loss 3.805, d_loss 0.041\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 365/390 d_loss_real= 0.000, d_loss_fake= 0.023, g_loss 3.929, d_loss 0.012\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 43 Batch 366/390 d_loss_real= 0.057, d_loss_fake= 0.026, g_loss 3.890, d_loss 0.041\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 367/390 d_loss_real= 0.153, d_loss_fake= 0.023, g_loss 3.968, d_loss 0.088\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 368/390 d_loss_real= 0.133, d_loss_fake= 0.023, g_loss 4.014, d_loss 0.078\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 43 Batch 369/390 d_loss_real= 0.046, d_loss_fake= 0.021, g_loss 4.023, d_loss 0.033\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 370/390 d_loss_real= 0.102, d_loss_fake= 0.021, g_loss 3.934, d_loss 0.061\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 371/390 d_loss_real= 0.027, d_loss_fake= 0.023, g_loss 3.914, d_loss 0.025\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 372/390 d_loss_real= 0.072, d_loss_fake= 0.025, g_loss 4.024, d_loss 0.049\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 373/390 d_loss_real= 0.165, d_loss_fake= 0.022, g_loss 4.108, d_loss 0.094\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 374/390 d_loss_real= 0.186, d_loss_fake= 0.019, g_loss 4.073, d_loss 0.103\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 43 Batch 375/390 d_loss_real= 0.150, d_loss_fake= 0.023, g_loss 3.962, d_loss 0.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 376/390 d_loss_real= 0.008, d_loss_fake= 0.024, g_loss 4.013, d_loss 0.016\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 377/390 d_loss_real= 0.141, d_loss_fake= 0.018, g_loss 4.150, d_loss 0.079\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 378/390 d_loss_real= 0.093, d_loss_fake= 0.018, g_loss 4.166, d_loss 0.055\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 379/390 d_loss_real= 0.125, d_loss_fake= 0.023, g_loss 3.931, d_loss 0.074\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 43 Batch 380/390 d_loss_real= 0.001, d_loss_fake= 0.022, g_loss 4.114, d_loss 0.012\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 381/390 d_loss_real= 0.254, d_loss_fake= 0.027, g_loss 4.098, d_loss 0.141\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43 Batch 382/390 d_loss_real= 0.070, d_loss_fake= 0.032, g_loss 3.936, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 383/390 d_loss_real= 0.095, d_loss_fake= 0.032, g_loss 3.938, d_loss 0.064\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43 Batch 384/390 d_loss_real= 0.025, d_loss_fake= 0.035, g_loss 3.937, d_loss 0.030\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43 Batch 385/390 d_loss_real= 0.081, d_loss_fake= 0.035, g_loss 3.968, d_loss 0.058\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 43 Batch 386/390 d_loss_real= 0.186, d_loss_fake= 0.024, g_loss 4.062, d_loss 0.105\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 43 Batch 387/390 d_loss_real= 0.147, d_loss_fake= 0.029, g_loss 3.729, d_loss 0.088\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 43 Batch 388/390 d_loss_real= 0.000, d_loss_fake= 0.023, g_loss 4.084, d_loss 0.011\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43 Batch 389/390 d_loss_real= 0.001, d_loss_fake= 0.027, g_loss 4.018, d_loss 0.014\n",
            "2/2 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43 Batch 390/390 d_loss_real= 0.376, d_loss_fake= 0.023, g_loss 3.750, d_loss 0.200\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 1/390 d_loss_real= 0.124, d_loss_fake= 0.054, g_loss 3.391, d_loss 0.089\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 2/390 d_loss_real= 0.075, d_loss_fake= 0.046, g_loss 3.398, d_loss 0.060\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 44 Batch 3/390 d_loss_real= 0.044, d_loss_fake= 0.053, g_loss 3.706, d_loss 0.049\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 44 Batch 4/390 d_loss_real= 0.000, d_loss_fake= 0.026, g_loss 4.070, d_loss 0.013\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 44 Batch 5/390 d_loss_real= 0.135, d_loss_fake= 0.023, g_loss 4.045, d_loss 0.079\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 44 Batch 6/390 d_loss_real= 0.090, d_loss_fake= 0.019, g_loss 4.109, d_loss 0.055\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 44 Batch 7/390 d_loss_real= 0.150, d_loss_fake= 0.020, g_loss 4.008, d_loss 0.085\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 44 Batch 8/390 d_loss_real= 0.162, d_loss_fake= 0.020, g_loss 3.986, d_loss 0.091\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 9/390 d_loss_real= 0.199, d_loss_fake= 0.025, g_loss 3.747, d_loss 0.112\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 44 Batch 10/390 d_loss_real= 0.077, d_loss_fake= 0.033, g_loss 3.715, d_loss 0.055\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 11/390 d_loss_real= 0.140, d_loss_fake= 0.034, g_loss 3.530, d_loss 0.087\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 12/390 d_loss_real= 0.188, d_loss_fake= 0.045, g_loss 3.463, d_loss 0.116\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 13/390 d_loss_real= 0.057, d_loss_fake= 0.036, g_loss 3.670, d_loss 0.047\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 14/390 d_loss_real= 0.124, d_loss_fake= 0.044, g_loss 3.516, d_loss 0.084\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 15/390 d_loss_real= 0.105, d_loss_fake= 0.030, g_loss 3.653, d_loss 0.068\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 44 Batch 16/390 d_loss_real= 0.246, d_loss_fake= 0.055, g_loss 3.738, d_loss 0.150\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 17/390 d_loss_real= 0.071, d_loss_fake= 0.041, g_loss 3.811, d_loss 0.056\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 44 Batch 18/390 d_loss_real= 0.046, d_loss_fake= 0.028, g_loss 4.010, d_loss 0.037\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 19/390 d_loss_real= 0.214, d_loss_fake= 0.027, g_loss 3.759, d_loss 0.120\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 20/390 d_loss_real= 0.066, d_loss_fake= 0.026, g_loss 3.957, d_loss 0.046\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 21/390 d_loss_real= 0.059, d_loss_fake= 0.021, g_loss 4.046, d_loss 0.040\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 22/390 d_loss_real= 0.000, d_loss_fake= 0.021, g_loss 4.123, d_loss 0.010\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 23/390 d_loss_real= 0.073, d_loss_fake= 0.018, g_loss 4.279, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 24/390 d_loss_real= 0.067, d_loss_fake= 0.015, g_loss 4.385, d_loss 0.041\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 25/390 d_loss_real= 0.059, d_loss_fake= 0.014, g_loss 4.436, d_loss 0.036\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 26/390 d_loss_real= 0.008, d_loss_fake= 0.013, g_loss 4.465, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 27/390 d_loss_real= 0.121, d_loss_fake= 0.014, g_loss 4.409, d_loss 0.068\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 28/390 d_loss_real= 0.000, d_loss_fake= 0.013, g_loss 4.455, d_loss 0.006\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 44 Batch 29/390 d_loss_real= 0.143, d_loss_fake= 0.013, g_loss 4.455, d_loss 0.078\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 30/390 d_loss_real= 0.133, d_loss_fake= 0.013, g_loss 4.396, d_loss 0.073\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 31/390 d_loss_real= 0.103, d_loss_fake= 0.014, g_loss 4.350, d_loss 0.059\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 32/390 d_loss_real= 0.052, d_loss_fake= 0.014, g_loss 4.158, d_loss 0.033\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 33/390 d_loss_real= 0.166, d_loss_fake= 0.017, g_loss 4.038, d_loss 0.091\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 34/390 d_loss_real= 0.124, d_loss_fake= 0.021, g_loss 3.837, d_loss 0.073\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 35/390 d_loss_real= 0.051, d_loss_fake= 0.028, g_loss 3.743, d_loss 0.040\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 36/390 d_loss_real= 0.000, d_loss_fake= 0.029, g_loss 3.561, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 37/390 d_loss_real= 0.094, d_loss_fake= 0.037, g_loss 3.580, d_loss 0.066\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 38/390 d_loss_real= 0.210, d_loss_fake= 0.036, g_loss 3.742, d_loss 0.123\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 39/390 d_loss_real= 0.283, d_loss_fake= 0.035, g_loss 3.815, d_loss 0.159\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 40/390 d_loss_real= 0.109, d_loss_fake= 0.026, g_loss 3.919, d_loss 0.067\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 41/390 d_loss_real= 0.213, d_loss_fake= 0.026, g_loss 3.937, d_loss 0.120\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 42/390 d_loss_real= 0.006, d_loss_fake= 0.022, g_loss 4.013, d_loss 0.014\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 43/390 d_loss_real= 0.160, d_loss_fake= 0.021, g_loss 4.041, d_loss 0.090\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 44 Batch 44/390 d_loss_real= 0.000, d_loss_fake= 0.021, g_loss 4.042, d_loss 0.011\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 45/390 d_loss_real= 0.117, d_loss_fake= 0.022, g_loss 3.901, d_loss 0.069\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 46/390 d_loss_real= 0.234, d_loss_fake= 0.025, g_loss 3.724, d_loss 0.129\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 47/390 d_loss_real= 0.048, d_loss_fake= 0.029, g_loss 3.599, d_loss 0.039\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 48/390 d_loss_real= 0.210, d_loss_fake= 0.037, g_loss 3.336, d_loss 0.123\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 44 Batch 49/390 d_loss_real= 0.034, d_loss_fake= 0.094, g_loss 3.350, d_loss 0.064\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 44 Batch 50/390 d_loss_real= 0.033, d_loss_fake= 0.032, g_loss 3.776, d_loss 0.033\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 44 Batch 51/390 d_loss_real= 0.000, d_loss_fake= 0.026, g_loss 3.875, d_loss 0.013\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 44 Batch 52/390 d_loss_real= 0.054, d_loss_fake= 0.023, g_loss 3.981, d_loss 0.039\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 44 Batch 53/390 d_loss_real= 0.163, d_loss_fake= 0.021, g_loss 4.003, d_loss 0.092\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 54/390 d_loss_real= 0.008, d_loss_fake= 0.022, g_loss 3.939, d_loss 0.015\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 55/390 d_loss_real= 0.014, d_loss_fake= 0.022, g_loss 3.961, d_loss 0.018\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 44 Batch 56/390 d_loss_real= 0.055, d_loss_fake= 0.022, g_loss 3.887, d_loss 0.039\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 57/390 d_loss_real= 0.029, d_loss_fake= 0.029, g_loss 3.701, d_loss 0.029\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 58/390 d_loss_real= 0.051, d_loss_fake= 0.030, g_loss 3.670, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 59/390 d_loss_real= 0.002, d_loss_fake= 0.034, g_loss 3.598, d_loss 0.018\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 44 Batch 60/390 d_loss_real= 0.126, d_loss_fake= 0.050, g_loss 3.407, d_loss 0.088\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 44 Batch 61/390 d_loss_real= 0.065, d_loss_fake= 0.075, g_loss 3.460, d_loss 0.070\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 62/390 d_loss_real= 0.002, d_loss_fake= 0.037, g_loss 3.945, d_loss 0.019\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 44 Batch 63/390 d_loss_real= 0.100, d_loss_fake= 0.022, g_loss 4.108, d_loss 0.061\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 44 Batch 64/390 d_loss_real= 0.267, d_loss_fake= 0.020, g_loss 4.093, d_loss 0.143\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 65/390 d_loss_real= 0.114, d_loss_fake= 0.022, g_loss 4.041, d_loss 0.068\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 44 Batch 66/390 d_loss_real= 0.002, d_loss_fake= 0.020, g_loss 3.993, d_loss 0.011\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 44 Batch 67/390 d_loss_real= 0.012, d_loss_fake= 0.023, g_loss 3.936, d_loss 0.017\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 68/390 d_loss_real= 0.104, d_loss_fake= 0.028, g_loss 3.772, d_loss 0.066\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 44 Batch 69/390 d_loss_real= 0.123, d_loss_fake= 0.040, g_loss 3.389, d_loss 0.082\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 70/390 d_loss_real= 0.036, d_loss_fake= 0.077, g_loss 3.435, d_loss 0.056\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 71/390 d_loss_real= 0.040, d_loss_fake= 0.054, g_loss 3.640, d_loss 0.047\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 44 Batch 72/390 d_loss_real= 0.069, d_loss_fake= 0.033, g_loss 4.077, d_loss 0.051\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 44 Batch 73/390 d_loss_real= 0.038, d_loss_fake= 0.025, g_loss 4.118, d_loss 0.032\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 44 Batch 74/390 d_loss_real= 0.075, d_loss_fake= 0.020, g_loss 4.162, d_loss 0.047\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 75/390 d_loss_real= 0.033, d_loss_fake= 0.018, g_loss 4.200, d_loss 0.025\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 76/390 d_loss_real= 0.185, d_loss_fake= 0.018, g_loss 4.140, d_loss 0.102\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 77/390 d_loss_real= 0.214, d_loss_fake= 0.024, g_loss 3.929, d_loss 0.119\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 78/390 d_loss_real= 0.065, d_loss_fake= 0.034, g_loss 3.647, d_loss 0.049\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 44 Batch 79/390 d_loss_real= 0.110, d_loss_fake= 0.049, g_loss 3.631, d_loss 0.079\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 80/390 d_loss_real= 0.111, d_loss_fake= 0.041, g_loss 3.471, d_loss 0.076\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 81/390 d_loss_real= 0.003, d_loss_fake= 0.030, g_loss 4.031, d_loss 0.016\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 82/390 d_loss_real= 0.066, d_loss_fake= 0.019, g_loss 4.292, d_loss 0.043\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 44 Batch 83/390 d_loss_real= 0.131, d_loss_fake= 0.019, g_loss 4.369, d_loss 0.075\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 84/390 d_loss_real= 0.064, d_loss_fake= 0.021, g_loss 4.159, d_loss 0.042\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 85/390 d_loss_real= 0.021, d_loss_fake= 0.019, g_loss 4.133, d_loss 0.020\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 86/390 d_loss_real= 0.122, d_loss_fake= 0.023, g_loss 3.953, d_loss 0.073\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 44 Batch 87/390 d_loss_real= 0.100, d_loss_fake= 0.025, g_loss 3.978, d_loss 0.062\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 88/390 d_loss_real= 0.212, d_loss_fake= 0.028, g_loss 3.761, d_loss 0.120\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 89/390 d_loss_real= 0.000, d_loss_fake= 0.036, g_loss 3.768, d_loss 0.018\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 90/390 d_loss_real= 0.053, d_loss_fake= 0.030, g_loss 3.599, d_loss 0.041\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 91/390 d_loss_real= 0.111, d_loss_fake= 0.059, g_loss 3.309, d_loss 0.085\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 92/390 d_loss_real= 0.060, d_loss_fake= 0.061, g_loss 3.786, d_loss 0.061\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 93/390 d_loss_real= 0.062, d_loss_fake= 0.040, g_loss 3.991, d_loss 0.051\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 94/390 d_loss_real= 0.004, d_loss_fake= 0.022, g_loss 4.336, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 95/390 d_loss_real= 0.095, d_loss_fake= 0.018, g_loss 4.381, d_loss 0.056\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 96/390 d_loss_real= 0.146, d_loss_fake= 0.015, g_loss 4.394, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 97/390 d_loss_real= 0.070, d_loss_fake= 0.016, g_loss 4.414, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 98/390 d_loss_real= 0.123, d_loss_fake= 0.016, g_loss 4.401, d_loss 0.069\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 99/390 d_loss_real= 0.187, d_loss_fake= 0.017, g_loss 4.220, d_loss 0.102\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 100/390 d_loss_real= 0.084, d_loss_fake= 0.023, g_loss 3.966, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 101/390 d_loss_real= 0.102, d_loss_fake= 0.024, g_loss 3.791, d_loss 0.063\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 102/390 d_loss_real= 0.056, d_loss_fake= 0.042, g_loss 3.605, d_loss 0.049\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 44 Batch 103/390 d_loss_real= 0.119, d_loss_fake= 0.072, g_loss 3.551, d_loss 0.095\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 104/390 d_loss_real= 0.059, d_loss_fake= 0.034, g_loss 3.844, d_loss 0.046\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 105/390 d_loss_real= 0.000, d_loss_fake= 0.023, g_loss 4.128, d_loss 0.011\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 106/390 d_loss_real= 0.062, d_loss_fake= 0.020, g_loss 4.313, d_loss 0.041\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 107/390 d_loss_real= 0.155, d_loss_fake= 0.017, g_loss 4.207, d_loss 0.086\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 108/390 d_loss_real= 0.050, d_loss_fake= 0.017, g_loss 4.257, d_loss 0.034\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 44 Batch 109/390 d_loss_real= 0.092, d_loss_fake= 0.017, g_loss 4.047, d_loss 0.055\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 110/390 d_loss_real= 0.005, d_loss_fake= 0.022, g_loss 3.889, d_loss 0.014\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 44 Batch 111/390 d_loss_real= 0.112, d_loss_fake= 0.025, g_loss 3.924, d_loss 0.069\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 112/390 d_loss_real= 0.154, d_loss_fake= 0.031, g_loss 3.884, d_loss 0.093\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 113/390 d_loss_real= 0.116, d_loss_fake= 0.032, g_loss 3.720, d_loss 0.074\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 44 Batch 114/390 d_loss_real= 0.005, d_loss_fake= 0.028, g_loss 3.940, d_loss 0.017\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 115/390 d_loss_real= 0.015, d_loss_fake= 0.020, g_loss 4.197, d_loss 0.017\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 116/390 d_loss_real= 0.138, d_loss_fake= 0.017, g_loss 4.323, d_loss 0.078\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 117/390 d_loss_real= 0.098, d_loss_fake= 0.014, g_loss 4.350, d_loss 0.056\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 118/390 d_loss_real= 0.071, d_loss_fake= 0.015, g_loss 4.284, d_loss 0.043\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 119/390 d_loss_real= 0.207, d_loss_fake= 0.017, g_loss 4.259, d_loss 0.112\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 44 Batch 120/390 d_loss_real= 0.112, d_loss_fake= 0.019, g_loss 4.107, d_loss 0.065\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 121/390 d_loss_real= 0.041, d_loss_fake= 0.026, g_loss 3.839, d_loss 0.033\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 44 Batch 122/390 d_loss_real= 0.051, d_loss_fake= 0.026, g_loss 3.609, d_loss 0.039\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 123/390 d_loss_real= 0.069, d_loss_fake= 0.043, g_loss 3.813, d_loss 0.056\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 124/390 d_loss_real= 0.063, d_loss_fake= 0.046, g_loss 4.096, d_loss 0.054\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 44 Batch 125/390 d_loss_real= 0.124, d_loss_fake= 0.021, g_loss 4.397, d_loss 0.072\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 126/390 d_loss_real= 0.192, d_loss_fake= 0.017, g_loss 4.319, d_loss 0.104\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 44 Batch 127/390 d_loss_real= 0.150, d_loss_fake= 0.016, g_loss 4.356, d_loss 0.083\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 44 Batch 128/390 d_loss_real= 0.248, d_loss_fake= 0.018, g_loss 4.146, d_loss 0.133\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 44 Batch 129/390 d_loss_real= 0.041, d_loss_fake= 0.020, g_loss 3.944, d_loss 0.030\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 44 Batch 130/390 d_loss_real= 0.112, d_loss_fake= 0.026, g_loss 3.756, d_loss 0.069\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 131/390 d_loss_real= 0.066, d_loss_fake= 0.040, g_loss 3.535, d_loss 0.053\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 132/390 d_loss_real= 0.083, d_loss_fake= 0.050, g_loss 3.439, d_loss 0.066\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 133/390 d_loss_real= 0.044, d_loss_fake= 0.052, g_loss 3.533, d_loss 0.048\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 44 Batch 134/390 d_loss_real= 0.269, d_loss_fake= 0.031, g_loss 3.525, d_loss 0.150\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 44 Batch 135/390 d_loss_real= 0.062, d_loss_fake= 0.031, g_loss 3.652, d_loss 0.047\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 44 Batch 136/390 d_loss_real= 0.059, d_loss_fake= 0.028, g_loss 3.723, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 137/390 d_loss_real= 0.173, d_loss_fake= 0.025, g_loss 3.713, d_loss 0.099\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 138/390 d_loss_real= 0.000, d_loss_fake= 0.026, g_loss 3.830, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 139/390 d_loss_real= 0.021, d_loss_fake= 0.026, g_loss 3.757, d_loss 0.023\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 44 Batch 140/390 d_loss_real= 0.413, d_loss_fake= 0.028, g_loss 3.677, d_loss 0.220\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 44 Batch 141/390 d_loss_real= 0.083, d_loss_fake= 0.033, g_loss 3.504, d_loss 0.058\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 142/390 d_loss_real= 0.105, d_loss_fake= 0.038, g_loss 3.448, d_loss 0.071\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 143/390 d_loss_real= 0.005, d_loss_fake= 0.036, g_loss 3.401, d_loss 0.021\n",
            "2/2 [==============================] - 0s 22ms/step\n",
            "Epoch 44 Batch 144/390 d_loss_real= 0.062, d_loss_fake= 0.031, g_loss 3.483, d_loss 0.047\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 44 Batch 145/390 d_loss_real= 0.084, d_loss_fake= 0.031, g_loss 3.452, d_loss 0.058\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 44 Batch 146/390 d_loss_real= 0.146, d_loss_fake= 0.031, g_loss 3.358, d_loss 0.088\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 44 Batch 147/390 d_loss_real= 0.073, d_loss_fake= 0.155, g_loss 4.063, d_loss 0.114\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 44 Batch 148/390 d_loss_real= 0.034, d_loss_fake= 0.018, g_loss 4.245, d_loss 0.026\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 149/390 d_loss_real= 0.082, d_loss_fake= 0.014, g_loss 4.376, d_loss 0.048\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 150/390 d_loss_real= 0.219, d_loss_fake= 0.015, g_loss 4.403, d_loss 0.117\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 151/390 d_loss_real= 0.406, d_loss_fake= 0.016, g_loss 4.210, d_loss 0.211\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 152/390 d_loss_real= 0.317, d_loss_fake= 0.018, g_loss 4.038, d_loss 0.167\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 153/390 d_loss_real= 0.263, d_loss_fake= 0.024, g_loss 3.814, d_loss 0.143\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 44 Batch 154/390 d_loss_real= 0.110, d_loss_fake= 0.027, g_loss 3.721, d_loss 0.069\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 155/390 d_loss_real= 0.266, d_loss_fake= 0.032, g_loss 3.455, d_loss 0.149\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 156/390 d_loss_real= 0.232, d_loss_fake= 0.038, g_loss 3.179, d_loss 0.135\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 44 Batch 157/390 d_loss_real= 0.151, d_loss_fake= 0.064, g_loss 2.667, d_loss 0.107\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 158/390 d_loss_real= 0.000, d_loss_fake= 0.252, g_loss 2.989, d_loss 0.126\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 159/390 d_loss_real= 0.289, d_loss_fake= 0.041, g_loss 3.367, d_loss 0.165\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 160/390 d_loss_real= 0.161, d_loss_fake= 0.038, g_loss 3.470, d_loss 0.099\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 161/390 d_loss_real= 0.192, d_loss_fake= 0.037, g_loss 3.453, d_loss 0.115\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 162/390 d_loss_real= 0.101, d_loss_fake= 0.035, g_loss 3.417, d_loss 0.068\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 163/390 d_loss_real= 0.150, d_loss_fake= 0.036, g_loss 3.443, d_loss 0.093\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 164/390 d_loss_real= 0.048, d_loss_fake= 0.035, g_loss 3.447, d_loss 0.041\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 165/390 d_loss_real= 0.209, d_loss_fake= 0.037, g_loss 3.358, d_loss 0.123\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 44 Batch 166/390 d_loss_real= 0.187, d_loss_fake= 0.040, g_loss 3.197, d_loss 0.114\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 44 Batch 167/390 d_loss_real= 0.139, d_loss_fake= 0.050, g_loss 3.026, d_loss 0.095\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 168/390 d_loss_real= 0.119, d_loss_fake= 0.058, g_loss 2.902, d_loss 0.088\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 169/390 d_loss_real= 0.119, d_loss_fake= 0.065, g_loss 2.701, d_loss 0.092\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 44 Batch 170/390 d_loss_real= 0.056, d_loss_fake= 0.074, g_loss 2.638, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 171/390 d_loss_real= 0.093, d_loss_fake= 0.077, g_loss 2.643, d_loss 0.085\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 44 Batch 172/390 d_loss_real= 0.172, d_loss_fake= 0.079, g_loss 2.603, d_loss 0.126\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 173/390 d_loss_real= 0.008, d_loss_fake= 0.107, g_loss 2.720, d_loss 0.058\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 174/390 d_loss_real= 0.054, d_loss_fake= 0.075, g_loss 2.968, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 175/390 d_loss_real= 0.013, d_loss_fake= 0.052, g_loss 3.184, d_loss 0.032\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 44 Batch 176/390 d_loss_real= 0.081, d_loss_fake= 0.043, g_loss 3.384, d_loss 0.062\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 44 Batch 177/390 d_loss_real= 0.000, d_loss_fake= 0.036, g_loss 3.547, d_loss 0.018\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 178/390 d_loss_real= 0.085, d_loss_fake= 0.030, g_loss 3.716, d_loss 0.057\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 179/390 d_loss_real= 0.072, d_loss_fake= 0.025, g_loss 3.880, d_loss 0.049\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 180/390 d_loss_real= 0.153, d_loss_fake= 0.024, g_loss 3.948, d_loss 0.088\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 181/390 d_loss_real= 0.182, d_loss_fake= 0.023, g_loss 3.889, d_loss 0.103\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 182/390 d_loss_real= 0.118, d_loss_fake= 0.023, g_loss 3.888, d_loss 0.070\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 183/390 d_loss_real= 0.112, d_loss_fake= 0.025, g_loss 3.960, d_loss 0.068\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 184/390 d_loss_real= 0.200, d_loss_fake= 0.025, g_loss 3.855, d_loss 0.112\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 185/390 d_loss_real= 0.000, d_loss_fake= 0.026, g_loss 3.828, d_loss 0.013\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 186/390 d_loss_real= 0.058, d_loss_fake= 0.027, g_loss 3.696, d_loss 0.042\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 187/390 d_loss_real= 0.054, d_loss_fake= 0.027, g_loss 3.953, d_loss 0.041\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 188/390 d_loss_real= 0.056, d_loss_fake= 0.025, g_loss 3.920, d_loss 0.040\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 44 Batch 189/390 d_loss_real= 0.000, d_loss_fake= 0.024, g_loss 3.875, d_loss 0.012\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 190/390 d_loss_real= 0.096, d_loss_fake= 0.023, g_loss 3.927, d_loss 0.060\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 191/390 d_loss_real= 0.021, d_loss_fake= 0.023, g_loss 3.885, d_loss 0.022\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 44 Batch 192/390 d_loss_real= 0.000, d_loss_fake= 0.023, g_loss 3.913, d_loss 0.011\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 44 Batch 193/390 d_loss_real= 0.104, d_loss_fake= 0.023, g_loss 3.879, d_loss 0.064\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 194/390 d_loss_real= 0.054, d_loss_fake= 0.022, g_loss 3.813, d_loss 0.038\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 195/390 d_loss_real= 0.055, d_loss_fake= 0.025, g_loss 3.777, d_loss 0.040\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 196/390 d_loss_real= 0.000, d_loss_fake= 0.032, g_loss 3.797, d_loss 0.016\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 197/390 d_loss_real= 0.063, d_loss_fake= 0.028, g_loss 3.813, d_loss 0.045\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 198/390 d_loss_real= 0.046, d_loss_fake= 0.029, g_loss 3.659, d_loss 0.037\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 44 Batch 199/390 d_loss_real= 0.060, d_loss_fake= 0.038, g_loss 3.698, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 200/390 d_loss_real= 0.098, d_loss_fake= 0.031, g_loss 3.646, d_loss 0.064\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 201/390 d_loss_real= 0.084, d_loss_fake= 0.030, g_loss 3.672, d_loss 0.057\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 202/390 d_loss_real= 0.000, d_loss_fake= 0.029, g_loss 3.763, d_loss 0.014\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 203/390 d_loss_real= 0.064, d_loss_fake= 0.027, g_loss 3.720, d_loss 0.045\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 204/390 d_loss_real= 0.039, d_loss_fake= 0.026, g_loss 3.870, d_loss 0.032\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 205/390 d_loss_real= 0.038, d_loss_fake= 0.025, g_loss 3.815, d_loss 0.031\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 206/390 d_loss_real= 0.000, d_loss_fake= 0.025, g_loss 3.928, d_loss 0.012\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 44 Batch 207/390 d_loss_real= 0.134, d_loss_fake= 0.023, g_loss 3.842, d_loss 0.079\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 208/390 d_loss_real= 0.085, d_loss_fake= 0.025, g_loss 3.819, d_loss 0.055\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 209/390 d_loss_real= 0.111, d_loss_fake= 0.026, g_loss 3.638, d_loss 0.069\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 210/390 d_loss_real= 0.063, d_loss_fake= 0.037, g_loss 3.509, d_loss 0.050\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 211/390 d_loss_real= 0.018, d_loss_fake= 0.051, g_loss 3.579, d_loss 0.035\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 212/390 d_loss_real= 0.055, d_loss_fake= 0.028, g_loss 3.918, d_loss 0.041\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 44 Batch 213/390 d_loss_real= 0.006, d_loss_fake= 0.021, g_loss 4.221, d_loss 0.014\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 214/390 d_loss_real= 0.158, d_loss_fake= 0.017, g_loss 4.315, d_loss 0.087\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 44 Batch 215/390 d_loss_real= 0.037, d_loss_fake= 0.016, g_loss 4.328, d_loss 0.026\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 216/390 d_loss_real= 0.186, d_loss_fake= 0.015, g_loss 4.271, d_loss 0.100\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 217/390 d_loss_real= 0.000, d_loss_fake= 0.015, g_loss 4.233, d_loss 0.008\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 44 Batch 218/390 d_loss_real= 0.168, d_loss_fake= 0.017, g_loss 4.147, d_loss 0.093\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 219/390 d_loss_real= 0.017, d_loss_fake= 0.019, g_loss 4.096, d_loss 0.018\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 44 Batch 220/390 d_loss_real= 0.076, d_loss_fake= 0.024, g_loss 3.888, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 221/390 d_loss_real= 0.046, d_loss_fake= 0.028, g_loss 3.643, d_loss 0.037\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 44 Batch 222/390 d_loss_real= 0.065, d_loss_fake= 0.034, g_loss 3.564, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 223/390 d_loss_real= 0.010, d_loss_fake= 0.040, g_loss 3.620, d_loss 0.025\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 44 Batch 224/390 d_loss_real= 0.156, d_loss_fake= 0.030, g_loss 3.761, d_loss 0.093\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 225/390 d_loss_real= 0.076, d_loss_fake= 0.032, g_loss 3.663, d_loss 0.054\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 44 Batch 226/390 d_loss_real= 0.087, d_loss_fake= 0.041, g_loss 3.512, d_loss 0.064\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 227/390 d_loss_real= 0.000, d_loss_fake= 0.038, g_loss 3.687, d_loss 0.019\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 44 Batch 228/390 d_loss_real= 0.042, d_loss_fake= 0.029, g_loss 3.811, d_loss 0.036\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 229/390 d_loss_real= 0.194, d_loss_fake= 0.028, g_loss 3.877, d_loss 0.111\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 230/390 d_loss_real= 0.158, d_loss_fake= 0.030, g_loss 3.954, d_loss 0.094\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 231/390 d_loss_real= 0.001, d_loss_fake= 0.027, g_loss 3.791, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 232/390 d_loss_real= 0.064, d_loss_fake= 0.045, g_loss 3.684, d_loss 0.055\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 233/390 d_loss_real= 0.269, d_loss_fake= 0.072, g_loss 3.789, d_loss 0.171\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 234/390 d_loss_real= 0.000, d_loss_fake= 0.028, g_loss 4.089, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 235/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 4.411, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 236/390 d_loss_real= 0.120, d_loss_fake= 0.014, g_loss 4.508, d_loss 0.067\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 44 Batch 237/390 d_loss_real= 0.146, d_loss_fake= 0.014, g_loss 4.483, d_loss 0.080\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 238/390 d_loss_real= 0.000, d_loss_fake= 0.012, g_loss 4.605, d_loss 0.006\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 44 Batch 239/390 d_loss_real= 0.029, d_loss_fake= 0.011, g_loss 4.617, d_loss 0.020\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 240/390 d_loss_real= 0.149, d_loss_fake= 0.011, g_loss 4.595, d_loss 0.080\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 44 Batch 241/390 d_loss_real= 0.106, d_loss_fake= 0.013, g_loss 4.397, d_loss 0.059\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 242/390 d_loss_real= 0.024, d_loss_fake= 0.015, g_loss 4.246, d_loss 0.019\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 243/390 d_loss_real= 0.156, d_loss_fake= 0.023, g_loss 3.741, d_loss 0.089\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 244/390 d_loss_real= 0.376, d_loss_fake= 0.052, g_loss 3.299, d_loss 0.214\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 44 Batch 245/390 d_loss_real= 0.081, d_loss_fake= 0.085, g_loss 3.638, d_loss 0.083\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 44 Batch 246/390 d_loss_real= 0.000, d_loss_fake= 0.030, g_loss 4.181, d_loss 0.015\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 247/390 d_loss_real= 0.093, d_loss_fake= 0.015, g_loss 4.487, d_loss 0.054\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 44 Batch 248/390 d_loss_real= 0.094, d_loss_fake= 0.012, g_loss 4.700, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 249/390 d_loss_real= 0.187, d_loss_fake= 0.012, g_loss 4.464, d_loss 0.099\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 250/390 d_loss_real= 0.011, d_loss_fake= 0.014, g_loss 4.501, d_loss 0.013\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 251/390 d_loss_real= 0.144, d_loss_fake= 0.017, g_loss 4.134, d_loss 0.080\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 252/390 d_loss_real= 0.085, d_loss_fake= 0.019, g_loss 4.093, d_loss 0.052\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 253/390 d_loss_real= 0.117, d_loss_fake= 0.024, g_loss 3.677, d_loss 0.071\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 44 Batch 254/390 d_loss_real= 0.205, d_loss_fake= 0.047, g_loss 3.339, d_loss 0.126\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 255/390 d_loss_real= 0.100, d_loss_fake= 0.071, g_loss 3.475, d_loss 0.086\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 44 Batch 256/390 d_loss_real= 0.100, d_loss_fake= 0.056, g_loss 3.701, d_loss 0.078\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 44 Batch 257/390 d_loss_real= 0.093, d_loss_fake= 0.030, g_loss 3.956, d_loss 0.061\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 44 Batch 258/390 d_loss_real= 0.023, d_loss_fake= 0.017, g_loss 4.167, d_loss 0.020\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 259/390 d_loss_real= 0.261, d_loss_fake= 0.018, g_loss 4.218, d_loss 0.139\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 260/390 d_loss_real= 0.000, d_loss_fake= 0.016, g_loss 4.220, d_loss 0.008\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 261/390 d_loss_real= 0.183, d_loss_fake= 0.017, g_loss 4.174, d_loss 0.100\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 262/390 d_loss_real= 0.260, d_loss_fake= 0.020, g_loss 3.935, d_loss 0.140\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 44 Batch 263/390 d_loss_real= 0.092, d_loss_fake= 0.027, g_loss 3.732, d_loss 0.059\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 264/390 d_loss_real= 0.010, d_loss_fake= 0.051, g_loss 3.447, d_loss 0.030\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 44 Batch 265/390 d_loss_real= 0.113, d_loss_fake= 0.045, g_loss 3.426, d_loss 0.079\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 266/390 d_loss_real= 0.027, d_loss_fake= 0.043, g_loss 3.554, d_loss 0.035\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 44 Batch 267/390 d_loss_real= 0.010, d_loss_fake= 0.044, g_loss 3.641, d_loss 0.027\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 268/390 d_loss_real= 0.097, d_loss_fake= 0.030, g_loss 3.729, d_loss 0.063\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 44 Batch 269/390 d_loss_real= 0.128, d_loss_fake= 0.026, g_loss 3.880, d_loss 0.077\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 270/390 d_loss_real= 0.099, d_loss_fake= 0.024, g_loss 3.891, d_loss 0.061\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 44 Batch 271/390 d_loss_real= 0.172, d_loss_fake= 0.023, g_loss 3.847, d_loss 0.097\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 44 Batch 272/390 d_loss_real= 0.014, d_loss_fake= 0.024, g_loss 3.794, d_loss 0.019\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 273/390 d_loss_real= 0.086, d_loss_fake= 0.026, g_loss 3.752, d_loss 0.056\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 44 Batch 274/390 d_loss_real= 0.035, d_loss_fake= 0.029, g_loss 3.690, d_loss 0.032\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 44 Batch 275/390 d_loss_real= 0.060, d_loss_fake= 0.032, g_loss 3.653, d_loss 0.046\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 44 Batch 276/390 d_loss_real= 0.215, d_loss_fake= 0.037, g_loss 3.456, d_loss 0.126\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 277/390 d_loss_real= 0.050, d_loss_fake= 0.041, g_loss 3.484, d_loss 0.046\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 278/390 d_loss_real= 0.055, d_loss_fake= 0.032, g_loss 3.571, d_loss 0.043\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 44 Batch 279/390 d_loss_real= 0.025, d_loss_fake= 0.028, g_loss 3.691, d_loss 0.026\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 280/390 d_loss_real= 0.043, d_loss_fake= 0.031, g_loss 3.726, d_loss 0.037\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 44 Batch 281/390 d_loss_real= 0.166, d_loss_fake= 0.026, g_loss 3.753, d_loss 0.096\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 44 Batch 282/390 d_loss_real= 0.081, d_loss_fake= 0.025, g_loss 3.694, d_loss 0.053\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 44 Batch 283/390 d_loss_real= 0.000, d_loss_fake= 0.032, g_loss 3.627, d_loss 0.016\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 284/390 d_loss_real= 0.077, d_loss_fake= 0.032, g_loss 3.664, d_loss 0.055\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 285/390 d_loss_real= 0.133, d_loss_fake= 0.028, g_loss 3.641, d_loss 0.081\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 44 Batch 286/390 d_loss_real= 0.095, d_loss_fake= 0.039, g_loss 3.411, d_loss 0.067\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 44 Batch 287/390 d_loss_real= 0.223, d_loss_fake= 0.042, g_loss 3.307, d_loss 0.133\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 288/390 d_loss_real= 0.022, d_loss_fake= 0.052, g_loss 3.436, d_loss 0.037\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 44 Batch 289/390 d_loss_real= 0.132, d_loss_fake= 0.057, g_loss 3.497, d_loss 0.095\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 290/390 d_loss_real= 0.161, d_loss_fake= 0.031, g_loss 3.809, d_loss 0.096\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 291/390 d_loss_real= 0.175, d_loss_fake= 0.024, g_loss 3.921, d_loss 0.100\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 292/390 d_loss_real= 0.120, d_loss_fake= 0.020, g_loss 3.992, d_loss 0.070\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 293/390 d_loss_real= 0.067, d_loss_fake= 0.020, g_loss 4.004, d_loss 0.043\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 294/390 d_loss_real= 0.000, d_loss_fake= 0.021, g_loss 3.963, d_loss 0.011\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 295/390 d_loss_real= 0.158, d_loss_fake= 0.021, g_loss 3.997, d_loss 0.089\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 296/390 d_loss_real= 0.095, d_loss_fake= 0.022, g_loss 3.914, d_loss 0.058\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 297/390 d_loss_real= 0.094, d_loss_fake= 0.023, g_loss 3.846, d_loss 0.059\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 298/390 d_loss_real= 0.112, d_loss_fake= 0.026, g_loss 3.646, d_loss 0.069\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 299/390 d_loss_real= 0.196, d_loss_fake= 0.035, g_loss 3.476, d_loss 0.115\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 300/390 d_loss_real= 0.054, d_loss_fake= 0.033, g_loss 3.335, d_loss 0.043\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 301/390 d_loss_real= 0.060, d_loss_fake= 0.038, g_loss 3.445, d_loss 0.049\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 302/390 d_loss_real= 0.037, d_loss_fake= 0.032, g_loss 3.644, d_loss 0.034\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 303/390 d_loss_real= 0.078, d_loss_fake= 0.028, g_loss 3.745, d_loss 0.053\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 44 Batch 304/390 d_loss_real= 0.034, d_loss_fake= 0.030, g_loss 3.570, d_loss 0.032\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 44 Batch 305/390 d_loss_real= 0.030, d_loss_fake= 0.031, g_loss 3.575, d_loss 0.031\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 44 Batch 306/390 d_loss_real= 0.094, d_loss_fake= 0.034, g_loss 3.514, d_loss 0.064\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 307/390 d_loss_real= 0.028, d_loss_fake= 0.031, g_loss 3.603, d_loss 0.029\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 308/390 d_loss_real= 0.044, d_loss_fake= 0.031, g_loss 3.698, d_loss 0.038\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 309/390 d_loss_real= 0.078, d_loss_fake= 0.024, g_loss 3.769, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 310/390 d_loss_real= 0.000, d_loss_fake= 0.021, g_loss 3.975, d_loss 0.011\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 311/390 d_loss_real= 0.021, d_loss_fake= 0.022, g_loss 3.908, d_loss 0.021\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 44 Batch 312/390 d_loss_real= 0.056, d_loss_fake= 0.021, g_loss 3.964, d_loss 0.039\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 313/390 d_loss_real= 0.121, d_loss_fake= 0.019, g_loss 4.028, d_loss 0.070\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 314/390 d_loss_real= 0.134, d_loss_fake= 0.024, g_loss 3.747, d_loss 0.079\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 44 Batch 315/390 d_loss_real= 0.071, d_loss_fake= 0.027, g_loss 3.762, d_loss 0.049\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 44 Batch 316/390 d_loss_real= 0.137, d_loss_fake= 0.030, g_loss 3.728, d_loss 0.083\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 317/390 d_loss_real= 0.138, d_loss_fake= 0.031, g_loss 3.593, d_loss 0.084\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 318/390 d_loss_real= 0.060, d_loss_fake= 0.034, g_loss 3.585, d_loss 0.047\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 319/390 d_loss_real= 0.000, d_loss_fake= 0.030, g_loss 3.808, d_loss 0.015\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 320/390 d_loss_real= 0.000, d_loss_fake= 0.023, g_loss 4.011, d_loss 0.011\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 321/390 d_loss_real= 0.051, d_loss_fake= 0.021, g_loss 4.123, d_loss 0.036\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 44 Batch 322/390 d_loss_real= 0.065, d_loss_fake= 0.018, g_loss 4.100, d_loss 0.041\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 323/390 d_loss_real= 0.000, d_loss_fake= 0.017, g_loss 4.139, d_loss 0.008\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 324/390 d_loss_real= 0.046, d_loss_fake= 0.016, g_loss 4.235, d_loss 0.031\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 44 Batch 325/390 d_loss_real= 0.001, d_loss_fake= 0.015, g_loss 4.346, d_loss 0.008\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 326/390 d_loss_real= 0.085, d_loss_fake= 0.015, g_loss 4.237, d_loss 0.050\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 327/390 d_loss_real= 0.040, d_loss_fake= 0.015, g_loss 4.243, d_loss 0.027\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 328/390 d_loss_real= 0.271, d_loss_fake= 0.017, g_loss 3.941, d_loss 0.144\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 329/390 d_loss_real= 0.068, d_loss_fake= 0.026, g_loss 3.678, d_loss 0.047\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 44 Batch 330/390 d_loss_real= 0.072, d_loss_fake= 0.031, g_loss 3.679, d_loss 0.051\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 331/390 d_loss_real= 0.088, d_loss_fake= 0.051, g_loss 3.231, d_loss 0.069\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 332/390 d_loss_real= 0.013, d_loss_fake= 0.047, g_loss 3.441, d_loss 0.030\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 44 Batch 333/390 d_loss_real= 0.000, d_loss_fake= 0.041, g_loss 3.701, d_loss 0.021\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 334/390 d_loss_real= 0.022, d_loss_fake= 0.019, g_loss 4.259, d_loss 0.021\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 335/390 d_loss_real= 0.065, d_loss_fake= 0.013, g_loss 4.556, d_loss 0.039\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 44 Batch 336/390 d_loss_real= 0.038, d_loss_fake= 0.012, g_loss 4.689, d_loss 0.025\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 337/390 d_loss_real= 0.137, d_loss_fake= 0.011, g_loss 4.709, d_loss 0.074\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 338/390 d_loss_real= 0.078, d_loss_fake= 0.010, g_loss 4.697, d_loss 0.044\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 44 Batch 339/390 d_loss_real= 0.166, d_loss_fake= 0.010, g_loss 4.595, d_loss 0.088\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 340/390 d_loss_real= 0.119, d_loss_fake= 0.011, g_loss 4.510, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 341/390 d_loss_real= 0.047, d_loss_fake= 0.013, g_loss 4.234, d_loss 0.030\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 342/390 d_loss_real= 0.179, d_loss_fake= 0.018, g_loss 3.926, d_loss 0.098\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 343/390 d_loss_real= 0.035, d_loss_fake= 0.026, g_loss 3.667, d_loss 0.031\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 44 Batch 344/390 d_loss_real= 0.153, d_loss_fake= 0.041, g_loss 3.127, d_loss 0.097\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 345/390 d_loss_real= 0.060, d_loss_fake= 0.082, g_loss 3.631, d_loss 0.071\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 346/390 d_loss_real= 0.077, d_loss_fake= 0.029, g_loss 3.999, d_loss 0.053\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 44 Batch 347/390 d_loss_real= 0.211, d_loss_fake= 0.018, g_loss 4.201, d_loss 0.115\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 348/390 d_loss_real= 0.280, d_loss_fake= 0.016, g_loss 4.214, d_loss 0.148\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 44 Batch 349/390 d_loss_real= 0.002, d_loss_fake= 0.016, g_loss 4.224, d_loss 0.009\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 350/390 d_loss_real= 0.056, d_loss_fake= 0.016, g_loss 4.197, d_loss 0.036\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 351/390 d_loss_real= 0.092, d_loss_fake= 0.018, g_loss 4.080, d_loss 0.055\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 352/390 d_loss_real= 0.096, d_loss_fake= 0.020, g_loss 4.035, d_loss 0.058\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 353/390 d_loss_real= 0.037, d_loss_fake= 0.020, g_loss 3.947, d_loss 0.028\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 354/390 d_loss_real= 0.188, d_loss_fake= 0.027, g_loss 3.719, d_loss 0.107\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 355/390 d_loss_real= 0.035, d_loss_fake= 0.032, g_loss 3.579, d_loss 0.033\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 44 Batch 356/390 d_loss_real= 0.106, d_loss_fake= 0.047, g_loss 3.258, d_loss 0.077\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 44 Batch 357/390 d_loss_real= 0.072, d_loss_fake= 0.036, g_loss 3.351, d_loss 0.054\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 358/390 d_loss_real= 0.035, d_loss_fake= 0.056, g_loss 3.274, d_loss 0.046\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 359/390 d_loss_real= 0.101, d_loss_fake= 0.043, g_loss 3.432, d_loss 0.072\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 44 Batch 360/390 d_loss_real= 0.004, d_loss_fake= 0.037, g_loss 3.762, d_loss 0.020\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 44 Batch 361/390 d_loss_real= 0.000, d_loss_fake= 0.021, g_loss 4.204, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 362/390 d_loss_real= 0.000, d_loss_fake= 0.014, g_loss 4.439, d_loss 0.007\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 363/390 d_loss_real= 0.000, d_loss_fake= 0.012, g_loss 4.604, d_loss 0.006\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 44 Batch 364/390 d_loss_real= 0.287, d_loss_fake= 0.011, g_loss 4.592, d_loss 0.149\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 44 Batch 365/390 d_loss_real= 0.078, d_loss_fake= 0.012, g_loss 4.516, d_loss 0.045\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 366/390 d_loss_real= 0.160, d_loss_fake= 0.012, g_loss 4.359, d_loss 0.086\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 44 Batch 367/390 d_loss_real= 0.128, d_loss_fake= 0.015, g_loss 4.194, d_loss 0.071\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 368/390 d_loss_real= 0.078, d_loss_fake= 0.021, g_loss 3.736, d_loss 0.049\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 369/390 d_loss_real= 0.207, d_loss_fake= 0.040, g_loss 3.240, d_loss 0.123\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 370/390 d_loss_real= 0.108, d_loss_fake= 0.065, g_loss 3.142, d_loss 0.087\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 44 Batch 371/390 d_loss_real= 0.047, d_loss_fake= 0.046, g_loss 3.461, d_loss 0.046\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 372/390 d_loss_real= 0.063, d_loss_fake= 0.036, g_loss 3.726, d_loss 0.050\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 44 Batch 373/390 d_loss_real= 0.050, d_loss_fake= 0.023, g_loss 4.010, d_loss 0.036\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 374/390 d_loss_real= 0.021, d_loss_fake= 0.019, g_loss 4.139, d_loss 0.020\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 375/390 d_loss_real= 0.070, d_loss_fake= 0.016, g_loss 4.260, d_loss 0.043\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 376/390 d_loss_real= 0.115, d_loss_fake= 0.015, g_loss 4.282, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 377/390 d_loss_real= 0.043, d_loss_fake= 0.016, g_loss 4.233, d_loss 0.029\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 44 Batch 378/390 d_loss_real= 0.086, d_loss_fake= 0.017, g_loss 4.042, d_loss 0.051\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 379/390 d_loss_real= 0.058, d_loss_fake= 0.023, g_loss 3.701, d_loss 0.041\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44 Batch 380/390 d_loss_real= 0.067, d_loss_fake= 0.041, g_loss 3.108, d_loss 0.054\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 44 Batch 381/390 d_loss_real= 0.020, d_loss_fake= 0.074, g_loss 3.365, d_loss 0.047\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 382/390 d_loss_real= 0.036, d_loss_fake= 0.030, g_loss 3.998, d_loss 0.033\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 383/390 d_loss_real= 0.202, d_loss_fake= 0.020, g_loss 4.290, d_loss 0.111\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44 Batch 384/390 d_loss_real= 0.070, d_loss_fake= 0.014, g_loss 4.464, d_loss 0.042\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 44 Batch 385/390 d_loss_real= 0.234, d_loss_fake= 0.012, g_loss 4.471, d_loss 0.123\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44 Batch 386/390 d_loss_real= 0.064, d_loss_fake= 0.012, g_loss 4.420, d_loss 0.038\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 387/390 d_loss_real= 0.001, d_loss_fake= 0.012, g_loss 4.428, d_loss 0.007\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44 Batch 388/390 d_loss_real= 0.215, d_loss_fake= 0.014, g_loss 4.337, d_loss 0.114\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 44 Batch 389/390 d_loss_real= 0.100, d_loss_fake= 0.015, g_loss 4.174, d_loss 0.057\n",
            "2/2 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44 Batch 390/390 d_loss_real= 0.044, d_loss_fake= 0.017, g_loss 3.997, d_loss 0.031\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 1/390 d_loss_real= 0.002, d_loss_fake= 0.020, g_loss 3.928, d_loss 0.011\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 45 Batch 2/390 d_loss_real= 0.075, d_loss_fake= 0.023, g_loss 3.789, d_loss 0.049\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 45 Batch 3/390 d_loss_real= 0.088, d_loss_fake= 0.030, g_loss 3.597, d_loss 0.059\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 4/390 d_loss_real= 0.007, d_loss_fake= 0.037, g_loss 3.471, d_loss 0.022\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 5/390 d_loss_real= 0.082, d_loss_fake= 0.033, g_loss 3.565, d_loss 0.058\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 45 Batch 6/390 d_loss_real= 0.193, d_loss_fake= 0.037, g_loss 3.670, d_loss 0.115\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 7/390 d_loss_real= 0.161, d_loss_fake= 0.031, g_loss 3.794, d_loss 0.096\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 8/390 d_loss_real= 0.007, d_loss_fake= 0.025, g_loss 3.997, d_loss 0.016\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 9/390 d_loss_real= 0.060, d_loss_fake= 0.019, g_loss 4.222, d_loss 0.039\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 45 Batch 10/390 d_loss_real= 0.086, d_loss_fake= 0.019, g_loss 4.053, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 11/390 d_loss_real= 0.105, d_loss_fake= 0.021, g_loss 3.960, d_loss 0.063\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 45 Batch 12/390 d_loss_real= 0.090, d_loss_fake= 0.029, g_loss 3.719, d_loss 0.060\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 45 Batch 13/390 d_loss_real= 0.065, d_loss_fake= 0.040, g_loss 3.770, d_loss 0.053\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 14/390 d_loss_real= 0.048, d_loss_fake= 0.037, g_loss 4.328, d_loss 0.042\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 15/390 d_loss_real= 0.242, d_loss_fake= 0.024, g_loss 4.478, d_loss 0.133\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 16/390 d_loss_real= 0.073, d_loss_fake= 0.019, g_loss 4.499, d_loss 0.046\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 45 Batch 17/390 d_loss_real= 0.068, d_loss_fake= 0.025, g_loss 4.480, d_loss 0.047\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 18/390 d_loss_real= 0.051, d_loss_fake= 0.017, g_loss 4.510, d_loss 0.034\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 19/390 d_loss_real= 0.178, d_loss_fake= 0.023, g_loss 4.394, d_loss 0.100\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 20/390 d_loss_real= 0.116, d_loss_fake= 0.020, g_loss 4.368, d_loss 0.068\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 21/390 d_loss_real= 0.006, d_loss_fake= 0.018, g_loss 4.505, d_loss 0.012\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 45 Batch 22/390 d_loss_real= 0.070, d_loss_fake= 0.020, g_loss 4.470, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 23/390 d_loss_real= 0.156, d_loss_fake= 0.017, g_loss 4.380, d_loss 0.086\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 24/390 d_loss_real= 0.070, d_loss_fake= 0.020, g_loss 4.090, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 25/390 d_loss_real= 0.350, d_loss_fake= 0.033, g_loss 3.080, d_loss 0.191\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 26/390 d_loss_real= 0.118, d_loss_fake= 0.236, g_loss 3.624, d_loss 0.177\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 45 Batch 27/390 d_loss_real= 0.108, d_loss_fake= 0.013, g_loss 4.788, d_loss 0.061\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 28/390 d_loss_real= 0.160, d_loss_fake= 0.010, g_loss 4.918, d_loss 0.085\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 45 Batch 29/390 d_loss_real= 0.476, d_loss_fake= 0.009, g_loss 4.798, d_loss 0.242\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 45 Batch 30/390 d_loss_real= 0.084, d_loss_fake= 0.011, g_loss 4.552, d_loss 0.047\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 31/390 d_loss_real= 0.151, d_loss_fake= 0.013, g_loss 4.322, d_loss 0.082\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 45 Batch 32/390 d_loss_real= 0.098, d_loss_fake= 0.016, g_loss 4.121, d_loss 0.057\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 33/390 d_loss_real= 0.077, d_loss_fake= 0.019, g_loss 3.979, d_loss 0.048\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 45 Batch 34/390 d_loss_real= 0.116, d_loss_fake= 0.022, g_loss 3.857, d_loss 0.069\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 35/390 d_loss_real= 0.258, d_loss_fake= 0.024, g_loss 3.680, d_loss 0.141\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 45 Batch 36/390 d_loss_real= 0.106, d_loss_fake= 0.028, g_loss 3.583, d_loss 0.067\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 37/390 d_loss_real= 0.056, d_loss_fake= 0.034, g_loss 3.411, d_loss 0.045\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 45 Batch 38/390 d_loss_real= 0.137, d_loss_fake= 0.039, g_loss 3.348, d_loss 0.088\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 45 Batch 39/390 d_loss_real= 0.065, d_loss_fake= 0.045, g_loss 3.228, d_loss 0.055\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 40/390 d_loss_real= 0.018, d_loss_fake= 0.063, g_loss 3.020, d_loss 0.041\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 41/390 d_loss_real= 0.050, d_loss_fake= 1.765, g_loss 4.435, d_loss 0.908\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 45 Batch 42/390 d_loss_real= 0.015, d_loss_fake= 0.010, g_loss 5.010, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 43/390 d_loss_real= 0.268, d_loss_fake= 0.006, g_loss 5.498, d_loss 0.137\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 44/390 d_loss_real= 1.489, d_loss_fake= 0.005, g_loss 5.281, d_loss 0.747\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 45/390 d_loss_real= 2.173, d_loss_fake= 0.008, g_loss 4.610, d_loss 1.091\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 45 Batch 46/390 d_loss_real= 1.345, d_loss_fake= 0.016, g_loss 3.837, d_loss 0.680\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 45 Batch 47/390 d_loss_real= 0.684, d_loss_fake= 0.034, g_loss 3.098, d_loss 0.359\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 48/390 d_loss_real= 0.135, d_loss_fake= 0.071, g_loss 2.416, d_loss 0.103\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 49/390 d_loss_real= 0.270, d_loss_fake= 0.206, g_loss 1.578, d_loss 0.238\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 50/390 d_loss_real= 0.019, d_loss_fake= 1.011, g_loss 1.973, d_loss 0.515\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 51/390 d_loss_real= 0.154, d_loss_fake= 0.128, g_loss 2.305, d_loss 0.141\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 52/390 d_loss_real= 0.114, d_loss_fake= 0.097, g_loss 2.521, d_loss 0.105\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 45 Batch 53/390 d_loss_real= 0.346, d_loss_fake= 0.082, g_loss 2.597, d_loss 0.214\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 54/390 d_loss_real= 0.501, d_loss_fake= 0.081, g_loss 2.551, d_loss 0.291\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 45 Batch 55/390 d_loss_real= 0.499, d_loss_fake= 0.090, g_loss 2.406, d_loss 0.295\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 56/390 d_loss_real= 0.488, d_loss_fake= 0.110, g_loss 2.194, d_loss 0.299\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 57/390 d_loss_real= 0.447, d_loss_fake= 0.144, g_loss 1.963, d_loss 0.296\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 58/390 d_loss_real= 0.392, d_loss_fake= 0.185, g_loss 1.746, d_loss 0.288\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 45 Batch 59/390 d_loss_real= 0.344, d_loss_fake= 0.241, g_loss 1.525, d_loss 0.292\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 60/390 d_loss_real= 0.215, d_loss_fake= 0.329, g_loss 1.335, d_loss 0.272\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 45 Batch 61/390 d_loss_real= 0.157, d_loss_fake= 0.415, g_loss 1.276, d_loss 0.286\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 62/390 d_loss_real= 0.211, d_loss_fake= 0.443, g_loss 1.419, d_loss 0.327\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 45 Batch 63/390 d_loss_real= 0.139, d_loss_fake= 0.365, g_loss 1.977, d_loss 0.252\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 64/390 d_loss_real= 0.188, d_loss_fake= 0.195, g_loss 3.320, d_loss 0.192\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 65/390 d_loss_real= 0.148, d_loss_fake= 0.022, g_loss 4.855, d_loss 0.085\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 66/390 d_loss_real= 0.026, d_loss_fake= 0.020, g_loss 4.824, d_loss 0.023\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 45 Batch 67/390 d_loss_real= 0.267, d_loss_fake= 0.117, g_loss 3.130, d_loss 0.192\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 68/390 d_loss_real= 0.360, d_loss_fake= 0.261, g_loss 2.557, d_loss 0.310\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 45 Batch 69/390 d_loss_real= 0.217, d_loss_fake= 0.123, g_loss 3.311, d_loss 0.170\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 45 Batch 70/390 d_loss_real= 0.149, d_loss_fake= 0.084, g_loss 3.409, d_loss 0.116\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 45 Batch 71/390 d_loss_real= 0.348, d_loss_fake= 0.046, g_loss 3.482, d_loss 0.197\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 72/390 d_loss_real= 0.058, d_loss_fake= 0.041, g_loss 3.555, d_loss 0.049\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 73/390 d_loss_real= 0.130, d_loss_fake= 0.041, g_loss 3.369, d_loss 0.085\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 74/390 d_loss_real= 0.278, d_loss_fake= 0.050, g_loss 3.098, d_loss 0.164\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 45 Batch 75/390 d_loss_real= 0.247, d_loss_fake= 0.071, g_loss 2.790, d_loss 0.159\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 45 Batch 76/390 d_loss_real= 0.137, d_loss_fake= 0.088, g_loss 2.557, d_loss 0.112\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 77/390 d_loss_real= 0.076, d_loss_fake= 0.120, g_loss 2.292, d_loss 0.098\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 45 Batch 78/390 d_loss_real= 0.001, d_loss_fake= 0.156, g_loss 2.223, d_loss 0.078\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 45 Batch 79/390 d_loss_real= 0.155, d_loss_fake= 0.139, g_loss 2.230, d_loss 0.147\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 45 Batch 80/390 d_loss_real= 0.130, d_loss_fake= 0.119, g_loss 2.432, d_loss 0.124\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 81/390 d_loss_real= 0.116, d_loss_fake= 0.083, g_loss 2.737, d_loss 0.100\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 45 Batch 82/390 d_loss_real= 0.023, d_loss_fake= 0.058, g_loss 3.024, d_loss 0.041\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 83/390 d_loss_real= 0.158, d_loss_fake= 0.044, g_loss 3.307, d_loss 0.101\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 84/390 d_loss_real= 0.211, d_loss_fake= 0.035, g_loss 3.455, d_loss 0.123\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 45 Batch 85/390 d_loss_real= 0.193, d_loss_fake= 0.029, g_loss 3.666, d_loss 0.111\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 86/390 d_loss_real= 0.000, d_loss_fake= 0.026, g_loss 3.782, d_loss 0.013\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 45 Batch 87/390 d_loss_real= 0.059, d_loss_fake= 0.023, g_loss 3.897, d_loss 0.041\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 88/390 d_loss_real= 0.073, d_loss_fake= 0.021, g_loss 4.001, d_loss 0.047\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 89/390 d_loss_real= 0.073, d_loss_fake= 0.018, g_loss 4.043, d_loss 0.046\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 90/390 d_loss_real= 0.163, d_loss_fake= 0.019, g_loss 4.029, d_loss 0.091\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 45 Batch 91/390 d_loss_real= 0.095, d_loss_fake= 0.018, g_loss 4.025, d_loss 0.057\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 45 Batch 92/390 d_loss_real= 0.137, d_loss_fake= 0.020, g_loss 3.959, d_loss 0.079\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 45 Batch 93/390 d_loss_real= 0.112, d_loss_fake= 0.023, g_loss 3.790, d_loss 0.067\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 45 Batch 94/390 d_loss_real= 0.067, d_loss_fake= 0.032, g_loss 3.600, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 95/390 d_loss_real= 0.172, d_loss_fake= 0.038, g_loss 3.442, d_loss 0.105\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 45 Batch 96/390 d_loss_real= 0.121, d_loss_fake= 0.062, g_loss 3.590, d_loss 0.091\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 45 Batch 97/390 d_loss_real= 0.135, d_loss_fake= 0.026, g_loss 3.922, d_loss 0.081\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 45 Batch 98/390 d_loss_real= 0.074, d_loss_fake= 0.019, g_loss 4.062, d_loss 0.046\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 99/390 d_loss_real= 0.089, d_loss_fake= 0.018, g_loss 4.124, d_loss 0.053\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 45 Batch 100/390 d_loss_real= 0.264, d_loss_fake= 0.018, g_loss 4.093, d_loss 0.141\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 101/390 d_loss_real= 0.221, d_loss_fake= 0.020, g_loss 4.023, d_loss 0.121\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 102/390 d_loss_real= 0.063, d_loss_fake= 0.021, g_loss 3.899, d_loss 0.042\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 103/390 d_loss_real= 0.228, d_loss_fake= 0.022, g_loss 3.875, d_loss 0.125\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 104/390 d_loss_real= 0.060, d_loss_fake= 0.023, g_loss 3.775, d_loss 0.041\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 105/390 d_loss_real= 0.205, d_loss_fake= 0.025, g_loss 3.724, d_loss 0.115\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 45 Batch 106/390 d_loss_real= 0.096, d_loss_fake= 0.027, g_loss 3.638, d_loss 0.061\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 107/390 d_loss_real= 0.020, d_loss_fake= 0.030, g_loss 3.563, d_loss 0.025\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 108/390 d_loss_real= 0.104, d_loss_fake= 0.033, g_loss 3.462, d_loss 0.069\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 45 Batch 109/390 d_loss_real= 0.062, d_loss_fake= 0.034, g_loss 3.371, d_loss 0.048\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 45 Batch 110/390 d_loss_real= 0.067, d_loss_fake= 0.046, g_loss 3.304, d_loss 0.056\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 111/390 d_loss_real= 0.087, d_loss_fake= 0.052, g_loss 3.246, d_loss 0.069\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 112/390 d_loss_real= 0.150, d_loss_fake= 0.056, g_loss 3.270, d_loss 0.103\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 113/390 d_loss_real= 0.000, d_loss_fake= 0.069, g_loss 3.349, d_loss 0.034\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 114/390 d_loss_real= 0.005, d_loss_fake= 0.053, g_loss 3.520, d_loss 0.029\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 115/390 d_loss_real= 0.080, d_loss_fake= 0.033, g_loss 3.574, d_loss 0.056\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 45 Batch 116/390 d_loss_real= 0.079, d_loss_fake= 0.031, g_loss 3.686, d_loss 0.055\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 45 Batch 117/390 d_loss_real= 0.029, d_loss_fake= 0.027, g_loss 3.739, d_loss 0.028\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 45 Batch 118/390 d_loss_real= 0.102, d_loss_fake= 0.026, g_loss 3.782, d_loss 0.064\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 45 Batch 119/390 d_loss_real= 0.223, d_loss_fake= 0.025, g_loss 3.821, d_loss 0.124\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 120/390 d_loss_real= 0.176, d_loss_fake= 0.025, g_loss 3.784, d_loss 0.101\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 121/390 d_loss_real= 0.057, d_loss_fake= 0.026, g_loss 3.734, d_loss 0.041\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 122/390 d_loss_real= 0.117, d_loss_fake= 0.027, g_loss 3.747, d_loss 0.072\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 123/390 d_loss_real= 0.099, d_loss_fake= 0.026, g_loss 3.716, d_loss 0.063\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 45 Batch 124/390 d_loss_real= 0.058, d_loss_fake= 0.030, g_loss 3.700, d_loss 0.044\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 45 Batch 125/390 d_loss_real= 0.036, d_loss_fake= 0.028, g_loss 3.608, d_loss 0.032\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 45 Batch 126/390 d_loss_real= 0.059, d_loss_fake= 0.030, g_loss 3.613, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 127/390 d_loss_real= 0.047, d_loss_fake= 0.041, g_loss 3.513, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 128/390 d_loss_real= 0.007, d_loss_fake= 0.040, g_loss 3.572, d_loss 0.024\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 129/390 d_loss_real= 0.051, d_loss_fake= 0.035, g_loss 3.574, d_loss 0.043\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 45 Batch 130/390 d_loss_real= 0.063, d_loss_fake= 0.033, g_loss 3.709, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 131/390 d_loss_real= 0.051, d_loss_fake= 0.028, g_loss 3.772, d_loss 0.039\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 132/390 d_loss_real= 0.077, d_loss_fake= 0.028, g_loss 3.858, d_loss 0.052\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 45 Batch 133/390 d_loss_real= 0.004, d_loss_fake= 0.028, g_loss 3.914, d_loss 0.016\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 45 Batch 134/390 d_loss_real= 0.174, d_loss_fake= 0.022, g_loss 3.858, d_loss 0.098\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 45 Batch 135/390 d_loss_real= 0.260, d_loss_fake= 0.021, g_loss 3.870, d_loss 0.140\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 136/390 d_loss_real= 0.016, d_loss_fake= 0.025, g_loss 3.831, d_loss 0.020\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 45 Batch 137/390 d_loss_real= 0.002, d_loss_fake= 0.025, g_loss 3.776, d_loss 0.013\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 45 Batch 138/390 d_loss_real= 0.209, d_loss_fake= 0.027, g_loss 3.631, d_loss 0.118\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 139/390 d_loss_real= 0.181, d_loss_fake= 0.034, g_loss 3.494, d_loss 0.107\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 140/390 d_loss_real= 0.108, d_loss_fake= 0.040, g_loss 3.431, d_loss 0.074\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 45 Batch 141/390 d_loss_real= 0.169, d_loss_fake= 0.047, g_loss 3.371, d_loss 0.108\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 142/390 d_loss_real= 0.000, d_loss_fake= 0.051, g_loss 3.440, d_loss 0.025\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 45 Batch 143/390 d_loss_real= 0.106, d_loss_fake= 0.056, g_loss 3.380, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 144/390 d_loss_real= 0.000, d_loss_fake= 0.044, g_loss 3.435, d_loss 0.022\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 45 Batch 145/390 d_loss_real= 0.064, d_loss_fake= 0.038, g_loss 3.597, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 146/390 d_loss_real= 0.000, d_loss_fake= 0.030, g_loss 3.741, d_loss 0.015\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 147/390 d_loss_real= 0.051, d_loss_fake= 0.026, g_loss 3.790, d_loss 0.038\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 148/390 d_loss_real= 0.282, d_loss_fake= 0.025, g_loss 3.789, d_loss 0.154\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 149/390 d_loss_real= 0.006, d_loss_fake= 0.025, g_loss 3.795, d_loss 0.015\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 150/390 d_loss_real= 0.199, d_loss_fake= 0.023, g_loss 3.779, d_loss 0.111\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 45 Batch 151/390 d_loss_real= 0.132, d_loss_fake= 0.026, g_loss 3.731, d_loss 0.079\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 45 Batch 152/390 d_loss_real= 0.017, d_loss_fake= 0.032, g_loss 3.634, d_loss 0.025\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 153/390 d_loss_real= 0.128, d_loss_fake= 0.037, g_loss 3.399, d_loss 0.083\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 154/390 d_loss_real= 0.015, d_loss_fake= 0.047, g_loss 3.394, d_loss 0.031\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 155/390 d_loss_real= 0.072, d_loss_fake= 0.065, g_loss 3.455, d_loss 0.069\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 156/390 d_loss_real= 0.098, d_loss_fake= 0.041, g_loss 3.608, d_loss 0.069\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 157/390 d_loss_real= 0.075, d_loss_fake= 0.036, g_loss 3.679, d_loss 0.055\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 158/390 d_loss_real= 0.158, d_loss_fake= 0.024, g_loss 3.870, d_loss 0.091\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 159/390 d_loss_real= 0.003, d_loss_fake= 0.023, g_loss 3.997, d_loss 0.013\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 160/390 d_loss_real= 0.058, d_loss_fake= 0.021, g_loss 4.037, d_loss 0.039\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 45 Batch 161/390 d_loss_real= 0.048, d_loss_fake= 0.021, g_loss 3.878, d_loss 0.034\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 45 Batch 162/390 d_loss_real= 0.138, d_loss_fake= 0.024, g_loss 3.898, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 163/390 d_loss_real= 0.064, d_loss_fake= 0.022, g_loss 3.854, d_loss 0.043\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 45 Batch 164/390 d_loss_real= 0.131, d_loss_fake= 0.021, g_loss 3.905, d_loss 0.076\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 45 Batch 165/390 d_loss_real= 0.143, d_loss_fake= 0.025, g_loss 3.858, d_loss 0.084\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 45 Batch 166/390 d_loss_real= 0.080, d_loss_fake= 0.023, g_loss 3.796, d_loss 0.051\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 45 Batch 167/390 d_loss_real= 0.077, d_loss_fake= 0.022, g_loss 3.739, d_loss 0.050\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 45 Batch 168/390 d_loss_real= 0.074, d_loss_fake= 0.027, g_loss 3.712, d_loss 0.050\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 45 Batch 169/390 d_loss_real= 0.212, d_loss_fake= 0.027, g_loss 3.693, d_loss 0.119\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 45 Batch 170/390 d_loss_real= 0.169, d_loss_fake= 0.025, g_loss 3.672, d_loss 0.097\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 171/390 d_loss_real= 0.144, d_loss_fake= 0.034, g_loss 3.460, d_loss 0.089\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 172/390 d_loss_real= 0.060, d_loss_fake= 0.039, g_loss 3.556, d_loss 0.049\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 173/390 d_loss_real= 0.193, d_loss_fake= 0.035, g_loss 3.361, d_loss 0.114\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 174/390 d_loss_real= 0.068, d_loss_fake= 0.040, g_loss 3.457, d_loss 0.054\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 45 Batch 175/390 d_loss_real= 0.054, d_loss_fake= 0.035, g_loss 3.601, d_loss 0.044\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 45 Batch 176/390 d_loss_real= 0.070, d_loss_fake= 0.039, g_loss 3.364, d_loss 0.054\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 45 Batch 177/390 d_loss_real= 0.122, d_loss_fake= 0.037, g_loss 3.540, d_loss 0.080\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 45 Batch 178/390 d_loss_real= 0.169, d_loss_fake= 0.040, g_loss 3.533, d_loss 0.104\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 179/390 d_loss_real= 0.000, d_loss_fake= 0.038, g_loss 3.763, d_loss 0.019\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 180/390 d_loss_real= 0.137, d_loss_fake= 0.034, g_loss 3.693, d_loss 0.086\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 45 Batch 181/390 d_loss_real= 0.203, d_loss_fake= 0.034, g_loss 3.621, d_loss 0.118\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 182/390 d_loss_real= 0.186, d_loss_fake= 0.035, g_loss 3.766, d_loss 0.111\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 183/390 d_loss_real= 0.122, d_loss_fake= 0.028, g_loss 3.713, d_loss 0.075\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 184/390 d_loss_real= 0.038, d_loss_fake= 0.039, g_loss 3.649, d_loss 0.038\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 185/390 d_loss_real= 0.160, d_loss_fake= 0.041, g_loss 3.496, d_loss 0.101\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 186/390 d_loss_real= 0.041, d_loss_fake= 0.034, g_loss 3.624, d_loss 0.038\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 45 Batch 187/390 d_loss_real= 0.001, d_loss_fake= 0.043, g_loss 3.545, d_loss 0.022\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 45 Batch 188/390 d_loss_real= 0.164, d_loss_fake= 0.044, g_loss 3.662, d_loss 0.104\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 189/390 d_loss_real= 0.001, d_loss_fake= 0.031, g_loss 3.964, d_loss 0.016\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 190/390 d_loss_real= 0.061, d_loss_fake= 0.033, g_loss 3.872, d_loss 0.047\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 191/390 d_loss_real= 0.283, d_loss_fake= 0.029, g_loss 4.000, d_loss 0.156\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 45 Batch 192/390 d_loss_real= 0.020, d_loss_fake= 0.025, g_loss 3.834, d_loss 0.022\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 193/390 d_loss_real= 0.033, d_loss_fake= 0.030, g_loss 3.760, d_loss 0.031\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 194/390 d_loss_real= 0.142, d_loss_fake= 0.031, g_loss 3.890, d_loss 0.087\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 195/390 d_loss_real= 0.102, d_loss_fake= 0.035, g_loss 3.730, d_loss 0.069\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 196/390 d_loss_real= 0.090, d_loss_fake= 0.034, g_loss 3.707, d_loss 0.062\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 197/390 d_loss_real= 0.399, d_loss_fake= 0.033, g_loss 3.665, d_loss 0.216\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 198/390 d_loss_real= 0.027, d_loss_fake= 0.031, g_loss 3.843, d_loss 0.029\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 45 Batch 199/390 d_loss_real= 0.071, d_loss_fake= 0.028, g_loss 3.828, d_loss 0.049\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 45 Batch 200/390 d_loss_real= 0.068, d_loss_fake= 0.022, g_loss 3.985, d_loss 0.045\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 201/390 d_loss_real= 0.042, d_loss_fake= 0.023, g_loss 3.986, d_loss 0.033\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 202/390 d_loss_real= 0.090, d_loss_fake= 0.023, g_loss 3.992, d_loss 0.056\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 203/390 d_loss_real= 0.204, d_loss_fake= 0.027, g_loss 3.837, d_loss 0.115\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 204/390 d_loss_real= 0.101, d_loss_fake= 0.028, g_loss 3.728, d_loss 0.064\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 205/390 d_loss_real= 0.075, d_loss_fake= 0.038, g_loss 3.563, d_loss 0.056\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 206/390 d_loss_real= 0.072, d_loss_fake= 0.030, g_loss 3.679, d_loss 0.051\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 45 Batch 207/390 d_loss_real= 0.083, d_loss_fake= 0.036, g_loss 3.423, d_loss 0.059\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 208/390 d_loss_real= 0.052, d_loss_fake= 0.049, g_loss 3.501, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 209/390 d_loss_real= 0.108, d_loss_fake= 0.037, g_loss 3.761, d_loss 0.072\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 45 Batch 210/390 d_loss_real= 0.162, d_loss_fake= 0.031, g_loss 3.883, d_loss 0.096\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 45 Batch 211/390 d_loss_real= 0.080, d_loss_fake= 0.021, g_loss 4.110, d_loss 0.050\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 212/390 d_loss_real= 0.143, d_loss_fake= 0.022, g_loss 4.004, d_loss 0.082\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 45 Batch 213/390 d_loss_real= 0.253, d_loss_fake= 0.019, g_loss 4.098, d_loss 0.136\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 214/390 d_loss_real= 0.096, d_loss_fake= 0.018, g_loss 4.103, d_loss 0.057\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 215/390 d_loss_real= 0.060, d_loss_fake= 0.017, g_loss 4.092, d_loss 0.038\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 45 Batch 216/390 d_loss_real= 0.125, d_loss_fake= 0.017, g_loss 4.202, d_loss 0.071\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 217/390 d_loss_real= 0.127, d_loss_fake= 0.017, g_loss 4.111, d_loss 0.072\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 45 Batch 218/390 d_loss_real= 0.063, d_loss_fake= 0.020, g_loss 4.000, d_loss 0.041\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 219/390 d_loss_real= 0.193, d_loss_fake= 0.023, g_loss 3.901, d_loss 0.108\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 45 Batch 220/390 d_loss_real= 0.060, d_loss_fake= 0.023, g_loss 3.834, d_loss 0.042\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 45 Batch 221/390 d_loss_real= 0.060, d_loss_fake= 0.024, g_loss 3.926, d_loss 0.042\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 222/390 d_loss_real= 0.077, d_loss_fake= 0.021, g_loss 3.970, d_loss 0.049\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 223/390 d_loss_real= 0.066, d_loss_fake= 0.024, g_loss 3.914, d_loss 0.045\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 45 Batch 224/390 d_loss_real= 0.146, d_loss_fake= 0.025, g_loss 3.851, d_loss 0.085\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 225/390 d_loss_real= 0.111, d_loss_fake= 0.022, g_loss 3.869, d_loss 0.066\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 45 Batch 226/390 d_loss_real= 0.037, d_loss_fake= 0.023, g_loss 3.849, d_loss 0.030\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 227/390 d_loss_real= 0.067, d_loss_fake= 0.023, g_loss 3.910, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 228/390 d_loss_real= 0.114, d_loss_fake= 0.022, g_loss 3.915, d_loss 0.068\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 45 Batch 229/390 d_loss_real= 0.074, d_loss_fake= 0.020, g_loss 3.945, d_loss 0.047\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 45 Batch 230/390 d_loss_real= 0.290, d_loss_fake= 0.022, g_loss 3.824, d_loss 0.156\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 45 Batch 231/390 d_loss_real= 0.114, d_loss_fake= 0.025, g_loss 3.767, d_loss 0.069\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 232/390 d_loss_real= 0.001, d_loss_fake= 0.026, g_loss 3.681, d_loss 0.014\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 233/390 d_loss_real= 0.060, d_loss_fake= 0.026, g_loss 3.705, d_loss 0.043\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 45 Batch 234/390 d_loss_real= 0.112, d_loss_fake= 0.026, g_loss 3.728, d_loss 0.069\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 235/390 d_loss_real= 0.000, d_loss_fake= 0.024, g_loss 3.828, d_loss 0.012\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 236/390 d_loss_real= 0.055, d_loss_fake= 0.023, g_loss 3.810, d_loss 0.039\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 237/390 d_loss_real= 0.024, d_loss_fake= 0.023, g_loss 3.813, d_loss 0.024\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 238/390 d_loss_real= 0.108, d_loss_fake= 0.024, g_loss 3.757, d_loss 0.066\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 239/390 d_loss_real= 0.124, d_loss_fake= 0.026, g_loss 3.700, d_loss 0.075\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 240/390 d_loss_real= 0.044, d_loss_fake= 0.027, g_loss 3.688, d_loss 0.035\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 241/390 d_loss_real= 0.127, d_loss_fake= 0.030, g_loss 3.593, d_loss 0.079\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 45 Batch 242/390 d_loss_real= 0.050, d_loss_fake= 0.032, g_loss 3.477, d_loss 0.041\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 45 Batch 243/390 d_loss_real= 0.186, d_loss_fake= 0.044, g_loss 3.366, d_loss 0.115\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 45 Batch 244/390 d_loss_real= 0.020, d_loss_fake= 0.048, g_loss 3.343, d_loss 0.034\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 245/390 d_loss_real= 0.090, d_loss_fake= 0.044, g_loss 3.430, d_loss 0.067\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 246/390 d_loss_real= 0.100, d_loss_fake= 0.037, g_loss 3.536, d_loss 0.069\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 45 Batch 247/390 d_loss_real= 0.001, d_loss_fake= 0.030, g_loss 3.734, d_loss 0.015\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 248/390 d_loss_real= 0.009, d_loss_fake= 0.025, g_loss 3.791, d_loss 0.017\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 249/390 d_loss_real= 0.052, d_loss_fake= 0.024, g_loss 3.819, d_loss 0.038\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 45 Batch 250/390 d_loss_real= 0.117, d_loss_fake= 0.025, g_loss 3.829, d_loss 0.071\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 251/390 d_loss_real= 0.237, d_loss_fake= 0.025, g_loss 3.774, d_loss 0.131\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 45 Batch 252/390 d_loss_real= 0.319, d_loss_fake= 0.025, g_loss 3.654, d_loss 0.172\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 45 Batch 253/390 d_loss_real= 0.176, d_loss_fake= 0.029, g_loss 3.537, d_loss 0.102\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 45 Batch 254/390 d_loss_real= 0.053, d_loss_fake= 0.031, g_loss 3.562, d_loss 0.042\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 45 Batch 255/390 d_loss_real= 0.137, d_loss_fake= 0.037, g_loss 3.465, d_loss 0.087\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 256/390 d_loss_real= 0.160, d_loss_fake= 0.034, g_loss 3.474, d_loss 0.097\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 45 Batch 257/390 d_loss_real= 0.036, d_loss_fake= 0.032, g_loss 3.554, d_loss 0.034\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 258/390 d_loss_real= 0.076, d_loss_fake= 0.030, g_loss 3.567, d_loss 0.053\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 259/390 d_loss_real= 0.146, d_loss_fake= 0.032, g_loss 3.553, d_loss 0.089\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 260/390 d_loss_real= 0.255, d_loss_fake= 0.034, g_loss 3.494, d_loss 0.145\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 261/390 d_loss_real= 0.216, d_loss_fake= 0.036, g_loss 3.312, d_loss 0.126\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 45 Batch 262/390 d_loss_real= 0.242, d_loss_fake= 0.049, g_loss 3.145, d_loss 0.146\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 45 Batch 263/390 d_loss_real= 0.018, d_loss_fake= 0.055, g_loss 3.206, d_loss 0.036\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 264/390 d_loss_real= 0.033, d_loss_fake= 0.049, g_loss 3.305, d_loss 0.041\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 265/390 d_loss_real= 0.039, d_loss_fake= 0.041, g_loss 3.434, d_loss 0.040\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 266/390 d_loss_real= 0.145, d_loss_fake= 0.032, g_loss 3.586, d_loss 0.089\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 267/390 d_loss_real= 0.059, d_loss_fake= 0.030, g_loss 3.679, d_loss 0.045\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 268/390 d_loss_real= 0.075, d_loss_fake= 0.027, g_loss 3.804, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 269/390 d_loss_real= 0.114, d_loss_fake= 0.027, g_loss 3.796, d_loss 0.071\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 270/390 d_loss_real= 0.071, d_loss_fake= 0.028, g_loss 3.753, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 271/390 d_loss_real= 0.023, d_loss_fake= 0.029, g_loss 3.725, d_loss 0.026\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 272/390 d_loss_real= 0.000, d_loss_fake= 0.028, g_loss 3.702, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 273/390 d_loss_real= 0.036, d_loss_fake= 0.030, g_loss 3.658, d_loss 0.033\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 274/390 d_loss_real= 0.000, d_loss_fake= 0.031, g_loss 3.668, d_loss 0.015\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 275/390 d_loss_real= 0.052, d_loss_fake= 0.028, g_loss 3.730, d_loss 0.040\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 45 Batch 276/390 d_loss_real= 0.022, d_loss_fake= 0.029, g_loss 3.761, d_loss 0.026\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 45 Batch 277/390 d_loss_real= 0.005, d_loss_fake= 0.026, g_loss 3.788, d_loss 0.016\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 45 Batch 278/390 d_loss_real= 0.165, d_loss_fake= 0.029, g_loss 3.762, d_loss 0.097\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 279/390 d_loss_real= 0.035, d_loss_fake= 0.029, g_loss 3.659, d_loss 0.032\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 45 Batch 280/390 d_loss_real= 0.000, d_loss_fake= 0.032, g_loss 3.625, d_loss 0.016\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 281/390 d_loss_real= 0.048, d_loss_fake= 0.028, g_loss 3.737, d_loss 0.038\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 282/390 d_loss_real= 0.121, d_loss_fake= 0.034, g_loss 3.722, d_loss 0.077\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 283/390 d_loss_real= 0.082, d_loss_fake= 0.028, g_loss 3.599, d_loss 0.055\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 45 Batch 284/390 d_loss_real= 0.210, d_loss_fake= 0.034, g_loss 3.470, d_loss 0.122\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 285/390 d_loss_real= 0.048, d_loss_fake= 0.036, g_loss 3.398, d_loss 0.042\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 45 Batch 286/390 d_loss_real= 0.225, d_loss_fake= 0.039, g_loss 3.281, d_loss 0.132\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 287/390 d_loss_real= 0.065, d_loss_fake= 0.047, g_loss 3.280, d_loss 0.056\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 288/390 d_loss_real= 0.162, d_loss_fake= 0.046, g_loss 3.259, d_loss 0.104\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 289/390 d_loss_real= 0.088, d_loss_fake= 0.048, g_loss 3.261, d_loss 0.068\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 45 Batch 290/390 d_loss_real= 0.184, d_loss_fake= 0.045, g_loss 3.293, d_loss 0.114\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 45 Batch 291/390 d_loss_real= 0.000, d_loss_fake= 0.040, g_loss 3.383, d_loss 0.020\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 45 Batch 292/390 d_loss_real= 0.214, d_loss_fake= 0.041, g_loss 3.363, d_loss 0.128\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 45 Batch 293/390 d_loss_real= 0.158, d_loss_fake= 0.042, g_loss 3.335, d_loss 0.100\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 45 Batch 294/390 d_loss_real= 0.167, d_loss_fake= 0.045, g_loss 3.192, d_loss 0.106\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 45 Batch 295/390 d_loss_real= 0.095, d_loss_fake= 0.058, g_loss 3.001, d_loss 0.076\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 296/390 d_loss_real= 0.040, d_loss_fake= 0.057, g_loss 3.034, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 297/390 d_loss_real= 0.195, d_loss_fake= 0.053, g_loss 3.165, d_loss 0.124\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 45 Batch 298/390 d_loss_real= 0.140, d_loss_fake= 0.041, g_loss 3.405, d_loss 0.090\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 45 Batch 299/390 d_loss_real= 0.049, d_loss_fake= 0.049, g_loss 3.292, d_loss 0.049\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 300/390 d_loss_real= 0.078, d_loss_fake= 0.034, g_loss 3.500, d_loss 0.056\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 45 Batch 301/390 d_loss_real= 0.057, d_loss_fake= 0.029, g_loss 3.692, d_loss 0.043\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 302/390 d_loss_real= 0.023, d_loss_fake= 0.027, g_loss 3.747, d_loss 0.025\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 45 Batch 303/390 d_loss_real= 0.116, d_loss_fake= 0.025, g_loss 3.789, d_loss 0.070\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 304/390 d_loss_real= 0.185, d_loss_fake= 0.025, g_loss 3.754, d_loss 0.105\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 45 Batch 305/390 d_loss_real= 0.186, d_loss_fake= 0.027, g_loss 3.629, d_loss 0.107\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "Epoch 45 Batch 306/390 d_loss_real= 0.136, d_loss_fake= 0.031, g_loss 3.454, d_loss 0.084\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 307/390 d_loss_real= 0.149, d_loss_fake= 0.034, g_loss 3.373, d_loss 0.092\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 308/390 d_loss_real= 0.069, d_loss_fake= 0.038, g_loss 3.404, d_loss 0.054\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 309/390 d_loss_real= 0.015, d_loss_fake= 0.033, g_loss 3.528, d_loss 0.024\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 45 Batch 310/390 d_loss_real= 0.222, d_loss_fake= 0.040, g_loss 3.372, d_loss 0.131\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 311/390 d_loss_real= 0.185, d_loss_fake= 0.041, g_loss 3.370, d_loss 0.113\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 312/390 d_loss_real= 0.210, d_loss_fake= 0.041, g_loss 3.276, d_loss 0.125\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 45 Batch 313/390 d_loss_real= 0.064, d_loss_fake= 0.053, g_loss 3.182, d_loss 0.058\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 314/390 d_loss_real= 0.187, d_loss_fake= 0.048, g_loss 3.257, d_loss 0.117\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 315/390 d_loss_real= 0.006, d_loss_fake= 0.039, g_loss 3.447, d_loss 0.022\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 316/390 d_loss_real= 0.138, d_loss_fake= 0.034, g_loss 3.549, d_loss 0.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 317/390 d_loss_real= 0.052, d_loss_fake= 0.032, g_loss 3.638, d_loss 0.042\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 318/390 d_loss_real= 0.041, d_loss_fake= 0.029, g_loss 3.767, d_loss 0.035\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 319/390 d_loss_real= 0.222, d_loss_fake= 0.025, g_loss 3.783, d_loss 0.124\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 320/390 d_loss_real= 0.056, d_loss_fake= 0.024, g_loss 3.866, d_loss 0.040\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 45 Batch 321/390 d_loss_real= 0.095, d_loss_fake= 0.023, g_loss 3.907, d_loss 0.059\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 322/390 d_loss_real= 0.000, d_loss_fake= 0.021, g_loss 3.953, d_loss 0.011\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 323/390 d_loss_real= 0.114, d_loss_fake= 0.020, g_loss 3.986, d_loss 0.067\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 45 Batch 324/390 d_loss_real= 0.081, d_loss_fake= 0.021, g_loss 3.959, d_loss 0.051\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 325/390 d_loss_real= 0.080, d_loss_fake= 0.020, g_loss 3.907, d_loss 0.050\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 326/390 d_loss_real= 0.138, d_loss_fake= 0.022, g_loss 3.869, d_loss 0.080\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 327/390 d_loss_real= 0.092, d_loss_fake= 0.023, g_loss 3.827, d_loss 0.057\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 45 Batch 328/390 d_loss_real= 0.090, d_loss_fake= 0.025, g_loss 3.764, d_loss 0.057\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 329/390 d_loss_real= 0.128, d_loss_fake= 0.029, g_loss 3.617, d_loss 0.078\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 45 Batch 330/390 d_loss_real= 0.077, d_loss_fake= 0.029, g_loss 3.599, d_loss 0.053\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 45 Batch 331/390 d_loss_real= 0.000, d_loss_fake= 0.028, g_loss 3.667, d_loss 0.014\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 332/390 d_loss_real= 0.410, d_loss_fake= 0.032, g_loss 3.513, d_loss 0.221\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 45 Batch 333/390 d_loss_real= 0.077, d_loss_fake= 0.030, g_loss 3.587, d_loss 0.053\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 45 Batch 334/390 d_loss_real= 0.189, d_loss_fake= 0.034, g_loss 3.480, d_loss 0.112\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 45 Batch 335/390 d_loss_real= 0.000, d_loss_fake= 0.033, g_loss 3.514, d_loss 0.016\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 336/390 d_loss_real= 0.171, d_loss_fake= 0.034, g_loss 3.636, d_loss 0.102\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 45 Batch 337/390 d_loss_real= 0.121, d_loss_fake= 0.031, g_loss 3.607, d_loss 0.076\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 45 Batch 338/390 d_loss_real= 0.087, d_loss_fake= 0.027, g_loss 3.726, d_loss 0.057\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 339/390 d_loss_real= 0.088, d_loss_fake= 0.028, g_loss 3.728, d_loss 0.058\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 45 Batch 340/390 d_loss_real= 0.076, d_loss_fake= 0.024, g_loss 3.761, d_loss 0.050\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 45 Batch 341/390 d_loss_real= 0.065, d_loss_fake= 0.024, g_loss 3.843, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 342/390 d_loss_real= 0.152, d_loss_fake= 0.021, g_loss 3.905, d_loss 0.087\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 45 Batch 343/390 d_loss_real= 0.089, d_loss_fake= 0.022, g_loss 3.922, d_loss 0.055\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 344/390 d_loss_real= 0.297, d_loss_fake= 0.022, g_loss 3.859, d_loss 0.159\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 45 Batch 345/390 d_loss_real= 0.073, d_loss_fake= 0.022, g_loss 3.757, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 346/390 d_loss_real= 0.013, d_loss_fake= 0.027, g_loss 3.630, d_loss 0.020\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 45 Batch 347/390 d_loss_real= 0.000, d_loss_fake= 0.028, g_loss 3.596, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 348/390 d_loss_real= 0.144, d_loss_fake= 0.025, g_loss 3.739, d_loss 0.084\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 45 Batch 349/390 d_loss_real= 0.151, d_loss_fake= 0.028, g_loss 3.605, d_loss 0.089\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 350/390 d_loss_real= 0.001, d_loss_fake= 0.031, g_loss 3.591, d_loss 0.016\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 351/390 d_loss_real= 0.270, d_loss_fake= 0.034, g_loss 3.564, d_loss 0.152\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 352/390 d_loss_real= 0.049, d_loss_fake= 0.030, g_loss 3.664, d_loss 0.040\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 353/390 d_loss_real= 0.151, d_loss_fake= 0.028, g_loss 3.686, d_loss 0.090\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 45 Batch 354/390 d_loss_real= 0.116, d_loss_fake= 0.026, g_loss 3.705, d_loss 0.071\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 45 Batch 355/390 d_loss_real= 0.039, d_loss_fake= 0.028, g_loss 3.766, d_loss 0.033\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 356/390 d_loss_real= 0.051, d_loss_fake= 0.025, g_loss 3.799, d_loss 0.038\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 45 Batch 357/390 d_loss_real= 0.119, d_loss_fake= 0.024, g_loss 3.840, d_loss 0.072\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 358/390 d_loss_real= 0.030, d_loss_fake= 0.021, g_loss 3.902, d_loss 0.026\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 45 Batch 359/390 d_loss_real= 0.134, d_loss_fake= 0.022, g_loss 3.864, d_loss 0.078\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 45 Batch 360/390 d_loss_real= 0.109, d_loss_fake= 0.024, g_loss 3.729, d_loss 0.067\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 45 Batch 361/390 d_loss_real= 0.094, d_loss_fake= 0.027, g_loss 3.643, d_loss 0.060\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 45 Batch 362/390 d_loss_real= 0.080, d_loss_fake= 0.030, g_loss 3.648, d_loss 0.055\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 45 Batch 363/390 d_loss_real= 0.173, d_loss_fake= 0.027, g_loss 3.735, d_loss 0.100\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 45 Batch 364/390 d_loss_real= 0.073, d_loss_fake= 0.031, g_loss 3.627, d_loss 0.052\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 365/390 d_loss_real= 0.059, d_loss_fake= 0.029, g_loss 3.653, d_loss 0.044\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 366/390 d_loss_real= 0.057, d_loss_fake= 0.028, g_loss 3.682, d_loss 0.042\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 45 Batch 367/390 d_loss_real= 0.068, d_loss_fake= 0.025, g_loss 3.760, d_loss 0.046\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 368/390 d_loss_real= 0.001, d_loss_fake= 0.024, g_loss 3.815, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 369/390 d_loss_real= 0.000, d_loss_fake= 0.021, g_loss 3.924, d_loss 0.011\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 370/390 d_loss_real= 0.311, d_loss_fake= 0.020, g_loss 3.932, d_loss 0.166\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 45 Batch 371/390 d_loss_real= 0.180, d_loss_fake= 0.022, g_loss 3.949, d_loss 0.101\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 372/390 d_loss_real= 0.097, d_loss_fake= 0.023, g_loss 3.907, d_loss 0.060\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 45 Batch 373/390 d_loss_real= 0.063, d_loss_fake= 0.025, g_loss 3.773, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 374/390 d_loss_real= 0.118, d_loss_fake= 0.026, g_loss 3.734, d_loss 0.072\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 375/390 d_loss_real= 0.048, d_loss_fake= 0.026, g_loss 3.728, d_loss 0.037\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 45 Batch 376/390 d_loss_real= 0.000, d_loss_fake= 0.026, g_loss 3.740, d_loss 0.013\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 45 Batch 377/390 d_loss_real= 0.002, d_loss_fake= 0.025, g_loss 3.773, d_loss 0.013\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45 Batch 378/390 d_loss_real= 0.125, d_loss_fake= 0.025, g_loss 3.774, d_loss 0.075\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 379/390 d_loss_real= 0.000, d_loss_fake= 0.024, g_loss 3.864, d_loss 0.012\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 45 Batch 380/390 d_loss_real= 0.244, d_loss_fake= 0.023, g_loss 3.848, d_loss 0.133\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 381/390 d_loss_real= 0.081, d_loss_fake= 0.023, g_loss 3.877, d_loss 0.052\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 382/390 d_loss_real= 0.040, d_loss_fake= 0.023, g_loss 3.818, d_loss 0.032\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 383/390 d_loss_real= 0.117, d_loss_fake= 0.023, g_loss 3.792, d_loss 0.070\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 384/390 d_loss_real= 0.059, d_loss_fake= 0.024, g_loss 3.751, d_loss 0.041\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 385/390 d_loss_real= 0.072, d_loss_fake= 0.024, g_loss 3.783, d_loss 0.048\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 45 Batch 386/390 d_loss_real= 0.050, d_loss_fake= 0.025, g_loss 3.740, d_loss 0.038\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45 Batch 387/390 d_loss_real= 0.058, d_loss_fake= 0.026, g_loss 3.688, d_loss 0.042\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 388/390 d_loss_real= 0.061, d_loss_fake= 0.026, g_loss 3.694, d_loss 0.044\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45 Batch 389/390 d_loss_real= 0.129, d_loss_fake= 0.028, g_loss 3.675, d_loss 0.078\n",
            "2/2 [==============================] - 0s 12ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45 Batch 390/390 d_loss_real= 0.081, d_loss_fake= 0.027, g_loss 3.702, d_loss 0.054\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 1/390 d_loss_real= 0.064, d_loss_fake= 0.026, g_loss 3.740, d_loss 0.045\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 2/390 d_loss_real= 0.065, d_loss_fake= 0.025, g_loss 3.749, d_loss 0.045\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 46 Batch 3/390 d_loss_real= 0.243, d_loss_fake= 0.024, g_loss 3.697, d_loss 0.133\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 4/390 d_loss_real= 0.180, d_loss_fake= 0.027, g_loss 3.577, d_loss 0.103\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 46 Batch 5/390 d_loss_real= 0.063, d_loss_fake= 0.031, g_loss 3.555, d_loss 0.047\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 46 Batch 6/390 d_loss_real= 0.061, d_loss_fake= 0.031, g_loss 3.521, d_loss 0.046\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 7/390 d_loss_real= 0.067, d_loss_fake= 0.031, g_loss 3.599, d_loss 0.049\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 8/390 d_loss_real= 0.004, d_loss_fake= 0.030, g_loss 3.572, d_loss 0.017\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 46 Batch 9/390 d_loss_real= 0.028, d_loss_fake= 0.029, g_loss 3.603, d_loss 0.029\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 10/390 d_loss_real= 0.061, d_loss_fake= 0.028, g_loss 3.677, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 11/390 d_loss_real= 0.190, d_loss_fake= 0.028, g_loss 3.652, d_loss 0.109\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 46 Batch 12/390 d_loss_real= 0.175, d_loss_fake= 0.028, g_loss 3.671, d_loss 0.102\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 46 Batch 13/390 d_loss_real= 0.065, d_loss_fake= 0.031, g_loss 3.495, d_loss 0.048\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 46 Batch 14/390 d_loss_real= 0.074, d_loss_fake= 0.030, g_loss 3.587, d_loss 0.052\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 15/390 d_loss_real= 0.136, d_loss_fake= 0.038, g_loss 3.381, d_loss 0.087\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 16/390 d_loss_real= 0.181, d_loss_fake= 0.041, g_loss 3.463, d_loss 0.111\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 46 Batch 17/390 d_loss_real= 0.171, d_loss_fake= 0.037, g_loss 3.442, d_loss 0.104\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 18/390 d_loss_real= 0.001, d_loss_fake= 0.039, g_loss 3.480, d_loss 0.020\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 19/390 d_loss_real= 0.059, d_loss_fake= 0.048, g_loss 3.495, d_loss 0.053\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 46 Batch 20/390 d_loss_real= 0.029, d_loss_fake= 0.037, g_loss 3.600, d_loss 0.033\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 21/390 d_loss_real= 0.188, d_loss_fake= 0.025, g_loss 3.844, d_loss 0.107\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 22/390 d_loss_real= 0.247, d_loss_fake= 0.027, g_loss 3.823, d_loss 0.137\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 23/390 d_loss_real= 0.005, d_loss_fake= 0.025, g_loss 3.939, d_loss 0.015\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 46 Batch 24/390 d_loss_real= 0.128, d_loss_fake= 0.023, g_loss 3.978, d_loss 0.075\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 46 Batch 25/390 d_loss_real= 0.061, d_loss_fake= 0.020, g_loss 3.977, d_loss 0.041\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 26/390 d_loss_real= 0.152, d_loss_fake= 0.019, g_loss 4.012, d_loss 0.086\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 46 Batch 27/390 d_loss_real= 0.000, d_loss_fake= 0.025, g_loss 3.788, d_loss 0.013\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 46 Batch 28/390 d_loss_real= 0.106, d_loss_fake= 0.029, g_loss 3.623, d_loss 0.068\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 46 Batch 29/390 d_loss_real= 0.028, d_loss_fake= 0.030, g_loss 3.629, d_loss 0.029\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 30/390 d_loss_real= 0.036, d_loss_fake= 0.043, g_loss 3.407, d_loss 0.039\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 31/390 d_loss_real= 0.128, d_loss_fake= 0.036, g_loss 3.531, d_loss 0.082\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 32/390 d_loss_real= 0.028, d_loss_fake= 0.042, g_loss 3.513, d_loss 0.035\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 46 Batch 33/390 d_loss_real= 0.070, d_loss_fake= 0.035, g_loss 3.655, d_loss 0.052\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 34/390 d_loss_real= 0.084, d_loss_fake= 0.031, g_loss 3.787, d_loss 0.057\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 35/390 d_loss_real= 0.116, d_loss_fake= 0.019, g_loss 4.333, d_loss 0.068\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 36/390 d_loss_real= 0.068, d_loss_fake= 0.019, g_loss 4.033, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 37/390 d_loss_real= 0.010, d_loss_fake= 0.020, g_loss 4.026, d_loss 0.015\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 38/390 d_loss_real= 0.054, d_loss_fake= 0.022, g_loss 3.972, d_loss 0.038\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 39/390 d_loss_real= 0.142, d_loss_fake= 0.020, g_loss 4.063, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 40/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 4.097, d_loss 0.010\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 46 Batch 41/390 d_loss_real= 0.196, d_loss_fake= 0.019, g_loss 4.133, d_loss 0.107\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 46 Batch 42/390 d_loss_real= 0.066, d_loss_fake= 0.021, g_loss 4.093, d_loss 0.044\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 43/390 d_loss_real= 0.112, d_loss_fake= 0.022, g_loss 4.004, d_loss 0.067\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 44/390 d_loss_real= 0.203, d_loss_fake= 0.024, g_loss 3.991, d_loss 0.113\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 45/390 d_loss_real= 0.314, d_loss_fake= 0.025, g_loss 3.782, d_loss 0.170\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 46/390 d_loss_real= 0.063, d_loss_fake= 0.035, g_loss 3.571, d_loss 0.049\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 46 Batch 47/390 d_loss_real= 0.054, d_loss_fake= 0.048, g_loss 3.435, d_loss 0.051\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 48/390 d_loss_real= 0.062, d_loss_fake= 0.063, g_loss 3.401, d_loss 0.062\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 49/390 d_loss_real= 0.154, d_loss_fake= 0.045, g_loss 3.682, d_loss 0.099\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 50/390 d_loss_real= 0.032, d_loss_fake= 0.030, g_loss 4.168, d_loss 0.031\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 46 Batch 51/390 d_loss_real= 0.094, d_loss_fake= 0.039, g_loss 3.635, d_loss 0.067\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 52/390 d_loss_real= 0.047, d_loss_fake= 0.027, g_loss 3.898, d_loss 0.037\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 53/390 d_loss_real= 0.090, d_loss_fake= 0.028, g_loss 3.888, d_loss 0.059\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 54/390 d_loss_real= 0.283, d_loss_fake= 0.033, g_loss 3.773, d_loss 0.158\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 55/390 d_loss_real= 0.134, d_loss_fake= 0.018, g_loss 4.157, d_loss 0.076\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 46 Batch 56/390 d_loss_real= 0.110, d_loss_fake= 0.057, g_loss 3.552, d_loss 0.083\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 46 Batch 57/390 d_loss_real= 0.193, d_loss_fake= 0.015, g_loss 4.454, d_loss 0.104\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 58/390 d_loss_real= 0.138, d_loss_fake= 0.023, g_loss 4.329, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 59/390 d_loss_real= 0.037, d_loss_fake= 0.009, g_loss 4.915, d_loss 0.023\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 46 Batch 60/390 d_loss_real= 0.030, d_loss_fake= 0.009, g_loss 4.889, d_loss 0.020\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 61/390 d_loss_real= 0.007, d_loss_fake= 0.011, g_loss 4.615, d_loss 0.009\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 62/390 d_loss_real= 0.008, d_loss_fake= 0.012, g_loss 4.543, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 63/390 d_loss_real= 0.065, d_loss_fake= 0.011, g_loss 4.561, d_loss 0.038\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 64/390 d_loss_real= 0.163, d_loss_fake= 0.013, g_loss 4.512, d_loss 0.088\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 46 Batch 65/390 d_loss_real= 0.180, d_loss_fake= 0.013, g_loss 4.346, d_loss 0.096\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 46 Batch 66/390 d_loss_real= 0.038, d_loss_fake= 0.016, g_loss 4.207, d_loss 0.027\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 67/390 d_loss_real= 0.104, d_loss_fake= 0.021, g_loss 4.025, d_loss 0.062\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 46 Batch 68/390 d_loss_real= 0.098, d_loss_fake= 0.023, g_loss 3.911, d_loss 0.061\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 69/390 d_loss_real= 0.105, d_loss_fake= 0.025, g_loss 3.943, d_loss 0.065\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 70/390 d_loss_real= 0.073, d_loss_fake= 0.029, g_loss 3.932, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 71/390 d_loss_real= 0.070, d_loss_fake= 0.025, g_loss 3.772, d_loss 0.048\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 46 Batch 72/390 d_loss_real= 0.047, d_loss_fake= 0.017, g_loss 4.282, d_loss 0.032\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 46 Batch 73/390 d_loss_real= 0.066, d_loss_fake= 0.026, g_loss 3.903, d_loss 0.046\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 46 Batch 74/390 d_loss_real= 0.084, d_loss_fake= 0.019, g_loss 4.092, d_loss 0.052\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 46 Batch 75/390 d_loss_real= 0.053, d_loss_fake= 0.024, g_loss 3.866, d_loss 0.039\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 46 Batch 76/390 d_loss_real= 0.068, d_loss_fake= 0.025, g_loss 3.800, d_loss 0.046\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 46 Batch 77/390 d_loss_real= 0.054, d_loss_fake= 0.027, g_loss 3.797, d_loss 0.040\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 46 Batch 78/390 d_loss_real= 0.039, d_loss_fake= 0.027, g_loss 3.731, d_loss 0.033\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 79/390 d_loss_real= 0.044, d_loss_fake= 0.028, g_loss 3.663, d_loss 0.036\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 46 Batch 80/390 d_loss_real= 0.122, d_loss_fake= 0.030, g_loss 3.547, d_loss 0.076\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 46 Batch 81/390 d_loss_real= 0.000, d_loss_fake= 0.034, g_loss 3.466, d_loss 0.017\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 82/390 d_loss_real= 0.122, d_loss_fake= 0.040, g_loss 3.264, d_loss 0.081\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 83/390 d_loss_real= 0.112, d_loss_fake= 0.048, g_loss 3.069, d_loss 0.080\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 84/390 d_loss_real= 0.000, d_loss_fake= 0.068, g_loss 2.827, d_loss 0.034\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 46 Batch 85/390 d_loss_real= 0.053, d_loss_fake= 0.084, g_loss 2.658, d_loss 0.068\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 86/390 d_loss_real= 0.087, d_loss_fake= 0.101, g_loss 2.593, d_loss 0.094\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 87/390 d_loss_real= 0.094, d_loss_fake= 0.106, g_loss 2.606, d_loss 0.100\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 46 Batch 88/390 d_loss_real= 0.024, d_loss_fake= 0.095, g_loss 2.676, d_loss 0.059\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 89/390 d_loss_real= 0.116, d_loss_fake= 0.086, g_loss 2.905, d_loss 0.101\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 46 Batch 90/390 d_loss_real= 0.000, d_loss_fake= 0.060, g_loss 3.124, d_loss 0.030\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 46 Batch 91/390 d_loss_real= 0.000, d_loss_fake= 0.043, g_loss 3.428, d_loss 0.021\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 92/390 d_loss_real= 0.234, d_loss_fake= 0.033, g_loss 3.484, d_loss 0.134\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 93/390 d_loss_real= 0.189, d_loss_fake= 0.031, g_loss 3.605, d_loss 0.110\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 46 Batch 94/390 d_loss_real= 0.053, d_loss_fake= 0.033, g_loss 3.567, d_loss 0.043\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 46 Batch 95/390 d_loss_real= 0.143, d_loss_fake= 0.033, g_loss 3.551, d_loss 0.088\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 96/390 d_loss_real= 0.019, d_loss_fake= 0.034, g_loss 3.531, d_loss 0.026\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 97/390 d_loss_real= 0.164, d_loss_fake= 0.040, g_loss 3.405, d_loss 0.102\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 46 Batch 98/390 d_loss_real= 0.057, d_loss_fake= 0.046, g_loss 3.441, d_loss 0.052\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 99/390 d_loss_real= 0.090, d_loss_fake= 0.057, g_loss 3.393, d_loss 0.074\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 100/390 d_loss_real= 0.077, d_loss_fake= 0.043, g_loss 3.410, d_loss 0.060\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 101/390 d_loss_real= 0.059, d_loss_fake= 0.038, g_loss 3.586, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 102/390 d_loss_real= 0.104, d_loss_fake= 0.034, g_loss 3.643, d_loss 0.069\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 46 Batch 103/390 d_loss_real= 0.278, d_loss_fake= 0.030, g_loss 3.663, d_loss 0.154\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 46 Batch 104/390 d_loss_real= 0.083, d_loss_fake= 0.031, g_loss 3.627, d_loss 0.057\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 46 Batch 105/390 d_loss_real= 0.084, d_loss_fake= 0.031, g_loss 3.645, d_loss 0.058\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 106/390 d_loss_real= 0.195, d_loss_fake= 0.031, g_loss 3.638, d_loss 0.113\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 46 Batch 107/390 d_loss_real= 0.125, d_loss_fake= 0.035, g_loss 3.435, d_loss 0.080\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 46 Batch 108/390 d_loss_real= 0.069, d_loss_fake= 0.062, g_loss 3.410, d_loss 0.065\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 46 Batch 109/390 d_loss_real= 0.064, d_loss_fake= 0.047, g_loss 3.561, d_loss 0.055\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 46 Batch 110/390 d_loss_real= 0.081, d_loss_fake= 0.029, g_loss 3.697, d_loss 0.055\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 111/390 d_loss_real= 0.007, d_loss_fake= 0.020, g_loss 3.988, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 112/390 d_loss_real= 0.040, d_loss_fake= 0.025, g_loss 3.831, d_loss 0.033\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 46 Batch 113/390 d_loss_real= 0.081, d_loss_fake= 0.018, g_loss 4.092, d_loss 0.049\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 114/390 d_loss_real= 0.092, d_loss_fake= 0.021, g_loss 3.983, d_loss 0.057\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 46 Batch 115/390 d_loss_real= 0.056, d_loss_fake= 0.024, g_loss 3.909, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 116/390 d_loss_real= 0.063, d_loss_fake= 0.022, g_loss 3.936, d_loss 0.042\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 46 Batch 117/390 d_loss_real= 0.133, d_loss_fake= 0.028, g_loss 3.767, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 118/390 d_loss_real= 0.001, d_loss_fake= 0.025, g_loss 3.792, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 119/390 d_loss_real= 0.083, d_loss_fake= 0.026, g_loss 3.773, d_loss 0.055\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 46 Batch 120/390 d_loss_real= 0.001, d_loss_fake= 0.020, g_loss 4.021, d_loss 0.011\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 46 Batch 121/390 d_loss_real= 0.093, d_loss_fake= 0.024, g_loss 3.822, d_loss 0.059\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 122/390 d_loss_real= 0.079, d_loss_fake= 0.032, g_loss 3.896, d_loss 0.055\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 123/390 d_loss_real= 0.198, d_loss_fake= 0.021, g_loss 3.946, d_loss 0.110\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 46 Batch 124/390 d_loss_real= 0.103, d_loss_fake= 0.038, g_loss 3.729, d_loss 0.071\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 125/390 d_loss_real= 0.140, d_loss_fake= 0.038, g_loss 3.654, d_loss 0.089\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 126/390 d_loss_real= 0.023, d_loss_fake= 0.027, g_loss 3.850, d_loss 0.025\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 127/390 d_loss_real= 0.041, d_loss_fake= 0.029, g_loss 3.932, d_loss 0.035\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 46 Batch 128/390 d_loss_real= 0.021, d_loss_fake= 0.019, g_loss 4.211, d_loss 0.020\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 129/390 d_loss_real= 0.115, d_loss_fake= 0.012, g_loss 4.473, d_loss 0.064\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 130/390 d_loss_real= 0.122, d_loss_fake= 0.012, g_loss 4.353, d_loss 0.067\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 46 Batch 131/390 d_loss_real= 0.062, d_loss_fake= 0.026, g_loss 4.026, d_loss 0.044\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 132/390 d_loss_real= 0.262, d_loss_fake= 0.024, g_loss 3.837, d_loss 0.143\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 46 Batch 133/390 d_loss_real= 0.154, d_loss_fake= 0.031, g_loss 3.798, d_loss 0.093\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 134/390 d_loss_real= 0.090, d_loss_fake= 0.036, g_loss 3.990, d_loss 0.063\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 135/390 d_loss_real= 0.137, d_loss_fake= 0.017, g_loss 4.265, d_loss 0.077\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 46 Batch 136/390 d_loss_real= 0.130, d_loss_fake= 0.018, g_loss 4.280, d_loss 0.074\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 46 Batch 137/390 d_loss_real= 0.079, d_loss_fake= 0.019, g_loss 4.346, d_loss 0.049\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 46 Batch 138/390 d_loss_real= 0.104, d_loss_fake= 0.019, g_loss 4.336, d_loss 0.062\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 46 Batch 139/390 d_loss_real= 0.007, d_loss_fake= 0.019, g_loss 4.202, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 140/390 d_loss_real= 0.134, d_loss_fake= 0.023, g_loss 4.055, d_loss 0.078\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 46 Batch 141/390 d_loss_real= 0.006, d_loss_fake= 0.031, g_loss 4.185, d_loss 0.018\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 46 Batch 142/390 d_loss_real= 0.173, d_loss_fake= 0.051, g_loss 4.006, d_loss 0.112\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 143/390 d_loss_real= 0.052, d_loss_fake= 0.045, g_loss 4.221, d_loss 0.048\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 46 Batch 144/390 d_loss_real= 0.316, d_loss_fake= 0.035, g_loss 4.139, d_loss 0.176\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 46 Batch 145/390 d_loss_real= 0.079, d_loss_fake= 0.026, g_loss 4.433, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 146/390 d_loss_real= 0.001, d_loss_fake= 0.013, g_loss 4.674, d_loss 0.007\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 46 Batch 147/390 d_loss_real= 0.116, d_loss_fake= 0.013, g_loss 4.516, d_loss 0.064\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 148/390 d_loss_real= 0.313, d_loss_fake= 0.013, g_loss 4.496, d_loss 0.163\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 149/390 d_loss_real= 0.318, d_loss_fake= 0.015, g_loss 4.368, d_loss 0.167\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 150/390 d_loss_real= 0.349, d_loss_fake= 0.018, g_loss 4.233, d_loss 0.183\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 151/390 d_loss_real= 0.049, d_loss_fake= 0.028, g_loss 3.982, d_loss 0.039\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 152/390 d_loss_real= 0.067, d_loss_fake= 0.031, g_loss 3.769, d_loss 0.049\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 153/390 d_loss_real= 0.367, d_loss_fake= 0.031, g_loss 3.897, d_loss 0.199\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 154/390 d_loss_real= 0.124, d_loss_fake= 0.033, g_loss 3.622, d_loss 0.078\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 155/390 d_loss_real= 0.046, d_loss_fake= 0.038, g_loss 3.532, d_loss 0.042\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 46 Batch 156/390 d_loss_real= 0.035, d_loss_fake= 0.031, g_loss 3.725, d_loss 0.033\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 157/390 d_loss_real= 0.000, d_loss_fake= 0.084, g_loss 3.522, d_loss 0.042\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 158/390 d_loss_real= 0.000, d_loss_fake= 0.023, g_loss 4.013, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 159/390 d_loss_real= 0.131, d_loss_fake= 0.021, g_loss 4.061, d_loss 0.076\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 46 Batch 160/390 d_loss_real= 0.105, d_loss_fake= 0.017, g_loss 4.115, d_loss 0.061\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 161/390 d_loss_real= 0.098, d_loss_fake= 0.017, g_loss 4.117, d_loss 0.058\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 162/390 d_loss_real= 0.061, d_loss_fake= 0.017, g_loss 4.112, d_loss 0.039\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 163/390 d_loss_real= 0.081, d_loss_fake= 0.017, g_loss 4.073, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 164/390 d_loss_real= 0.025, d_loss_fake= 0.018, g_loss 4.042, d_loss 0.021\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 46 Batch 165/390 d_loss_real= 0.001, d_loss_fake= 0.019, g_loss 4.021, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 166/390 d_loss_real= 0.060, d_loss_fake= 0.020, g_loss 3.973, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 167/390 d_loss_real= 0.167, d_loss_fake= 0.020, g_loss 3.886, d_loss 0.093\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 46 Batch 168/390 d_loss_real= 0.009, d_loss_fake= 0.023, g_loss 3.868, d_loss 0.016\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 46 Batch 169/390 d_loss_real= 0.001, d_loss_fake= 0.023, g_loss 3.849, d_loss 0.012\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 170/390 d_loss_real= 0.193, d_loss_fake= 0.026, g_loss 3.818, d_loss 0.109\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 171/390 d_loss_real= 0.077, d_loss_fake= 0.028, g_loss 3.763, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 172/390 d_loss_real= 0.087, d_loss_fake= 0.036, g_loss 3.645, d_loss 0.062\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 46 Batch 173/390 d_loss_real= 0.222, d_loss_fake= 0.032, g_loss 3.602, d_loss 0.127\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 174/390 d_loss_real= 0.101, d_loss_fake= 0.033, g_loss 3.654, d_loss 0.067\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 175/390 d_loss_real= 0.093, d_loss_fake= 0.036, g_loss 3.563, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 176/390 d_loss_real= 0.002, d_loss_fake= 0.026, g_loss 3.841, d_loss 0.014\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 46 Batch 177/390 d_loss_real= 0.112, d_loss_fake= 0.038, g_loss 3.733, d_loss 0.075\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 178/390 d_loss_real= 0.105, d_loss_fake= 0.030, g_loss 3.823, d_loss 0.068\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 46 Batch 179/390 d_loss_real= 0.202, d_loss_fake= 0.024, g_loss 3.783, d_loss 0.113\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 46 Batch 180/390 d_loss_real= 0.166, d_loss_fake= 0.030, g_loss 3.611, d_loss 0.098\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 181/390 d_loss_real= 0.431, d_loss_fake= 0.033, g_loss 3.472, d_loss 0.232\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 182/390 d_loss_real= 0.035, d_loss_fake= 0.037, g_loss 3.540, d_loss 0.036\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 183/390 d_loss_real= 0.161, d_loss_fake= 0.036, g_loss 3.616, d_loss 0.098\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 46 Batch 184/390 d_loss_real= 0.160, d_loss_fake= 0.031, g_loss 3.561, d_loss 0.096\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 185/390 d_loss_real= 0.070, d_loss_fake= 0.033, g_loss 3.667, d_loss 0.051\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 46 Batch 186/390 d_loss_real= 0.132, d_loss_fake= 0.027, g_loss 3.693, d_loss 0.080\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 46 Batch 187/390 d_loss_real= 0.214, d_loss_fake= 0.031, g_loss 3.601, d_loss 0.123\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 188/390 d_loss_real= 0.059, d_loss_fake= 0.030, g_loss 3.648, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 189/390 d_loss_real= 0.024, d_loss_fake= 0.030, g_loss 3.672, d_loss 0.027\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 46 Batch 190/390 d_loss_real= 0.087, d_loss_fake= 0.029, g_loss 3.658, d_loss 0.058\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 191/390 d_loss_real= 0.135, d_loss_fake= 0.031, g_loss 3.553, d_loss 0.083\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 192/390 d_loss_real= 0.000, d_loss_fake= 0.029, g_loss 3.723, d_loss 0.015\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 46 Batch 193/390 d_loss_real= 0.000, d_loss_fake= 0.031, g_loss 3.716, d_loss 0.016\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 194/390 d_loss_real= 0.065, d_loss_fake= 0.026, g_loss 3.759, d_loss 0.045\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 46 Batch 195/390 d_loss_real= 0.239, d_loss_fake= 0.027, g_loss 3.738, d_loss 0.133\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 196/390 d_loss_real= 0.114, d_loss_fake= 0.026, g_loss 3.769, d_loss 0.070\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 46 Batch 197/390 d_loss_real= 0.000, d_loss_fake= 0.026, g_loss 3.779, d_loss 0.013\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 46 Batch 198/390 d_loss_real= 0.064, d_loss_fake= 0.025, g_loss 3.866, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 199/390 d_loss_real= 0.122, d_loss_fake= 0.024, g_loss 3.851, d_loss 0.073\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 46 Batch 200/390 d_loss_real= 0.139, d_loss_fake= 0.026, g_loss 3.792, d_loss 0.082\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 46 Batch 201/390 d_loss_real= 0.163, d_loss_fake= 0.026, g_loss 3.629, d_loss 0.095\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 202/390 d_loss_real= 0.091, d_loss_fake= 0.029, g_loss 3.537, d_loss 0.060\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 46 Batch 203/390 d_loss_real= 0.275, d_loss_fake= 0.030, g_loss 3.521, d_loss 0.152\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 204/390 d_loss_real= 0.000, d_loss_fake= 0.049, g_loss 3.315, d_loss 0.025\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 46 Batch 205/390 d_loss_real= 0.121, d_loss_fake= 0.053, g_loss 3.283, d_loss 0.087\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 46 Batch 206/390 d_loss_real= 0.075, d_loss_fake= 0.047, g_loss 3.430, d_loss 0.061\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 46 Batch 207/390 d_loss_real= 0.185, d_loss_fake= 0.034, g_loss 3.643, d_loss 0.110\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 46 Batch 208/390 d_loss_real= 0.072, d_loss_fake= 0.037, g_loss 3.555, d_loss 0.055\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 209/390 d_loss_real= 0.106, d_loss_fake= 0.034, g_loss 3.639, d_loss 0.070\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 210/390 d_loss_real= 0.115, d_loss_fake= 0.028, g_loss 3.700, d_loss 0.071\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 46 Batch 211/390 d_loss_real= 0.010, d_loss_fake= 0.028, g_loss 3.767, d_loss 0.019\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 212/390 d_loss_real= 0.000, d_loss_fake= 0.022, g_loss 3.977, d_loss 0.011\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 213/390 d_loss_real= 0.180, d_loss_fake= 0.024, g_loss 3.911, d_loss 0.102\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 46 Batch 214/390 d_loss_real= 0.150, d_loss_fake= 0.023, g_loss 3.867, d_loss 0.086\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 46 Batch 215/390 d_loss_real= 0.062, d_loss_fake= 0.025, g_loss 3.883, d_loss 0.043\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 46 Batch 216/390 d_loss_real= 0.134, d_loss_fake= 0.024, g_loss 3.926, d_loss 0.079\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 217/390 d_loss_real= 0.029, d_loss_fake= 0.023, g_loss 3.858, d_loss 0.026\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 46 Batch 218/390 d_loss_real= 0.114, d_loss_fake= 0.025, g_loss 3.721, d_loss 0.070\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 219/390 d_loss_real= 0.068, d_loss_fake= 0.029, g_loss 3.663, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 220/390 d_loss_real= 0.011, d_loss_fake= 0.030, g_loss 3.684, d_loss 0.020\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 46 Batch 221/390 d_loss_real= 0.002, d_loss_fake= 0.021, g_loss 3.877, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 222/390 d_loss_real= 0.066, d_loss_fake= 0.033, g_loss 3.524, d_loss 0.049\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 46 Batch 223/390 d_loss_real= 0.158, d_loss_fake= 0.028, g_loss 3.748, d_loss 0.093\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 224/390 d_loss_real= 0.140, d_loss_fake= 0.032, g_loss 3.579, d_loss 0.086\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 225/390 d_loss_real= 0.115, d_loss_fake= 0.054, g_loss 3.308, d_loss 0.084\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 226/390 d_loss_real= 0.000, d_loss_fake= 0.045, g_loss 3.364, d_loss 0.022\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 227/390 d_loss_real= 0.196, d_loss_fake= 0.034, g_loss 3.690, d_loss 0.115\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 46 Batch 228/390 d_loss_real= 0.007, d_loss_fake= 0.029, g_loss 3.763, d_loss 0.018\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 229/390 d_loss_real= 0.234, d_loss_fake= 0.026, g_loss 3.842, d_loss 0.130\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 46 Batch 230/390 d_loss_real= 0.106, d_loss_fake= 0.023, g_loss 3.843, d_loss 0.065\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 231/390 d_loss_real= 0.077, d_loss_fake= 0.023, g_loss 3.856, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 232/390 d_loss_real= 0.125, d_loss_fake= 0.022, g_loss 3.872, d_loss 0.074\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 233/390 d_loss_real= 0.097, d_loss_fake= 0.024, g_loss 3.854, d_loss 0.061\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 46 Batch 234/390 d_loss_real= 0.177, d_loss_fake= 0.024, g_loss 3.824, d_loss 0.101\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 46 Batch 235/390 d_loss_real= 0.063, d_loss_fake= 0.025, g_loss 3.759, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 236/390 d_loss_real= 0.228, d_loss_fake= 0.027, g_loss 3.609, d_loss 0.128\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 237/390 d_loss_real= 0.162, d_loss_fake= 0.034, g_loss 3.488, d_loss 0.098\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 238/390 d_loss_real= 0.057, d_loss_fake= 0.036, g_loss 3.430, d_loss 0.046\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 239/390 d_loss_real= 0.110, d_loss_fake= 0.039, g_loss 3.359, d_loss 0.075\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 46 Batch 240/390 d_loss_real= 0.234, d_loss_fake= 0.038, g_loss 3.465, d_loss 0.136\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 241/390 d_loss_real= 0.133, d_loss_fake= 0.034, g_loss 3.574, d_loss 0.083\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 242/390 d_loss_real= 0.113, d_loss_fake= 0.030, g_loss 3.569, d_loss 0.071\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 243/390 d_loss_real= 0.155, d_loss_fake= 0.032, g_loss 3.614, d_loss 0.094\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 244/390 d_loss_real= 0.283, d_loss_fake= 0.034, g_loss 3.549, d_loss 0.158\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 46 Batch 245/390 d_loss_real= 0.187, d_loss_fake= 0.030, g_loss 3.558, d_loss 0.109\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 246/390 d_loss_real= 0.164, d_loss_fake= 0.033, g_loss 3.514, d_loss 0.099\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 46 Batch 247/390 d_loss_real= 0.070, d_loss_fake= 0.028, g_loss 3.642, d_loss 0.049\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 46 Batch 248/390 d_loss_real= 0.013, d_loss_fake= 0.033, g_loss 3.588, d_loss 0.023\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 249/390 d_loss_real= 0.206, d_loss_fake= 0.034, g_loss 3.583, d_loss 0.120\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 46 Batch 250/390 d_loss_real= 0.085, d_loss_fake= 0.032, g_loss 3.578, d_loss 0.058\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 251/390 d_loss_real= 0.096, d_loss_fake= 0.032, g_loss 3.591, d_loss 0.064\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 46 Batch 252/390 d_loss_real= 0.116, d_loss_fake= 0.030, g_loss 3.681, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 253/390 d_loss_real= 0.108, d_loss_fake= 0.030, g_loss 3.682, d_loss 0.069\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 254/390 d_loss_real= 0.233, d_loss_fake= 0.031, g_loss 3.608, d_loss 0.132\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 255/390 d_loss_real= 0.069, d_loss_fake= 0.030, g_loss 3.519, d_loss 0.050\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 256/390 d_loss_real= 0.124, d_loss_fake= 0.036, g_loss 3.466, d_loss 0.080\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 257/390 d_loss_real= 0.048, d_loss_fake= 0.036, g_loss 3.528, d_loss 0.042\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 258/390 d_loss_real= 0.088, d_loss_fake= 0.033, g_loss 3.474, d_loss 0.061\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 259/390 d_loss_real= 0.005, d_loss_fake= 0.033, g_loss 3.565, d_loss 0.019\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 260/390 d_loss_real= 0.026, d_loss_fake= 0.033, g_loss 3.658, d_loss 0.029\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 261/390 d_loss_real= 0.038, d_loss_fake= 0.028, g_loss 3.737, d_loss 0.033\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 262/390 d_loss_real= 0.150, d_loss_fake= 0.028, g_loss 3.818, d_loss 0.089\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 263/390 d_loss_real= 0.049, d_loss_fake= 0.022, g_loss 3.980, d_loss 0.036\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 46 Batch 264/390 d_loss_real= 0.130, d_loss_fake= 0.020, g_loss 3.989, d_loss 0.075\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 265/390 d_loss_real= 0.129, d_loss_fake= 0.021, g_loss 3.891, d_loss 0.075\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 266/390 d_loss_real= 0.051, d_loss_fake= 0.025, g_loss 3.863, d_loss 0.038\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 267/390 d_loss_real= 0.079, d_loss_fake= 0.024, g_loss 3.820, d_loss 0.051\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 46 Batch 268/390 d_loss_real= 0.152, d_loss_fake= 0.027, g_loss 3.777, d_loss 0.090\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 269/390 d_loss_real= 0.143, d_loss_fake= 0.033, g_loss 3.623, d_loss 0.088\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 46 Batch 270/390 d_loss_real= 0.000, d_loss_fake= 0.032, g_loss 3.678, d_loss 0.016\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 271/390 d_loss_real= 0.115, d_loss_fake= 0.023, g_loss 3.834, d_loss 0.069\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 272/390 d_loss_real= 0.128, d_loss_fake= 0.028, g_loss 3.715, d_loss 0.078\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 273/390 d_loss_real= 0.060, d_loss_fake= 0.032, g_loss 3.716, d_loss 0.046\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 274/390 d_loss_real= 0.128, d_loss_fake= 0.029, g_loss 3.751, d_loss 0.078\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 275/390 d_loss_real= 0.056, d_loss_fake= 0.027, g_loss 3.799, d_loss 0.042\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 46 Batch 276/390 d_loss_real= 0.065, d_loss_fake= 0.024, g_loss 3.868, d_loss 0.044\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 46 Batch 277/390 d_loss_real= 0.086, d_loss_fake= 0.022, g_loss 3.945, d_loss 0.054\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 46 Batch 278/390 d_loss_real= 0.170, d_loss_fake= 0.021, g_loss 3.890, d_loss 0.095\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 46 Batch 279/390 d_loss_real= 0.092, d_loss_fake= 0.022, g_loss 3.893, d_loss 0.057\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 46 Batch 280/390 d_loss_real= 0.057, d_loss_fake= 0.023, g_loss 3.888, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 281/390 d_loss_real= 0.176, d_loss_fake= 0.023, g_loss 3.809, d_loss 0.100\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 46 Batch 282/390 d_loss_real= 0.000, d_loss_fake= 0.027, g_loss 3.734, d_loss 0.013\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 283/390 d_loss_real= 0.150, d_loss_fake= 0.027, g_loss 3.628, d_loss 0.088\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 284/390 d_loss_real= 0.055, d_loss_fake= 0.028, g_loss 3.646, d_loss 0.041\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 285/390 d_loss_real= 0.145, d_loss_fake= 0.036, g_loss 3.373, d_loss 0.090\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 286/390 d_loss_real= 0.052, d_loss_fake= 0.027, g_loss 3.666, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 287/390 d_loss_real= 0.061, d_loss_fake= 0.036, g_loss 3.483, d_loss 0.049\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 288/390 d_loss_real= 0.314, d_loss_fake= 0.030, g_loss 3.648, d_loss 0.172\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 289/390 d_loss_real= 0.239, d_loss_fake= 0.042, g_loss 3.548, d_loss 0.140\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 46 Batch 290/390 d_loss_real= 0.233, d_loss_fake= 0.035, g_loss 3.588, d_loss 0.134\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 291/390 d_loss_real= 0.051, d_loss_fake= 0.030, g_loss 3.704, d_loss 0.040\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 292/390 d_loss_real= 0.182, d_loss_fake= 0.027, g_loss 3.764, d_loss 0.105\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 46 Batch 293/390 d_loss_real= 0.000, d_loss_fake= 0.024, g_loss 3.820, d_loss 0.012\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 294/390 d_loss_real= 0.027, d_loss_fake= 0.026, g_loss 3.875, d_loss 0.026\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 46 Batch 295/390 d_loss_real= 0.250, d_loss_fake= 0.028, g_loss 3.764, d_loss 0.139\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 46 Batch 296/390 d_loss_real= 0.037, d_loss_fake= 0.028, g_loss 3.627, d_loss 0.032\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 297/390 d_loss_real= 0.082, d_loss_fake= 0.032, g_loss 3.630, d_loss 0.057\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 46 Batch 298/390 d_loss_real= 0.089, d_loss_fake= 0.032, g_loss 3.409, d_loss 0.060\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 299/390 d_loss_real= 0.022, d_loss_fake= 0.032, g_loss 3.450, d_loss 0.027\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 300/390 d_loss_real= 0.054, d_loss_fake= 0.040, g_loss 3.406, d_loss 0.047\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 46 Batch 301/390 d_loss_real= 0.071, d_loss_fake= 0.036, g_loss 3.443, d_loss 0.054\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 302/390 d_loss_real= 0.130, d_loss_fake= 0.037, g_loss 3.437, d_loss 0.084\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 303/390 d_loss_real= 0.213, d_loss_fake= 0.041, g_loss 3.242, d_loss 0.127\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 304/390 d_loss_real= 0.072, d_loss_fake= 0.048, g_loss 3.127, d_loss 0.060\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 305/390 d_loss_real= 0.100, d_loss_fake= 0.056, g_loss 3.159, d_loss 0.078\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 46 Batch 306/390 d_loss_real= 0.186, d_loss_fake= 0.053, g_loss 3.220, d_loss 0.119\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 46 Batch 307/390 d_loss_real= 0.046, d_loss_fake= 0.044, g_loss 3.303, d_loss 0.045\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 46 Batch 308/390 d_loss_real= 0.054, d_loss_fake= 0.033, g_loss 3.619, d_loss 0.044\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 46 Batch 309/390 d_loss_real= 0.190, d_loss_fake= 0.028, g_loss 3.709, d_loss 0.109\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 310/390 d_loss_real= 0.000, d_loss_fake= 0.031, g_loss 3.855, d_loss 0.016\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 311/390 d_loss_real= 0.027, d_loss_fake= 0.025, g_loss 3.838, d_loss 0.026\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 312/390 d_loss_real= 0.136, d_loss_fake= 0.029, g_loss 3.781, d_loss 0.082\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 46 Batch 313/390 d_loss_real= 0.133, d_loss_fake= 0.030, g_loss 3.803, d_loss 0.082\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 46 Batch 314/390 d_loss_real= 0.147, d_loss_fake= 0.032, g_loss 3.594, d_loss 0.090\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 46 Batch 315/390 d_loss_real= 0.084, d_loss_fake= 0.039, g_loss 3.397, d_loss 0.061\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 316/390 d_loss_real= 0.091, d_loss_fake= 0.041, g_loss 3.358, d_loss 0.066\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 317/390 d_loss_real= 0.000, d_loss_fake= 0.051, g_loss 3.190, d_loss 0.025\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 318/390 d_loss_real= 0.077, d_loss_fake= 0.041, g_loss 3.107, d_loss 0.059\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 319/390 d_loss_real= 0.169, d_loss_fake= 0.058, g_loss 3.020, d_loss 0.114\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 46 Batch 320/390 d_loss_real= 0.052, d_loss_fake= 0.057, g_loss 3.134, d_loss 0.054\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 46 Batch 321/390 d_loss_real= 0.058, d_loss_fake= 0.042, g_loss 3.324, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 322/390 d_loss_real= 0.000, d_loss_fake= 0.037, g_loss 3.491, d_loss 0.019\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 323/390 d_loss_real= 0.064, d_loss_fake= 0.030, g_loss 3.731, d_loss 0.047\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 324/390 d_loss_real= 0.000, d_loss_fake= 0.024, g_loss 3.966, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 325/390 d_loss_real= 0.085, d_loss_fake= 0.019, g_loss 4.087, d_loss 0.052\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 326/390 d_loss_real= 0.126, d_loss_fake= 0.019, g_loss 4.117, d_loss 0.073\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 327/390 d_loss_real= 0.063, d_loss_fake= 0.019, g_loss 4.092, d_loss 0.041\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 46 Batch 328/390 d_loss_real= 0.055, d_loss_fake= 0.019, g_loss 4.087, d_loss 0.037\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 329/390 d_loss_real= 0.145, d_loss_fake= 0.022, g_loss 3.806, d_loss 0.084\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 330/390 d_loss_real= 0.122, d_loss_fake= 0.031, g_loss 3.636, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 331/390 d_loss_real= 0.001, d_loss_fake= 0.042, g_loss 3.476, d_loss 0.022\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 46 Batch 332/390 d_loss_real= 0.011, d_loss_fake= 0.045, g_loss 3.554, d_loss 0.028\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 333/390 d_loss_real= 0.193, d_loss_fake= 0.041, g_loss 3.864, d_loss 0.117\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 334/390 d_loss_real= 0.128, d_loss_fake= 0.024, g_loss 4.054, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 335/390 d_loss_real= 0.001, d_loss_fake= 0.018, g_loss 4.250, d_loss 0.009\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 46 Batch 336/390 d_loss_real= 0.096, d_loss_fake= 0.014, g_loss 4.348, d_loss 0.055\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 46 Batch 337/390 d_loss_real= 0.210, d_loss_fake= 0.013, g_loss 4.373, d_loss 0.112\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 338/390 d_loss_real= 0.049, d_loss_fake= 0.014, g_loss 4.333, d_loss 0.031\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 339/390 d_loss_real= 0.139, d_loss_fake= 0.014, g_loss 4.305, d_loss 0.077\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 46 Batch 340/390 d_loss_real= 0.188, d_loss_fake= 0.015, g_loss 4.207, d_loss 0.101\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 46 Batch 341/390 d_loss_real= 0.098, d_loss_fake= 0.017, g_loss 4.030, d_loss 0.057\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 342/390 d_loss_real= 0.042, d_loss_fake= 0.021, g_loss 3.823, d_loss 0.031\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 343/390 d_loss_real= 0.054, d_loss_fake= 0.024, g_loss 3.614, d_loss 0.039\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 46 Batch 344/390 d_loss_real= 0.132, d_loss_fake= 0.039, g_loss 3.401, d_loss 0.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 345/390 d_loss_real= 0.121, d_loss_fake= 0.049, g_loss 3.228, d_loss 0.085\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 46 Batch 346/390 d_loss_real= 0.064, d_loss_fake= 0.048, g_loss 3.374, d_loss 0.056\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 46 Batch 347/390 d_loss_real= 0.000, d_loss_fake= 0.039, g_loss 3.661, d_loss 0.020\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 46 Batch 348/390 d_loss_real= 0.136, d_loss_fake= 0.027, g_loss 3.920, d_loss 0.081\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 349/390 d_loss_real= 0.129, d_loss_fake= 0.020, g_loss 3.964, d_loss 0.075\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 350/390 d_loss_real= 0.158, d_loss_fake= 0.019, g_loss 3.969, d_loss 0.089\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 46 Batch 351/390 d_loss_real= 0.161, d_loss_fake= 0.021, g_loss 3.888, d_loss 0.091\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 46 Batch 352/390 d_loss_real= 0.110, d_loss_fake= 0.024, g_loss 3.832, d_loss 0.067\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 46 Batch 353/390 d_loss_real= 0.059, d_loss_fake= 0.027, g_loss 3.771, d_loss 0.043\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 46 Batch 354/390 d_loss_real= 0.150, d_loss_fake= 0.026, g_loss 3.697, d_loss 0.088\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 46 Batch 355/390 d_loss_real= 0.072, d_loss_fake= 0.028, g_loss 3.652, d_loss 0.050\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 46 Batch 356/390 d_loss_real= 0.012, d_loss_fake= 0.029, g_loss 3.626, d_loss 0.021\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 46 Batch 357/390 d_loss_real= 0.150, d_loss_fake= 0.033, g_loss 3.651, d_loss 0.091\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 358/390 d_loss_real= 0.095, d_loss_fake= 0.029, g_loss 3.661, d_loss 0.062\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 359/390 d_loss_real= 0.197, d_loss_fake= 0.029, g_loss 3.664, d_loss 0.113\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 360/390 d_loss_real= 0.168, d_loss_fake= 0.027, g_loss 3.668, d_loss 0.097\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 46 Batch 361/390 d_loss_real= 0.177, d_loss_fake= 0.031, g_loss 3.513, d_loss 0.104\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 362/390 d_loss_real= 0.043, d_loss_fake= 0.036, g_loss 3.407, d_loss 0.040\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 363/390 d_loss_real= 0.000, d_loss_fake= 0.037, g_loss 3.363, d_loss 0.019\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 46 Batch 364/390 d_loss_real= 0.070, d_loss_fake= 0.037, g_loss 3.519, d_loss 0.053\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 365/390 d_loss_real= 0.017, d_loss_fake= 0.031, g_loss 3.638, d_loss 0.024\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 366/390 d_loss_real= 0.058, d_loss_fake= 0.028, g_loss 3.771, d_loss 0.043\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 46 Batch 367/390 d_loss_real= 0.062, d_loss_fake= 0.024, g_loss 3.836, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 368/390 d_loss_real= 0.200, d_loss_fake= 0.020, g_loss 4.006, d_loss 0.110\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 369/390 d_loss_real= 0.139, d_loss_fake= 0.019, g_loss 4.023, d_loss 0.079\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 370/390 d_loss_real= 0.001, d_loss_fake= 0.018, g_loss 4.108, d_loss 0.009\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 371/390 d_loss_real= 0.110, d_loss_fake= 0.018, g_loss 4.121, d_loss 0.064\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 372/390 d_loss_real= 0.000, d_loss_fake= 0.018, g_loss 4.133, d_loss 0.009\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 373/390 d_loss_real= 0.005, d_loss_fake= 0.017, g_loss 4.142, d_loss 0.011\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 374/390 d_loss_real= 0.232, d_loss_fake= 0.017, g_loss 4.097, d_loss 0.125\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 375/390 d_loss_real= 0.005, d_loss_fake= 0.018, g_loss 4.037, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 376/390 d_loss_real= 0.084, d_loss_fake= 0.019, g_loss 3.991, d_loss 0.051\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 377/390 d_loss_real= 0.035, d_loss_fake= 0.020, g_loss 3.921, d_loss 0.028\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 378/390 d_loss_real= 0.134, d_loss_fake= 0.022, g_loss 3.826, d_loss 0.078\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 46 Batch 379/390 d_loss_real= 0.138, d_loss_fake= 0.023, g_loss 3.778, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 380/390 d_loss_real= 0.054, d_loss_fake= 0.026, g_loss 3.709, d_loss 0.040\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 381/390 d_loss_real= 0.000, d_loss_fake= 0.026, g_loss 3.720, d_loss 0.013\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 46 Batch 382/390 d_loss_real= 0.072, d_loss_fake= 0.025, g_loss 3.675, d_loss 0.048\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 46 Batch 383/390 d_loss_real= 0.057, d_loss_fake= 0.027, g_loss 3.658, d_loss 0.042\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 46 Batch 384/390 d_loss_real= 0.069, d_loss_fake= 0.026, g_loss 3.715, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 385/390 d_loss_real= 0.069, d_loss_fake= 0.026, g_loss 3.741, d_loss 0.047\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46 Batch 386/390 d_loss_real= 0.071, d_loss_fake= 0.025, g_loss 3.808, d_loss 0.048\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46 Batch 387/390 d_loss_real= 0.120, d_loss_fake= 0.024, g_loss 3.721, d_loss 0.072\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 46 Batch 388/390 d_loss_real= 0.005, d_loss_fake= 0.025, g_loss 3.702, d_loss 0.015\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46 Batch 389/390 d_loss_real= 0.118, d_loss_fake= 0.030, g_loss 3.656, d_loss 0.074\n",
            "2/2 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46 Batch 390/390 d_loss_real= 0.017, d_loss_fake= 0.028, g_loss 3.641, d_loss 0.022\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 1/390 d_loss_real= 0.211, d_loss_fake= 0.030, g_loss 3.597, d_loss 0.121\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 2/390 d_loss_real= 0.133, d_loss_fake= 0.030, g_loss 3.615, d_loss 0.082\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 3/390 d_loss_real= 0.261, d_loss_fake= 0.036, g_loss 3.425, d_loss 0.149\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 4/390 d_loss_real= 0.144, d_loss_fake= 0.037, g_loss 3.489, d_loss 0.090\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 47 Batch 5/390 d_loss_real= 0.128, d_loss_fake= 0.045, g_loss 3.548, d_loss 0.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 6/390 d_loss_real= 0.061, d_loss_fake= 0.030, g_loss 3.712, d_loss 0.046\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 7/390 d_loss_real= 0.082, d_loss_fake= 0.027, g_loss 3.860, d_loss 0.055\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 8/390 d_loss_real= 0.171, d_loss_fake= 0.021, g_loss 3.946, d_loss 0.096\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 9/390 d_loss_real= 0.086, d_loss_fake= 0.022, g_loss 3.940, d_loss 0.054\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 47 Batch 10/390 d_loss_real= 0.059, d_loss_fake= 0.020, g_loss 4.001, d_loss 0.039\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 11/390 d_loss_real= 0.044, d_loss_fake= 0.019, g_loss 4.022, d_loss 0.031\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 12/390 d_loss_real= 0.012, d_loss_fake= 0.019, g_loss 4.028, d_loss 0.015\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 13/390 d_loss_real= 0.208, d_loss_fake= 0.020, g_loss 4.002, d_loss 0.114\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 14/390 d_loss_real= 0.000, d_loss_fake= 0.019, g_loss 4.025, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 15/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 4.088, d_loss 0.010\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 16/390 d_loss_real= 0.192, d_loss_fake= 0.018, g_loss 4.008, d_loss 0.105\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 17/390 d_loss_real= 0.021, d_loss_fake= 0.020, g_loss 3.920, d_loss 0.020\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 47 Batch 18/390 d_loss_real= 0.060, d_loss_fake= 0.020, g_loss 3.890, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 19/390 d_loss_real= 0.025, d_loss_fake= 0.023, g_loss 3.802, d_loss 0.024\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 20/390 d_loss_real= 0.000, d_loss_fake= 0.024, g_loss 3.817, d_loss 0.012\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 47 Batch 21/390 d_loss_real= 0.069, d_loss_fake= 0.024, g_loss 3.780, d_loss 0.046\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 47 Batch 22/390 d_loss_real= 0.101, d_loss_fake= 0.026, g_loss 3.722, d_loss 0.064\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 23/390 d_loss_real= 0.096, d_loss_fake= 0.024, g_loss 3.794, d_loss 0.060\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 24/390 d_loss_real= 0.229, d_loss_fake= 0.024, g_loss 3.810, d_loss 0.127\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 47 Batch 25/390 d_loss_real= 0.128, d_loss_fake= 0.031, g_loss 3.598, d_loss 0.079\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 47 Batch 26/390 d_loss_real= 0.037, d_loss_fake= 0.032, g_loss 3.544, d_loss 0.034\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 27/390 d_loss_real= 0.001, d_loss_fake= 0.042, g_loss 3.607, d_loss 0.022\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 28/390 d_loss_real= 0.000, d_loss_fake= 0.026, g_loss 3.802, d_loss 0.013\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 29/390 d_loss_real= 0.032, d_loss_fake= 0.023, g_loss 3.899, d_loss 0.027\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 47 Batch 30/390 d_loss_real= 0.135, d_loss_fake= 0.021, g_loss 3.956, d_loss 0.078\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 31/390 d_loss_real= 0.003, d_loss_fake= 0.019, g_loss 3.971, d_loss 0.011\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 32/390 d_loss_real= 0.157, d_loss_fake= 0.020, g_loss 4.017, d_loss 0.088\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 47 Batch 33/390 d_loss_real= 0.058, d_loss_fake= 0.019, g_loss 4.008, d_loss 0.039\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 34/390 d_loss_real= 0.154, d_loss_fake= 0.022, g_loss 3.826, d_loss 0.088\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 35/390 d_loss_real= 0.079, d_loss_fake= 0.026, g_loss 3.651, d_loss 0.052\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 47 Batch 36/390 d_loss_real= 0.114, d_loss_fake= 0.029, g_loss 3.575, d_loss 0.071\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 37/390 d_loss_real= 0.071, d_loss_fake= 0.033, g_loss 3.688, d_loss 0.052\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 47 Batch 38/390 d_loss_real= 0.047, d_loss_fake= 0.029, g_loss 3.640, d_loss 0.038\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 39/390 d_loss_real= 0.010, d_loss_fake= 0.032, g_loss 3.600, d_loss 0.021\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 40/390 d_loss_real= 0.024, d_loss_fake= 0.028, g_loss 3.688, d_loss 0.026\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 41/390 d_loss_real= 0.119, d_loss_fake= 0.028, g_loss 3.659, d_loss 0.074\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 42/390 d_loss_real= 0.121, d_loss_fake= 0.028, g_loss 3.712, d_loss 0.074\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 43/390 d_loss_real= 0.108, d_loss_fake= 0.026, g_loss 3.696, d_loss 0.067\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 44/390 d_loss_real= 0.021, d_loss_fake= 0.030, g_loss 3.664, d_loss 0.026\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 47 Batch 45/390 d_loss_real= 0.011, d_loss_fake= 0.027, g_loss 3.736, d_loss 0.019\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 46/390 d_loss_real= 0.121, d_loss_fake= 0.026, g_loss 3.724, d_loss 0.073\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 47/390 d_loss_real= 0.002, d_loss_fake= 0.026, g_loss 3.775, d_loss 0.014\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 48/390 d_loss_real= 0.251, d_loss_fake= 0.026, g_loss 3.738, d_loss 0.138\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 47 Batch 49/390 d_loss_real= 0.022, d_loss_fake= 0.025, g_loss 3.726, d_loss 0.024\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 50/390 d_loss_real= 0.121, d_loss_fake= 0.028, g_loss 3.715, d_loss 0.074\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 47 Batch 51/390 d_loss_real= 0.070, d_loss_fake= 0.027, g_loss 3.766, d_loss 0.049\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 52/390 d_loss_real= 0.051, d_loss_fake= 0.025, g_loss 3.702, d_loss 0.038\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 53/390 d_loss_real= 0.084, d_loss_fake= 0.026, g_loss 3.740, d_loss 0.055\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 47 Batch 54/390 d_loss_real= 0.170, d_loss_fake= 0.029, g_loss 3.581, d_loss 0.099\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 55/390 d_loss_real= 0.055, d_loss_fake= 0.031, g_loss 3.648, d_loss 0.043\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 47 Batch 56/390 d_loss_real= 0.069, d_loss_fake= 0.029, g_loss 3.654, d_loss 0.049\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 47 Batch 57/390 d_loss_real= 0.172, d_loss_fake= 0.033, g_loss 3.639, d_loss 0.102\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 58/390 d_loss_real= 0.259, d_loss_fake= 0.033, g_loss 3.536, d_loss 0.146\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 47 Batch 59/390 d_loss_real= 0.070, d_loss_fake= 0.037, g_loss 3.493, d_loss 0.054\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 47 Batch 60/390 d_loss_real= 0.052, d_loss_fake= 0.031, g_loss 3.643, d_loss 0.041\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 61/390 d_loss_real= 0.100, d_loss_fake= 0.033, g_loss 3.588, d_loss 0.067\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 62/390 d_loss_real= 0.016, d_loss_fake= 0.030, g_loss 3.597, d_loss 0.023\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 63/390 d_loss_real= 0.147, d_loss_fake= 0.035, g_loss 3.497, d_loss 0.091\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 47 Batch 64/390 d_loss_real= 0.246, d_loss_fake= 0.037, g_loss 3.562, d_loss 0.142\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 47 Batch 65/390 d_loss_real= 0.133, d_loss_fake= 0.040, g_loss 3.623, d_loss 0.086\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 47 Batch 66/390 d_loss_real= 0.000, d_loss_fake= 0.036, g_loss 3.630, d_loss 0.018\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 47 Batch 67/390 d_loss_real= 0.252, d_loss_fake= 0.028, g_loss 3.758, d_loss 0.140\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 68/390 d_loss_real= 0.212, d_loss_fake= 0.025, g_loss 3.895, d_loss 0.119\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 47 Batch 69/390 d_loss_real= 0.147, d_loss_fake= 0.023, g_loss 3.847, d_loss 0.085\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 47 Batch 70/390 d_loss_real= 0.003, d_loss_fake= 0.024, g_loss 3.801, d_loss 0.013\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 47 Batch 71/390 d_loss_real= 0.061, d_loss_fake= 0.026, g_loss 3.771, d_loss 0.044\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 72/390 d_loss_real= 0.162, d_loss_fake= 0.027, g_loss 3.733, d_loss 0.094\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 73/390 d_loss_real= 0.131, d_loss_fake= 0.030, g_loss 3.595, d_loss 0.080\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 47 Batch 74/390 d_loss_real= 0.155, d_loss_fake= 0.036, g_loss 3.245, d_loss 0.096\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 75/390 d_loss_real= 0.086, d_loss_fake= 0.092, g_loss 3.210, d_loss 0.089\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 47 Batch 76/390 d_loss_real= 0.045, d_loss_fake= 0.037, g_loss 3.538, d_loss 0.041\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 47 Batch 77/390 d_loss_real= 0.109, d_loss_fake= 0.032, g_loss 3.647, d_loss 0.071\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 78/390 d_loss_real= 0.056, d_loss_fake= 0.029, g_loss 3.665, d_loss 0.042\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 47 Batch 79/390 d_loss_real= 0.161, d_loss_fake= 0.030, g_loss 3.583, d_loss 0.096\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 80/390 d_loss_real= 0.121, d_loss_fake= 0.030, g_loss 3.614, d_loss 0.075\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 47 Batch 81/390 d_loss_real= 0.057, d_loss_fake= 0.030, g_loss 3.662, d_loss 0.043\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 47 Batch 82/390 d_loss_real= 0.105, d_loss_fake= 0.029, g_loss 3.671, d_loss 0.067\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 47 Batch 83/390 d_loss_real= 0.109, d_loss_fake= 0.027, g_loss 3.703, d_loss 0.068\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 47 Batch 84/390 d_loss_real= 0.003, d_loss_fake= 0.027, g_loss 3.740, d_loss 0.015\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 85/390 d_loss_real= 0.243, d_loss_fake= 0.029, g_loss 3.566, d_loss 0.136\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 47 Batch 86/390 d_loss_real= 0.029, d_loss_fake= 0.034, g_loss 3.427, d_loss 0.031\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 47 Batch 87/390 d_loss_real= 0.047, d_loss_fake= 0.034, g_loss 3.433, d_loss 0.040\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 47 Batch 88/390 d_loss_real= 0.027, d_loss_fake= 0.035, g_loss 3.421, d_loss 0.031\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 47 Batch 89/390 d_loss_real= 0.055, d_loss_fake= 0.039, g_loss 3.557, d_loss 0.047\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 47 Batch 90/390 d_loss_real= 0.109, d_loss_fake= 0.039, g_loss 3.547, d_loss 0.074\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 91/390 d_loss_real= 0.071, d_loss_fake= 0.032, g_loss 3.620, d_loss 0.051\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 92/390 d_loss_real= 0.050, d_loss_fake= 0.028, g_loss 3.768, d_loss 0.039\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 93/390 d_loss_real= 0.240, d_loss_fake= 0.025, g_loss 3.862, d_loss 0.132\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 47 Batch 94/390 d_loss_real= 0.167, d_loss_fake= 0.025, g_loss 3.732, d_loss 0.096\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 47 Batch 95/390 d_loss_real= 0.109, d_loss_fake= 0.028, g_loss 3.594, d_loss 0.068\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 47 Batch 96/390 d_loss_real= 0.001, d_loss_fake= 0.030, g_loss 3.505, d_loss 0.015\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 47 Batch 97/390 d_loss_real= 0.113, d_loss_fake= 0.032, g_loss 3.509, d_loss 0.072\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 98/390 d_loss_real= 0.062, d_loss_fake= 0.035, g_loss 3.453, d_loss 0.048\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 47 Batch 99/390 d_loss_real= 0.032, d_loss_fake= 0.040, g_loss 3.358, d_loss 0.036\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 100/390 d_loss_real= 0.140, d_loss_fake= 0.045, g_loss 3.396, d_loss 0.092\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 101/390 d_loss_real= 0.000, d_loss_fake= 0.037, g_loss 3.498, d_loss 0.019\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 102/390 d_loss_real= 0.213, d_loss_fake= 0.029, g_loss 3.580, d_loss 0.121\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 47 Batch 103/390 d_loss_real= 0.213, d_loss_fake= 0.031, g_loss 3.574, d_loss 0.122\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 104/390 d_loss_real= 0.000, d_loss_fake= 0.030, g_loss 3.695, d_loss 0.015\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 105/390 d_loss_real= 0.018, d_loss_fake= 0.027, g_loss 3.811, d_loss 0.023\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 47 Batch 106/390 d_loss_real= 0.056, d_loss_fake= 0.029, g_loss 3.670, d_loss 0.043\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 107/390 d_loss_real= 0.021, d_loss_fake= 0.028, g_loss 3.685, d_loss 0.025\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 47 Batch 108/390 d_loss_real= 0.006, d_loss_fake= 0.028, g_loss 3.618, d_loss 0.017\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 109/390 d_loss_real= 0.104, d_loss_fake= 0.029, g_loss 3.583, d_loss 0.066\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 110/390 d_loss_real= 0.003, d_loss_fake= 0.029, g_loss 3.630, d_loss 0.016\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 111/390 d_loss_real= 0.115, d_loss_fake= 0.028, g_loss 3.632, d_loss 0.071\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 47 Batch 112/390 d_loss_real= 0.141, d_loss_fake= 0.030, g_loss 3.607, d_loss 0.086\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 47 Batch 113/390 d_loss_real= 0.049, d_loss_fake= 0.031, g_loss 3.596, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 114/390 d_loss_real= 0.000, d_loss_fake= 0.035, g_loss 3.536, d_loss 0.017\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 47 Batch 115/390 d_loss_real= 0.000, d_loss_fake= 0.032, g_loss 3.571, d_loss 0.016\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 47 Batch 116/390 d_loss_real= 0.124, d_loss_fake= 0.032, g_loss 3.579, d_loss 0.078\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 117/390 d_loss_real= 0.153, d_loss_fake= 0.032, g_loss 3.512, d_loss 0.093\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 118/390 d_loss_real= 0.000, d_loss_fake= 0.035, g_loss 3.574, d_loss 0.017\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 119/390 d_loss_real= 0.131, d_loss_fake= 0.032, g_loss 3.704, d_loss 0.081\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 47 Batch 120/390 d_loss_real= 0.000, d_loss_fake= 0.030, g_loss 3.724, d_loss 0.015\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 47 Batch 121/390 d_loss_real= 0.067, d_loss_fake= 0.025, g_loss 3.802, d_loss 0.046\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 47 Batch 122/390 d_loss_real= 0.129, d_loss_fake= 0.025, g_loss 3.816, d_loss 0.077\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 123/390 d_loss_real= 0.051, d_loss_fake= 0.026, g_loss 3.893, d_loss 0.038\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 47 Batch 124/390 d_loss_real= 0.168, d_loss_fake= 0.026, g_loss 3.750, d_loss 0.097\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 47 Batch 125/390 d_loss_real= 0.074, d_loss_fake= 0.029, g_loss 3.627, d_loss 0.052\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 47 Batch 126/390 d_loss_real= 0.133, d_loss_fake= 0.027, g_loss 3.591, d_loss 0.080\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 47 Batch 127/390 d_loss_real= 0.020, d_loss_fake= 0.033, g_loss 3.528, d_loss 0.026\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 128/390 d_loss_real= 0.109, d_loss_fake= 0.028, g_loss 3.712, d_loss 0.069\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 129/390 d_loss_real= 0.132, d_loss_fake= 0.036, g_loss 3.450, d_loss 0.084\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 47 Batch 130/390 d_loss_real= 0.233, d_loss_fake= 0.037, g_loss 3.572, d_loss 0.135\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 131/390 d_loss_real= 0.128, d_loss_fake= 0.032, g_loss 3.693, d_loss 0.080\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 132/390 d_loss_real= 0.073, d_loss_fake= 0.024, g_loss 3.800, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 133/390 d_loss_real= 0.071, d_loss_fake= 0.021, g_loss 4.099, d_loss 0.046\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 47 Batch 134/390 d_loss_real= 0.005, d_loss_fake= 0.021, g_loss 4.051, d_loss 0.013\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 135/390 d_loss_real= 0.029, d_loss_fake= 0.019, g_loss 4.034, d_loss 0.024\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 136/390 d_loss_real= 0.028, d_loss_fake= 0.021, g_loss 3.924, d_loss 0.024\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 137/390 d_loss_real= 0.078, d_loss_fake= 0.024, g_loss 3.857, d_loss 0.051\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 138/390 d_loss_real= 0.053, d_loss_fake= 0.024, g_loss 3.849, d_loss 0.039\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 139/390 d_loss_real= 0.218, d_loss_fake= 0.028, g_loss 3.618, d_loss 0.123\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 47 Batch 140/390 d_loss_real= 0.170, d_loss_fake= 0.047, g_loss 3.508, d_loss 0.108\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 141/390 d_loss_real= 0.033, d_loss_fake= 0.043, g_loss 3.626, d_loss 0.038\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 47 Batch 142/390 d_loss_real= 0.001, d_loss_fake= 0.031, g_loss 3.755, d_loss 0.016\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 143/390 d_loss_real= 0.115, d_loss_fake= 0.019, g_loss 4.170, d_loss 0.067\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 144/390 d_loss_real= 0.000, d_loss_fake= 0.017, g_loss 4.336, d_loss 0.008\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 145/390 d_loss_real= 0.057, d_loss_fake= 0.016, g_loss 4.346, d_loss 0.037\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 47 Batch 146/390 d_loss_real= 0.047, d_loss_fake= 0.017, g_loss 4.297, d_loss 0.032\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 47 Batch 147/390 d_loss_real= 0.000, d_loss_fake= 0.015, g_loss 4.259, d_loss 0.008\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 148/390 d_loss_real= 0.051, d_loss_fake= 0.015, g_loss 4.298, d_loss 0.033\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 149/390 d_loss_real= 0.061, d_loss_fake= 0.016, g_loss 4.186, d_loss 0.039\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 150/390 d_loss_real= 0.079, d_loss_fake= 0.016, g_loss 4.142, d_loss 0.048\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 47 Batch 151/390 d_loss_real= 0.001, d_loss_fake= 0.018, g_loss 4.150, d_loss 0.009\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 152/390 d_loss_real= 0.162, d_loss_fake= 0.015, g_loss 4.271, d_loss 0.089\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 47 Batch 153/390 d_loss_real= 0.314, d_loss_fake= 0.018, g_loss 4.021, d_loss 0.166\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 47 Batch 154/390 d_loss_real= 0.053, d_loss_fake= 0.020, g_loss 3.884, d_loss 0.037\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 155/390 d_loss_real= 0.113, d_loss_fake= 0.030, g_loss 3.586, d_loss 0.072\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 156/390 d_loss_real= 0.134, d_loss_fake= 0.031, g_loss 3.541, d_loss 0.083\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 47 Batch 157/390 d_loss_real= 0.065, d_loss_fake= 0.059, g_loss 3.669, d_loss 0.062\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 158/390 d_loss_real= 0.194, d_loss_fake= 0.032, g_loss 3.795, d_loss 0.113\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 159/390 d_loss_real= 0.052, d_loss_fake= 0.022, g_loss 4.140, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 160/390 d_loss_real= 0.078, d_loss_fake= 0.014, g_loss 4.434, d_loss 0.046\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Epoch 47 Batch 161/390 d_loss_real= 0.201, d_loss_fake= 0.017, g_loss 4.167, d_loss 0.109\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 162/390 d_loss_real= 0.227, d_loss_fake= 0.014, g_loss 4.160, d_loss 0.121\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 163/390 d_loss_real= 0.001, d_loss_fake= 0.020, g_loss 4.062, d_loss 0.011\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 47 Batch 164/390 d_loss_real= 0.053, d_loss_fake= 0.020, g_loss 3.997, d_loss 0.036\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 47 Batch 165/390 d_loss_real= 0.260, d_loss_fake= 0.022, g_loss 3.861, d_loss 0.141\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 47 Batch 166/390 d_loss_real= 0.001, d_loss_fake= 0.023, g_loss 3.766, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 167/390 d_loss_real= 0.010, d_loss_fake= 0.029, g_loss 3.746, d_loss 0.020\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 168/390 d_loss_real= 0.052, d_loss_fake= 0.028, g_loss 3.767, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 169/390 d_loss_real= 0.045, d_loss_fake= 0.028, g_loss 3.690, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 170/390 d_loss_real= 0.062, d_loss_fake= 0.032, g_loss 3.630, d_loss 0.047\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 171/390 d_loss_real= 0.121, d_loss_fake= 0.026, g_loss 3.772, d_loss 0.074\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 47 Batch 172/390 d_loss_real= 0.179, d_loss_fake= 0.026, g_loss 3.858, d_loss 0.102\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 173/390 d_loss_real= 0.070, d_loss_fake= 0.020, g_loss 3.973, d_loss 0.045\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 174/390 d_loss_real= 0.065, d_loss_fake= 0.024, g_loss 3.829, d_loss 0.044\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 175/390 d_loss_real= 0.058, d_loss_fake= 0.022, g_loss 3.861, d_loss 0.040\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 47 Batch 176/390 d_loss_real= 0.128, d_loss_fake= 0.027, g_loss 3.721, d_loss 0.077\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 177/390 d_loss_real= 0.057, d_loss_fake= 0.037, g_loss 3.692, d_loss 0.047\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 178/390 d_loss_real= 0.066, d_loss_fake= 0.033, g_loss 3.753, d_loss 0.050\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 47 Batch 179/390 d_loss_real= 0.043, d_loss_fake= 0.033, g_loss 3.829, d_loss 0.038\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 47 Batch 180/390 d_loss_real= 0.042, d_loss_fake= 0.025, g_loss 4.062, d_loss 0.034\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 181/390 d_loss_real= 0.053, d_loss_fake= 0.021, g_loss 4.183, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 182/390 d_loss_real= 0.267, d_loss_fake= 0.019, g_loss 4.205, d_loss 0.143\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 183/390 d_loss_real= 0.096, d_loss_fake= 0.022, g_loss 4.076, d_loss 0.059\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 184/390 d_loss_real= 0.004, d_loss_fake= 0.019, g_loss 4.084, d_loss 0.012\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 47 Batch 185/390 d_loss_real= 0.060, d_loss_fake= 0.023, g_loss 4.145, d_loss 0.041\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 47 Batch 186/390 d_loss_real= 0.219, d_loss_fake= 0.023, g_loss 3.993, d_loss 0.121\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 187/390 d_loss_real= 0.000, d_loss_fake= 0.023, g_loss 3.950, d_loss 0.011\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 188/390 d_loss_real= 0.074, d_loss_fake= 0.025, g_loss 3.943, d_loss 0.049\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 47 Batch 189/390 d_loss_real= 0.013, d_loss_fake= 0.022, g_loss 3.934, d_loss 0.018\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 190/390 d_loss_real= 0.103, d_loss_fake= 0.024, g_loss 3.851, d_loss 0.063\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 191/390 d_loss_real= 0.040, d_loss_fake= 0.025, g_loss 3.800, d_loss 0.033\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 192/390 d_loss_real= 0.182, d_loss_fake= 0.023, g_loss 3.867, d_loss 0.102\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 193/390 d_loss_real= 0.065, d_loss_fake= 0.027, g_loss 3.780, d_loss 0.046\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 47 Batch 194/390 d_loss_real= 0.042, d_loss_fake= 0.031, g_loss 3.788, d_loss 0.036\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 195/390 d_loss_real= 0.009, d_loss_fake= 0.028, g_loss 3.848, d_loss 0.019\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 196/390 d_loss_real= 0.169, d_loss_fake= 0.023, g_loss 3.863, d_loss 0.096\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 197/390 d_loss_real= 0.110, d_loss_fake= 0.021, g_loss 3.828, d_loss 0.065\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 47 Batch 198/390 d_loss_real= 0.022, d_loss_fake= 0.028, g_loss 3.747, d_loss 0.025\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 47 Batch 199/390 d_loss_real= 0.161, d_loss_fake= 0.025, g_loss 3.730, d_loss 0.093\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 200/390 d_loss_real= 0.000, d_loss_fake= 0.034, g_loss 3.784, d_loss 0.017\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 47 Batch 201/390 d_loss_real= 0.064, d_loss_fake= 0.021, g_loss 3.960, d_loss 0.043\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 47 Batch 202/390 d_loss_real= 0.111, d_loss_fake= 0.021, g_loss 4.000, d_loss 0.066\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 203/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 4.020, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 204/390 d_loss_real= 0.046, d_loss_fake= 0.018, g_loss 4.098, d_loss 0.032\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 205/390 d_loss_real= 0.011, d_loss_fake= 0.018, g_loss 4.091, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 206/390 d_loss_real= 0.034, d_loss_fake= 0.018, g_loss 4.079, d_loss 0.026\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 47 Batch 207/390 d_loss_real= 0.093, d_loss_fake= 0.018, g_loss 4.088, d_loss 0.055\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 208/390 d_loss_real= 0.103, d_loss_fake= 0.020, g_loss 3.989, d_loss 0.061\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 47 Batch 209/390 d_loss_real= 0.003, d_loss_fake= 0.020, g_loss 3.942, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 210/390 d_loss_real= 0.196, d_loss_fake= 0.026, g_loss 3.867, d_loss 0.111\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 47 Batch 211/390 d_loss_real= 0.064, d_loss_fake= 0.029, g_loss 3.712, d_loss 0.046\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 47 Batch 212/390 d_loss_real= 0.049, d_loss_fake= 0.031, g_loss 3.818, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 213/390 d_loss_real= 0.061, d_loss_fake= 0.023, g_loss 3.927, d_loss 0.042\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 214/390 d_loss_real= 0.030, d_loss_fake= 0.019, g_loss 4.087, d_loss 0.025\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 215/390 d_loss_real= 0.015, d_loss_fake= 0.023, g_loss 4.026, d_loss 0.019\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 47 Batch 216/390 d_loss_real= 0.013, d_loss_fake= 0.019, g_loss 4.154, d_loss 0.016\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 47 Batch 217/390 d_loss_real= 0.139, d_loss_fake= 0.017, g_loss 4.185, d_loss 0.078\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 218/390 d_loss_real= 0.019, d_loss_fake= 0.018, g_loss 4.124, d_loss 0.019\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 219/390 d_loss_real= 0.119, d_loss_fake= 0.018, g_loss 4.150, d_loss 0.069\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 220/390 d_loss_real= 0.255, d_loss_fake= 0.020, g_loss 4.018, d_loss 0.138\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 221/390 d_loss_real= 0.061, d_loss_fake= 0.022, g_loss 4.009, d_loss 0.041\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 47 Batch 222/390 d_loss_real= 0.037, d_loss_fake= 0.024, g_loss 3.827, d_loss 0.031\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 47 Batch 223/390 d_loss_real= 0.157, d_loss_fake= 0.027, g_loss 3.706, d_loss 0.092\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 47 Batch 224/390 d_loss_real= 0.000, d_loss_fake= 0.032, g_loss 3.838, d_loss 0.016\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 225/390 d_loss_real= 0.014, d_loss_fake= 0.029, g_loss 3.900, d_loss 0.022\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 47 Batch 226/390 d_loss_real= 0.002, d_loss_fake= 0.025, g_loss 3.871, d_loss 0.014\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 47 Batch 227/390 d_loss_real= 0.077, d_loss_fake= 0.025, g_loss 3.849, d_loss 0.051\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 47 Batch 228/390 d_loss_real= 0.037, d_loss_fake= 0.029, g_loss 3.785, d_loss 0.033\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 47 Batch 229/390 d_loss_real= 0.194, d_loss_fake= 0.034, g_loss 3.518, d_loss 0.114\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 230/390 d_loss_real= 0.000, d_loss_fake= 0.044, g_loss 3.599, d_loss 0.022\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 47 Batch 231/390 d_loss_real= 0.000, d_loss_fake= 0.043, g_loss 3.416, d_loss 0.021\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 232/390 d_loss_real= 0.033, d_loss_fake= 0.044, g_loss 3.407, d_loss 0.038\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 233/390 d_loss_real= 0.000, d_loss_fake= 0.038, g_loss 3.485, d_loss 0.019\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 234/390 d_loss_real= 0.001, d_loss_fake= 0.037, g_loss 3.514, d_loss 0.019\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 47 Batch 235/390 d_loss_real= 0.126, d_loss_fake= 0.034, g_loss 3.631, d_loss 0.080\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 236/390 d_loss_real= 0.280, d_loss_fake= 0.032, g_loss 3.584, d_loss 0.156\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 237/390 d_loss_real= 0.034, d_loss_fake= 0.035, g_loss 3.417, d_loss 0.035\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 47 Batch 238/390 d_loss_real= 0.066, d_loss_fake= 0.043, g_loss 3.386, d_loss 0.054\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 47 Batch 239/390 d_loss_real= 0.073, d_loss_fake= 0.069, g_loss 3.312, d_loss 0.071\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 47 Batch 240/390 d_loss_real= 0.000, d_loss_fake= 0.055, g_loss 3.615, d_loss 0.028\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 47 Batch 241/390 d_loss_real= 0.045, d_loss_fake= 0.033, g_loss 4.046, d_loss 0.039\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 47 Batch 242/390 d_loss_real= 0.142, d_loss_fake= 0.017, g_loss 4.386, d_loss 0.079\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 243/390 d_loss_real= 0.078, d_loss_fake= 0.013, g_loss 4.549, d_loss 0.045\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 244/390 d_loss_real= 0.010, d_loss_fake= 0.011, g_loss 4.660, d_loss 0.010\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 47 Batch 245/390 d_loss_real= 0.153, d_loss_fake= 0.010, g_loss 4.718, d_loss 0.081\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 47 Batch 246/390 d_loss_real= 0.070, d_loss_fake= 0.009, g_loss 4.701, d_loss 0.040\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 47 Batch 247/390 d_loss_real= 0.573, d_loss_fake= 0.011, g_loss 4.473, d_loss 0.292\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 248/390 d_loss_real= 0.198, d_loss_fake= 0.014, g_loss 4.205, d_loss 0.106\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 249/390 d_loss_real= 0.100, d_loss_fake= 0.021, g_loss 3.765, d_loss 0.060\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 250/390 d_loss_real= 0.211, d_loss_fake= 0.070, g_loss 3.256, d_loss 0.140\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 251/390 d_loss_real= 0.069, d_loss_fake= 0.297, g_loss 4.077, d_loss 0.183\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 47 Batch 252/390 d_loss_real= 0.154, d_loss_fake= 0.011, g_loss 4.780, d_loss 0.083\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 47 Batch 253/390 d_loss_real= 0.443, d_loss_fake= 0.010, g_loss 4.651, d_loss 0.227\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 47 Batch 254/390 d_loss_real= 0.194, d_loss_fake= 0.012, g_loss 4.447, d_loss 0.103\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 255/390 d_loss_real= 0.188, d_loss_fake= 0.013, g_loss 4.311, d_loss 0.101\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 256/390 d_loss_real= 0.362, d_loss_fake= 0.016, g_loss 4.071, d_loss 0.189\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 257/390 d_loss_real= 0.102, d_loss_fake= 0.020, g_loss 3.881, d_loss 0.061\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 258/390 d_loss_real= 0.118, d_loss_fake= 0.025, g_loss 3.672, d_loss 0.071\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 259/390 d_loss_real= 0.123, d_loss_fake= 0.029, g_loss 3.508, d_loss 0.076\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 47 Batch 260/390 d_loss_real= 0.085, d_loss_fake= 0.036, g_loss 3.362, d_loss 0.061\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 261/390 d_loss_real= 0.062, d_loss_fake= 0.043, g_loss 3.082, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 262/390 d_loss_real= 0.057, d_loss_fake= 0.065, g_loss 2.710, d_loss 0.061\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 47 Batch 263/390 d_loss_real= 0.109, d_loss_fake= 0.194, g_loss 2.542, d_loss 0.151\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 47 Batch 264/390 d_loss_real= 0.032, d_loss_fake= 0.128, g_loss 2.880, d_loss 0.080\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 265/390 d_loss_real= 0.170, d_loss_fake= 0.056, g_loss 3.211, d_loss 0.113\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 47 Batch 266/390 d_loss_real= 0.037, d_loss_fake= 0.037, g_loss 3.474, d_loss 0.037\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 47 Batch 267/390 d_loss_real= 0.090, d_loss_fake= 0.031, g_loss 3.578, d_loss 0.061\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 268/390 d_loss_real= 0.254, d_loss_fake= 0.029, g_loss 3.616, d_loss 0.142\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 47 Batch 269/390 d_loss_real= 0.153, d_loss_fake= 0.030, g_loss 3.613, d_loss 0.091\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 270/390 d_loss_real= 0.134, d_loss_fake= 0.028, g_loss 3.558, d_loss 0.081\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 47 Batch 271/390 d_loss_real= 0.005, d_loss_fake= 0.029, g_loss 3.645, d_loss 0.017\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 272/390 d_loss_real= 0.098, d_loss_fake= 0.030, g_loss 3.572, d_loss 0.064\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 273/390 d_loss_real= 0.199, d_loss_fake= 0.032, g_loss 3.494, d_loss 0.116\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 274/390 d_loss_real= 0.000, d_loss_fake= 0.033, g_loss 3.422, d_loss 0.017\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 47 Batch 275/390 d_loss_real= 0.099, d_loss_fake= 0.040, g_loss 3.314, d_loss 0.070\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 276/390 d_loss_real= 0.123, d_loss_fake= 0.051, g_loss 3.046, d_loss 0.087\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 277/390 d_loss_real= 0.127, d_loss_fake= 0.191, g_loss 3.512, d_loss 0.159\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 278/390 d_loss_real= 0.066, d_loss_fake= 0.022, g_loss 4.086, d_loss 0.044\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 47 Batch 279/390 d_loss_real= 0.072, d_loss_fake= 0.017, g_loss 4.189, d_loss 0.044\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 47 Batch 280/390 d_loss_real= 0.239, d_loss_fake= 0.016, g_loss 4.189, d_loss 0.128\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 47 Batch 281/390 d_loss_real= 0.123, d_loss_fake= 0.016, g_loss 4.216, d_loss 0.069\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 282/390 d_loss_real= 0.235, d_loss_fake= 0.016, g_loss 4.162, d_loss 0.125\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 283/390 d_loss_real= 0.165, d_loss_fake= 0.017, g_loss 4.099, d_loss 0.091\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 47 Batch 284/390 d_loss_real= 0.263, d_loss_fake= 0.019, g_loss 3.929, d_loss 0.141\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 285/390 d_loss_real= 0.195, d_loss_fake= 0.022, g_loss 3.825, d_loss 0.109\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 286/390 d_loss_real= 0.045, d_loss_fake= 0.023, g_loss 3.699, d_loss 0.034\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 287/390 d_loss_real= 0.127, d_loss_fake= 0.026, g_loss 3.645, d_loss 0.077\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 47 Batch 288/390 d_loss_real= 0.104, d_loss_fake= 0.028, g_loss 3.615, d_loss 0.066\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 47 Batch 289/390 d_loss_real= 0.000, d_loss_fake= 0.030, g_loss 3.485, d_loss 0.015\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 290/390 d_loss_real= 0.221, d_loss_fake= 0.032, g_loss 3.487, d_loss 0.126\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 47 Batch 291/390 d_loss_real= 0.006, d_loss_fake= 0.035, g_loss 3.424, d_loss 0.021\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 47 Batch 292/390 d_loss_real= 0.031, d_loss_fake= 0.036, g_loss 3.325, d_loss 0.033\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 293/390 d_loss_real= 0.159, d_loss_fake= 0.042, g_loss 3.129, d_loss 0.101\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 294/390 d_loss_real= 0.082, d_loss_fake= 0.067, g_loss 2.951, d_loss 0.074\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 295/390 d_loss_real= 0.061, d_loss_fake= 0.128, g_loss 3.022, d_loss 0.095\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 296/390 d_loss_real= 0.110, d_loss_fake= 0.049, g_loss 3.387, d_loss 0.079\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 297/390 d_loss_real= 0.243, d_loss_fake= 0.035, g_loss 3.578, d_loss 0.139\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 298/390 d_loss_real= 0.000, d_loss_fake= 0.029, g_loss 3.649, d_loss 0.015\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 47 Batch 299/390 d_loss_real= 0.160, d_loss_fake= 0.027, g_loss 3.719, d_loss 0.094\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 300/390 d_loss_real= 0.172, d_loss_fake= 0.022, g_loss 3.829, d_loss 0.097\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 47 Batch 301/390 d_loss_real= 0.010, d_loss_fake= 0.025, g_loss 3.817, d_loss 0.017\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 302/390 d_loss_real= 0.057, d_loss_fake= 0.022, g_loss 3.837, d_loss 0.039\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 47 Batch 303/390 d_loss_real= 0.160, d_loss_fake= 0.024, g_loss 3.821, d_loss 0.092\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 47 Batch 304/390 d_loss_real= 0.000, d_loss_fake= 0.024, g_loss 3.835, d_loss 0.012\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 305/390 d_loss_real= 0.071, d_loss_fake= 0.022, g_loss 3.887, d_loss 0.046\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 47 Batch 306/390 d_loss_real= 0.065, d_loss_fake= 0.023, g_loss 3.805, d_loss 0.044\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 47 Batch 307/390 d_loss_real= 0.000, d_loss_fake= 0.023, g_loss 3.846, d_loss 0.012\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 308/390 d_loss_real= 0.022, d_loss_fake= 0.024, g_loss 3.747, d_loss 0.023\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 309/390 d_loss_real= 0.116, d_loss_fake= 0.025, g_loss 3.770, d_loss 0.070\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 310/390 d_loss_real= 0.063, d_loss_fake= 0.026, g_loss 3.697, d_loss 0.045\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 311/390 d_loss_real= 0.000, d_loss_fake= 0.026, g_loss 3.643, d_loss 0.013\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 312/390 d_loss_real= 0.096, d_loss_fake= 0.028, g_loss 3.591, d_loss 0.062\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 313/390 d_loss_real= 0.000, d_loss_fake= 0.031, g_loss 3.551, d_loss 0.016\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 314/390 d_loss_real= 0.081, d_loss_fake= 0.032, g_loss 3.533, d_loss 0.056\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 315/390 d_loss_real= 0.056, d_loss_fake= 0.033, g_loss 3.477, d_loss 0.044\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 316/390 d_loss_real= 0.000, d_loss_fake= 0.035, g_loss 3.472, d_loss 0.017\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 317/390 d_loss_real= 0.065, d_loss_fake= 0.037, g_loss 3.442, d_loss 0.051\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 47 Batch 318/390 d_loss_real= 0.111, d_loss_fake= 0.036, g_loss 3.423, d_loss 0.073\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 47 Batch 319/390 d_loss_real= 0.000, d_loss_fake= 0.035, g_loss 3.498, d_loss 0.018\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 320/390 d_loss_real= 0.006, d_loss_fake= 0.035, g_loss 3.533, d_loss 0.021\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 321/390 d_loss_real= 0.196, d_loss_fake= 0.031, g_loss 3.635, d_loss 0.113\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 322/390 d_loss_real= 0.001, d_loss_fake= 0.027, g_loss 3.736, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 323/390 d_loss_real= 0.110, d_loss_fake= 0.025, g_loss 3.792, d_loss 0.067\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 324/390 d_loss_real= 0.000, d_loss_fake= 0.023, g_loss 3.904, d_loss 0.012\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 325/390 d_loss_real= 0.243, d_loss_fake= 0.022, g_loss 3.851, d_loss 0.132\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 326/390 d_loss_real= 0.061, d_loss_fake= 0.023, g_loss 3.814, d_loss 0.042\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 327/390 d_loss_real= 0.071, d_loss_fake= 0.023, g_loss 3.836, d_loss 0.047\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 328/390 d_loss_real= 0.108, d_loss_fake= 0.023, g_loss 3.800, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 329/390 d_loss_real= 0.246, d_loss_fake= 0.025, g_loss 3.682, d_loss 0.136\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 47 Batch 330/390 d_loss_real= 0.201, d_loss_fake= 0.027, g_loss 3.613, d_loss 0.114\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 47 Batch 331/390 d_loss_real= 0.004, d_loss_fake= 0.031, g_loss 3.504, d_loss 0.017\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 47 Batch 332/390 d_loss_real= 0.001, d_loss_fake= 0.039, g_loss 3.476, d_loss 0.020\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 47 Batch 333/390 d_loss_real= 0.001, d_loss_fake= 0.041, g_loss 3.575, d_loss 0.021\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 47 Batch 334/390 d_loss_real= 0.080, d_loss_fake= 0.033, g_loss 3.547, d_loss 0.056\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 47 Batch 335/390 d_loss_real= 0.000, d_loss_fake= 0.030, g_loss 3.654, d_loss 0.015\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 336/390 d_loss_real= 0.071, d_loss_fake= 0.030, g_loss 3.782, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 337/390 d_loss_real= 0.000, d_loss_fake= 0.026, g_loss 3.865, d_loss 0.013\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 338/390 d_loss_real= 0.006, d_loss_fake= 0.022, g_loss 4.008, d_loss 0.014\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 339/390 d_loss_real= 0.062, d_loss_fake= 0.019, g_loss 4.142, d_loss 0.041\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 47 Batch 340/390 d_loss_real= 0.000, d_loss_fake= 0.018, g_loss 4.262, d_loss 0.009\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 47 Batch 341/390 d_loss_real= 0.214, d_loss_fake= 0.016, g_loss 4.251, d_loss 0.115\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 47 Batch 342/390 d_loss_real= 0.171, d_loss_fake= 0.016, g_loss 4.132, d_loss 0.093\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 47 Batch 343/390 d_loss_real= 0.184, d_loss_fake= 0.021, g_loss 3.958, d_loss 0.103\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 47 Batch 344/390 d_loss_real= 0.116, d_loss_fake= 0.030, g_loss 3.593, d_loss 0.073\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 345/390 d_loss_real= 0.145, d_loss_fake= 0.041, g_loss 3.525, d_loss 0.093\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 47 Batch 346/390 d_loss_real= 0.153, d_loss_fake= 0.048, g_loss 3.494, d_loss 0.100\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 47 Batch 347/390 d_loss_real= 0.034, d_loss_fake= 0.067, g_loss 3.813, d_loss 0.050\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 348/390 d_loss_real= 0.028, d_loss_fake= 0.025, g_loss 4.186, d_loss 0.026\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 349/390 d_loss_real= 0.000, d_loss_fake= 0.017, g_loss 4.466, d_loss 0.008\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 350/390 d_loss_real= 0.053, d_loss_fake= 0.012, g_loss 4.573, d_loss 0.032\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 47 Batch 351/390 d_loss_real= 0.070, d_loss_fake= 0.010, g_loss 4.551, d_loss 0.040\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 47 Batch 352/390 d_loss_real= 0.003, d_loss_fake= 0.010, g_loss 4.726, d_loss 0.007\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 353/390 d_loss_real= 0.002, d_loss_fake= 0.010, g_loss 4.761, d_loss 0.006\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 354/390 d_loss_real= 0.159, d_loss_fake= 0.010, g_loss 4.728, d_loss 0.084\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 47 Batch 355/390 d_loss_real= 0.220, d_loss_fake= 0.010, g_loss 4.526, d_loss 0.115\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 356/390 d_loss_real= 0.000, d_loss_fake= 0.012, g_loss 4.501, d_loss 0.006\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 357/390 d_loss_real= 0.231, d_loss_fake= 0.014, g_loss 4.247, d_loss 0.122\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 358/390 d_loss_real= 0.167, d_loss_fake= 0.021, g_loss 4.024, d_loss 0.094\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 359/390 d_loss_real= 0.144, d_loss_fake= 0.030, g_loss 3.638, d_loss 0.087\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 360/390 d_loss_real= 0.000, d_loss_fake= 0.045, g_loss 3.542, d_loss 0.022\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 361/390 d_loss_real= 0.158, d_loss_fake= 0.042, g_loss 3.610, d_loss 0.100\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 47 Batch 362/390 d_loss_real= 0.051, d_loss_fake= 0.041, g_loss 3.685, d_loss 0.046\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47 Batch 363/390 d_loss_real= 0.007, d_loss_fake= 0.022, g_loss 4.021, d_loss 0.015\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 47 Batch 364/390 d_loss_real= 0.000, d_loss_fake= 0.028, g_loss 4.064, d_loss 0.014\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 47 Batch 365/390 d_loss_real= 0.081, d_loss_fake= 0.016, g_loss 4.327, d_loss 0.049\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 47 Batch 366/390 d_loss_real= 0.070, d_loss_fake= 0.012, g_loss 4.551, d_loss 0.041\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 47 Batch 367/390 d_loss_real= 0.076, d_loss_fake= 0.013, g_loss 4.583, d_loss 0.044\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 47 Batch 368/390 d_loss_real= 0.032, d_loss_fake= 0.011, g_loss 4.582, d_loss 0.021\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 369/390 d_loss_real= 0.077, d_loss_fake= 0.012, g_loss 4.561, d_loss 0.044\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 47 Batch 370/390 d_loss_real= 0.079, d_loss_fake= 0.012, g_loss 4.330, d_loss 0.046\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 371/390 d_loss_real= 0.157, d_loss_fake= 0.016, g_loss 4.262, d_loss 0.087\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 47 Batch 372/390 d_loss_real= 0.312, d_loss_fake= 0.018, g_loss 4.032, d_loss 0.165\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 47 Batch 373/390 d_loss_real= 0.000, d_loss_fake= 0.019, g_loss 3.988, d_loss 0.010\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 374/390 d_loss_real= 0.000, d_loss_fake= 0.014, g_loss 4.391, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 375/390 d_loss_real= 0.062, d_loss_fake= 0.015, g_loss 4.261, d_loss 0.038\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 376/390 d_loss_real= 0.001, d_loss_fake= 0.021, g_loss 4.065, d_loss 0.011\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 377/390 d_loss_real= 0.207, d_loss_fake= 0.017, g_loss 4.092, d_loss 0.112\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 378/390 d_loss_real= 0.000, d_loss_fake= 0.017, g_loss 4.211, d_loss 0.008\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 379/390 d_loss_real= 0.000, d_loss_fake= 0.021, g_loss 4.282, d_loss 0.011\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 47 Batch 380/390 d_loss_real= 0.071, d_loss_fake= 0.014, g_loss 4.490, d_loss 0.043\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 47 Batch 381/390 d_loss_real= 0.147, d_loss_fake= 0.014, g_loss 4.547, d_loss 0.080\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 47 Batch 382/390 d_loss_real= 0.114, d_loss_fake= 0.012, g_loss 4.478, d_loss 0.063\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 47 Batch 383/390 d_loss_real= 0.255, d_loss_fake= 0.011, g_loss 4.481, d_loss 0.133\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 384/390 d_loss_real= 0.068, d_loss_fake= 0.012, g_loss 4.310, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 385/390 d_loss_real= 0.047, d_loss_fake= 0.026, g_loss 3.693, d_loss 0.036\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 386/390 d_loss_real= 0.070, d_loss_fake= 0.022, g_loss 3.981, d_loss 0.046\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 47 Batch 387/390 d_loss_real= 0.168, d_loss_fake= 0.015, g_loss 4.259, d_loss 0.091\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47 Batch 388/390 d_loss_real= 0.060, d_loss_fake= 0.024, g_loss 3.864, d_loss 0.042\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47 Batch 389/390 d_loss_real= 0.000, d_loss_fake= 0.089, g_loss 3.919, d_loss 0.045\n",
            "2/2 [==============================] - 0s 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47 Batch 390/390 d_loss_real= 0.105, d_loss_fake= 0.020, g_loss 4.470, d_loss 0.063\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 1/390 d_loss_real= 0.088, d_loss_fake= 0.011, g_loss 4.726, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 2/390 d_loss_real= 0.022, d_loss_fake= 0.009, g_loss 4.828, d_loss 0.016\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 3/390 d_loss_real= 0.152, d_loss_fake= 0.009, g_loss 4.877, d_loss 0.080\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 4/390 d_loss_real= 0.189, d_loss_fake= 0.008, g_loss 4.783, d_loss 0.099\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 5/390 d_loss_real= 0.071, d_loss_fake= 0.009, g_loss 4.757, d_loss 0.040\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 6/390 d_loss_real= 0.179, d_loss_fake= 0.010, g_loss 4.472, d_loss 0.095\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 48 Batch 7/390 d_loss_real= 0.192, d_loss_fake= 0.013, g_loss 4.253, d_loss 0.103\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 8/390 d_loss_real= 0.062, d_loss_fake= 0.018, g_loss 3.994, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 9/390 d_loss_real= 0.171, d_loss_fake= 0.026, g_loss 3.795, d_loss 0.098\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 10/390 d_loss_real= 0.000, d_loss_fake= 0.031, g_loss 3.639, d_loss 0.016\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 48 Batch 11/390 d_loss_real= 0.119, d_loss_fake= 0.040, g_loss 3.634, d_loss 0.080\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 12/390 d_loss_real= 0.000, d_loss_fake= 0.026, g_loss 3.774, d_loss 0.013\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 13/390 d_loss_real= 0.129, d_loss_fake= 0.025, g_loss 3.896, d_loss 0.077\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 14/390 d_loss_real= 0.017, d_loss_fake= 0.020, g_loss 4.020, d_loss 0.019\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 15/390 d_loss_real= 0.089, d_loss_fake= 0.023, g_loss 3.891, d_loss 0.056\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 16/390 d_loss_real= 0.000, d_loss_fake= 0.022, g_loss 3.979, d_loss 0.011\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48 Batch 17/390 d_loss_real= 0.179, d_loss_fake= 0.022, g_loss 3.792, d_loss 0.100\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 18/390 d_loss_real= 0.064, d_loss_fake= 0.024, g_loss 3.762, d_loss 0.044\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 19/390 d_loss_real= 0.001, d_loss_fake= 0.026, g_loss 3.836, d_loss 0.013\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 20/390 d_loss_real= 0.149, d_loss_fake= 0.028, g_loss 3.757, d_loss 0.089\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 48 Batch 21/390 d_loss_real= 0.191, d_loss_fake= 0.034, g_loss 3.688, d_loss 0.112\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 22/390 d_loss_real= 0.219, d_loss_fake= 0.027, g_loss 3.677, d_loss 0.123\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 23/390 d_loss_real= 0.077, d_loss_fake= 0.031, g_loss 3.714, d_loss 0.054\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 48 Batch 24/390 d_loss_real= 0.000, d_loss_fake= 0.022, g_loss 3.916, d_loss 0.011\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 25/390 d_loss_real= 0.122, d_loss_fake= 0.024, g_loss 3.866, d_loss 0.073\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 48 Batch 26/390 d_loss_real= 0.080, d_loss_fake= 0.023, g_loss 3.932, d_loss 0.052\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 27/390 d_loss_real= 0.070, d_loss_fake= 0.022, g_loss 3.989, d_loss 0.046\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 48 Batch 28/390 d_loss_real= 0.103, d_loss_fake= 0.021, g_loss 3.930, d_loss 0.062\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 48 Batch 29/390 d_loss_real= 0.073, d_loss_fake= 0.024, g_loss 3.806, d_loss 0.048\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 48 Batch 30/390 d_loss_real= 0.057, d_loss_fake= 0.026, g_loss 3.799, d_loss 0.042\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 31/390 d_loss_real= 0.066, d_loss_fake= 0.025, g_loss 3.762, d_loss 0.046\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 32/390 d_loss_real= 0.064, d_loss_fake= 0.022, g_loss 3.834, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 33/390 d_loss_real= 0.002, d_loss_fake= 0.021, g_loss 3.939, d_loss 0.011\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 48 Batch 34/390 d_loss_real= 0.224, d_loss_fake= 0.027, g_loss 3.794, d_loss 0.125\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 35/390 d_loss_real= 0.137, d_loss_fake= 0.029, g_loss 3.714, d_loss 0.083\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48 Batch 36/390 d_loss_real= 0.127, d_loss_fake= 0.029, g_loss 3.620, d_loss 0.078\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 48 Batch 37/390 d_loss_real= 0.084, d_loss_fake= 0.037, g_loss 3.397, d_loss 0.060\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 48 Batch 38/390 d_loss_real= 0.127, d_loss_fake= 0.032, g_loss 3.563, d_loss 0.080\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 39/390 d_loss_real= 0.108, d_loss_fake= 0.042, g_loss 3.498, d_loss 0.075\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 40/390 d_loss_real= 0.194, d_loss_fake= 0.033, g_loss 3.599, d_loss 0.113\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 48 Batch 41/390 d_loss_real= 0.090, d_loss_fake= 0.031, g_loss 3.664, d_loss 0.061\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 42/390 d_loss_real= 0.003, d_loss_fake= 0.026, g_loss 3.866, d_loss 0.014\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 43/390 d_loss_real= 0.126, d_loss_fake= 0.023, g_loss 3.910, d_loss 0.074\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 44/390 d_loss_real= 0.069, d_loss_fake= 0.022, g_loss 3.904, d_loss 0.045\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 48 Batch 45/390 d_loss_real= 0.162, d_loss_fake= 0.023, g_loss 3.827, d_loss 0.093\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 48 Batch 46/390 d_loss_real= 0.080, d_loss_fake= 0.024, g_loss 3.808, d_loss 0.052\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 47/390 d_loss_real= 0.059, d_loss_fake= 0.028, g_loss 3.717, d_loss 0.043\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 48/390 d_loss_real= 0.116, d_loss_fake= 0.031, g_loss 3.589, d_loss 0.073\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 49/390 d_loss_real= 0.045, d_loss_fake= 0.028, g_loss 3.650, d_loss 0.036\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 50/390 d_loss_real= 0.106, d_loss_fake= 0.032, g_loss 3.574, d_loss 0.069\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48 Batch 51/390 d_loss_real= 0.098, d_loss_fake= 0.034, g_loss 3.559, d_loss 0.066\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 52/390 d_loss_real= 0.122, d_loss_fake= 0.030, g_loss 3.712, d_loss 0.076\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 48 Batch 53/390 d_loss_real= 0.191, d_loss_fake= 0.029, g_loss 3.678, d_loss 0.110\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 54/390 d_loss_real= 0.000, d_loss_fake= 0.025, g_loss 3.874, d_loss 0.012\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 48 Batch 55/390 d_loss_real= 0.000, d_loss_fake= 0.021, g_loss 3.969, d_loss 0.011\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 56/390 d_loss_real= 0.002, d_loss_fake= 0.020, g_loss 4.043, d_loss 0.011\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 57/390 d_loss_real= 0.171, d_loss_fake= 0.020, g_loss 4.049, d_loss 0.095\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 58/390 d_loss_real= 0.137, d_loss_fake= 0.020, g_loss 3.966, d_loss 0.078\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 59/390 d_loss_real= 0.115, d_loss_fake= 0.022, g_loss 3.754, d_loss 0.069\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 48 Batch 60/390 d_loss_real= 0.000, d_loss_fake= 0.027, g_loss 3.573, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 61/390 d_loss_real= 0.105, d_loss_fake= 0.030, g_loss 3.502, d_loss 0.067\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 62/390 d_loss_real= 0.193, d_loss_fake= 0.041, g_loss 3.307, d_loss 0.117\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 48 Batch 63/390 d_loss_real= 0.054, d_loss_fake= 0.041, g_loss 3.323, d_loss 0.047\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 64/390 d_loss_real= 0.130, d_loss_fake= 0.041, g_loss 3.380, d_loss 0.086\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 65/390 d_loss_real= 0.109, d_loss_fake= 0.043, g_loss 3.394, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 66/390 d_loss_real= 0.034, d_loss_fake= 0.033, g_loss 3.536, d_loss 0.034\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 48 Batch 67/390 d_loss_real= 0.185, d_loss_fake= 0.031, g_loss 3.545, d_loss 0.108\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 48 Batch 68/390 d_loss_real= 0.039, d_loss_fake= 0.031, g_loss 3.590, d_loss 0.035\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 69/390 d_loss_real= 0.000, d_loss_fake= 0.029, g_loss 3.631, d_loss 0.014\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 48 Batch 70/390 d_loss_real= 0.053, d_loss_fake= 0.027, g_loss 3.644, d_loss 0.040\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 71/390 d_loss_real= 0.046, d_loss_fake= 0.027, g_loss 3.649, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 72/390 d_loss_real= 0.163, d_loss_fake= 0.029, g_loss 3.517, d_loss 0.096\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 48 Batch 73/390 d_loss_real= 0.001, d_loss_fake= 0.030, g_loss 3.546, d_loss 0.016\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 48 Batch 74/390 d_loss_real= 0.064, d_loss_fake= 0.034, g_loss 3.472, d_loss 0.049\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 75/390 d_loss_real= 0.143, d_loss_fake= 0.033, g_loss 3.469, d_loss 0.088\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 48 Batch 76/390 d_loss_real= 0.019, d_loss_fake= 0.032, g_loss 3.489, d_loss 0.025\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 77/390 d_loss_real= 0.054, d_loss_fake= 0.029, g_loss 3.659, d_loss 0.042\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 48 Batch 78/390 d_loss_real= 0.053, d_loss_fake= 0.032, g_loss 3.453, d_loss 0.042\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 79/390 d_loss_real= 0.000, d_loss_fake= 0.034, g_loss 3.566, d_loss 0.017\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 80/390 d_loss_real= 0.053, d_loss_fake= 0.030, g_loss 3.608, d_loss 0.041\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48 Batch 81/390 d_loss_real= 0.180, d_loss_fake= 0.026, g_loss 3.702, d_loss 0.103\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 82/390 d_loss_real= 0.126, d_loss_fake= 0.027, g_loss 3.714, d_loss 0.077\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 83/390 d_loss_real= 0.086, d_loss_fake= 0.030, g_loss 3.505, d_loss 0.058\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48 Batch 84/390 d_loss_real= 0.001, d_loss_fake= 0.031, g_loss 3.511, d_loss 0.016\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 85/390 d_loss_real= 0.114, d_loss_fake= 0.034, g_loss 3.555, d_loss 0.074\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 48 Batch 86/390 d_loss_real= 0.057, d_loss_fake= 0.028, g_loss 3.643, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 87/390 d_loss_real= 0.063, d_loss_fake= 0.027, g_loss 3.737, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 88/390 d_loss_real= 0.090, d_loss_fake= 0.026, g_loss 3.758, d_loss 0.058\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 48 Batch 89/390 d_loss_real= 0.006, d_loss_fake= 0.024, g_loss 3.801, d_loss 0.015\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 90/390 d_loss_real= 0.000, d_loss_fake= 0.022, g_loss 3.903, d_loss 0.011\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 91/390 d_loss_real= 0.045, d_loss_fake= 0.022, g_loss 3.984, d_loss 0.034\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 48 Batch 92/390 d_loss_real= 0.056, d_loss_fake= 0.021, g_loss 3.963, d_loss 0.038\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 93/390 d_loss_real= 0.180, d_loss_fake= 0.022, g_loss 3.874, d_loss 0.101\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 94/390 d_loss_real= 0.049, d_loss_fake= 0.023, g_loss 3.861, d_loss 0.036\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 95/390 d_loss_real= 0.096, d_loss_fake= 0.023, g_loss 3.828, d_loss 0.060\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48 Batch 96/390 d_loss_real= 0.161, d_loss_fake= 0.024, g_loss 3.813, d_loss 0.093\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 97/390 d_loss_real= 0.139, d_loss_fake= 0.027, g_loss 3.694, d_loss 0.083\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 48 Batch 98/390 d_loss_real= 0.063, d_loss_fake= 0.030, g_loss 3.599, d_loss 0.046\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 99/390 d_loss_real= 0.010, d_loss_fake= 0.031, g_loss 3.571, d_loss 0.020\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 100/390 d_loss_real= 0.040, d_loss_fake= 0.032, g_loss 3.566, d_loss 0.036\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 101/390 d_loss_real= 0.040, d_loss_fake= 0.030, g_loss 3.511, d_loss 0.035\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 102/390 d_loss_real= 0.106, d_loss_fake= 0.032, g_loss 3.532, d_loss 0.069\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 48 Batch 103/390 d_loss_real= 0.085, d_loss_fake= 0.031, g_loss 3.507, d_loss 0.058\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 104/390 d_loss_real= 0.037, d_loss_fake= 0.033, g_loss 3.434, d_loss 0.035\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 105/390 d_loss_real= 0.000, d_loss_fake= 0.031, g_loss 3.522, d_loss 0.016\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 106/390 d_loss_real= 0.131, d_loss_fake= 0.035, g_loss 3.470, d_loss 0.083\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48 Batch 107/390 d_loss_real= 0.000, d_loss_fake= 0.033, g_loss 3.590, d_loss 0.017\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 48 Batch 108/390 d_loss_real= 0.243, d_loss_fake= 0.030, g_loss 3.651, d_loss 0.136\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 48 Batch 109/390 d_loss_real= 0.092, d_loss_fake= 0.028, g_loss 3.631, d_loss 0.060\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 48 Batch 110/390 d_loss_real= 0.133, d_loss_fake= 0.032, g_loss 3.415, d_loss 0.083\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 111/390 d_loss_real= 0.143, d_loss_fake= 0.038, g_loss 3.331, d_loss 0.090\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 112/390 d_loss_real= 0.044, d_loss_fake= 0.035, g_loss 3.372, d_loss 0.039\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 48 Batch 113/390 d_loss_real= 0.001, d_loss_fake= 0.047, g_loss 3.161, d_loss 0.024\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 114/390 d_loss_real= 0.002, d_loss_fake= 0.086, g_loss 3.271, d_loss 0.044\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 48 Batch 115/390 d_loss_real= 0.065, d_loss_fake= 0.043, g_loss 3.647, d_loss 0.054\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 116/390 d_loss_real= 0.162, d_loss_fake= 0.031, g_loss 3.726, d_loss 0.096\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48 Batch 117/390 d_loss_real= 0.003, d_loss_fake= 0.025, g_loss 3.893, d_loss 0.014\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 118/390 d_loss_real= 0.142, d_loss_fake= 0.019, g_loss 4.164, d_loss 0.080\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 48 Batch 119/390 d_loss_real= 0.026, d_loss_fake= 0.017, g_loss 4.163, d_loss 0.022\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 48 Batch 120/390 d_loss_real= 0.113, d_loss_fake= 0.018, g_loss 4.155, d_loss 0.065\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 48 Batch 121/390 d_loss_real= 0.127, d_loss_fake= 0.018, g_loss 4.103, d_loss 0.072\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 122/390 d_loss_real= 0.000, d_loss_fake= 0.019, g_loss 4.096, d_loss 0.009\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 123/390 d_loss_real= 0.071, d_loss_fake= 0.017, g_loss 4.158, d_loss 0.044\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 48 Batch 124/390 d_loss_real= 0.126, d_loss_fake= 0.020, g_loss 3.964, d_loss 0.073\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 48 Batch 125/390 d_loss_real= 0.139, d_loss_fake= 0.029, g_loss 3.772, d_loss 0.084\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 126/390 d_loss_real= 0.038, d_loss_fake= 0.041, g_loss 3.630, d_loss 0.039\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 127/390 d_loss_real= 0.127, d_loss_fake= 0.035, g_loss 3.916, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 128/390 d_loss_real= 0.144, d_loss_fake= 0.024, g_loss 3.971, d_loss 0.084\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 48 Batch 129/390 d_loss_real= 0.238, d_loss_fake= 0.021, g_loss 4.074, d_loss 0.130\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 130/390 d_loss_real= 0.015, d_loss_fake= 0.021, g_loss 4.077, d_loss 0.018\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 131/390 d_loss_real= 0.147, d_loss_fake= 0.033, g_loss 3.466, d_loss 0.090\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 48 Batch 132/390 d_loss_real= 0.055, d_loss_fake= 0.038, g_loss 3.570, d_loss 0.046\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 48 Batch 133/390 d_loss_real= 0.027, d_loss_fake= 0.013, g_loss 4.520, d_loss 0.020\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 134/390 d_loss_real= 0.080, d_loss_fake= 0.031, g_loss 4.042, d_loss 0.055\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 135/390 d_loss_real= 0.000, d_loss_fake= 0.028, g_loss 4.158, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 136/390 d_loss_real= 0.075, d_loss_fake= 0.043, g_loss 4.164, d_loss 0.059\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 137/390 d_loss_real= 0.246, d_loss_fake= 0.019, g_loss 4.330, d_loss 0.133\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 138/390 d_loss_real= 0.067, d_loss_fake= 0.013, g_loss 4.612, d_loss 0.040\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 48 Batch 139/390 d_loss_real= 0.072, d_loss_fake= 0.013, g_loss 4.567, d_loss 0.042\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 140/390 d_loss_real= 0.009, d_loss_fake= 0.013, g_loss 4.476, d_loss 0.011\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48 Batch 141/390 d_loss_real= 0.170, d_loss_fake= 0.014, g_loss 4.306, d_loss 0.092\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 142/390 d_loss_real= 0.014, d_loss_fake= 0.016, g_loss 4.287, d_loss 0.015\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 143/390 d_loss_real= 0.077, d_loss_fake= 0.019, g_loss 4.094, d_loss 0.048\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 144/390 d_loss_real= 0.001, d_loss_fake= 0.019, g_loss 4.222, d_loss 0.010\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 145/390 d_loss_real= 0.138, d_loss_fake= 0.020, g_loss 4.027, d_loss 0.079\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 146/390 d_loss_real= 0.076, d_loss_fake= 0.024, g_loss 4.028, d_loss 0.050\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 48 Batch 147/390 d_loss_real= 0.000, d_loss_fake= 0.025, g_loss 3.942, d_loss 0.013\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 148/390 d_loss_real= 0.000, d_loss_fake= 0.022, g_loss 3.881, d_loss 0.011\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 149/390 d_loss_real= 0.022, d_loss_fake= 0.025, g_loss 4.016, d_loss 0.023\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 150/390 d_loss_real= 0.142, d_loss_fake= 0.023, g_loss 4.018, d_loss 0.083\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 151/390 d_loss_real= 0.044, d_loss_fake= 0.025, g_loss 4.029, d_loss 0.035\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 152/390 d_loss_real= 0.229, d_loss_fake= 0.023, g_loss 3.873, d_loss 0.126\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 153/390 d_loss_real= 0.265, d_loss_fake= 0.028, g_loss 3.715, d_loss 0.146\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 154/390 d_loss_real= 0.211, d_loss_fake= 0.030, g_loss 3.666, d_loss 0.120\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48 Batch 155/390 d_loss_real= 0.259, d_loss_fake= 0.034, g_loss 3.651, d_loss 0.146\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 48 Batch 156/390 d_loss_real= 0.069, d_loss_fake= 0.037, g_loss 3.633, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 157/390 d_loss_real= 0.078, d_loss_fake= 0.027, g_loss 3.791, d_loss 0.052\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 158/390 d_loss_real= 0.082, d_loss_fake= 0.031, g_loss 3.742, d_loss 0.057\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 48 Batch 159/390 d_loss_real= 0.124, d_loss_fake= 0.026, g_loss 3.898, d_loss 0.075\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 48 Batch 160/390 d_loss_real= 0.068, d_loss_fake= 0.024, g_loss 3.792, d_loss 0.046\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 161/390 d_loss_real= 0.093, d_loss_fake= 0.026, g_loss 3.844, d_loss 0.059\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 48 Batch 162/390 d_loss_real= 0.235, d_loss_fake= 0.023, g_loss 3.932, d_loss 0.129\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 48 Batch 163/390 d_loss_real= 0.191, d_loss_fake= 0.041, g_loss 3.476, d_loss 0.116\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 164/390 d_loss_real= 0.112, d_loss_fake= 0.038, g_loss 3.494, d_loss 0.075\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 48 Batch 165/390 d_loss_real= 0.070, d_loss_fake= 0.031, g_loss 3.681, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 166/390 d_loss_real= 0.091, d_loss_fake= 0.033, g_loss 3.806, d_loss 0.062\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 48 Batch 167/390 d_loss_real= 0.065, d_loss_fake= 0.024, g_loss 3.989, d_loss 0.044\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 48 Batch 168/390 d_loss_real= 0.047, d_loss_fake= 0.019, g_loss 4.050, d_loss 0.033\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 169/390 d_loss_real= 0.095, d_loss_fake= 0.020, g_loss 4.117, d_loss 0.058\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 170/390 d_loss_real= 0.155, d_loss_fake= 0.022, g_loss 4.049, d_loss 0.088\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 171/390 d_loss_real= 0.185, d_loss_fake= 0.021, g_loss 3.966, d_loss 0.103\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 48 Batch 172/390 d_loss_real= 0.035, d_loss_fake= 0.023, g_loss 3.952, d_loss 0.029\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48 Batch 173/390 d_loss_real= 0.064, d_loss_fake= 0.025, g_loss 3.857, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 174/390 d_loss_real= 0.144, d_loss_fake= 0.034, g_loss 3.781, d_loss 0.089\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 175/390 d_loss_real= 0.006, d_loss_fake= 0.026, g_loss 3.785, d_loss 0.016\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 48 Batch 176/390 d_loss_real= 0.012, d_loss_fake= 0.026, g_loss 3.921, d_loss 0.019\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 48 Batch 177/390 d_loss_real= 0.045, d_loss_fake= 0.031, g_loss 3.806, d_loss 0.038\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 178/390 d_loss_real= 0.165, d_loss_fake= 0.029, g_loss 3.923, d_loss 0.097\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 179/390 d_loss_real= 0.003, d_loss_fake= 0.028, g_loss 3.868, d_loss 0.016\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 180/390 d_loss_real= 0.051, d_loss_fake= 0.027, g_loss 3.919, d_loss 0.039\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 48 Batch 181/390 d_loss_real= 0.048, d_loss_fake= 0.024, g_loss 4.059, d_loss 0.036\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48 Batch 182/390 d_loss_real= 0.095, d_loss_fake= 0.023, g_loss 4.048, d_loss 0.059\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 183/390 d_loss_real= 0.075, d_loss_fake= 0.023, g_loss 4.097, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 184/390 d_loss_real= 0.064, d_loss_fake= 0.019, g_loss 4.164, d_loss 0.041\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 185/390 d_loss_real= 0.058, d_loss_fake= 0.018, g_loss 4.265, d_loss 0.038\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48 Batch 186/390 d_loss_real= 0.280, d_loss_fake= 0.019, g_loss 3.896, d_loss 0.150\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 187/390 d_loss_real= 0.064, d_loss_fake= 0.028, g_loss 3.780, d_loss 0.046\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 188/390 d_loss_real= 0.046, d_loss_fake= 0.032, g_loss 3.628, d_loss 0.039\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48 Batch 189/390 d_loss_real= 0.140, d_loss_fake= 0.036, g_loss 3.356, d_loss 0.088\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 48 Batch 190/390 d_loss_real= 0.294, d_loss_fake= 0.066, g_loss 3.559, d_loss 0.180\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 191/390 d_loss_real= 0.012, d_loss_fake= 0.027, g_loss 4.060, d_loss 0.019\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 192/390 d_loss_real= 0.115, d_loss_fake= 0.022, g_loss 4.170, d_loss 0.068\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 193/390 d_loss_real= 0.066, d_loss_fake= 0.021, g_loss 4.108, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 194/390 d_loss_real= 0.090, d_loss_fake= 0.022, g_loss 4.100, d_loss 0.056\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 195/390 d_loss_real= 0.001, d_loss_fake= 0.018, g_loss 4.262, d_loss 0.009\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 196/390 d_loss_real= 0.002, d_loss_fake= 0.018, g_loss 4.181, d_loss 0.010\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 197/390 d_loss_real= 0.213, d_loss_fake= 0.018, g_loss 4.312, d_loss 0.116\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 198/390 d_loss_real= 0.095, d_loss_fake= 0.016, g_loss 4.148, d_loss 0.055\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 48 Batch 199/390 d_loss_real= 0.088, d_loss_fake= 0.020, g_loss 3.973, d_loss 0.054\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 200/390 d_loss_real= 0.013, d_loss_fake= 0.019, g_loss 4.022, d_loss 0.016\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 201/390 d_loss_real= 0.093, d_loss_fake= 0.023, g_loss 3.826, d_loss 0.058\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48 Batch 202/390 d_loss_real= 0.152, d_loss_fake= 0.030, g_loss 3.773, d_loss 0.091\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 203/390 d_loss_real= 0.001, d_loss_fake= 0.031, g_loss 3.983, d_loss 0.016\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 204/390 d_loss_real= 0.000, d_loss_fake= 0.021, g_loss 4.184, d_loss 0.011\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 48 Batch 205/390 d_loss_real= 0.133, d_loss_fake= 0.021, g_loss 4.084, d_loss 0.077\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 48 Batch 206/390 d_loss_real= 0.124, d_loss_fake= 0.017, g_loss 4.061, d_loss 0.070\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 207/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 4.078, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 208/390 d_loss_real= 0.057, d_loss_fake= 0.018, g_loss 4.127, d_loss 0.037\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 48 Batch 209/390 d_loss_real= 0.040, d_loss_fake= 0.020, g_loss 4.132, d_loss 0.030\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 48 Batch 210/390 d_loss_real= 0.064, d_loss_fake= 0.019, g_loss 4.179, d_loss 0.041\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 48 Batch 211/390 d_loss_real= 0.000, d_loss_fake= 0.025, g_loss 3.908, d_loss 0.013\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 212/390 d_loss_real= 0.060, d_loss_fake= 0.043, g_loss 3.848, d_loss 0.052\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 213/390 d_loss_real= 0.000, d_loss_fake= 0.026, g_loss 4.225, d_loss 0.013\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 48 Batch 214/390 d_loss_real= 0.071, d_loss_fake= 0.013, g_loss 4.614, d_loss 0.042\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 215/390 d_loss_real= 0.221, d_loss_fake= 0.013, g_loss 4.654, d_loss 0.117\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 216/390 d_loss_real= 0.136, d_loss_fake= 0.012, g_loss 4.630, d_loss 0.074\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 217/390 d_loss_real= 0.126, d_loss_fake= 0.012, g_loss 4.524, d_loss 0.069\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 218/390 d_loss_real= 0.049, d_loss_fake= 0.014, g_loss 4.434, d_loss 0.031\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 219/390 d_loss_real= 0.001, d_loss_fake= 0.014, g_loss 4.235, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 220/390 d_loss_real= 0.158, d_loss_fake= 0.017, g_loss 4.134, d_loss 0.087\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 221/390 d_loss_real= 0.133, d_loss_fake= 0.019, g_loss 3.997, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 222/390 d_loss_real= 0.250, d_loss_fake= 0.021, g_loss 3.854, d_loss 0.136\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 223/390 d_loss_real= 0.117, d_loss_fake= 0.026, g_loss 3.703, d_loss 0.071\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 48 Batch 224/390 d_loss_real= 0.031, d_loss_fake= 0.035, g_loss 3.599, d_loss 0.033\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 225/390 d_loss_real= 0.108, d_loss_fake= 0.034, g_loss 3.655, d_loss 0.071\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 226/390 d_loss_real= 0.007, d_loss_fake= 0.030, g_loss 3.696, d_loss 0.019\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 227/390 d_loss_real= 0.036, d_loss_fake= 0.025, g_loss 3.788, d_loss 0.030\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 48 Batch 228/390 d_loss_real= 0.030, d_loss_fake= 0.024, g_loss 3.857, d_loss 0.027\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 229/390 d_loss_real= 0.072, d_loss_fake= 0.024, g_loss 3.855, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 230/390 d_loss_real= 0.166, d_loss_fake= 0.022, g_loss 3.948, d_loss 0.094\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 48 Batch 231/390 d_loss_real= 0.314, d_loss_fake= 0.022, g_loss 3.857, d_loss 0.168\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 232/390 d_loss_real= 0.120, d_loss_fake= 0.023, g_loss 3.853, d_loss 0.071\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 48 Batch 233/390 d_loss_real= 0.000, d_loss_fake= 0.022, g_loss 3.866, d_loss 0.011\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 234/390 d_loss_real= 0.083, d_loss_fake= 0.025, g_loss 3.812, d_loss 0.054\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 48 Batch 235/390 d_loss_real= 0.105, d_loss_fake= 0.025, g_loss 3.694, d_loss 0.065\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 236/390 d_loss_real= 0.035, d_loss_fake= 0.027, g_loss 3.597, d_loss 0.031\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 237/390 d_loss_real= 0.123, d_loss_fake= 0.030, g_loss 3.469, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 238/390 d_loss_real= 0.055, d_loss_fake= 0.037, g_loss 3.489, d_loss 0.046\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 239/390 d_loss_real= 0.029, d_loss_fake= 0.034, g_loss 3.593, d_loss 0.031\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 240/390 d_loss_real= 0.111, d_loss_fake= 0.030, g_loss 3.750, d_loss 0.071\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 48 Batch 241/390 d_loss_real= 0.129, d_loss_fake= 0.029, g_loss 3.714, d_loss 0.079\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 242/390 d_loss_real= 0.026, d_loss_fake= 0.025, g_loss 3.830, d_loss 0.026\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 48 Batch 243/390 d_loss_real= 0.029, d_loss_fake= 0.024, g_loss 3.868, d_loss 0.027\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 244/390 d_loss_real= 0.106, d_loss_fake= 0.023, g_loss 3.820, d_loss 0.064\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 48 Batch 245/390 d_loss_real= 0.115, d_loss_fake= 0.023, g_loss 3.900, d_loss 0.069\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 48 Batch 246/390 d_loss_real= 0.060, d_loss_fake= 0.022, g_loss 3.912, d_loss 0.041\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 247/390 d_loss_real= 0.172, d_loss_fake= 0.023, g_loss 3.877, d_loss 0.098\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 48 Batch 248/390 d_loss_real= 0.225, d_loss_fake= 0.022, g_loss 3.830, d_loss 0.124\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 249/390 d_loss_real= 0.112, d_loss_fake= 0.026, g_loss 3.754, d_loss 0.069\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 48 Batch 250/390 d_loss_real= 0.142, d_loss_fake= 0.026, g_loss 3.645, d_loss 0.084\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 251/390 d_loss_real= 0.125, d_loss_fake= 0.029, g_loss 3.526, d_loss 0.077\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 252/390 d_loss_real= 0.000, d_loss_fake= 0.035, g_loss 3.526, d_loss 0.018\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 253/390 d_loss_real= 0.128, d_loss_fake= 0.033, g_loss 3.531, d_loss 0.080\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 254/390 d_loss_real= 0.252, d_loss_fake= 0.035, g_loss 3.429, d_loss 0.143\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 255/390 d_loss_real= 0.116, d_loss_fake= 0.038, g_loss 3.378, d_loss 0.077\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 256/390 d_loss_real= 0.045, d_loss_fake= 0.033, g_loss 3.490, d_loss 0.039\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 48 Batch 257/390 d_loss_real= 0.114, d_loss_fake= 0.032, g_loss 3.520, d_loss 0.073\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 48 Batch 258/390 d_loss_real= 0.000, d_loss_fake= 0.031, g_loss 3.576, d_loss 0.016\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 48 Batch 259/390 d_loss_real= 0.099, d_loss_fake= 0.029, g_loss 3.664, d_loss 0.064\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 260/390 d_loss_real= 0.161, d_loss_fake= 0.027, g_loss 3.631, d_loss 0.094\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 48 Batch 261/390 d_loss_real= 0.116, d_loss_fake= 0.027, g_loss 3.639, d_loss 0.072\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 262/390 d_loss_real= 0.004, d_loss_fake= 0.028, g_loss 3.634, d_loss 0.016\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 263/390 d_loss_real= 0.000, d_loss_fake= 0.027, g_loss 3.690, d_loss 0.013\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 48 Batch 264/390 d_loss_real= 0.003, d_loss_fake= 0.026, g_loss 3.716, d_loss 0.014\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 48 Batch 265/390 d_loss_real= 0.002, d_loss_fake= 0.025, g_loss 3.790, d_loss 0.013\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 48 Batch 266/390 d_loss_real= 0.073, d_loss_fake= 0.023, g_loss 3.844, d_loss 0.048\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 267/390 d_loss_real= 0.000, d_loss_fake= 0.022, g_loss 3.916, d_loss 0.011\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 48 Batch 268/390 d_loss_real= 0.007, d_loss_fake= 0.020, g_loss 3.930, d_loss 0.014\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 269/390 d_loss_real= 0.002, d_loss_fake= 0.020, g_loss 4.021, d_loss 0.011\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48 Batch 270/390 d_loss_real= 0.095, d_loss_fake= 0.019, g_loss 3.919, d_loss 0.057\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 271/390 d_loss_real= 0.131, d_loss_fake= 0.020, g_loss 3.797, d_loss 0.076\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 272/390 d_loss_real= 0.075, d_loss_fake= 0.026, g_loss 3.649, d_loss 0.051\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 273/390 d_loss_real= 0.110, d_loss_fake= 0.040, g_loss 3.411, d_loss 0.075\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 274/390 d_loss_real= 0.076, d_loss_fake= 0.040, g_loss 3.647, d_loss 0.058\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 275/390 d_loss_real= 0.035, d_loss_fake= 0.032, g_loss 3.833, d_loss 0.033\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 276/390 d_loss_real= 0.001, d_loss_fake= 0.020, g_loss 4.070, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 277/390 d_loss_real= 0.101, d_loss_fake= 0.018, g_loss 4.170, d_loss 0.059\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 278/390 d_loss_real= 0.072, d_loss_fake= 0.017, g_loss 4.168, d_loss 0.045\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 279/390 d_loss_real= 0.151, d_loss_fake= 0.017, g_loss 4.144, d_loss 0.084\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 48 Batch 280/390 d_loss_real= 0.148, d_loss_fake= 0.017, g_loss 4.172, d_loss 0.083\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 281/390 d_loss_real= 0.091, d_loss_fake= 0.019, g_loss 3.889, d_loss 0.055\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 48 Batch 282/390 d_loss_real= 0.000, d_loss_fake= 0.025, g_loss 3.705, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 283/390 d_loss_real= 0.088, d_loss_fake= 0.030, g_loss 3.591, d_loss 0.059\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 284/390 d_loss_real= 0.066, d_loss_fake= 0.030, g_loss 3.742, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 285/390 d_loss_real= 0.212, d_loss_fake= 0.025, g_loss 3.934, d_loss 0.118\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 286/390 d_loss_real= 0.029, d_loss_fake= 0.025, g_loss 3.955, d_loss 0.027\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 287/390 d_loss_real= 0.147, d_loss_fake= 0.019, g_loss 4.027, d_loss 0.083\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 288/390 d_loss_real= 0.141, d_loss_fake= 0.017, g_loss 4.125, d_loss 0.079\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 289/390 d_loss_real= 0.215, d_loss_fake= 0.017, g_loss 4.136, d_loss 0.116\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 290/390 d_loss_real= 0.108, d_loss_fake= 0.016, g_loss 4.173, d_loss 0.062\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 291/390 d_loss_real= 0.000, d_loss_fake= 0.018, g_loss 4.155, d_loss 0.009\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 48 Batch 292/390 d_loss_real= 0.165, d_loss_fake= 0.019, g_loss 4.050, d_loss 0.092\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 48 Batch 293/390 d_loss_real= 0.117, d_loss_fake= 0.018, g_loss 3.971, d_loss 0.068\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 48 Batch 294/390 d_loss_real= 0.213, d_loss_fake= 0.023, g_loss 3.700, d_loss 0.118\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48 Batch 295/390 d_loss_real= 0.015, d_loss_fake= 0.032, g_loss 3.310, d_loss 0.023\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 296/390 d_loss_real= 0.000, d_loss_fake= 0.063, g_loss 3.310, d_loss 0.032\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 297/390 d_loss_real= 0.085, d_loss_fake= 0.038, g_loss 3.528, d_loss 0.062\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 48 Batch 298/390 d_loss_real= 0.068, d_loss_fake= 0.028, g_loss 3.751, d_loss 0.048\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 299/390 d_loss_real= 0.000, d_loss_fake= 0.021, g_loss 3.924, d_loss 0.011\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48 Batch 300/390 d_loss_real= 0.235, d_loss_fake= 0.021, g_loss 3.954, d_loss 0.128\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 301/390 d_loss_real= 0.029, d_loss_fake= 0.022, g_loss 3.987, d_loss 0.025\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 48 Batch 302/390 d_loss_real= 0.000, d_loss_fake= 0.021, g_loss 3.948, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 303/390 d_loss_real= 0.007, d_loss_fake= 0.020, g_loss 3.988, d_loss 0.014\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 304/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 3.994, d_loss 0.010\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 305/390 d_loss_real= 0.009, d_loss_fake= 0.019, g_loss 4.043, d_loss 0.014\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 306/390 d_loss_real= 0.000, d_loss_fake= 0.018, g_loss 4.041, d_loss 0.009\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 48 Batch 307/390 d_loss_real= 0.118, d_loss_fake= 0.019, g_loss 4.010, d_loss 0.068\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 308/390 d_loss_real= 0.110, d_loss_fake= 0.021, g_loss 3.900, d_loss 0.065\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 48 Batch 309/390 d_loss_real= 0.000, d_loss_fake= 0.021, g_loss 3.856, d_loss 0.011\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 310/390 d_loss_real= 0.180, d_loss_fake= 0.032, g_loss 3.656, d_loss 0.106\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 311/390 d_loss_real= 0.000, d_loss_fake= 0.040, g_loss 3.434, d_loss 0.020\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 48 Batch 312/390 d_loss_real= 0.000, d_loss_fake= 0.050, g_loss 3.686, d_loss 0.025\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 313/390 d_loss_real= 0.021, d_loss_fake= 0.026, g_loss 4.015, d_loss 0.023\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 314/390 d_loss_real= 0.039, d_loss_fake= 0.017, g_loss 4.188, d_loss 0.028\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 315/390 d_loss_real= 0.091, d_loss_fake= 0.016, g_loss 4.203, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 316/390 d_loss_real= 0.109, d_loss_fake= 0.018, g_loss 4.152, d_loss 0.063\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48 Batch 317/390 d_loss_real= 0.105, d_loss_fake= 0.018, g_loss 4.228, d_loss 0.061\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 318/390 d_loss_real= 0.068, d_loss_fake= 0.018, g_loss 4.070, d_loss 0.043\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 48 Batch 319/390 d_loss_real= 0.169, d_loss_fake= 0.020, g_loss 4.024, d_loss 0.095\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 320/390 d_loss_real= 0.007, d_loss_fake= 0.020, g_loss 3.941, d_loss 0.013\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 321/390 d_loss_real= 0.123, d_loss_fake= 0.022, g_loss 3.735, d_loss 0.073\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 322/390 d_loss_real= 0.128, d_loss_fake= 0.029, g_loss 3.637, d_loss 0.078\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 48 Batch 323/390 d_loss_real= 0.062, d_loss_fake= 0.029, g_loss 3.595, d_loss 0.046\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 48 Batch 324/390 d_loss_real= 0.158, d_loss_fake= 0.053, g_loss 3.551, d_loss 0.105\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 325/390 d_loss_real= 0.067, d_loss_fake= 0.030, g_loss 3.690, d_loss 0.048\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 326/390 d_loss_real= 0.228, d_loss_fake= 0.026, g_loss 3.882, d_loss 0.127\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 327/390 d_loss_real= 0.202, d_loss_fake= 0.023, g_loss 3.882, d_loss 0.112\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 328/390 d_loss_real= 0.008, d_loss_fake= 0.023, g_loss 4.034, d_loss 0.016\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 48 Batch 329/390 d_loss_real= 0.195, d_loss_fake= 0.021, g_loss 4.027, d_loss 0.108\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48 Batch 330/390 d_loss_real= 0.066, d_loss_fake= 0.020, g_loss 4.015, d_loss 0.043\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48 Batch 331/390 d_loss_real= 0.126, d_loss_fake= 0.021, g_loss 3.948, d_loss 0.073\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48 Batch 332/390 d_loss_real= 0.031, d_loss_fake= 0.018, g_loss 3.925, d_loss 0.025\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 333/390 d_loss_real= 0.000, d_loss_fake= 0.021, g_loss 3.923, d_loss 0.010\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 334/390 d_loss_real= 0.140, d_loss_fake= 0.020, g_loss 3.898, d_loss 0.080\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 335/390 d_loss_real= 0.070, d_loss_fake= 0.023, g_loss 3.877, d_loss 0.047\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 336/390 d_loss_real= 0.047, d_loss_fake= 0.023, g_loss 3.814, d_loss 0.035\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 48 Batch 337/390 d_loss_real= 0.080, d_loss_fake= 0.027, g_loss 3.647, d_loss 0.054\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 48 Batch 338/390 d_loss_real= 0.000, d_loss_fake= 0.030, g_loss 3.532, d_loss 0.015\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 48 Batch 339/390 d_loss_real= 0.118, d_loss_fake= 0.034, g_loss 3.423, d_loss 0.076\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 340/390 d_loss_real= 0.057, d_loss_fake= 0.038, g_loss 3.329, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 341/390 d_loss_real= 0.004, d_loss_fake= 0.040, g_loss 3.340, d_loss 0.022\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 342/390 d_loss_real= 0.087, d_loss_fake= 0.040, g_loss 3.365, d_loss 0.063\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 343/390 d_loss_real= 0.066, d_loss_fake= 0.041, g_loss 3.328, d_loss 0.053\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 48 Batch 344/390 d_loss_real= 0.034, d_loss_fake= 0.042, g_loss 3.409, d_loss 0.038\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 345/390 d_loss_real= 0.100, d_loss_fake= 0.039, g_loss 3.561, d_loss 0.069\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 48 Batch 346/390 d_loss_real= 0.052, d_loss_fake= 0.032, g_loss 3.767, d_loss 0.042\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 48 Batch 347/390 d_loss_real= 0.067, d_loss_fake= 0.023, g_loss 3.994, d_loss 0.045\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 348/390 d_loss_real= 0.000, d_loss_fake= 0.016, g_loss 4.275, d_loss 0.008\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48 Batch 349/390 d_loss_real= 0.057, d_loss_fake= 0.015, g_loss 4.418, d_loss 0.036\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 350/390 d_loss_real= 0.000, d_loss_fake= 0.012, g_loss 4.514, d_loss 0.006\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 351/390 d_loss_real= 0.000, d_loss_fake= 0.011, g_loss 4.603, d_loss 0.006\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 352/390 d_loss_real= 0.071, d_loss_fake= 0.011, g_loss 4.617, d_loss 0.041\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 48 Batch 353/390 d_loss_real= 0.069, d_loss_fake= 0.010, g_loss 4.643, d_loss 0.039\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 48 Batch 354/390 d_loss_real= 0.034, d_loss_fake= 0.010, g_loss 4.619, d_loss 0.022\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 48 Batch 355/390 d_loss_real= 0.136, d_loss_fake= 0.011, g_loss 4.516, d_loss 0.074\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 356/390 d_loss_real= 0.043, d_loss_fake= 0.012, g_loss 4.480, d_loss 0.028\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 357/390 d_loss_real= 0.000, d_loss_fake= 0.013, g_loss 4.386, d_loss 0.006\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 48 Batch 358/390 d_loss_real= 0.115, d_loss_fake= 0.014, g_loss 4.223, d_loss 0.065\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 359/390 d_loss_real= 0.204, d_loss_fake= 0.017, g_loss 4.074, d_loss 0.111\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48 Batch 360/390 d_loss_real= 0.065, d_loss_fake= 0.021, g_loss 3.922, d_loss 0.043\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48 Batch 361/390 d_loss_real= 0.092, d_loss_fake= 0.029, g_loss 3.690, d_loss 0.060\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48 Batch 362/390 d_loss_real= 0.181, d_loss_fake= 0.040, g_loss 3.512, d_loss 0.110\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48 Batch 363/390 d_loss_real= 0.106, d_loss_fake= 0.042, g_loss 3.363, d_loss 0.074\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 364/390 d_loss_real= 0.004, d_loss_fake= 0.045, g_loss 3.590, d_loss 0.025\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 365/390 d_loss_real= 0.066, d_loss_fake= 0.025, g_loss 4.046, d_loss 0.046\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 48 Batch 366/390 d_loss_real= 0.085, d_loss_fake= 0.019, g_loss 4.207, d_loss 0.052\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 367/390 d_loss_real= 0.003, d_loss_fake= 0.015, g_loss 4.361, d_loss 0.009\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 48 Batch 368/390 d_loss_real= 0.136, d_loss_fake= 0.013, g_loss 4.439, d_loss 0.075\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48 Batch 369/390 d_loss_real= 0.079, d_loss_fake= 0.013, g_loss 4.482, d_loss 0.046\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 48 Batch 370/390 d_loss_real= 0.092, d_loss_fake= 0.012, g_loss 4.452, d_loss 0.052\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 48 Batch 371/390 d_loss_real= 0.134, d_loss_fake= 0.013, g_loss 4.320, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 372/390 d_loss_real= 0.095, d_loss_fake= 0.015, g_loss 4.163, d_loss 0.055\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 373/390 d_loss_real= 0.083, d_loss_fake= 0.018, g_loss 4.098, d_loss 0.050\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 48 Batch 374/390 d_loss_real= 0.000, d_loss_fake= 0.021, g_loss 3.984, d_loss 0.010\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 48 Batch 375/390 d_loss_real= 0.054, d_loss_fake= 0.020, g_loss 3.986, d_loss 0.037\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 48 Batch 376/390 d_loss_real= 0.035, d_loss_fake= 0.021, g_loss 3.909, d_loss 0.028\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 377/390 d_loss_real= 0.097, d_loss_fake= 0.024, g_loss 3.800, d_loss 0.060\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 378/390 d_loss_real= 0.061, d_loss_fake= 0.021, g_loss 3.976, d_loss 0.041\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 379/390 d_loss_real= 0.099, d_loss_fake= 0.022, g_loss 4.002, d_loss 0.060\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 380/390 d_loss_real= 0.134, d_loss_fake= 0.046, g_loss 3.791, d_loss 0.090\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 381/390 d_loss_real= 0.003, d_loss_fake= 0.037, g_loss 4.003, d_loss 0.020\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48 Batch 382/390 d_loss_real= 0.109, d_loss_fake= 0.016, g_loss 4.345, d_loss 0.063\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 48 Batch 383/390 d_loss_real= 0.051, d_loss_fake= 0.014, g_loss 4.477, d_loss 0.032\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 48 Batch 384/390 d_loss_real= 0.165, d_loss_fake= 0.013, g_loss 4.405, d_loss 0.089\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 385/390 d_loss_real= 0.182, d_loss_fake= 0.014, g_loss 4.274, d_loss 0.098\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48 Batch 386/390 d_loss_real= 0.000, d_loss_fake= 0.019, g_loss 4.080, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48 Batch 387/390 d_loss_real= 0.035, d_loss_fake= 0.022, g_loss 4.039, d_loss 0.029\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48 Batch 388/390 d_loss_real= 0.123, d_loss_fake= 0.020, g_loss 4.171, d_loss 0.071\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 48 Batch 389/390 d_loss_real= 0.065, d_loss_fake= 0.017, g_loss 4.280, d_loss 0.041\n",
            "2/2 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48 Batch 390/390 d_loss_real= 0.041, d_loss_fake= 0.017, g_loss 4.240, d_loss 0.029\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 1/390 d_loss_real= 0.119, d_loss_fake= 0.018, g_loss 4.263, d_loss 0.068\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 2/390 d_loss_real= 0.000, d_loss_fake= 0.016, g_loss 4.189, d_loss 0.008\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 3/390 d_loss_real= 0.000, d_loss_fake= 0.016, g_loss 4.276, d_loss 0.008\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 49 Batch 4/390 d_loss_real= 0.000, d_loss_fake= 0.014, g_loss 4.407, d_loss 0.007\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 5/390 d_loss_real= 0.164, d_loss_fake= 0.014, g_loss 4.463, d_loss 0.089\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 6/390 d_loss_real= 0.115, d_loss_fake= 0.013, g_loss 4.350, d_loss 0.064\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 49 Batch 7/390 d_loss_real= 0.120, d_loss_fake= 0.014, g_loss 4.321, d_loss 0.067\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 49 Batch 8/390 d_loss_real= 0.165, d_loss_fake= 0.017, g_loss 4.262, d_loss 0.091\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 49 Batch 9/390 d_loss_real= 0.122, d_loss_fake= 0.019, g_loss 3.950, d_loss 0.070\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 10/390 d_loss_real= 0.169, d_loss_fake= 0.021, g_loss 3.728, d_loss 0.095\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 11/390 d_loss_real= 0.000, d_loss_fake= 0.035, g_loss 3.636, d_loss 0.018\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 49 Batch 12/390 d_loss_real= 0.093, d_loss_fake= 0.059, g_loss 3.406, d_loss 0.076\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 13/390 d_loss_real= 0.057, d_loss_fake= 0.029, g_loss 3.765, d_loss 0.043\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 14/390 d_loss_real= 0.011, d_loss_fake= 0.023, g_loss 3.927, d_loss 0.017\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 15/390 d_loss_real= 0.000, d_loss_fake= 0.023, g_loss 4.024, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 16/390 d_loss_real= 0.091, d_loss_fake= 0.027, g_loss 4.008, d_loss 0.059\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 17/390 d_loss_real= 0.097, d_loss_fake= 0.023, g_loss 3.922, d_loss 0.060\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 18/390 d_loss_real= 0.044, d_loss_fake= 0.025, g_loss 3.990, d_loss 0.034\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 19/390 d_loss_real= 0.093, d_loss_fake= 0.021, g_loss 4.048, d_loss 0.057\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 49 Batch 20/390 d_loss_real= 0.158, d_loss_fake= 0.028, g_loss 3.837, d_loss 0.093\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 49 Batch 21/390 d_loss_real= 0.222, d_loss_fake= 0.028, g_loss 3.774, d_loss 0.125\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 49 Batch 22/390 d_loss_real= 0.194, d_loss_fake= 0.031, g_loss 3.542, d_loss 0.112\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 23/390 d_loss_real= 0.107, d_loss_fake= 0.035, g_loss 3.485, d_loss 0.071\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 49 Batch 24/390 d_loss_real= 0.060, d_loss_fake= 0.041, g_loss 3.391, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 25/390 d_loss_real= 0.000, d_loss_fake= 0.036, g_loss 3.608, d_loss 0.018\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 26/390 d_loss_real= 0.058, d_loss_fake= 0.031, g_loss 3.761, d_loss 0.044\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 49 Batch 27/390 d_loss_real= 0.000, d_loss_fake= 0.028, g_loss 3.959, d_loss 0.014\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 28/390 d_loss_real= 0.000, d_loss_fake= 0.022, g_loss 4.130, d_loss 0.011\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 29/390 d_loss_real= 0.100, d_loss_fake= 0.020, g_loss 4.086, d_loss 0.060\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 30/390 d_loss_real= 0.000, d_loss_fake= 0.018, g_loss 4.186, d_loss 0.009\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 31/390 d_loss_real= 0.115, d_loss_fake= 0.020, g_loss 4.245, d_loss 0.068\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 49 Batch 32/390 d_loss_real= 0.011, d_loss_fake= 0.020, g_loss 4.127, d_loss 0.015\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 49 Batch 33/390 d_loss_real= 0.149, d_loss_fake= 0.017, g_loss 4.185, d_loss 0.083\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 49 Batch 34/390 d_loss_real= 0.057, d_loss_fake= 0.019, g_loss 4.039, d_loss 0.038\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 35/390 d_loss_real= 0.000, d_loss_fake= 0.021, g_loss 4.050, d_loss 0.011\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 36/390 d_loss_real= 0.108, d_loss_fake= 0.021, g_loss 3.959, d_loss 0.064\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 49 Batch 37/390 d_loss_real= 0.001, d_loss_fake= 0.023, g_loss 3.919, d_loss 0.012\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 38/390 d_loss_real= 0.028, d_loss_fake= 0.028, g_loss 3.680, d_loss 0.028\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 39/390 d_loss_real= 0.049, d_loss_fake= 0.052, g_loss 3.656, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 40/390 d_loss_real= 0.087, d_loss_fake= 0.028, g_loss 3.943, d_loss 0.058\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 49 Batch 41/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 4.289, d_loss 0.010\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 42/390 d_loss_real= 0.015, d_loss_fake= 0.016, g_loss 4.444, d_loss 0.015\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 43/390 d_loss_real= 0.101, d_loss_fake= 0.017, g_loss 4.265, d_loss 0.059\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 44/390 d_loss_real= 0.113, d_loss_fake= 0.017, g_loss 4.210, d_loss 0.065\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 45/390 d_loss_real= 0.205, d_loss_fake= 0.017, g_loss 4.241, d_loss 0.111\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 49 Batch 46/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 4.074, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 47/390 d_loss_real= 0.142, d_loss_fake= 0.022, g_loss 3.939, d_loss 0.082\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 48/390 d_loss_real= 0.019, d_loss_fake= 0.023, g_loss 3.966, d_loss 0.021\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 49/390 d_loss_real= 0.052, d_loss_fake= 0.024, g_loss 3.711, d_loss 0.038\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 50/390 d_loss_real= 0.169, d_loss_fake= 0.043, g_loss 3.453, d_loss 0.106\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 49 Batch 51/390 d_loss_real= 0.098, d_loss_fake= 0.055, g_loss 3.397, d_loss 0.076\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 52/390 d_loss_real= 0.062, d_loss_fake= 0.042, g_loss 3.571, d_loss 0.052\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 53/390 d_loss_real= 0.080, d_loss_fake= 0.030, g_loss 3.684, d_loss 0.055\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 54/390 d_loss_real= 0.105, d_loss_fake= 0.029, g_loss 3.723, d_loss 0.067\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 55/390 d_loss_real= 0.114, d_loss_fake= 0.027, g_loss 3.750, d_loss 0.071\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 49 Batch 56/390 d_loss_real= 0.000, d_loss_fake= 0.027, g_loss 3.830, d_loss 0.014\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 49 Batch 57/390 d_loss_real= 0.117, d_loss_fake= 0.025, g_loss 3.792, d_loss 0.071\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 58/390 d_loss_real= 0.066, d_loss_fake= 0.026, g_loss 3.734, d_loss 0.046\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 59/390 d_loss_real= 0.129, d_loss_fake= 0.027, g_loss 3.608, d_loss 0.078\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 60/390 d_loss_real= 0.000, d_loss_fake= 0.031, g_loss 3.573, d_loss 0.015\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 61/390 d_loss_real= 0.025, d_loss_fake= 0.031, g_loss 3.607, d_loss 0.028\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 62/390 d_loss_real= 0.141, d_loss_fake= 0.031, g_loss 3.589, d_loss 0.086\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 49 Batch 63/390 d_loss_real= 0.026, d_loss_fake= 0.030, g_loss 3.573, d_loss 0.028\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 49 Batch 64/390 d_loss_real= 0.019, d_loss_fake= 0.032, g_loss 3.583, d_loss 0.025\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 49 Batch 65/390 d_loss_real= 0.086, d_loss_fake= 0.032, g_loss 3.512, d_loss 0.059\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 49 Batch 66/390 d_loss_real= 0.057, d_loss_fake= 0.026, g_loss 3.758, d_loss 0.042\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 67/390 d_loss_real= 0.065, d_loss_fake= 0.028, g_loss 3.682, d_loss 0.046\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 68/390 d_loss_real= 0.066, d_loss_fake= 0.025, g_loss 3.778, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 69/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 4.040, d_loss 0.010\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 49 Batch 70/390 d_loss_real= 0.189, d_loss_fake= 0.020, g_loss 3.979, d_loss 0.104\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 71/390 d_loss_real= 0.060, d_loss_fake= 0.020, g_loss 4.014, d_loss 0.040\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 72/390 d_loss_real= 0.000, d_loss_fake= 0.018, g_loss 4.095, d_loss 0.009\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 49 Batch 73/390 d_loss_real= 0.190, d_loss_fake= 0.019, g_loss 4.055, d_loss 0.104\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 74/390 d_loss_real= 0.209, d_loss_fake= 0.020, g_loss 4.013, d_loss 0.115\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 75/390 d_loss_real= 0.067, d_loss_fake= 0.020, g_loss 4.036, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 76/390 d_loss_real= 0.053, d_loss_fake= 0.019, g_loss 4.041, d_loss 0.036\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 77/390 d_loss_real= 0.231, d_loss_fake= 0.018, g_loss 4.007, d_loss 0.125\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 78/390 d_loss_real= 0.003, d_loss_fake= 0.019, g_loss 3.947, d_loss 0.011\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 79/390 d_loss_real= 0.074, d_loss_fake= 0.021, g_loss 3.956, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 80/390 d_loss_real= 0.186, d_loss_fake= 0.022, g_loss 3.831, d_loss 0.104\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 49 Batch 81/390 d_loss_real= 0.000, d_loss_fake= 0.028, g_loss 3.767, d_loss 0.014\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 82/390 d_loss_real= 0.132, d_loss_fake= 0.025, g_loss 3.840, d_loss 0.078\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 83/390 d_loss_real= 0.000, d_loss_fake= 0.021, g_loss 3.962, d_loss 0.011\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 49 Batch 84/390 d_loss_real= 0.070, d_loss_fake= 0.018, g_loss 4.124, d_loss 0.044\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 85/390 d_loss_real= 0.000, d_loss_fake= 0.016, g_loss 4.194, d_loss 0.008\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 86/390 d_loss_real= 0.019, d_loss_fake= 0.016, g_loss 4.185, d_loss 0.017\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 49 Batch 87/390 d_loss_real= 0.088, d_loss_fake= 0.016, g_loss 4.181, d_loss 0.052\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 49 Batch 88/390 d_loss_real= 0.068, d_loss_fake= 0.016, g_loss 4.138, d_loss 0.042\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 49 Batch 89/390 d_loss_real= 0.159, d_loss_fake= 0.018, g_loss 3.997, d_loss 0.088\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 49 Batch 90/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 4.018, d_loss 0.010\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 49 Batch 91/390 d_loss_real= 0.003, d_loss_fake= 0.022, g_loss 3.942, d_loss 0.012\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 49 Batch 92/390 d_loss_real= 0.212, d_loss_fake= 0.024, g_loss 3.936, d_loss 0.118\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 93/390 d_loss_real= 0.158, d_loss_fake= 0.026, g_loss 3.966, d_loss 0.092\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 94/390 d_loss_real= 0.077, d_loss_fake= 0.022, g_loss 3.991, d_loss 0.049\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 49 Batch 95/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 4.112, d_loss 0.010\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 96/390 d_loss_real= 0.070, d_loss_fake= 0.019, g_loss 4.203, d_loss 0.045\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 49 Batch 97/390 d_loss_real= 0.153, d_loss_fake= 0.017, g_loss 4.173, d_loss 0.085\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 98/390 d_loss_real= 0.070, d_loss_fake= 0.017, g_loss 4.217, d_loss 0.043\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 99/390 d_loss_real= 0.078, d_loss_fake= 0.016, g_loss 4.189, d_loss 0.047\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 100/390 d_loss_real= 0.118, d_loss_fake= 0.018, g_loss 4.031, d_loss 0.068\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 49 Batch 101/390 d_loss_real= 0.021, d_loss_fake= 0.019, g_loss 4.100, d_loss 0.020\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 102/390 d_loss_real= 0.130, d_loss_fake= 0.023, g_loss 3.674, d_loss 0.076\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 49 Batch 103/390 d_loss_real= 0.022, d_loss_fake= 0.037, g_loss 3.414, d_loss 0.030\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 49 Batch 104/390 d_loss_real= 0.134, d_loss_fake= 0.097, g_loss 3.920, d_loss 0.116\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 105/390 d_loss_real= 0.089, d_loss_fake= 0.016, g_loss 4.402, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 106/390 d_loss_real= 0.030, d_loss_fake= 0.012, g_loss 4.564, d_loss 0.021\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 107/390 d_loss_real= 0.070, d_loss_fake= 0.011, g_loss 4.576, d_loss 0.040\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 49 Batch 108/390 d_loss_real= 0.156, d_loss_fake= 0.012, g_loss 4.558, d_loss 0.084\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 109/390 d_loss_real= 0.002, d_loss_fake= 0.011, g_loss 4.549, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 110/390 d_loss_real= 0.121, d_loss_fake= 0.014, g_loss 4.401, d_loss 0.068\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 49 Batch 111/390 d_loss_real= 0.048, d_loss_fake= 0.015, g_loss 4.295, d_loss 0.032\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 49 Batch 112/390 d_loss_real= 0.153, d_loss_fake= 0.018, g_loss 4.040, d_loss 0.085\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 113/390 d_loss_real= 0.070, d_loss_fake= 0.028, g_loss 3.984, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 114/390 d_loss_real= 0.045, d_loss_fake= 0.028, g_loss 3.967, d_loss 0.036\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 115/390 d_loss_real= 0.200, d_loss_fake= 0.026, g_loss 3.997, d_loss 0.113\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 49 Batch 116/390 d_loss_real= 0.140, d_loss_fake= 0.027, g_loss 3.870, d_loss 0.083\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 49 Batch 117/390 d_loss_real= 0.106, d_loss_fake= 0.021, g_loss 3.926, d_loss 0.064\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 118/390 d_loss_real= 0.124, d_loss_fake= 0.023, g_loss 3.759, d_loss 0.073\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 49 Batch 119/390 d_loss_real= 0.071, d_loss_fake= 0.040, g_loss 3.668, d_loss 0.056\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 120/390 d_loss_real= 0.039, d_loss_fake= 0.037, g_loss 3.629, d_loss 0.038\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 121/390 d_loss_real= 0.000, d_loss_fake= 0.033, g_loss 3.879, d_loss 0.017\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 49 Batch 122/390 d_loss_real= 0.127, d_loss_fake= 0.022, g_loss 4.000, d_loss 0.075\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 123/390 d_loss_real= 0.216, d_loss_fake= 0.022, g_loss 3.824, d_loss 0.119\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 49 Batch 124/390 d_loss_real= 0.209, d_loss_fake= 0.031, g_loss 3.577, d_loss 0.120\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 49 Batch 125/390 d_loss_real= 0.111, d_loss_fake= 0.044, g_loss 3.404, d_loss 0.077\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 126/390 d_loss_real= 0.036, d_loss_fake= 0.041, g_loss 3.498, d_loss 0.039\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 127/390 d_loss_real= 0.095, d_loss_fake= 0.036, g_loss 3.631, d_loss 0.065\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 49 Batch 128/390 d_loss_real= 0.058, d_loss_fake= 0.025, g_loss 3.870, d_loss 0.042\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 49 Batch 129/390 d_loss_real= 0.068, d_loss_fake= 0.021, g_loss 4.040, d_loss 0.044\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 130/390 d_loss_real= 0.214, d_loss_fake= 0.019, g_loss 4.023, d_loss 0.117\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 131/390 d_loss_real= 0.323, d_loss_fake= 0.022, g_loss 3.789, d_loss 0.172\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 132/390 d_loss_real= 0.000, d_loss_fake= 0.026, g_loss 3.652, d_loss 0.013\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 133/390 d_loss_real= 0.012, d_loss_fake= 0.030, g_loss 3.587, d_loss 0.021\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 49 Batch 134/390 d_loss_real= 0.101, d_loss_fake= 0.031, g_loss 3.574, d_loss 0.066\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 135/390 d_loss_real= 0.028, d_loss_fake= 0.034, g_loss 3.451, d_loss 0.031\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 136/390 d_loss_real= 0.056, d_loss_fake= 0.037, g_loss 3.472, d_loss 0.047\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 137/390 d_loss_real= 0.010, d_loss_fake= 0.035, g_loss 3.510, d_loss 0.023\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 138/390 d_loss_real= 0.000, d_loss_fake= 0.031, g_loss 3.676, d_loss 0.015\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 49 Batch 139/390 d_loss_real= 0.057, d_loss_fake= 0.025, g_loss 3.846, d_loss 0.041\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 140/390 d_loss_real= 0.078, d_loss_fake= 0.023, g_loss 3.880, d_loss 0.051\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 141/390 d_loss_real= 0.084, d_loss_fake= 0.022, g_loss 3.899, d_loss 0.053\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 142/390 d_loss_real= 0.019, d_loss_fake= 0.022, g_loss 3.921, d_loss 0.020\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 143/390 d_loss_real= 0.119, d_loss_fake= 0.021, g_loss 3.974, d_loss 0.070\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 144/390 d_loss_real= 0.060, d_loss_fake= 0.019, g_loss 4.033, d_loss 0.039\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 145/390 d_loss_real= 0.047, d_loss_fake= 0.018, g_loss 4.090, d_loss 0.032\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 146/390 d_loss_real= 0.122, d_loss_fake= 0.017, g_loss 4.138, d_loss 0.069\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 147/390 d_loss_real= 0.127, d_loss_fake= 0.020, g_loss 3.928, d_loss 0.073\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 49 Batch 148/390 d_loss_real= 0.103, d_loss_fake= 0.030, g_loss 3.586, d_loss 0.067\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 149/390 d_loss_real= 0.048, d_loss_fake= 0.028, g_loss 3.636, d_loss 0.038\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 49 Batch 150/390 d_loss_real= 0.104, d_loss_fake= 0.024, g_loss 3.678, d_loss 0.064\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 49 Batch 151/390 d_loss_real= 0.032, d_loss_fake= 0.087, g_loss 3.261, d_loss 0.059\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 152/390 d_loss_real= 0.034, d_loss_fake= 0.028, g_loss 3.880, d_loss 0.031\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 153/390 d_loss_real= 0.158, d_loss_fake= 0.027, g_loss 3.866, d_loss 0.092\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 154/390 d_loss_real= 0.119, d_loss_fake= 0.024, g_loss 3.953, d_loss 0.071\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 155/390 d_loss_real= 0.000, d_loss_fake= 0.019, g_loss 4.084, d_loss 0.010\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 156/390 d_loss_real= 0.092, d_loss_fake= 0.017, g_loss 4.121, d_loss 0.055\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 157/390 d_loss_real= 0.000, d_loss_fake= 0.016, g_loss 4.308, d_loss 0.008\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 158/390 d_loss_real= 0.115, d_loss_fake= 0.017, g_loss 4.254, d_loss 0.066\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 159/390 d_loss_real= 0.177, d_loss_fake= 0.019, g_loss 4.076, d_loss 0.098\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 160/390 d_loss_real= 0.062, d_loss_fake= 0.027, g_loss 3.982, d_loss 0.044\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 161/390 d_loss_real= 0.105, d_loss_fake= 0.034, g_loss 3.853, d_loss 0.069\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 162/390 d_loss_real= 0.051, d_loss_fake= 0.022, g_loss 4.078, d_loss 0.036\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 163/390 d_loss_real= 0.089, d_loss_fake= 0.018, g_loss 4.201, d_loss 0.054\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 164/390 d_loss_real= 0.063, d_loss_fake= 0.015, g_loss 4.288, d_loss 0.039\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 49 Batch 165/390 d_loss_real= 0.174, d_loss_fake= 0.016, g_loss 4.201, d_loss 0.095\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 166/390 d_loss_real= 0.181, d_loss_fake= 0.016, g_loss 4.120, d_loss 0.099\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 49 Batch 167/390 d_loss_real= 0.058, d_loss_fake= 0.020, g_loss 3.954, d_loss 0.039\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 49 Batch 168/390 d_loss_real= 0.003, d_loss_fake= 0.024, g_loss 3.804, d_loss 0.014\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 169/390 d_loss_real= 0.223, d_loss_fake= 0.028, g_loss 3.700, d_loss 0.125\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 170/390 d_loss_real= 0.017, d_loss_fake= 0.034, g_loss 3.713, d_loss 0.026\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 171/390 d_loss_real= 0.057, d_loss_fake= 0.031, g_loss 3.570, d_loss 0.044\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 49 Batch 172/390 d_loss_real= 0.061, d_loss_fake= 0.031, g_loss 3.662, d_loss 0.046\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 49 Batch 173/390 d_loss_real= 0.087, d_loss_fake= 0.038, g_loss 3.657, d_loss 0.063\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 174/390 d_loss_real= 0.003, d_loss_fake= 0.028, g_loss 3.897, d_loss 0.016\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 175/390 d_loss_real= 0.000, d_loss_fake= 0.023, g_loss 4.100, d_loss 0.012\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 49 Batch 176/390 d_loss_real= 0.059, d_loss_fake= 0.022, g_loss 4.123, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 177/390 d_loss_real= 0.207, d_loss_fake= 0.019, g_loss 4.164, d_loss 0.113\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 178/390 d_loss_real= 0.000, d_loss_fake= 0.021, g_loss 4.026, d_loss 0.010\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 49 Batch 179/390 d_loss_real= 0.028, d_loss_fake= 0.024, g_loss 3.827, d_loss 0.026\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 49 Batch 180/390 d_loss_real= 0.101, d_loss_fake= 0.032, g_loss 3.691, d_loss 0.067\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 181/390 d_loss_real= 0.004, d_loss_fake= 0.035, g_loss 3.505, d_loss 0.020\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 182/390 d_loss_real= 0.070, d_loss_fake= 0.053, g_loss 3.305, d_loss 0.062\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 183/390 d_loss_real= 0.090, d_loss_fake= 0.068, g_loss 3.260, d_loss 0.079\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 184/390 d_loss_real= 0.129, d_loss_fake= 0.069, g_loss 3.171, d_loss 0.099\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 185/390 d_loss_real= 0.084, d_loss_fake= 0.066, g_loss 3.253, d_loss 0.075\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 49 Batch 186/390 d_loss_real= 0.137, d_loss_fake= 0.047, g_loss 3.652, d_loss 0.092\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 187/390 d_loss_real= 0.048, d_loss_fake= 0.031, g_loss 3.812, d_loss 0.039\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 188/390 d_loss_real= 0.087, d_loss_fake= 0.022, g_loss 3.998, d_loss 0.055\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 49 Batch 189/390 d_loss_real= 0.118, d_loss_fake= 0.021, g_loss 4.118, d_loss 0.069\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 49 Batch 190/390 d_loss_real= 0.167, d_loss_fake= 0.018, g_loss 4.123, d_loss 0.093\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 191/390 d_loss_real= 0.068, d_loss_fake= 0.018, g_loss 4.102, d_loss 0.043\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 192/390 d_loss_real= 0.064, d_loss_fake= 0.018, g_loss 4.110, d_loss 0.041\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 49 Batch 193/390 d_loss_real= 0.182, d_loss_fake= 0.021, g_loss 3.922, d_loss 0.102\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 194/390 d_loss_real= 0.001, d_loss_fake= 0.033, g_loss 3.729, d_loss 0.017\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 195/390 d_loss_real= 0.105, d_loss_fake= 0.041, g_loss 3.761, d_loss 0.073\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 196/390 d_loss_real= 0.000, d_loss_fake= 0.030, g_loss 3.980, d_loss 0.015\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 197/390 d_loss_real= 0.027, d_loss_fake= 0.021, g_loss 4.207, d_loss 0.024\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 198/390 d_loss_real= 0.101, d_loss_fake= 0.018, g_loss 4.304, d_loss 0.059\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 49 Batch 199/390 d_loss_real= 0.003, d_loss_fake= 0.017, g_loss 4.464, d_loss 0.010\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 200/390 d_loss_real= 0.125, d_loss_fake= 0.015, g_loss 4.402, d_loss 0.070\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 201/390 d_loss_real= 0.046, d_loss_fake= 0.018, g_loss 4.091, d_loss 0.032\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 202/390 d_loss_real= 0.233, d_loss_fake= 0.029, g_loss 3.813, d_loss 0.131\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 49 Batch 203/390 d_loss_real= 0.122, d_loss_fake= 0.047, g_loss 3.808, d_loss 0.084\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 204/390 d_loss_real= 0.006, d_loss_fake= 0.030, g_loss 3.828, d_loss 0.018\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 205/390 d_loss_real= 0.172, d_loss_fake= 0.025, g_loss 4.103, d_loss 0.099\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 206/390 d_loss_real= 0.187, d_loss_fake= 0.019, g_loss 4.198, d_loss 0.103\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 207/390 d_loss_real= 0.000, d_loss_fake= 0.016, g_loss 4.368, d_loss 0.008\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 208/390 d_loss_real= 0.000, d_loss_fake= 0.013, g_loss 4.498, d_loss 0.006\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 209/390 d_loss_real= 0.133, d_loss_fake= 0.011, g_loss 4.540, d_loss 0.072\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 210/390 d_loss_real= 0.201, d_loss_fake= 0.013, g_loss 4.439, d_loss 0.107\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 211/390 d_loss_real= 0.326, d_loss_fake= 0.015, g_loss 4.132, d_loss 0.170\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 49 Batch 212/390 d_loss_real= 0.233, d_loss_fake= 0.024, g_loss 3.583, d_loss 0.129\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 49 Batch 213/390 d_loss_real= 0.159, d_loss_fake= 0.052, g_loss 3.280, d_loss 0.105\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 214/390 d_loss_real= 0.217, d_loss_fake= 0.078, g_loss 3.396, d_loss 0.148\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 215/390 d_loss_real= 0.058, d_loss_fake= 0.029, g_loss 3.778, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 216/390 d_loss_real= 0.098, d_loss_fake= 0.023, g_loss 3.960, d_loss 0.060\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 217/390 d_loss_real= 0.136, d_loss_fake= 0.021, g_loss 3.888, d_loss 0.079\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 218/390 d_loss_real= 0.064, d_loss_fake= 0.021, g_loss 3.939, d_loss 0.043\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 219/390 d_loss_real= 0.000, d_loss_fake= 0.022, g_loss 3.861, d_loss 0.011\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 220/390 d_loss_real= 0.077, d_loss_fake= 0.025, g_loss 3.740, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 221/390 d_loss_real= 0.091, d_loss_fake= 0.029, g_loss 3.475, d_loss 0.060\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 222/390 d_loss_real= 0.065, d_loss_fake= 0.041, g_loss 3.197, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 223/390 d_loss_real= 0.069, d_loss_fake= 0.060, g_loss 3.364, d_loss 0.065\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 224/390 d_loss_real= 0.110, d_loss_fake= 0.039, g_loss 3.639, d_loss 0.075\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 225/390 d_loss_real= 0.160, d_loss_fake= 0.026, g_loss 3.850, d_loss 0.093\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 226/390 d_loss_real= 0.063, d_loss_fake= 0.020, g_loss 4.014, d_loss 0.041\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 227/390 d_loss_real= 0.001, d_loss_fake= 0.019, g_loss 4.140, d_loss 0.010\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 228/390 d_loss_real= 0.013, d_loss_fake= 0.017, g_loss 4.242, d_loss 0.015\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 229/390 d_loss_real= 0.001, d_loss_fake= 0.016, g_loss 4.269, d_loss 0.008\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 230/390 d_loss_real= 0.121, d_loss_fake= 0.015, g_loss 4.247, d_loss 0.068\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 49 Batch 231/390 d_loss_real= 0.092, d_loss_fake= 0.016, g_loss 4.232, d_loss 0.054\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 232/390 d_loss_real= 0.160, d_loss_fake= 0.018, g_loss 4.165, d_loss 0.089\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 233/390 d_loss_real= 0.046, d_loss_fake= 0.020, g_loss 4.011, d_loss 0.033\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 234/390 d_loss_real= 0.157, d_loss_fake= 0.021, g_loss 3.839, d_loss 0.089\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 235/390 d_loss_real= 0.059, d_loss_fake= 0.026, g_loss 3.591, d_loss 0.042\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 49 Batch 236/390 d_loss_real= 0.000, d_loss_fake= 0.035, g_loss 3.468, d_loss 0.017\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 237/390 d_loss_real= 0.000, d_loss_fake= 0.052, g_loss 3.435, d_loss 0.026\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 238/390 d_loss_real= 0.076, d_loss_fake= 0.036, g_loss 3.629, d_loss 0.056\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 239/390 d_loss_real= 0.000, d_loss_fake= 0.028, g_loss 3.800, d_loss 0.014\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 49 Batch 240/390 d_loss_real= 0.138, d_loss_fake= 0.022, g_loss 4.010, d_loss 0.080\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 241/390 d_loss_real= 0.049, d_loss_fake= 0.020, g_loss 4.058, d_loss 0.035\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 49 Batch 242/390 d_loss_real= 0.231, d_loss_fake= 0.021, g_loss 3.763, d_loss 0.126\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 49 Batch 243/390 d_loss_real= 0.039, d_loss_fake= 0.048, g_loss 3.434, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 244/390 d_loss_real= 0.061, d_loss_fake= 0.077, g_loss 3.640, d_loss 0.069\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 245/390 d_loss_real= 0.147, d_loss_fake= 0.027, g_loss 4.051, d_loss 0.087\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 49 Batch 246/390 d_loss_real= 0.001, d_loss_fake= 0.018, g_loss 4.354, d_loss 0.009\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 247/390 d_loss_real= 0.074, d_loss_fake= 0.013, g_loss 4.504, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 248/390 d_loss_real= 0.012, d_loss_fake= 0.011, g_loss 4.534, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 249/390 d_loss_real= 0.111, d_loss_fake= 0.014, g_loss 4.448, d_loss 0.062\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 250/390 d_loss_real= 0.000, d_loss_fake= 0.013, g_loss 4.422, d_loss 0.007\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 49 Batch 251/390 d_loss_real= 0.071, d_loss_fake= 0.014, g_loss 4.411, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 252/390 d_loss_real= 0.019, d_loss_fake= 0.014, g_loss 4.317, d_loss 0.017\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 253/390 d_loss_real= 0.020, d_loss_fake= 0.019, g_loss 4.142, d_loss 0.020\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 49 Batch 254/390 d_loss_real= 0.115, d_loss_fake= 0.029, g_loss 3.985, d_loss 0.072\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 49 Batch 255/390 d_loss_real= 0.000, d_loss_fake= 0.041, g_loss 4.057, d_loss 0.020\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 256/390 d_loss_real= 0.124, d_loss_fake= 0.038, g_loss 4.248, d_loss 0.081\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 49 Batch 257/390 d_loss_real= 0.119, d_loss_fake= 0.014, g_loss 4.431, d_loss 0.067\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 258/390 d_loss_real= 0.071, d_loss_fake= 0.014, g_loss 4.405, d_loss 0.042\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 259/390 d_loss_real= 0.000, d_loss_fake= 0.012, g_loss 4.495, d_loss 0.006\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 260/390 d_loss_real= 0.012, d_loss_fake= 0.013, g_loss 4.485, d_loss 0.013\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 261/390 d_loss_real= 0.000, d_loss_fake= 0.012, g_loss 4.503, d_loss 0.006\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 49 Batch 262/390 d_loss_real= 0.186, d_loss_fake= 0.014, g_loss 4.281, d_loss 0.100\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 263/390 d_loss_real= 0.030, d_loss_fake= 0.020, g_loss 4.151, d_loss 0.025\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 264/390 d_loss_real= 0.188, d_loss_fake= 0.032, g_loss 3.758, d_loss 0.110\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 265/390 d_loss_real= 0.239, d_loss_fake= 0.132, g_loss 3.922, d_loss 0.186\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 49 Batch 266/390 d_loss_real= 0.000, d_loss_fake= 0.015, g_loss 4.868, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 267/390 d_loss_real= 0.194, d_loss_fake= 0.009, g_loss 4.983, d_loss 0.101\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 268/390 d_loss_real= 0.024, d_loss_fake= 0.010, g_loss 4.980, d_loss 0.017\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 49 Batch 269/390 d_loss_real= 0.113, d_loss_fake= 0.010, g_loss 4.823, d_loss 0.061\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 49 Batch 270/390 d_loss_real= 0.081, d_loss_fake= 0.010, g_loss 4.637, d_loss 0.045\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 271/390 d_loss_real= 0.297, d_loss_fake= 0.012, g_loss 4.504, d_loss 0.154\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 272/390 d_loss_real= 0.031, d_loss_fake= 0.013, g_loss 4.314, d_loss 0.022\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 273/390 d_loss_real= 0.086, d_loss_fake= 0.015, g_loss 4.270, d_loss 0.051\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 49 Batch 274/390 d_loss_real= 0.162, d_loss_fake= 0.018, g_loss 4.013, d_loss 0.090\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 275/390 d_loss_real= 0.136, d_loss_fake= 0.024, g_loss 3.903, d_loss 0.080\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 276/390 d_loss_real= 0.040, d_loss_fake= 0.034, g_loss 3.701, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 277/390 d_loss_real= 0.096, d_loss_fake= 0.055, g_loss 3.399, d_loss 0.076\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 49 Batch 278/390 d_loss_real= 0.154, d_loss_fake= 0.049, g_loss 3.452, d_loss 0.102\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 279/390 d_loss_real= 0.063, d_loss_fake= 0.044, g_loss 3.523, d_loss 0.054\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 280/390 d_loss_real= 0.005, d_loss_fake= 0.030, g_loss 3.881, d_loss 0.018\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 49 Batch 281/390 d_loss_real= 0.192, d_loss_fake= 0.027, g_loss 3.881, d_loss 0.110\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 282/390 d_loss_real= 0.149, d_loss_fake= 0.023, g_loss 3.875, d_loss 0.086\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 49 Batch 283/390 d_loss_real= 0.001, d_loss_fake= 0.021, g_loss 3.874, d_loss 0.011\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 284/390 d_loss_real= 0.054, d_loss_fake= 0.023, g_loss 3.905, d_loss 0.038\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 285/390 d_loss_real= 0.238, d_loss_fake= 0.020, g_loss 3.852, d_loss 0.129\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 49 Batch 286/390 d_loss_real= 0.104, d_loss_fake= 0.024, g_loss 3.743, d_loss 0.064\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 49 Batch 287/390 d_loss_real= 0.000, d_loss_fake= 0.026, g_loss 3.678, d_loss 0.013\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 288/390 d_loss_real= 0.124, d_loss_fake= 0.028, g_loss 3.581, d_loss 0.076\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 49 Batch 289/390 d_loss_real= 0.066, d_loss_fake= 0.030, g_loss 3.576, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 290/390 d_loss_real= 0.046, d_loss_fake= 0.033, g_loss 3.551, d_loss 0.039\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 49 Batch 291/390 d_loss_real= 0.061, d_loss_fake= 0.032, g_loss 3.538, d_loss 0.046\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 292/390 d_loss_real= 0.064, d_loss_fake= 0.033, g_loss 3.564, d_loss 0.049\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 49 Batch 293/390 d_loss_real= 0.021, d_loss_fake= 0.033, g_loss 3.535, d_loss 0.027\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 49 Batch 294/390 d_loss_real= 0.097, d_loss_fake= 0.034, g_loss 3.579, d_loss 0.066\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 49 Batch 295/390 d_loss_real= 0.052, d_loss_fake= 0.031, g_loss 3.575, d_loss 0.042\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 49 Batch 296/390 d_loss_real= 0.114, d_loss_fake= 0.031, g_loss 3.667, d_loss 0.072\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 49 Batch 297/390 d_loss_real= 0.001, d_loss_fake= 0.027, g_loss 3.758, d_loss 0.014\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 49 Batch 298/390 d_loss_real= 0.000, d_loss_fake= 0.023, g_loss 3.899, d_loss 0.012\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 49 Batch 299/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 3.999, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 300/390 d_loss_real= 0.025, d_loss_fake= 0.018, g_loss 4.076, d_loss 0.022\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 49 Batch 301/390 d_loss_real= 0.083, d_loss_fake= 0.018, g_loss 4.133, d_loss 0.050\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 49 Batch 302/390 d_loss_real= 0.268, d_loss_fake= 0.017, g_loss 4.055, d_loss 0.143\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 303/390 d_loss_real= 0.007, d_loss_fake= 0.019, g_loss 4.003, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 304/390 d_loss_real= 0.052, d_loss_fake= 0.020, g_loss 3.923, d_loss 0.036\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 305/390 d_loss_real= 0.115, d_loss_fake= 0.026, g_loss 3.766, d_loss 0.070\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 49 Batch 306/390 d_loss_real= 0.080, d_loss_fake= 0.032, g_loss 3.560, d_loss 0.056\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 49 Batch 307/390 d_loss_real= 0.141, d_loss_fake= 0.047, g_loss 3.526, d_loss 0.094\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 49 Batch 308/390 d_loss_real= 0.053, d_loss_fake= 0.074, g_loss 3.878, d_loss 0.063\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 309/390 d_loss_real= 0.177, d_loss_fake= 0.018, g_loss 4.229, d_loss 0.097\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 310/390 d_loss_real= 0.070, d_loss_fake= 0.014, g_loss 4.376, d_loss 0.042\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 311/390 d_loss_real= 0.084, d_loss_fake= 0.012, g_loss 4.447, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 312/390 d_loss_real= 0.000, d_loss_fake= 0.013, g_loss 4.353, d_loss 0.006\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 313/390 d_loss_real= 0.217, d_loss_fake= 0.014, g_loss 4.364, d_loss 0.115\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 49 Batch 314/390 d_loss_real= 0.024, d_loss_fake= 0.014, g_loss 4.324, d_loss 0.019\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 49 Batch 315/390 d_loss_real= 0.145, d_loss_fake= 0.015, g_loss 4.233, d_loss 0.080\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 49 Batch 316/390 d_loss_real= 0.267, d_loss_fake= 0.016, g_loss 4.069, d_loss 0.141\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 49 Batch 317/390 d_loss_real= 0.001, d_loss_fake= 0.018, g_loss 3.990, d_loss 0.010\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 318/390 d_loss_real= 0.036, d_loss_fake= 0.020, g_loss 3.835, d_loss 0.028\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 319/390 d_loss_real= 0.115, d_loss_fake= 0.023, g_loss 3.675, d_loss 0.069\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 320/390 d_loss_real= 0.084, d_loss_fake= 0.032, g_loss 3.332, d_loss 0.058\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 49 Batch 321/390 d_loss_real= 0.124, d_loss_fake= 0.057, g_loss 2.942, d_loss 0.090\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 49 Batch 322/390 d_loss_real= 0.130, d_loss_fake= 0.083, g_loss 3.038, d_loss 0.107\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 49 Batch 323/390 d_loss_real= 0.014, d_loss_fake= 0.053, g_loss 3.528, d_loss 0.034\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 324/390 d_loss_real= 0.000, d_loss_fake= 0.026, g_loss 3.829, d_loss 0.013\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 325/390 d_loss_real= 0.124, d_loss_fake= 0.022, g_loss 3.977, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 326/390 d_loss_real= 0.197, d_loss_fake= 0.020, g_loss 4.024, d_loss 0.108\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 49 Batch 327/390 d_loss_real= 0.064, d_loss_fake= 0.019, g_loss 4.009, d_loss 0.042\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 49 Batch 328/390 d_loss_real= 0.060, d_loss_fake= 0.018, g_loss 4.024, d_loss 0.039\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 49 Batch 329/390 d_loss_real= 0.041, d_loss_fake= 0.019, g_loss 3.939, d_loss 0.030\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 330/390 d_loss_real= 0.062, d_loss_fake= 0.019, g_loss 3.996, d_loss 0.041\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 49 Batch 331/390 d_loss_real= 0.001, d_loss_fake= 0.020, g_loss 3.971, d_loss 0.010\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 332/390 d_loss_real= 0.002, d_loss_fake= 0.022, g_loss 3.988, d_loss 0.012\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 49 Batch 333/390 d_loss_real= 0.130, d_loss_fake= 0.020, g_loss 3.997, d_loss 0.075\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 334/390 d_loss_real= 0.057, d_loss_fake= 0.019, g_loss 3.985, d_loss 0.038\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 49 Batch 335/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 3.973, d_loss 0.010\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 336/390 d_loss_real= 0.054, d_loss_fake= 0.020, g_loss 3.950, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 337/390 d_loss_real= 0.099, d_loss_fake= 0.021, g_loss 3.867, d_loss 0.060\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 338/390 d_loss_real= 0.043, d_loss_fake= 0.023, g_loss 3.790, d_loss 0.033\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 49 Batch 339/390 d_loss_real= 0.000, d_loss_fake= 0.025, g_loss 3.757, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 340/390 d_loss_real= 0.036, d_loss_fake= 0.027, g_loss 3.673, d_loss 0.032\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 341/390 d_loss_real= 0.000, d_loss_fake= 0.030, g_loss 3.707, d_loss 0.015\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 49 Batch 342/390 d_loss_real= 0.000, d_loss_fake= 0.027, g_loss 3.857, d_loss 0.014\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 49 Batch 343/390 d_loss_real= 0.000, d_loss_fake= 0.021, g_loss 4.020, d_loss 0.011\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 49 Batch 344/390 d_loss_real= 0.071, d_loss_fake= 0.019, g_loss 4.128, d_loss 0.045\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 345/390 d_loss_real= 0.007, d_loss_fake= 0.017, g_loss 4.233, d_loss 0.012\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 49 Batch 346/390 d_loss_real= 0.141, d_loss_fake= 0.017, g_loss 4.224, d_loss 0.079\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 49 Batch 347/390 d_loss_real= 0.092, d_loss_fake= 0.015, g_loss 4.216, d_loss 0.054\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 49 Batch 348/390 d_loss_real= 0.010, d_loss_fake= 0.016, g_loss 4.160, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 349/390 d_loss_real= 0.076, d_loss_fake= 0.017, g_loss 4.141, d_loss 0.047\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 350/390 d_loss_real= 0.074, d_loss_fake= 0.017, g_loss 4.052, d_loss 0.045\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 351/390 d_loss_real= 0.000, d_loss_fake= 0.019, g_loss 4.170, d_loss 0.010\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 352/390 d_loss_real= 0.034, d_loss_fake= 0.018, g_loss 4.111, d_loss 0.026\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 353/390 d_loss_real= 0.089, d_loss_fake= 0.020, g_loss 3.993, d_loss 0.055\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 49 Batch 354/390 d_loss_real= 0.137, d_loss_fake= 0.021, g_loss 3.977, d_loss 0.079\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 355/390 d_loss_real= 0.069, d_loss_fake= 0.018, g_loss 4.101, d_loss 0.043\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 356/390 d_loss_real= 0.000, d_loss_fake= 0.018, g_loss 4.155, d_loss 0.009\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 357/390 d_loss_real= 0.220, d_loss_fake= 0.016, g_loss 4.172, d_loss 0.118\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 358/390 d_loss_real= 0.086, d_loss_fake= 0.030, g_loss 3.909, d_loss 0.058\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 49 Batch 359/390 d_loss_real= 0.001, d_loss_fake= 0.024, g_loss 3.977, d_loss 0.012\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 360/390 d_loss_real= 0.124, d_loss_fake= 0.016, g_loss 4.251, d_loss 0.070\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 361/390 d_loss_real= 0.008, d_loss_fake= 0.028, g_loss 3.947, d_loss 0.018\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 362/390 d_loss_real= 0.044, d_loss_fake= 0.018, g_loss 4.104, d_loss 0.031\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 363/390 d_loss_real= 0.203, d_loss_fake= 0.016, g_loss 4.141, d_loss 0.110\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 364/390 d_loss_real= 0.001, d_loss_fake= 0.032, g_loss 3.907, d_loss 0.016\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 49 Batch 365/390 d_loss_real= 0.078, d_loss_fake= 0.026, g_loss 3.916, d_loss 0.052\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 366/390 d_loss_real= 0.000, d_loss_fake= 0.022, g_loss 4.100, d_loss 0.011\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 49 Batch 367/390 d_loss_real= 0.151, d_loss_fake= 0.030, g_loss 4.066, d_loss 0.091\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 368/390 d_loss_real= 0.225, d_loss_fake= 0.021, g_loss 4.195, d_loss 0.123\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 369/390 d_loss_real= 0.085, d_loss_fake= 0.013, g_loss 4.247, d_loss 0.049\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 49 Batch 370/390 d_loss_real= 0.124, d_loss_fake= 0.036, g_loss 3.850, d_loss 0.080\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 371/390 d_loss_real= 0.022, d_loss_fake= 0.032, g_loss 3.939, d_loss 0.027\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 372/390 d_loss_real= 0.021, d_loss_fake= 0.028, g_loss 4.033, d_loss 0.025\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 373/390 d_loss_real= 0.029, d_loss_fake= 0.020, g_loss 4.230, d_loss 0.024\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 374/390 d_loss_real= 0.010, d_loss_fake= 0.014, g_loss 4.535, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 375/390 d_loss_real= 0.133, d_loss_fake= 0.016, g_loss 4.430, d_loss 0.074\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 376/390 d_loss_real= 0.101, d_loss_fake= 0.014, g_loss 4.440, d_loss 0.058\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 377/390 d_loss_real= 0.081, d_loss_fake= 0.011, g_loss 4.494, d_loss 0.046\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 49 Batch 378/390 d_loss_real= 0.028, d_loss_fake= 0.023, g_loss 4.057, d_loss 0.025\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 379/390 d_loss_real= 0.202, d_loss_fake= 0.023, g_loss 4.142, d_loss 0.113\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49 Batch 380/390 d_loss_real= 0.059, d_loss_fake= 0.013, g_loss 4.511, d_loss 0.036\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 49 Batch 381/390 d_loss_real= 0.094, d_loss_fake= 0.018, g_loss 4.355, d_loss 0.056\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 382/390 d_loss_real= 0.036, d_loss_fake= 0.014, g_loss 4.493, d_loss 0.025\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49 Batch 383/390 d_loss_real= 0.000, d_loss_fake= 0.014, g_loss 4.448, d_loss 0.007\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49 Batch 384/390 d_loss_real= 0.130, d_loss_fake= 0.013, g_loss 4.543, d_loss 0.071\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 49 Batch 385/390 d_loss_real= 0.370, d_loss_fake= 0.015, g_loss 4.191, d_loss 0.192\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 49 Batch 386/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 4.189, d_loss 0.010\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 387/390 d_loss_real= 0.000, d_loss_fake= 0.015, g_loss 4.350, d_loss 0.008\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 388/390 d_loss_real= 0.065, d_loss_fake= 0.021, g_loss 4.154, d_loss 0.043\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49 Batch 389/390 d_loss_real= 0.033, d_loss_fake= 0.016, g_loss 4.345, d_loss 0.024\n",
            "2/2 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49 Batch 390/390 d_loss_real= 0.124, d_loss_fake= 0.013, g_loss 4.407, d_loss 0.068\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 50 Batch 1/390 d_loss_real= 0.163, d_loss_fake= 0.019, g_loss 4.150, d_loss 0.091\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 50 Batch 2/390 d_loss_real= 0.064, d_loss_fake= 0.016, g_loss 4.207, d_loss 0.040\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 50 Batch 3/390 d_loss_real= 0.068, d_loss_fake= 0.016, g_loss 4.178, d_loss 0.042\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 50 Batch 4/390 d_loss_real= 0.026, d_loss_fake= 0.019, g_loss 4.048, d_loss 0.023\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 50 Batch 5/390 d_loss_real= 0.175, d_loss_fake= 0.026, g_loss 3.710, d_loss 0.101\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 50 Batch 6/390 d_loss_real= 0.001, d_loss_fake= 0.028, g_loss 3.637, d_loss 0.014\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 50 Batch 7/390 d_loss_real= 0.000, d_loss_fake= 0.030, g_loss 3.819, d_loss 0.015\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 8/390 d_loss_real= 0.049, d_loss_fake= 0.030, g_loss 3.705, d_loss 0.039\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 9/390 d_loss_real= 0.057, d_loss_fake= 0.025, g_loss 3.734, d_loss 0.041\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 10/390 d_loss_real= 0.067, d_loss_fake= 0.025, g_loss 3.763, d_loss 0.046\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 11/390 d_loss_real= 0.038, d_loss_fake= 0.029, g_loss 3.851, d_loss 0.034\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 12/390 d_loss_real= 0.063, d_loss_fake= 0.024, g_loss 3.853, d_loss 0.044\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 50 Batch 13/390 d_loss_real= 0.051, d_loss_fake= 0.024, g_loss 3.902, d_loss 0.038\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 50 Batch 14/390 d_loss_real= 0.097, d_loss_fake= 0.024, g_loss 3.846, d_loss 0.060\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 50 Batch 15/390 d_loss_real= 0.195, d_loss_fake= 0.024, g_loss 3.831, d_loss 0.110\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 50 Batch 16/390 d_loss_real= 0.023, d_loss_fake= 0.025, g_loss 3.811, d_loss 0.024\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 17/390 d_loss_real= 0.020, d_loss_fake= 0.024, g_loss 3.817, d_loss 0.022\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 18/390 d_loss_real= 0.000, d_loss_fake= 0.024, g_loss 3.877, d_loss 0.012\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 50 Batch 19/390 d_loss_real= 0.068, d_loss_fake= 0.020, g_loss 4.059, d_loss 0.044\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 20/390 d_loss_real= 0.000, d_loss_fake= 0.018, g_loss 4.101, d_loss 0.009\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 21/390 d_loss_real= 0.076, d_loss_fake= 0.018, g_loss 4.069, d_loss 0.047\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 22/390 d_loss_real= 0.210, d_loss_fake= 0.018, g_loss 3.855, d_loss 0.114\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 50 Batch 23/390 d_loss_real= 0.068, d_loss_fake= 0.029, g_loss 3.668, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 24/390 d_loss_real= 0.066, d_loss_fake= 0.036, g_loss 3.622, d_loss 0.051\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 50 Batch 25/390 d_loss_real= 0.031, d_loss_fake= 0.045, g_loss 3.689, d_loss 0.038\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 50 Batch 26/390 d_loss_real= 0.033, d_loss_fake= 0.025, g_loss 3.951, d_loss 0.029\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 50 Batch 27/390 d_loss_real= 0.070, d_loss_fake= 0.024, g_loss 4.239, d_loss 0.047\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 50 Batch 28/390 d_loss_real= 0.142, d_loss_fake= 0.018, g_loss 4.254, d_loss 0.080\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 29/390 d_loss_real= 0.070, d_loss_fake= 0.016, g_loss 4.347, d_loss 0.043\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 30/390 d_loss_real= 0.217, d_loss_fake= 0.016, g_loss 4.337, d_loss 0.116\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 50 Batch 31/390 d_loss_real= 0.047, d_loss_fake= 0.015, g_loss 4.296, d_loss 0.031\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 50 Batch 32/390 d_loss_real= 0.180, d_loss_fake= 0.019, g_loss 4.019, d_loss 0.099\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 50 Batch 33/390 d_loss_real= 0.036, d_loss_fake= 0.030, g_loss 3.922, d_loss 0.033\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 34/390 d_loss_real= 0.000, d_loss_fake= 0.030, g_loss 3.970, d_loss 0.015\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 35/390 d_loss_real= 0.075, d_loss_fake= 0.017, g_loss 4.368, d_loss 0.046\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 50 Batch 36/390 d_loss_real= 0.293, d_loss_fake= 0.014, g_loss 4.280, d_loss 0.154\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 37/390 d_loss_real= 0.000, d_loss_fake= 0.018, g_loss 4.278, d_loss 0.009\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 38/390 d_loss_real= 0.000, d_loss_fake= 0.016, g_loss 4.310, d_loss 0.008\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 50 Batch 39/390 d_loss_real= 0.014, d_loss_fake= 0.016, g_loss 4.358, d_loss 0.015\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 40/390 d_loss_real= 0.138, d_loss_fake= 0.016, g_loss 4.227, d_loss 0.077\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 41/390 d_loss_real= 0.073, d_loss_fake= 0.020, g_loss 4.244, d_loss 0.046\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 50 Batch 42/390 d_loss_real= 0.012, d_loss_fake= 0.019, g_loss 4.262, d_loss 0.015\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 43/390 d_loss_real= 0.079, d_loss_fake= 0.017, g_loss 4.240, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 44/390 d_loss_real= 0.118, d_loss_fake= 0.018, g_loss 4.201, d_loss 0.068\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 50 Batch 45/390 d_loss_real= 0.104, d_loss_fake= 0.017, g_loss 4.156, d_loss 0.061\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 46/390 d_loss_real= 0.116, d_loss_fake= 0.027, g_loss 4.058, d_loss 0.072\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 47/390 d_loss_real= 0.021, d_loss_fake= 0.026, g_loss 4.071, d_loss 0.023\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 50 Batch 48/390 d_loss_real= 0.074, d_loss_fake= 0.023, g_loss 4.074, d_loss 0.048\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 50 Batch 49/390 d_loss_real= 0.076, d_loss_fake= 0.020, g_loss 4.046, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 50/390 d_loss_real= 0.097, d_loss_fake= 0.024, g_loss 4.013, d_loss 0.061\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 50 Batch 51/390 d_loss_real= 0.075, d_loss_fake= 0.020, g_loss 3.986, d_loss 0.048\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 52/390 d_loss_real= 0.003, d_loss_fake= 0.019, g_loss 4.111, d_loss 0.011\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 50 Batch 53/390 d_loss_real= 0.000, d_loss_fake= 0.017, g_loss 4.226, d_loss 0.008\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 50 Batch 54/390 d_loss_real= 0.129, d_loss_fake= 0.015, g_loss 4.256, d_loss 0.072\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 55/390 d_loss_real= 0.220, d_loss_fake= 0.015, g_loss 4.292, d_loss 0.117\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 56/390 d_loss_real= 0.080, d_loss_fake= 0.015, g_loss 4.312, d_loss 0.047\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 57/390 d_loss_real= 0.100, d_loss_fake= 0.016, g_loss 4.216, d_loss 0.058\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 50 Batch 58/390 d_loss_real= 0.083, d_loss_fake= 0.018, g_loss 3.991, d_loss 0.051\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 59/390 d_loss_real= 0.174, d_loss_fake= 0.023, g_loss 3.796, d_loss 0.099\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 60/390 d_loss_real= 0.001, d_loss_fake= 0.031, g_loss 3.617, d_loss 0.016\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 50 Batch 61/390 d_loss_real= 0.000, d_loss_fake= 0.032, g_loss 3.734, d_loss 0.016\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 62/390 d_loss_real= 0.000, d_loss_fake= 0.024, g_loss 3.986, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 63/390 d_loss_real= 0.269, d_loss_fake= 0.021, g_loss 3.984, d_loss 0.145\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 50 Batch 64/390 d_loss_real= 0.156, d_loss_fake= 0.023, g_loss 3.909, d_loss 0.090\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 65/390 d_loss_real= 0.010, d_loss_fake= 0.024, g_loss 3.990, d_loss 0.017\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 50 Batch 66/390 d_loss_real= 0.043, d_loss_fake= 0.022, g_loss 3.967, d_loss 0.032\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 50 Batch 67/390 d_loss_real= 0.092, d_loss_fake= 0.024, g_loss 3.855, d_loss 0.058\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 68/390 d_loss_real= 0.123, d_loss_fake= 0.029, g_loss 3.654, d_loss 0.076\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 69/390 d_loss_real= 0.070, d_loss_fake= 0.031, g_loss 3.689, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 70/390 d_loss_real= 0.109, d_loss_fake= 0.025, g_loss 4.066, d_loss 0.067\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 50 Batch 71/390 d_loss_real= 0.000, d_loss_fake= 0.028, g_loss 4.051, d_loss 0.014\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 72/390 d_loss_real= 0.076, d_loss_fake= 0.018, g_loss 4.413, d_loss 0.047\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 50 Batch 73/390 d_loss_real= 0.023, d_loss_fake= 0.013, g_loss 4.628, d_loss 0.018\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 74/390 d_loss_real= 0.000, d_loss_fake= 0.010, g_loss 4.874, d_loss 0.005\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 50 Batch 75/390 d_loss_real= 0.070, d_loss_fake= 0.009, g_loss 4.794, d_loss 0.039\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 76/390 d_loss_real= 0.008, d_loss_fake= 0.007, g_loss 5.057, d_loss 0.007\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 50 Batch 77/390 d_loss_real= 0.157, d_loss_fake= 0.010, g_loss 4.315, d_loss 0.083\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 78/390 d_loss_real= 0.117, d_loss_fake= 0.060, g_loss 4.965, d_loss 0.089\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 50 Batch 79/390 d_loss_real= 0.106, d_loss_fake= 0.008, g_loss 5.439, d_loss 0.057\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 80/390 d_loss_real= 0.057, d_loss_fake= 0.004, g_loss 5.812, d_loss 0.031\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 50 Batch 81/390 d_loss_real= 0.082, d_loss_fake= 0.005, g_loss 5.746, d_loss 0.044\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 82/390 d_loss_real= 0.290, d_loss_fake= 0.005, g_loss 5.200, d_loss 0.148\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 83/390 d_loss_real= 0.018, d_loss_fake= 0.008, g_loss 4.907, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 84/390 d_loss_real= 0.088, d_loss_fake= 0.014, g_loss 4.484, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 85/390 d_loss_real= 0.098, d_loss_fake= 0.019, g_loss 4.161, d_loss 0.059\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 86/390 d_loss_real= 0.196, d_loss_fake= 0.024, g_loss 3.814, d_loss 0.110\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 87/390 d_loss_real= 0.073, d_loss_fake= 0.034, g_loss 3.299, d_loss 0.054\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 88/390 d_loss_real= 0.047, d_loss_fake= 0.047, g_loss 3.064, d_loss 0.047\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 89/390 d_loss_real= 0.000, d_loss_fake= 0.072, g_loss 2.714, d_loss 0.036\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 50 Batch 90/390 d_loss_real= 0.045, d_loss_fake= 0.102, g_loss 2.584, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 91/390 d_loss_real= 0.030, d_loss_fake= 0.106, g_loss 2.757, d_loss 0.068\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 92/390 d_loss_real= 0.054, d_loss_fake= 0.063, g_loss 3.315, d_loss 0.058\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 50 Batch 93/390 d_loss_real= 0.047, d_loss_fake= 0.034, g_loss 3.820, d_loss 0.041\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 94/390 d_loss_real= 0.059, d_loss_fake= 0.022, g_loss 4.166, d_loss 0.040\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 95/390 d_loss_real= 0.000, d_loss_fake= 0.015, g_loss 4.436, d_loss 0.008\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 50 Batch 96/390 d_loss_real= 0.005, d_loss_fake= 0.012, g_loss 4.608, d_loss 0.009\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 50 Batch 97/390 d_loss_real= 0.237, d_loss_fake= 0.012, g_loss 4.608, d_loss 0.125\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 50 Batch 98/390 d_loss_real= 0.066, d_loss_fake= 0.011, g_loss 4.608, d_loss 0.038\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 50 Batch 99/390 d_loss_real= 0.083, d_loss_fake= 0.023, g_loss 4.587, d_loss 0.053\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 100/390 d_loss_real= 0.000, d_loss_fake= 0.026, g_loss 4.625, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 101/390 d_loss_real= 0.009, d_loss_fake= 0.065, g_loss 5.369, d_loss 0.037\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 102/390 d_loss_real= 0.143, d_loss_fake= 0.007, g_loss 5.607, d_loss 0.075\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 50 Batch 103/390 d_loss_real= 0.111, d_loss_fake= 0.004, g_loss 5.702, d_loss 0.058\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 50 Batch 104/390 d_loss_real= 0.172, d_loss_fake= 0.004, g_loss 5.644, d_loss 0.088\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 50 Batch 105/390 d_loss_real= 0.385, d_loss_fake= 0.005, g_loss 5.372, d_loss 0.195\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 106/390 d_loss_real= 0.135, d_loss_fake= 0.006, g_loss 5.146, d_loss 0.071\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 107/390 d_loss_real= 0.273, d_loss_fake= 0.007, g_loss 4.908, d_loss 0.140\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 108/390 d_loss_real= 0.030, d_loss_fake= 0.013, g_loss 4.512, d_loss 0.021\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 50 Batch 109/390 d_loss_real= 0.072, d_loss_fake= 0.045, g_loss 4.286, d_loss 0.059\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 110/390 d_loss_real= 0.066, d_loss_fake= 0.010, g_loss 4.919, d_loss 0.038\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 111/390 d_loss_real= 0.000, d_loss_fake= 0.007, g_loss 5.168, d_loss 0.004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 112/390 d_loss_real= 0.148, d_loss_fake= 0.009, g_loss 5.021, d_loss 0.078\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 50 Batch 113/390 d_loss_real= 0.092, d_loss_fake= 0.011, g_loss 4.655, d_loss 0.051\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 50 Batch 114/390 d_loss_real= 0.000, d_loss_fake= 0.013, g_loss 4.495, d_loss 0.006\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 50 Batch 115/390 d_loss_real= 0.000, d_loss_fake= 0.016, g_loss 4.210, d_loss 0.008\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 116/390 d_loss_real= 0.040, d_loss_fake= 0.021, g_loss 3.870, d_loss 0.031\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 50 Batch 117/390 d_loss_real= 0.000, d_loss_fake= 0.032, g_loss 3.790, d_loss 0.016\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 50 Batch 118/390 d_loss_real= 0.045, d_loss_fake= 0.034, g_loss 3.818, d_loss 0.040\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 50 Batch 119/390 d_loss_real= 0.000, d_loss_fake= 0.027, g_loss 3.923, d_loss 0.014\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 50 Batch 120/390 d_loss_real= 0.000, d_loss_fake= 0.023, g_loss 4.091, d_loss 0.012\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 50 Batch 121/390 d_loss_real= 0.000, d_loss_fake= 0.019, g_loss 4.238, d_loss 0.009\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 122/390 d_loss_real= 0.100, d_loss_fake= 0.017, g_loss 4.278, d_loss 0.059\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 50 Batch 123/390 d_loss_real= 0.094, d_loss_fake= 0.016, g_loss 4.211, d_loss 0.055\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 124/390 d_loss_real= 0.066, d_loss_fake= 0.020, g_loss 4.129, d_loss 0.043\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 125/390 d_loss_real= 0.003, d_loss_fake= 0.019, g_loss 4.169, d_loss 0.011\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 50 Batch 126/390 d_loss_real= 0.223, d_loss_fake= 0.020, g_loss 4.077, d_loss 0.122\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 127/390 d_loss_real= 0.000, d_loss_fake= 0.024, g_loss 3.961, d_loss 0.012\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 50 Batch 128/390 d_loss_real= 0.139, d_loss_fake= 0.030, g_loss 3.940, d_loss 0.085\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 129/390 d_loss_real= 0.075, d_loss_fake= 0.033, g_loss 4.069, d_loss 0.054\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 50 Batch 130/390 d_loss_real= 0.175, d_loss_fake= 0.027, g_loss 4.148, d_loss 0.101\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 131/390 d_loss_real= 0.229, d_loss_fake= 0.032, g_loss 4.110, d_loss 0.130\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 132/390 d_loss_real= 0.107, d_loss_fake= 0.030, g_loss 3.933, d_loss 0.068\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 133/390 d_loss_real= 0.164, d_loss_fake= 0.024, g_loss 4.322, d_loss 0.094\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 134/390 d_loss_real= 0.212, d_loss_fake= 0.022, g_loss 4.242, d_loss 0.117\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 50 Batch 135/390 d_loss_real= 0.032, d_loss_fake= 0.036, g_loss 4.136, d_loss 0.034\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 136/390 d_loss_real= 0.077, d_loss_fake= 0.025, g_loss 4.723, d_loss 0.051\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 137/390 d_loss_real= 0.162, d_loss_fake= 0.009, g_loss 5.097, d_loss 0.085\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 50 Batch 138/390 d_loss_real= 0.073, d_loss_fake= 0.007, g_loss 5.364, d_loss 0.040\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 50 Batch 139/390 d_loss_real= 0.060, d_loss_fake= 0.007, g_loss 5.008, d_loss 0.034\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 140/390 d_loss_real= 0.000, d_loss_fake= 0.010, g_loss 4.846, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 141/390 d_loss_real= 0.183, d_loss_fake= 0.011, g_loss 4.635, d_loss 0.097\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 142/390 d_loss_real= 0.047, d_loss_fake= 0.020, g_loss 4.249, d_loss 0.033\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 50 Batch 143/390 d_loss_real= 0.040, d_loss_fake= 0.019, g_loss 3.988, d_loss 0.029\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 50 Batch 144/390 d_loss_real= 0.074, d_loss_fake= 0.045, g_loss 3.698, d_loss 0.059\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 145/390 d_loss_real= 0.146, d_loss_fake= 0.043, g_loss 4.066, d_loss 0.095\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 146/390 d_loss_real= 0.000, d_loss_fake= 0.017, g_loss 4.438, d_loss 0.008\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 147/390 d_loss_real= 0.000, d_loss_fake= 0.012, g_loss 4.629, d_loss 0.006\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 50 Batch 148/390 d_loss_real= 0.281, d_loss_fake= 0.013, g_loss 4.427, d_loss 0.147\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 50 Batch 149/390 d_loss_real= 0.006, d_loss_fake= 0.016, g_loss 4.269, d_loss 0.011\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 50 Batch 150/390 d_loss_real= 0.079, d_loss_fake= 0.022, g_loss 4.138, d_loss 0.051\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 151/390 d_loss_real= 0.065, d_loss_fake= 0.037, g_loss 4.141, d_loss 0.051\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 152/390 d_loss_real= 0.166, d_loss_fake= 0.038, g_loss 4.280, d_loss 0.102\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 50 Batch 153/390 d_loss_real= 0.162, d_loss_fake= 0.022, g_loss 4.368, d_loss 0.092\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 50 Batch 154/390 d_loss_real= 0.070, d_loss_fake= 0.015, g_loss 4.442, d_loss 0.042\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 50 Batch 155/390 d_loss_real= 0.194, d_loss_fake= 0.014, g_loss 4.461, d_loss 0.104\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 156/390 d_loss_real= 0.000, d_loss_fake= 0.013, g_loss 4.391, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 157/390 d_loss_real= 0.168, d_loss_fake= 0.014, g_loss 4.325, d_loss 0.091\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 158/390 d_loss_real= 0.071, d_loss_fake= 0.015, g_loss 4.250, d_loss 0.043\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 50 Batch 159/390 d_loss_real= 0.160, d_loss_fake= 0.018, g_loss 4.170, d_loss 0.089\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 50 Batch 160/390 d_loss_real= 0.113, d_loss_fake= 0.017, g_loss 3.984, d_loss 0.065\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 50 Batch 161/390 d_loss_real= 0.104, d_loss_fake= 0.023, g_loss 3.742, d_loss 0.063\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 162/390 d_loss_real= 0.010, d_loss_fake= 0.044, g_loss 3.573, d_loss 0.027\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 50 Batch 163/390 d_loss_real= 0.118, d_loss_fake= 0.064, g_loss 3.632, d_loss 0.091\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 50 Batch 164/390 d_loss_real= 0.164, d_loss_fake= 0.030, g_loss 3.929, d_loss 0.097\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 165/390 d_loss_real= 0.114, d_loss_fake= 0.020, g_loss 4.034, d_loss 0.067\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 166/390 d_loss_real= 0.090, d_loss_fake= 0.021, g_loss 3.999, d_loss 0.056\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 50 Batch 167/390 d_loss_real= 0.121, d_loss_fake= 0.020, g_loss 3.979, d_loss 0.071\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 168/390 d_loss_real= 0.111, d_loss_fake= 0.023, g_loss 3.866, d_loss 0.067\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 169/390 d_loss_real= 0.100, d_loss_fake= 0.027, g_loss 3.727, d_loss 0.063\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 170/390 d_loss_real= 0.263, d_loss_fake= 0.031, g_loss 3.441, d_loss 0.147\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 171/390 d_loss_real= 0.105, d_loss_fake= 0.048, g_loss 3.227, d_loss 0.077\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 50 Batch 172/390 d_loss_real= 0.048, d_loss_fake= 0.054, g_loss 3.394, d_loss 0.051\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 50 Batch 173/390 d_loss_real= 0.000, d_loss_fake= 0.032, g_loss 3.614, d_loss 0.016\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 174/390 d_loss_real= 0.153, d_loss_fake= 0.032, g_loss 3.701, d_loss 0.093\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 175/390 d_loss_real= 0.051, d_loss_fake= 0.036, g_loss 3.704, d_loss 0.043\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 176/390 d_loss_real= 0.101, d_loss_fake= 0.039, g_loss 3.457, d_loss 0.070\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 50 Batch 177/390 d_loss_real= 0.055, d_loss_fake= 0.046, g_loss 3.250, d_loss 0.050\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 178/390 d_loss_real= 0.161, d_loss_fake= 0.053, g_loss 3.186, d_loss 0.107\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 179/390 d_loss_real= 0.156, d_loss_fake= 0.052, g_loss 3.188, d_loss 0.104\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 50 Batch 180/390 d_loss_real= 0.006, d_loss_fake= 0.056, g_loss 3.045, d_loss 0.031\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 181/390 d_loss_real= 0.064, d_loss_fake= 0.058, g_loss 2.948, d_loss 0.061\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 182/390 d_loss_real= 0.002, d_loss_fake= 0.067, g_loss 3.029, d_loss 0.035\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 183/390 d_loss_real= 0.076, d_loss_fake= 0.052, g_loss 3.189, d_loss 0.064\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 184/390 d_loss_real= 0.168, d_loss_fake= 0.046, g_loss 3.317, d_loss 0.107\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 185/390 d_loss_real= 0.114, d_loss_fake= 0.040, g_loss 3.431, d_loss 0.077\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 186/390 d_loss_real= 0.000, d_loss_fake= 0.033, g_loss 3.625, d_loss 0.016\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 187/390 d_loss_real= 0.060, d_loss_fake= 0.027, g_loss 3.795, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 188/390 d_loss_real= 0.093, d_loss_fake= 0.022, g_loss 3.956, d_loss 0.058\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 189/390 d_loss_real= 0.160, d_loss_fake= 0.021, g_loss 3.945, d_loss 0.090\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 190/390 d_loss_real= 0.029, d_loss_fake= 0.022, g_loss 3.982, d_loss 0.025\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 191/390 d_loss_real= 0.058, d_loss_fake= 0.022, g_loss 3.994, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 192/390 d_loss_real= 0.225, d_loss_fake= 0.023, g_loss 3.850, d_loss 0.124\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 50 Batch 193/390 d_loss_real= 0.000, d_loss_fake= 0.023, g_loss 3.769, d_loss 0.011\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 194/390 d_loss_real= 0.071, d_loss_fake= 0.027, g_loss 3.839, d_loss 0.049\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 50 Batch 195/390 d_loss_real= 0.063, d_loss_fake= 0.026, g_loss 3.932, d_loss 0.045\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 196/390 d_loss_real= 0.083, d_loss_fake= 0.024, g_loss 3.935, d_loss 0.053\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 197/390 d_loss_real= 0.000, d_loss_fake= 0.017, g_loss 4.219, d_loss 0.009\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 50 Batch 198/390 d_loss_real= 0.184, d_loss_fake= 0.016, g_loss 4.187, d_loss 0.100\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 199/390 d_loss_real= 0.003, d_loss_fake= 0.016, g_loss 4.239, d_loss 0.010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 50 Batch 200/390 d_loss_real= 0.072, d_loss_fake= 0.015, g_loss 4.322, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 201/390 d_loss_real= 0.000, d_loss_fake= 0.014, g_loss 4.379, d_loss 0.007\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 202/390 d_loss_real= 0.147, d_loss_fake= 0.013, g_loss 4.440, d_loss 0.080\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 50 Batch 203/390 d_loss_real= 0.090, d_loss_fake= 0.013, g_loss 4.407, d_loss 0.051\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 50 Batch 204/390 d_loss_real= 0.117, d_loss_fake= 0.014, g_loss 4.361, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 205/390 d_loss_real= 0.002, d_loss_fake= 0.014, g_loss 4.333, d_loss 0.008\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 50 Batch 206/390 d_loss_real= 0.198, d_loss_fake= 0.017, g_loss 4.160, d_loss 0.108\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 50 Batch 207/390 d_loss_real= 0.076, d_loss_fake= 0.020, g_loss 3.865, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 208/390 d_loss_real= 0.078, d_loss_fake= 0.027, g_loss 3.789, d_loss 0.052\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 50 Batch 209/390 d_loss_real= 0.079, d_loss_fake= 0.033, g_loss 3.687, d_loss 0.056\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 50 Batch 210/390 d_loss_real= 0.136, d_loss_fake= 0.030, g_loss 3.742, d_loss 0.083\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 211/390 d_loss_real= 0.064, d_loss_fake= 0.025, g_loss 3.860, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 212/390 d_loss_real= 0.026, d_loss_fake= 0.023, g_loss 4.001, d_loss 0.024\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 213/390 d_loss_real= 0.052, d_loss_fake= 0.021, g_loss 3.977, d_loss 0.036\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 50 Batch 214/390 d_loss_real= 0.174, d_loss_fake= 0.020, g_loss 3.988, d_loss 0.097\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 50 Batch 215/390 d_loss_real= 0.000, d_loss_fake= 0.018, g_loss 4.087, d_loss 0.009\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 50 Batch 216/390 d_loss_real= 0.075, d_loss_fake= 0.017, g_loss 4.221, d_loss 0.046\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 50 Batch 217/390 d_loss_real= 0.082, d_loss_fake= 0.014, g_loss 4.330, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 218/390 d_loss_real= 0.193, d_loss_fake= 0.015, g_loss 4.274, d_loss 0.104\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 219/390 d_loss_real= 0.000, d_loss_fake= 0.016, g_loss 4.222, d_loss 0.008\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 220/390 d_loss_real= 0.110, d_loss_fake= 0.016, g_loss 4.138, d_loss 0.063\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 50 Batch 221/390 d_loss_real= 0.091, d_loss_fake= 0.020, g_loss 3.987, d_loss 0.055\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 222/390 d_loss_real= 0.000, d_loss_fake= 0.022, g_loss 3.856, d_loss 0.011\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 223/390 d_loss_real= 0.126, d_loss_fake= 0.024, g_loss 3.880, d_loss 0.075\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 50 Batch 224/390 d_loss_real= 0.009, d_loss_fake= 0.026, g_loss 3.932, d_loss 0.017\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 50 Batch 225/390 d_loss_real= 0.081, d_loss_fake= 0.023, g_loss 4.142, d_loss 0.052\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 226/390 d_loss_real= 0.003, d_loss_fake= 0.018, g_loss 4.249, d_loss 0.011\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 227/390 d_loss_real= 0.000, d_loss_fake= 0.014, g_loss 4.454, d_loss 0.007\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 50 Batch 228/390 d_loss_real= 0.007, d_loss_fake= 0.014, g_loss 4.508, d_loss 0.010\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 229/390 d_loss_real= 0.092, d_loss_fake= 0.011, g_loss 4.663, d_loss 0.052\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 230/390 d_loss_real= 0.172, d_loss_fake= 0.013, g_loss 4.486, d_loss 0.092\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 231/390 d_loss_real= 0.044, d_loss_fake= 0.014, g_loss 4.386, d_loss 0.029\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 50 Batch 232/390 d_loss_real= 0.025, d_loss_fake= 0.013, g_loss 4.296, d_loss 0.019\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 233/390 d_loss_real= 0.087, d_loss_fake= 0.018, g_loss 4.139, d_loss 0.053\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 234/390 d_loss_real= 0.096, d_loss_fake= 0.024, g_loss 3.991, d_loss 0.060\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 235/390 d_loss_real= 0.145, d_loss_fake= 0.028, g_loss 3.929, d_loss 0.086\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 236/390 d_loss_real= 0.165, d_loss_fake= 0.023, g_loss 4.183, d_loss 0.094\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 237/390 d_loss_real= 0.141, d_loss_fake= 0.018, g_loss 4.357, d_loss 0.080\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 238/390 d_loss_real= 0.120, d_loss_fake= 0.020, g_loss 4.180, d_loss 0.070\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 239/390 d_loss_real= 0.034, d_loss_fake= 0.020, g_loss 4.246, d_loss 0.027\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 50 Batch 240/390 d_loss_real= 0.096, d_loss_fake= 0.020, g_loss 3.976, d_loss 0.058\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 241/390 d_loss_real= 0.072, d_loss_fake= 0.019, g_loss 4.237, d_loss 0.046\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 50 Batch 242/390 d_loss_real= 0.032, d_loss_fake= 0.019, g_loss 4.236, d_loss 0.026\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 50 Batch 243/390 d_loss_real= 0.202, d_loss_fake= 0.018, g_loss 4.176, d_loss 0.110\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 244/390 d_loss_real= 0.055, d_loss_fake= 0.019, g_loss 4.133, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 245/390 d_loss_real= 0.091, d_loss_fake= 0.022, g_loss 4.027, d_loss 0.056\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 246/390 d_loss_real= 0.061, d_loss_fake= 0.027, g_loss 4.001, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 247/390 d_loss_real= 0.041, d_loss_fake= 0.021, g_loss 4.182, d_loss 0.031\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 248/390 d_loss_real= 0.081, d_loss_fake= 0.017, g_loss 4.317, d_loss 0.049\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 50 Batch 249/390 d_loss_real= 0.245, d_loss_fake= 0.015, g_loss 4.332, d_loss 0.130\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 250/390 d_loss_real= 0.000, d_loss_fake= 0.017, g_loss 4.260, d_loss 0.009\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 251/390 d_loss_real= 0.083, d_loss_fake= 0.018, g_loss 4.155, d_loss 0.050\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 252/390 d_loss_real= 0.069, d_loss_fake= 0.017, g_loss 4.227, d_loss 0.043\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 253/390 d_loss_real= 0.068, d_loss_fake= 0.016, g_loss 4.276, d_loss 0.042\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 254/390 d_loss_real= 0.084, d_loss_fake= 0.017, g_loss 4.193, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 255/390 d_loss_real= 0.131, d_loss_fake= 0.019, g_loss 3.995, d_loss 0.075\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 256/390 d_loss_real= 0.105, d_loss_fake= 0.028, g_loss 3.736, d_loss 0.067\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 257/390 d_loss_real= 0.036, d_loss_fake= 0.031, g_loss 3.676, d_loss 0.033\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 50 Batch 258/390 d_loss_real= 0.000, d_loss_fake= 0.023, g_loss 4.005, d_loss 0.012\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 259/390 d_loss_real= 0.125, d_loss_fake= 0.020, g_loss 4.180, d_loss 0.073\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 260/390 d_loss_real= 0.049, d_loss_fake= 0.018, g_loss 4.150, d_loss 0.034\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 50 Batch 261/390 d_loss_real= 0.000, d_loss_fake= 0.017, g_loss 4.209, d_loss 0.009\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 262/390 d_loss_real= 0.026, d_loss_fake= 0.015, g_loss 4.308, d_loss 0.020\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 50 Batch 263/390 d_loss_real= 0.012, d_loss_fake= 0.015, g_loss 4.232, d_loss 0.014\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 264/390 d_loss_real= 0.143, d_loss_fake= 0.017, g_loss 4.178, d_loss 0.080\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 265/390 d_loss_real= 0.011, d_loss_fake= 0.016, g_loss 4.172, d_loss 0.014\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 50 Batch 266/390 d_loss_real= 0.000, d_loss_fake= 0.016, g_loss 4.123, d_loss 0.008\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 50 Batch 267/390 d_loss_real= 0.000, d_loss_fake= 0.015, g_loss 4.301, d_loss 0.008\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 268/390 d_loss_real= 0.006, d_loss_fake= 0.016, g_loss 4.253, d_loss 0.011\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 269/390 d_loss_real= 0.181, d_loss_fake= 0.019, g_loss 4.007, d_loss 0.100\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 50 Batch 270/390 d_loss_real= 0.000, d_loss_fake= 0.024, g_loss 4.065, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 271/390 d_loss_real= 0.173, d_loss_fake= 0.018, g_loss 4.067, d_loss 0.096\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 50 Batch 272/390 d_loss_real= 0.000, d_loss_fake= 0.019, g_loss 4.073, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 273/390 d_loss_real= 0.000, d_loss_fake= 0.016, g_loss 4.256, d_loss 0.008\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 50 Batch 274/390 d_loss_real= 0.236, d_loss_fake= 0.018, g_loss 4.217, d_loss 0.127\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 50 Batch 275/390 d_loss_real= 0.013, d_loss_fake= 0.018, g_loss 4.234, d_loss 0.015\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 276/390 d_loss_real= 0.093, d_loss_fake= 0.018, g_loss 4.054, d_loss 0.055\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 277/390 d_loss_real= 0.063, d_loss_fake= 0.017, g_loss 4.182, d_loss 0.040\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 278/390 d_loss_real= 0.000, d_loss_fake= 0.018, g_loss 4.238, d_loss 0.009\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 279/390 d_loss_real= 0.042, d_loss_fake= 0.019, g_loss 4.140, d_loss 0.030\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 50 Batch 280/390 d_loss_real= 0.126, d_loss_fake= 0.017, g_loss 4.129, d_loss 0.072\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 50 Batch 281/390 d_loss_real= 0.057, d_loss_fake= 0.021, g_loss 4.041, d_loss 0.039\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 282/390 d_loss_real= 0.021, d_loss_fake= 0.022, g_loss 3.927, d_loss 0.022\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 50 Batch 283/390 d_loss_real= 0.021, d_loss_fake= 0.023, g_loss 3.959, d_loss 0.022\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 50 Batch 284/390 d_loss_real= 0.109, d_loss_fake= 0.028, g_loss 3.813, d_loss 0.069\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 285/390 d_loss_real= 0.000, d_loss_fake= 0.028, g_loss 3.880, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 286/390 d_loss_real= 0.025, d_loss_fake= 0.028, g_loss 3.912, d_loss 0.027\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 50 Batch 287/390 d_loss_real= 0.013, d_loss_fake= 0.022, g_loss 4.078, d_loss 0.017\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 288/390 d_loss_real= 0.120, d_loss_fake= 0.021, g_loss 4.087, d_loss 0.071\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 50 Batch 289/390 d_loss_real= 0.001, d_loss_fake= 0.021, g_loss 4.109, d_loss 0.011\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 50 Batch 290/390 d_loss_real= 0.010, d_loss_fake= 0.017, g_loss 4.203, d_loss 0.013\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 50 Batch 291/390 d_loss_real= 0.050, d_loss_fake= 0.018, g_loss 4.196, d_loss 0.034\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 50 Batch 292/390 d_loss_real= 0.006, d_loss_fake= 0.017, g_loss 4.281, d_loss 0.011\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 293/390 d_loss_real= 0.000, d_loss_fake= 0.016, g_loss 4.408, d_loss 0.008\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 294/390 d_loss_real= 0.071, d_loss_fake= 0.015, g_loss 4.400, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 295/390 d_loss_real= 0.200, d_loss_fake= 0.015, g_loss 4.266, d_loss 0.108\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 296/390 d_loss_real= 0.026, d_loss_fake= 0.019, g_loss 3.949, d_loss 0.022\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 297/390 d_loss_real= 0.005, d_loss_fake= 0.023, g_loss 3.879, d_loss 0.014\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 298/390 d_loss_real= 0.066, d_loss_fake= 0.027, g_loss 3.982, d_loss 0.046\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 299/390 d_loss_real= 0.142, d_loss_fake= 0.020, g_loss 4.171, d_loss 0.081\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 300/390 d_loss_real= 0.082, d_loss_fake= 0.017, g_loss 4.288, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 301/390 d_loss_real= 0.146, d_loss_fake= 0.019, g_loss 4.430, d_loss 0.082\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 50 Batch 302/390 d_loss_real= 0.000, d_loss_fake= 0.017, g_loss 4.264, d_loss 0.009\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 303/390 d_loss_real= 0.000, d_loss_fake= 0.014, g_loss 4.436, d_loss 0.007\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 50 Batch 304/390 d_loss_real= 0.000, d_loss_fake= 0.014, g_loss 4.677, d_loss 0.007\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 50 Batch 305/390 d_loss_real= 0.199, d_loss_fake= 0.015, g_loss 4.375, d_loss 0.107\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 50 Batch 306/390 d_loss_real= 0.089, d_loss_fake= 0.019, g_loss 4.125, d_loss 0.054\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 307/390 d_loss_real= 0.128, d_loss_fake= 0.020, g_loss 4.024, d_loss 0.074\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 308/390 d_loss_real= 0.000, d_loss_fake= 0.025, g_loss 3.834, d_loss 0.012\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 50 Batch 309/390 d_loss_real= 0.094, d_loss_fake= 0.030, g_loss 3.611, d_loss 0.062\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 310/390 d_loss_real= 0.077, d_loss_fake= 0.031, g_loss 3.600, d_loss 0.054\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 50 Batch 311/390 d_loss_real= 0.068, d_loss_fake= 0.028, g_loss 3.746, d_loss 0.048\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 50 Batch 312/390 d_loss_real= 0.039, d_loss_fake= 0.042, g_loss 3.497, d_loss 0.040\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 50 Batch 313/390 d_loss_real= 0.001, d_loss_fake= 0.029, g_loss 3.856, d_loss 0.015\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 50 Batch 314/390 d_loss_real= 0.025, d_loss_fake= 0.022, g_loss 4.080, d_loss 0.023\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 50 Batch 315/390 d_loss_real= 0.189, d_loss_fake= 0.020, g_loss 4.172, d_loss 0.105\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 50 Batch 316/390 d_loss_real= 0.127, d_loss_fake= 0.017, g_loss 4.187, d_loss 0.072\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 50 Batch 317/390 d_loss_real= 0.000, d_loss_fake= 0.019, g_loss 4.253, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 318/390 d_loss_real= 0.253, d_loss_fake= 0.017, g_loss 4.109, d_loss 0.135\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 50 Batch 319/390 d_loss_real= 0.065, d_loss_fake= 0.020, g_loss 3.974, d_loss 0.043\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 320/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 4.133, d_loss 0.010\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 321/390 d_loss_real= 0.000, d_loss_fake= 0.017, g_loss 4.153, d_loss 0.009\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 322/390 d_loss_real= 0.084, d_loss_fake= 0.018, g_loss 4.105, d_loss 0.051\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 50 Batch 323/390 d_loss_real= 0.002, d_loss_fake= 0.022, g_loss 3.998, d_loss 0.012\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 50 Batch 324/390 d_loss_real= 0.069, d_loss_fake= 0.020, g_loss 4.027, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 325/390 d_loss_real= 0.036, d_loss_fake= 0.022, g_loss 3.974, d_loss 0.029\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 50 Batch 326/390 d_loss_real= 0.000, d_loss_fake= 0.022, g_loss 3.975, d_loss 0.011\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 327/390 d_loss_real= 0.049, d_loss_fake= 0.020, g_loss 4.110, d_loss 0.034\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 50 Batch 328/390 d_loss_real= 0.158, d_loss_fake= 0.019, g_loss 3.996, d_loss 0.088\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 329/390 d_loss_real= 0.070, d_loss_fake= 0.022, g_loss 3.928, d_loss 0.046\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 330/390 d_loss_real= 0.148, d_loss_fake= 0.021, g_loss 4.016, d_loss 0.084\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 50 Batch 331/390 d_loss_real= 0.005, d_loss_fake= 0.022, g_loss 4.016, d_loss 0.013\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 332/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 4.187, d_loss 0.010\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 50 Batch 333/390 d_loss_real= 0.000, d_loss_fake= 0.016, g_loss 4.367, d_loss 0.008\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 50 Batch 334/390 d_loss_real= 0.042, d_loss_fake= 0.013, g_loss 4.475, d_loss 0.028\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 335/390 d_loss_real= 0.193, d_loss_fake= 0.013, g_loss 4.476, d_loss 0.103\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 50 Batch 336/390 d_loss_real= 0.246, d_loss_fake= 0.014, g_loss 4.230, d_loss 0.130\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 337/390 d_loss_real= 0.178, d_loss_fake= 0.016, g_loss 4.045, d_loss 0.097\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 50 Batch 338/390 d_loss_real= 0.018, d_loss_fake= 0.019, g_loss 4.068, d_loss 0.019\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 50 Batch 339/390 d_loss_real= 0.131, d_loss_fake= 0.021, g_loss 4.021, d_loss 0.076\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 340/390 d_loss_real= 0.265, d_loss_fake= 0.028, g_loss 3.748, d_loss 0.146\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 50 Batch 341/390 d_loss_real= 0.207, d_loss_fake= 0.038, g_loss 3.498, d_loss 0.122\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 342/390 d_loss_real= 0.123, d_loss_fake= 0.037, g_loss 3.737, d_loss 0.080\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 343/390 d_loss_real= 0.000, d_loss_fake= 0.027, g_loss 3.943, d_loss 0.014\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 344/390 d_loss_real= 0.167, d_loss_fake= 0.023, g_loss 3.878, d_loss 0.095\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 50 Batch 345/390 d_loss_real= 0.066, d_loss_fake= 0.019, g_loss 4.099, d_loss 0.043\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 50 Batch 346/390 d_loss_real= 0.031, d_loss_fake= 0.019, g_loss 4.114, d_loss 0.025\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 347/390 d_loss_real= 0.123, d_loss_fake= 0.016, g_loss 4.211, d_loss 0.070\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 348/390 d_loss_real= 0.042, d_loss_fake= 0.015, g_loss 4.288, d_loss 0.029\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 50 Batch 349/390 d_loss_real= 0.000, d_loss_fake= 0.015, g_loss 4.269, d_loss 0.008\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 350/390 d_loss_real= 0.075, d_loss_fake= 0.014, g_loss 4.380, d_loss 0.044\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 351/390 d_loss_real= 0.279, d_loss_fake= 0.014, g_loss 4.322, d_loss 0.147\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 352/390 d_loss_real= 0.001, d_loss_fake= 0.015, g_loss 4.255, d_loss 0.008\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 353/390 d_loss_real= 0.128, d_loss_fake= 0.015, g_loss 4.255, d_loss 0.072\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 354/390 d_loss_real= 0.040, d_loss_fake= 0.016, g_loss 4.180, d_loss 0.028\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 355/390 d_loss_real= 0.139, d_loss_fake= 0.017, g_loss 4.137, d_loss 0.078\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 356/390 d_loss_real= 0.043, d_loss_fake= 0.019, g_loss 3.958, d_loss 0.031\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 357/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 3.874, d_loss 0.010\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 50 Batch 358/390 d_loss_real= 0.096, d_loss_fake= 0.023, g_loss 3.760, d_loss 0.060\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 359/390 d_loss_real= 0.053, d_loss_fake= 0.039, g_loss 3.647, d_loss 0.046\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 360/390 d_loss_real= 0.114, d_loss_fake= 0.035, g_loss 3.633, d_loss 0.075\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 50 Batch 361/390 d_loss_real= 0.093, d_loss_fake= 0.026, g_loss 3.744, d_loss 0.059\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 362/390 d_loss_real= 0.050, d_loss_fake= 0.029, g_loss 3.819, d_loss 0.040\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 50 Batch 363/390 d_loss_real= 0.010, d_loss_fake= 0.025, g_loss 3.859, d_loss 0.018\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 50 Batch 364/390 d_loss_real= 0.071, d_loss_fake= 0.022, g_loss 3.911, d_loss 0.047\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 50 Batch 365/390 d_loss_real= 0.076, d_loss_fake= 0.023, g_loss 3.999, d_loss 0.049\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 50 Batch 366/390 d_loss_real= 0.014, d_loss_fake= 0.021, g_loss 4.015, d_loss 0.018\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 50 Batch 367/390 d_loss_real= 0.153, d_loss_fake= 0.021, g_loss 3.949, d_loss 0.087\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 368/390 d_loss_real= 0.031, d_loss_fake= 0.024, g_loss 3.862, d_loss 0.028\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 50 Batch 369/390 d_loss_real= 0.070, d_loss_fake= 0.026, g_loss 3.704, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 370/390 d_loss_real= 0.078, d_loss_fake= 0.071, g_loss 3.840, d_loss 0.074\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 371/390 d_loss_real= 0.058, d_loss_fake= 0.021, g_loss 4.090, d_loss 0.040\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 372/390 d_loss_real= 0.109, d_loss_fake= 0.017, g_loss 4.290, d_loss 0.063\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 50 Batch 373/390 d_loss_real= 0.150, d_loss_fake= 0.017, g_loss 4.203, d_loss 0.083\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 374/390 d_loss_real= 0.113, d_loss_fake= 0.018, g_loss 4.129, d_loss 0.065\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 50 Batch 375/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 4.085, d_loss 0.010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 50 Batch 376/390 d_loss_real= 0.001, d_loss_fake= 0.019, g_loss 4.098, d_loss 0.010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 50 Batch 377/390 d_loss_real= 0.002, d_loss_fake= 0.021, g_loss 4.033, d_loss 0.011\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 378/390 d_loss_real= 0.114, d_loss_fake= 0.021, g_loss 3.945, d_loss 0.067\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 379/390 d_loss_real= 0.120, d_loss_fake= 0.024, g_loss 3.860, d_loss 0.072\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 380/390 d_loss_real= 0.066, d_loss_fake= 0.028, g_loss 3.603, d_loss 0.047\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 381/390 d_loss_real= 0.000, d_loss_fake= 0.036, g_loss 3.564, d_loss 0.018\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 382/390 d_loss_real= 0.001, d_loss_fake= 0.036, g_loss 3.473, d_loss 0.019\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 383/390 d_loss_real= 0.000, d_loss_fake= 0.038, g_loss 3.401, d_loss 0.019\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50 Batch 384/390 d_loss_real= 0.049, d_loss_fake= 0.042, g_loss 3.447, d_loss 0.046\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 385/390 d_loss_real= 0.066, d_loss_fake= 0.035, g_loss 3.584, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 386/390 d_loss_real= 0.010, d_loss_fake= 0.032, g_loss 3.660, d_loss 0.021\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50 Batch 387/390 d_loss_real= 0.062, d_loss_fake= 0.030, g_loss 3.681, d_loss 0.046\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 50 Batch 388/390 d_loss_real= 0.083, d_loss_fake= 0.032, g_loss 3.679, d_loss 0.058\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50 Batch 389/390 d_loss_real= 0.012, d_loss_fake= 0.033, g_loss 3.638, d_loss 0.023\n",
            "2/2 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50 Batch 390/390 d_loss_real= 0.057, d_loss_fake= 0.038, g_loss 3.613, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 1/390 d_loss_real= 0.000, d_loss_fake= 0.033, g_loss 3.650, d_loss 0.016\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 2/390 d_loss_real= 0.080, d_loss_fake= 0.031, g_loss 3.707, d_loss 0.055\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 3/390 d_loss_real= 0.127, d_loss_fake= 0.028, g_loss 3.739, d_loss 0.077\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 4/390 d_loss_real= 0.107, d_loss_fake= 0.028, g_loss 3.768, d_loss 0.067\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 51 Batch 5/390 d_loss_real= 0.170, d_loss_fake= 0.032, g_loss 3.640, d_loss 0.101\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 6/390 d_loss_real= 0.070, d_loss_fake= 0.056, g_loss 3.723, d_loss 0.063\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 7/390 d_loss_real= 0.000, d_loss_fake= 0.034, g_loss 4.088, d_loss 0.017\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 51 Batch 8/390 d_loss_real= 0.000, d_loss_fake= 0.016, g_loss 4.496, d_loss 0.008\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 51 Batch 9/390 d_loss_real= 0.059, d_loss_fake= 0.014, g_loss 4.626, d_loss 0.037\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 51 Batch 10/390 d_loss_real= 0.162, d_loss_fake= 0.013, g_loss 4.522, d_loss 0.087\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 11/390 d_loss_real= 0.079, d_loss_fake= 0.016, g_loss 4.313, d_loss 0.047\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 51 Batch 12/390 d_loss_real= 0.079, d_loss_fake= 0.018, g_loss 4.248, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 13/390 d_loss_real= 0.191, d_loss_fake= 0.020, g_loss 4.037, d_loss 0.105\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 14/390 d_loss_real= 0.091, d_loss_fake= 0.039, g_loss 3.634, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 15/390 d_loss_real= 0.000, d_loss_fake= 0.130, g_loss 4.363, d_loss 0.065\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 16/390 d_loss_real= 0.194, d_loss_fake= 0.013, g_loss 4.702, d_loss 0.103\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 17/390 d_loss_real= 0.037, d_loss_fake= 0.012, g_loss 4.774, d_loss 0.025\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 18/390 d_loss_real= 0.000, d_loss_fake= 0.012, g_loss 4.791, d_loss 0.006\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 19/390 d_loss_real= 0.098, d_loss_fake= 0.009, g_loss 4.604, d_loss 0.054\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 51 Batch 20/390 d_loss_real= 0.158, d_loss_fake= 0.014, g_loss 4.600, d_loss 0.086\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 21/390 d_loss_real= 0.437, d_loss_fake= 0.016, g_loss 4.536, d_loss 0.226\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 22/390 d_loss_real= 0.121, d_loss_fake= 0.017, g_loss 4.252, d_loss 0.069\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 51 Batch 23/390 d_loss_real= 0.073, d_loss_fake= 0.021, g_loss 3.918, d_loss 0.047\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 51 Batch 24/390 d_loss_real= 0.001, d_loss_fake= 0.023, g_loss 3.811, d_loss 0.012\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 25/390 d_loss_real= 0.070, d_loss_fake= 0.026, g_loss 3.783, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 26/390 d_loss_real= 0.000, d_loss_fake= 0.026, g_loss 3.803, d_loss 0.013\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 51 Batch 27/390 d_loss_real= 0.000, d_loss_fake= 0.024, g_loss 3.815, d_loss 0.012\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 28/390 d_loss_real= 0.132, d_loss_fake= 0.026, g_loss 3.700, d_loss 0.079\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 29/390 d_loss_real= 0.001, d_loss_fake= 0.030, g_loss 3.550, d_loss 0.015\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 30/390 d_loss_real= 0.000, d_loss_fake= 0.107, g_loss 3.401, d_loss 0.054\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 31/390 d_loss_real= 0.078, d_loss_fake= 0.123, g_loss 4.165, d_loss 0.100\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 51 Batch 32/390 d_loss_real= 0.063, d_loss_fake= 0.014, g_loss 4.520, d_loss 0.038\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 33/390 d_loss_real= 0.139, d_loss_fake= 0.010, g_loss 4.720, d_loss 0.075\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 51 Batch 34/390 d_loss_real= 0.248, d_loss_fake= 0.009, g_loss 4.733, d_loss 0.129\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 35/390 d_loss_real= 0.154, d_loss_fake= 0.009, g_loss 4.664, d_loss 0.082\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 51 Batch 36/390 d_loss_real= 0.249, d_loss_fake= 0.010, g_loss 4.624, d_loss 0.129\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 37/390 d_loss_real= 0.092, d_loss_fake= 0.011, g_loss 4.585, d_loss 0.052\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 38/390 d_loss_real= 0.432, d_loss_fake= 0.012, g_loss 4.375, d_loss 0.222\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 39/390 d_loss_real= 0.409, d_loss_fake= 0.015, g_loss 4.175, d_loss 0.212\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 40/390 d_loss_real= 0.145, d_loss_fake= 0.018, g_loss 3.958, d_loss 0.082\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 41/390 d_loss_real= 0.096, d_loss_fake= 0.022, g_loss 3.812, d_loss 0.059\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 42/390 d_loss_real= 0.060, d_loss_fake= 0.025, g_loss 3.669, d_loss 0.042\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 43/390 d_loss_real= 0.020, d_loss_fake= 0.027, g_loss 3.602, d_loss 0.024\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 44/390 d_loss_real= 0.238, d_loss_fake= 0.031, g_loss 3.493, d_loss 0.134\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 45/390 d_loss_real= 0.123, d_loss_fake= 0.033, g_loss 3.431, d_loss 0.078\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 46/390 d_loss_real= 0.012, d_loss_fake= 0.034, g_loss 3.367, d_loss 0.023\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 47/390 d_loss_real= 0.111, d_loss_fake= 0.036, g_loss 3.288, d_loss 0.074\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 51 Batch 48/390 d_loss_real= 0.005, d_loss_fake= 0.038, g_loss 3.284, d_loss 0.022\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 49/390 d_loss_real= 0.000, d_loss_fake= 0.044, g_loss 3.220, d_loss 0.022\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 51 Batch 50/390 d_loss_real= 0.059, d_loss_fake= 0.067, g_loss 2.968, d_loss 0.063\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 51/390 d_loss_real= 0.057, d_loss_fake= 0.219, g_loss 3.876, d_loss 0.138\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 52/390 d_loss_real= 0.040, d_loss_fake= 0.016, g_loss 4.518, d_loss 0.028\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 53/390 d_loss_real= 0.060, d_loss_fake= 0.012, g_loss 4.588, d_loss 0.036\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 54/390 d_loss_real= 0.084, d_loss_fake= 0.011, g_loss 4.647, d_loss 0.047\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 55/390 d_loss_real= 0.080, d_loss_fake= 0.010, g_loss 4.736, d_loss 0.045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 56/390 d_loss_real= 0.155, d_loss_fake= 0.009, g_loss 4.720, d_loss 0.082\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 51 Batch 57/390 d_loss_real= 0.361, d_loss_fake= 0.010, g_loss 4.616, d_loss 0.186\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 58/390 d_loss_real= 0.228, d_loss_fake= 0.011, g_loss 4.425, d_loss 0.120\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 51 Batch 59/390 d_loss_real= 0.301, d_loss_fake= 0.014, g_loss 4.186, d_loss 0.158\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 60/390 d_loss_real= 0.089, d_loss_fake= 0.017, g_loss 3.963, d_loss 0.053\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 51 Batch 61/390 d_loss_real= 0.000, d_loss_fake= 0.021, g_loss 3.835, d_loss 0.010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 51 Batch 62/390 d_loss_real= 0.071, d_loss_fake= 0.023, g_loss 3.741, d_loss 0.047\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 51 Batch 63/390 d_loss_real= 0.037, d_loss_fake= 0.029, g_loss 3.632, d_loss 0.033\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 51 Batch 64/390 d_loss_real= 0.020, d_loss_fake= 0.122, g_loss 3.700, d_loss 0.071\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 65/390 d_loss_real= 0.057, d_loss_fake= 0.025, g_loss 3.809, d_loss 0.041\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 51 Batch 66/390 d_loss_real= 0.326, d_loss_fake= 0.022, g_loss 3.852, d_loss 0.174\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 67/390 d_loss_real= 0.100, d_loss_fake= 0.021, g_loss 3.893, d_loss 0.060\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 51 Batch 68/390 d_loss_real= 0.086, d_loss_fake= 0.021, g_loss 3.910, d_loss 0.053\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 69/390 d_loss_real= 0.119, d_loss_fake= 0.020, g_loss 3.940, d_loss 0.070\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 70/390 d_loss_real= 0.278, d_loss_fake= 0.020, g_loss 3.946, d_loss 0.149\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 71/390 d_loss_real= 0.063, d_loss_fake= 0.020, g_loss 3.948, d_loss 0.042\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 51 Batch 72/390 d_loss_real= 0.054, d_loss_fake= 0.020, g_loss 3.947, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 73/390 d_loss_real= 0.093, d_loss_fake= 0.019, g_loss 4.006, d_loss 0.056\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 74/390 d_loss_real= 0.039, d_loss_fake= 0.021, g_loss 3.975, d_loss 0.030\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 75/390 d_loss_real= 0.002, d_loss_fake= 0.021, g_loss 3.938, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 76/390 d_loss_real= 0.000, d_loss_fake= 0.021, g_loss 3.954, d_loss 0.011\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 51 Batch 77/390 d_loss_real= 0.035, d_loss_fake= 0.022, g_loss 3.831, d_loss 0.029\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 78/390 d_loss_real= 0.047, d_loss_fake= 0.026, g_loss 3.708, d_loss 0.036\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 79/390 d_loss_real= 0.000, d_loss_fake= 0.034, g_loss 3.420, d_loss 0.017\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 51 Batch 80/390 d_loss_real= 0.055, d_loss_fake= 0.290, g_loss 3.518, d_loss 0.173\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 51 Batch 81/390 d_loss_real= 0.053, d_loss_fake= 0.045, g_loss 3.987, d_loss 0.049\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 51 Batch 82/390 d_loss_real= 0.036, d_loss_fake= 0.018, g_loss 4.380, d_loss 0.027\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 83/390 d_loss_real= 0.103, d_loss_fake= 0.016, g_loss 4.318, d_loss 0.060\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 84/390 d_loss_real= 0.146, d_loss_fake= 0.017, g_loss 4.145, d_loss 0.082\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 85/390 d_loss_real= 0.000, d_loss_fake= 0.017, g_loss 4.192, d_loss 0.008\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 51 Batch 86/390 d_loss_real= 0.125, d_loss_fake= 0.017, g_loss 4.103, d_loss 0.071\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 51 Batch 87/390 d_loss_real= 0.123, d_loss_fake= 0.017, g_loss 4.018, d_loss 0.070\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 88/390 d_loss_real= 0.040, d_loss_fake= 0.019, g_loss 3.930, d_loss 0.030\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 51 Batch 89/390 d_loss_real= 0.026, d_loss_fake= 0.021, g_loss 3.887, d_loss 0.023\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 90/390 d_loss_real= 0.067, d_loss_fake= 0.024, g_loss 3.798, d_loss 0.046\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 91/390 d_loss_real= 0.068, d_loss_fake= 0.025, g_loss 3.655, d_loss 0.047\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 51 Batch 92/390 d_loss_real= 0.037, d_loss_fake= 0.028, g_loss 3.552, d_loss 0.032\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 93/390 d_loss_real= 0.070, d_loss_fake= 0.035, g_loss 3.446, d_loss 0.052\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 51 Batch 94/390 d_loss_real= 0.001, d_loss_fake= 0.037, g_loss 3.268, d_loss 0.019\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 95/390 d_loss_real= 0.002, d_loss_fake= 0.117, g_loss 3.194, d_loss 0.059\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 96/390 d_loss_real= 0.058, d_loss_fake= 0.121, g_loss 3.273, d_loss 0.089\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 97/390 d_loss_real= 0.001, d_loss_fake= 0.041, g_loss 3.640, d_loss 0.021\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 98/390 d_loss_real= 0.017, d_loss_fake= 0.027, g_loss 3.901, d_loss 0.022\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 51 Batch 99/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 4.079, d_loss 0.010\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 100/390 d_loss_real= 0.073, d_loss_fake= 0.016, g_loss 4.236, d_loss 0.044\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 51 Batch 101/390 d_loss_real= 0.082, d_loss_fake= 0.014, g_loss 4.379, d_loss 0.048\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 51 Batch 102/390 d_loss_real= 0.198, d_loss_fake= 0.013, g_loss 4.419, d_loss 0.105\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 103/390 d_loss_real= 0.134, d_loss_fake= 0.013, g_loss 4.438, d_loss 0.073\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 104/390 d_loss_real= 0.087, d_loss_fake= 0.012, g_loss 4.453, d_loss 0.050\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 105/390 d_loss_real= 0.030, d_loss_fake= 0.013, g_loss 4.372, d_loss 0.021\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 51 Batch 106/390 d_loss_real= 0.058, d_loss_fake= 0.013, g_loss 4.308, d_loss 0.036\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 107/390 d_loss_real= 0.203, d_loss_fake= 0.015, g_loss 4.215, d_loss 0.109\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 108/390 d_loss_real= 0.046, d_loss_fake= 0.016, g_loss 4.128, d_loss 0.031\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 109/390 d_loss_real= 0.076, d_loss_fake= 0.019, g_loss 3.978, d_loss 0.047\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 51 Batch 110/390 d_loss_real= 0.056, d_loss_fake= 0.024, g_loss 3.808, d_loss 0.040\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 111/390 d_loss_real= 0.083, d_loss_fake= 0.029, g_loss 3.727, d_loss 0.056\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 112/390 d_loss_real= 0.045, d_loss_fake= 0.059, g_loss 3.375, d_loss 0.052\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 113/390 d_loss_real= 0.000, d_loss_fake= 0.085, g_loss 3.286, d_loss 0.042\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 114/390 d_loss_real= 0.101, d_loss_fake= 0.063, g_loss 3.699, d_loss 0.082\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 115/390 d_loss_real= 0.000, d_loss_fake= 0.037, g_loss 3.893, d_loss 0.019\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 116/390 d_loss_real= 0.005, d_loss_fake= 0.020, g_loss 4.166, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 117/390 d_loss_real= 0.080, d_loss_fake= 0.015, g_loss 4.359, d_loss 0.047\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 118/390 d_loss_real= 0.018, d_loss_fake= 0.013, g_loss 4.441, d_loss 0.015\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 51 Batch 119/390 d_loss_real= 0.066, d_loss_fake= 0.012, g_loss 4.482, d_loss 0.039\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 120/390 d_loss_real= 0.063, d_loss_fake= 0.011, g_loss 4.501, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 121/390 d_loss_real= 0.000, d_loss_fake= 0.011, g_loss 4.527, d_loss 0.006\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 122/390 d_loss_real= 0.000, d_loss_fake= 0.011, g_loss 4.548, d_loss 0.006\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 123/390 d_loss_real= 0.227, d_loss_fake= 0.011, g_loss 4.501, d_loss 0.119\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 124/390 d_loss_real= 0.142, d_loss_fake= 0.012, g_loss 4.456, d_loss 0.077\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 51 Batch 125/390 d_loss_real= 0.011, d_loss_fake= 0.013, g_loss 4.380, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 126/390 d_loss_real= 0.000, d_loss_fake= 0.013, g_loss 4.343, d_loss 0.007\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 127/390 d_loss_real= 0.125, d_loss_fake= 0.014, g_loss 4.265, d_loss 0.070\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 128/390 d_loss_real= 0.061, d_loss_fake= 0.016, g_loss 4.264, d_loss 0.039\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 129/390 d_loss_real= 0.072, d_loss_fake= 0.015, g_loss 4.120, d_loss 0.044\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 130/390 d_loss_real= 0.067, d_loss_fake= 0.019, g_loss 4.151, d_loss 0.043\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 131/390 d_loss_real= 0.035, d_loss_fake= 0.018, g_loss 4.051, d_loss 0.027\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 132/390 d_loss_real= 0.070, d_loss_fake= 0.022, g_loss 3.920, d_loss 0.046\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 51 Batch 133/390 d_loss_real= 0.020, d_loss_fake= 0.032, g_loss 3.817, d_loss 0.026\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 134/390 d_loss_real= 0.199, d_loss_fake= 0.062, g_loss 3.945, d_loss 0.131\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 51 Batch 135/390 d_loss_real= 0.185, d_loss_fake= 0.022, g_loss 4.157, d_loss 0.104\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 136/390 d_loss_real= 0.013, d_loss_fake= 0.020, g_loss 4.267, d_loss 0.016\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 137/390 d_loss_real= 0.006, d_loss_fake= 0.016, g_loss 4.320, d_loss 0.011\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 138/390 d_loss_real= 0.068, d_loss_fake= 0.016, g_loss 4.355, d_loss 0.042\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 139/390 d_loss_real= 0.119, d_loss_fake= 0.016, g_loss 4.203, d_loss 0.067\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 51 Batch 140/390 d_loss_real= 0.295, d_loss_fake= 0.025, g_loss 4.034, d_loss 0.160\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 141/390 d_loss_real= 0.002, d_loss_fake= 0.044, g_loss 4.068, d_loss 0.023\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 51 Batch 142/390 d_loss_real= 0.126, d_loss_fake= 0.030, g_loss 3.878, d_loss 0.078\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 143/390 d_loss_real= 0.070, d_loss_fake= 0.034, g_loss 3.949, d_loss 0.052\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 51 Batch 144/390 d_loss_real= 0.138, d_loss_fake= 0.038, g_loss 4.150, d_loss 0.088\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 51 Batch 145/390 d_loss_real= 0.087, d_loss_fake= 0.018, g_loss 4.388, d_loss 0.052\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 146/390 d_loss_real= 0.160, d_loss_fake= 0.014, g_loss 4.452, d_loss 0.087\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 147/390 d_loss_real= 0.061, d_loss_fake= 0.013, g_loss 4.530, d_loss 0.037\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 148/390 d_loss_real= 0.180, d_loss_fake= 0.013, g_loss 4.430, d_loss 0.096\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 149/390 d_loss_real= 0.006, d_loss_fake= 0.014, g_loss 4.418, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 150/390 d_loss_real= 0.069, d_loss_fake= 0.013, g_loss 4.390, d_loss 0.041\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 151/390 d_loss_real= 0.063, d_loss_fake= 0.013, g_loss 4.361, d_loss 0.038\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 152/390 d_loss_real= 0.000, d_loss_fake= 0.014, g_loss 4.350, d_loss 0.007\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 153/390 d_loss_real= 0.019, d_loss_fake= 0.014, g_loss 4.230, d_loss 0.017\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 154/390 d_loss_real= 0.077, d_loss_fake= 0.016, g_loss 4.092, d_loss 0.047\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 155/390 d_loss_real= 0.020, d_loss_fake= 0.021, g_loss 3.955, d_loss 0.020\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 156/390 d_loss_real= 0.005, d_loss_fake= 0.029, g_loss 3.760, d_loss 0.017\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 157/390 d_loss_real= 0.113, d_loss_fake= 0.038, g_loss 3.396, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 158/390 d_loss_real= 0.069, d_loss_fake= 0.069, g_loss 3.506, d_loss 0.069\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 159/390 d_loss_real= 0.123, d_loss_fake= 0.046, g_loss 3.565, d_loss 0.085\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 160/390 d_loss_real= 0.069, d_loss_fake= 0.037, g_loss 3.801, d_loss 0.053\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 51 Batch 161/390 d_loss_real= 0.013, d_loss_fake= 0.028, g_loss 3.999, d_loss 0.020\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 51 Batch 162/390 d_loss_real= 0.000, d_loss_fake= 0.021, g_loss 4.259, d_loss 0.011\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 163/390 d_loss_real= 0.122, d_loss_fake= 0.016, g_loss 4.380, d_loss 0.069\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 164/390 d_loss_real= 0.188, d_loss_fake= 0.014, g_loss 4.361, d_loss 0.101\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 165/390 d_loss_real= 0.055, d_loss_fake= 0.016, g_loss 4.323, d_loss 0.036\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 51 Batch 166/390 d_loss_real= 0.000, d_loss_fake= 0.016, g_loss 4.224, d_loss 0.008\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 167/390 d_loss_real= 0.077, d_loss_fake= 0.018, g_loss 4.245, d_loss 0.047\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 51 Batch 168/390 d_loss_real= 0.067, d_loss_fake= 0.020, g_loss 4.228, d_loss 0.043\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 51 Batch 169/390 d_loss_real= 0.189, d_loss_fake= 0.023, g_loss 4.084, d_loss 0.106\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 170/390 d_loss_real= 0.128, d_loss_fake= 0.018, g_loss 4.019, d_loss 0.073\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 51 Batch 171/390 d_loss_real= 0.153, d_loss_fake= 0.026, g_loss 3.917, d_loss 0.089\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 172/390 d_loss_real= 0.201, d_loss_fake= 0.032, g_loss 4.107, d_loss 0.116\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 173/390 d_loss_real= 0.079, d_loss_fake= 0.042, g_loss 3.876, d_loss 0.061\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 51 Batch 174/390 d_loss_real= 0.115, d_loss_fake= 0.022, g_loss 4.334, d_loss 0.069\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 51 Batch 175/390 d_loss_real= 0.124, d_loss_fake= 0.017, g_loss 4.261, d_loss 0.071\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 176/390 d_loss_real= 0.140, d_loss_fake= 0.028, g_loss 4.117, d_loss 0.084\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 51 Batch 177/390 d_loss_real= 0.093, d_loss_fake= 0.025, g_loss 4.107, d_loss 0.059\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 178/390 d_loss_real= 0.026, d_loss_fake= 0.040, g_loss 3.981, d_loss 0.033\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 179/390 d_loss_real= 0.102, d_loss_fake= 0.032, g_loss 4.120, d_loss 0.067\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 51 Batch 180/390 d_loss_real= 0.038, d_loss_fake= 0.019, g_loss 4.389, d_loss 0.029\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 181/390 d_loss_real= 0.202, d_loss_fake= 0.015, g_loss 4.645, d_loss 0.108\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 182/390 d_loss_real= 0.279, d_loss_fake= 0.013, g_loss 4.708, d_loss 0.146\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 183/390 d_loss_real= 0.076, d_loss_fake= 0.010, g_loss 4.850, d_loss 0.043\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 51 Batch 184/390 d_loss_real= 0.146, d_loss_fake= 0.009, g_loss 4.819, d_loss 0.078\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 185/390 d_loss_real= 0.010, d_loss_fake= 0.010, g_loss 4.830, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 186/390 d_loss_real= 0.200, d_loss_fake= 0.009, g_loss 4.807, d_loss 0.105\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 187/390 d_loss_real= 0.170, d_loss_fake= 0.011, g_loss 4.551, d_loss 0.090\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 51 Batch 188/390 d_loss_real= 0.186, d_loss_fake= 0.013, g_loss 4.321, d_loss 0.100\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 51 Batch 189/390 d_loss_real= 0.308, d_loss_fake= 0.020, g_loss 4.044, d_loss 0.164\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 190/390 d_loss_real= 0.071, d_loss_fake= 0.025, g_loss 3.932, d_loss 0.048\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 191/390 d_loss_real= 0.094, d_loss_fake= 0.029, g_loss 3.583, d_loss 0.061\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 51 Batch 192/390 d_loss_real= 0.195, d_loss_fake= 0.049, g_loss 3.461, d_loss 0.122\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 51 Batch 193/390 d_loss_real= 0.023, d_loss_fake= 0.067, g_loss 3.687, d_loss 0.045\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 51 Batch 194/390 d_loss_real= 0.075, d_loss_fake= 0.031, g_loss 4.168, d_loss 0.053\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 51 Batch 195/390 d_loss_real= 0.115, d_loss_fake= 0.017, g_loss 4.399, d_loss 0.066\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 196/390 d_loss_real= 0.001, d_loss_fake= 0.012, g_loss 4.551, d_loss 0.007\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 51 Batch 197/390 d_loss_real= 0.062, d_loss_fake= 0.011, g_loss 4.591, d_loss 0.037\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 51 Batch 198/390 d_loss_real= 0.001, d_loss_fake= 0.011, g_loss 4.559, d_loss 0.006\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 199/390 d_loss_real= 0.053, d_loss_fake= 0.012, g_loss 4.542, d_loss 0.033\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 51 Batch 200/390 d_loss_real= 0.117, d_loss_fake= 0.012, g_loss 4.481, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 201/390 d_loss_real= 0.207, d_loss_fake= 0.013, g_loss 4.392, d_loss 0.110\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 202/390 d_loss_real= 0.167, d_loss_fake= 0.015, g_loss 4.218, d_loss 0.091\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 203/390 d_loss_real= 0.061, d_loss_fake= 0.019, g_loss 4.045, d_loss 0.040\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 204/390 d_loss_real= 0.114, d_loss_fake= 0.024, g_loss 3.679, d_loss 0.069\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 205/390 d_loss_real= 0.115, d_loss_fake= 0.045, g_loss 3.425, d_loss 0.080\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 206/390 d_loss_real= 0.058, d_loss_fake= 0.059, g_loss 3.499, d_loss 0.059\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 207/390 d_loss_real= 0.110, d_loss_fake= 0.031, g_loss 3.643, d_loss 0.071\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 208/390 d_loss_real= 0.171, d_loss_fake= 0.028, g_loss 3.755, d_loss 0.099\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 209/390 d_loss_real= 0.001, d_loss_fake= 0.026, g_loss 3.776, d_loss 0.013\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 210/390 d_loss_real= 0.075, d_loss_fake= 0.027, g_loss 3.809, d_loss 0.051\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 211/390 d_loss_real= 0.076, d_loss_fake= 0.022, g_loss 3.952, d_loss 0.049\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 212/390 d_loss_real= 0.004, d_loss_fake= 0.020, g_loss 4.052, d_loss 0.012\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 213/390 d_loss_real= 0.069, d_loss_fake= 0.020, g_loss 4.046, d_loss 0.045\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 214/390 d_loss_real= 0.001, d_loss_fake= 0.018, g_loss 4.138, d_loss 0.010\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 51 Batch 215/390 d_loss_real= 0.173, d_loss_fake= 0.019, g_loss 4.098, d_loss 0.096\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 216/390 d_loss_real= 0.119, d_loss_fake= 0.019, g_loss 3.966, d_loss 0.069\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 217/390 d_loss_real= 0.103, d_loss_fake= 0.021, g_loss 3.913, d_loss 0.062\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 218/390 d_loss_real= 0.106, d_loss_fake= 0.025, g_loss 3.781, d_loss 0.066\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 219/390 d_loss_real= 0.122, d_loss_fake= 0.026, g_loss 3.579, d_loss 0.074\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 220/390 d_loss_real= 0.001, d_loss_fake= 0.035, g_loss 3.665, d_loss 0.018\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 51 Batch 221/390 d_loss_real= 0.119, d_loss_fake= 0.030, g_loss 3.663, d_loss 0.075\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 222/390 d_loss_real= 0.021, d_loss_fake= 0.035, g_loss 3.681, d_loss 0.028\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 223/390 d_loss_real= 0.055, d_loss_fake= 0.025, g_loss 3.847, d_loss 0.040\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 224/390 d_loss_real= 0.103, d_loss_fake= 0.028, g_loss 3.793, d_loss 0.066\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 225/390 d_loss_real= 0.000, d_loss_fake= 0.023, g_loss 3.885, d_loss 0.012\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 51 Batch 226/390 d_loss_real= 0.064, d_loss_fake= 0.026, g_loss 3.839, d_loss 0.045\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 227/390 d_loss_real= 0.065, d_loss_fake= 0.026, g_loss 3.754, d_loss 0.046\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 228/390 d_loss_real= 0.000, d_loss_fake= 0.033, g_loss 3.909, d_loss 0.016\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 229/390 d_loss_real= 0.119, d_loss_fake= 0.024, g_loss 3.958, d_loss 0.072\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 230/390 d_loss_real= 0.141, d_loss_fake= 0.025, g_loss 3.976, d_loss 0.083\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 51 Batch 231/390 d_loss_real= 0.000, d_loss_fake= 0.021, g_loss 4.056, d_loss 0.010\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 232/390 d_loss_real= 0.054, d_loss_fake= 0.020, g_loss 4.109, d_loss 0.037\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 51 Batch 233/390 d_loss_real= 0.142, d_loss_fake= 0.024, g_loss 4.094, d_loss 0.083\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 234/390 d_loss_real= 0.059, d_loss_fake= 0.022, g_loss 4.061, d_loss 0.040\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 235/390 d_loss_real= 0.056, d_loss_fake= 0.018, g_loss 4.095, d_loss 0.037\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 51 Batch 236/390 d_loss_real= 0.072, d_loss_fake= 0.021, g_loss 4.080, d_loss 0.047\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 51 Batch 237/390 d_loss_real= 0.057, d_loss_fake= 0.023, g_loss 4.016, d_loss 0.040\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 238/390 d_loss_real= 0.000, d_loss_fake= 0.025, g_loss 3.923, d_loss 0.013\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 239/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 3.953, d_loss 0.010\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 240/390 d_loss_real= 0.058, d_loss_fake= 0.021, g_loss 3.934, d_loss 0.039\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 241/390 d_loss_real= 0.174, d_loss_fake= 0.026, g_loss 4.036, d_loss 0.100\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 242/390 d_loss_real= 0.114, d_loss_fake= 0.027, g_loss 3.875, d_loss 0.071\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 51 Batch 243/390 d_loss_real= 0.000, d_loss_fake= 0.027, g_loss 4.017, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 244/390 d_loss_real= 0.233, d_loss_fake= 0.030, g_loss 3.669, d_loss 0.131\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 245/390 d_loss_real= 0.060, d_loss_fake= 0.029, g_loss 3.827, d_loss 0.045\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 51 Batch 246/390 d_loss_real= 0.068, d_loss_fake= 0.028, g_loss 3.873, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 247/390 d_loss_real= 0.142, d_loss_fake= 0.030, g_loss 3.781, d_loss 0.086\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 51 Batch 248/390 d_loss_real= 0.055, d_loss_fake= 0.031, g_loss 3.916, d_loss 0.043\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 249/390 d_loss_real= 0.005, d_loss_fake= 0.026, g_loss 3.956, d_loss 0.016\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 250/390 d_loss_real= 0.102, d_loss_fake= 0.022, g_loss 4.016, d_loss 0.062\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 251/390 d_loss_real= 0.076, d_loss_fake= 0.019, g_loss 4.151, d_loss 0.048\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 252/390 d_loss_real= 0.015, d_loss_fake= 0.019, g_loss 4.084, d_loss 0.017\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 253/390 d_loss_real= 0.232, d_loss_fake= 0.019, g_loss 4.100, d_loss 0.126\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 51 Batch 254/390 d_loss_real= 0.000, d_loss_fake= 0.016, g_loss 4.099, d_loss 0.008\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 255/390 d_loss_real= 0.046, d_loss_fake= 0.026, g_loss 3.929, d_loss 0.036\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 256/390 d_loss_real= 0.138, d_loss_fake= 0.025, g_loss 3.848, d_loss 0.082\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 257/390 d_loss_real= 0.000, d_loss_fake= 0.025, g_loss 3.981, d_loss 0.013\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 51 Batch 258/390 d_loss_real= 0.142, d_loss_fake= 0.025, g_loss 3.968, d_loss 0.084\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 259/390 d_loss_real= 0.153, d_loss_fake= 0.023, g_loss 3.924, d_loss 0.088\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 260/390 d_loss_real= 0.087, d_loss_fake= 0.029, g_loss 3.930, d_loss 0.058\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 261/390 d_loss_real= 0.176, d_loss_fake= 0.033, g_loss 3.821, d_loss 0.105\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 262/390 d_loss_real= 0.001, d_loss_fake= 0.030, g_loss 4.037, d_loss 0.015\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 263/390 d_loss_real= 0.167, d_loss_fake= 0.024, g_loss 4.136, d_loss 0.095\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 264/390 d_loss_real= 0.083, d_loss_fake= 0.019, g_loss 4.039, d_loss 0.051\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 265/390 d_loss_real= 0.017, d_loss_fake= 0.021, g_loss 4.032, d_loss 0.019\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 266/390 d_loss_real= 0.167, d_loss_fake= 0.027, g_loss 3.826, d_loss 0.097\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 267/390 d_loss_real= 0.000, d_loss_fake= 0.028, g_loss 3.838, d_loss 0.014\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 51 Batch 268/390 d_loss_real= 0.049, d_loss_fake= 0.029, g_loss 4.019, d_loss 0.039\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 51 Batch 269/390 d_loss_real= 0.075, d_loss_fake= 0.018, g_loss 4.150, d_loss 0.047\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 51 Batch 270/390 d_loss_real= 0.076, d_loss_fake= 0.016, g_loss 4.312, d_loss 0.046\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 271/390 d_loss_real= 0.172, d_loss_fake= 0.015, g_loss 4.356, d_loss 0.093\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 272/390 d_loss_real= 0.223, d_loss_fake= 0.014, g_loss 4.271, d_loss 0.118\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 51 Batch 273/390 d_loss_real= 0.033, d_loss_fake= 0.017, g_loss 4.100, d_loss 0.025\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 274/390 d_loss_real= 0.032, d_loss_fake= 0.019, g_loss 3.947, d_loss 0.026\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 275/390 d_loss_real= 0.101, d_loss_fake= 0.027, g_loss 3.713, d_loss 0.064\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 51 Batch 276/390 d_loss_real= 0.174, d_loss_fake= 0.045, g_loss 3.439, d_loss 0.109\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 277/390 d_loss_real= 0.084, d_loss_fake= 0.060, g_loss 3.527, d_loss 0.072\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 278/390 d_loss_real= 0.086, d_loss_fake= 0.030, g_loss 3.821, d_loss 0.058\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 51 Batch 279/390 d_loss_real= 0.003, d_loss_fake= 0.020, g_loss 4.022, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 280/390 d_loss_real= 0.238, d_loss_fake= 0.019, g_loss 4.087, d_loss 0.129\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 281/390 d_loss_real= 0.083, d_loss_fake= 0.020, g_loss 3.943, d_loss 0.051\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 51 Batch 282/390 d_loss_real= 0.057, d_loss_fake= 0.021, g_loss 3.890, d_loss 0.039\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 283/390 d_loss_real= 0.010, d_loss_fake= 0.025, g_loss 3.787, d_loss 0.017\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 284/390 d_loss_real= 0.008, d_loss_fake= 0.027, g_loss 3.692, d_loss 0.018\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 51 Batch 285/390 d_loss_real= 0.046, d_loss_fake= 0.033, g_loss 3.610, d_loss 0.039\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 51 Batch 286/390 d_loss_real= 0.000, d_loss_fake= 0.028, g_loss 3.781, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 287/390 d_loss_real= 0.003, d_loss_fake= 0.024, g_loss 3.867, d_loss 0.014\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 288/390 d_loss_real= 0.130, d_loss_fake= 0.022, g_loss 4.012, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 289/390 d_loss_real= 0.086, d_loss_fake= 0.019, g_loss 4.048, d_loss 0.053\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 290/390 d_loss_real= 0.078, d_loss_fake= 0.018, g_loss 4.136, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 291/390 d_loss_real= 0.083, d_loss_fake= 0.017, g_loss 4.161, d_loss 0.050\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 292/390 d_loss_real= 0.000, d_loss_fake= 0.016, g_loss 4.209, d_loss 0.008\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 293/390 d_loss_real= 0.119, d_loss_fake= 0.016, g_loss 4.171, d_loss 0.068\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 51 Batch 294/390 d_loss_real= 0.001, d_loss_fake= 0.017, g_loss 4.137, d_loss 0.009\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 51 Batch 295/390 d_loss_real= 0.048, d_loss_fake= 0.017, g_loss 4.050, d_loss 0.033\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 296/390 d_loss_real= 0.030, d_loss_fake= 0.020, g_loss 3.908, d_loss 0.025\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 51 Batch 297/390 d_loss_real= 0.069, d_loss_fake= 0.024, g_loss 3.837, d_loss 0.047\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 51 Batch 298/390 d_loss_real= 0.068, d_loss_fake= 0.025, g_loss 3.935, d_loss 0.046\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 299/390 d_loss_real= 0.069, d_loss_fake= 0.021, g_loss 4.036, d_loss 0.045\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 300/390 d_loss_real= 0.167, d_loss_fake= 0.019, g_loss 4.147, d_loss 0.093\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 301/390 d_loss_real= 0.003, d_loss_fake= 0.016, g_loss 4.224, d_loss 0.010\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 302/390 d_loss_real= 0.283, d_loss_fake= 0.016, g_loss 4.207, d_loss 0.150\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 51 Batch 303/390 d_loss_real= 0.045, d_loss_fake= 0.014, g_loss 4.259, d_loss 0.030\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 304/390 d_loss_real= 0.079, d_loss_fake= 0.015, g_loss 4.245, d_loss 0.047\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 305/390 d_loss_real= 0.000, d_loss_fake= 0.015, g_loss 4.338, d_loss 0.007\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 306/390 d_loss_real= 0.001, d_loss_fake= 0.014, g_loss 4.326, d_loss 0.007\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 307/390 d_loss_real= 0.181, d_loss_fake= 0.014, g_loss 4.318, d_loss 0.097\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 308/390 d_loss_real= 0.000, d_loss_fake= 0.015, g_loss 4.247, d_loss 0.007\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 309/390 d_loss_real= 0.213, d_loss_fake= 0.016, g_loss 4.158, d_loss 0.115\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 310/390 d_loss_real= 0.196, d_loss_fake= 0.021, g_loss 3.849, d_loss 0.108\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 311/390 d_loss_real= 0.197, d_loss_fake= 0.032, g_loss 3.571, d_loss 0.115\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 312/390 d_loss_real= 0.000, d_loss_fake= 0.040, g_loss 3.542, d_loss 0.020\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 313/390 d_loss_real= 0.073, d_loss_fake= 0.030, g_loss 3.705, d_loss 0.052\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 314/390 d_loss_real= 0.058, d_loss_fake= 0.029, g_loss 3.646, d_loss 0.043\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 315/390 d_loss_real= 0.096, d_loss_fake= 0.030, g_loss 3.739, d_loss 0.063\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 51 Batch 316/390 d_loss_real= 0.190, d_loss_fake= 0.024, g_loss 3.780, d_loss 0.107\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 317/390 d_loss_real= 0.084, d_loss_fake= 0.024, g_loss 3.720, d_loss 0.054\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 318/390 d_loss_real= 0.150, d_loss_fake= 0.030, g_loss 3.634, d_loss 0.090\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 319/390 d_loss_real= 0.000, d_loss_fake= 0.029, g_loss 3.620, d_loss 0.015\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 51 Batch 320/390 d_loss_real= 0.099, d_loss_fake= 0.030, g_loss 3.617, d_loss 0.065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 321/390 d_loss_real= 0.065, d_loss_fake= 0.029, g_loss 3.710, d_loss 0.047\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 51 Batch 322/390 d_loss_real= 0.040, d_loss_fake= 0.026, g_loss 3.747, d_loss 0.033\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 323/390 d_loss_real= 0.000, d_loss_fake= 0.025, g_loss 3.880, d_loss 0.013\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 324/390 d_loss_real= 0.100, d_loss_fake= 0.022, g_loss 3.875, d_loss 0.061\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 325/390 d_loss_real= 0.100, d_loss_fake= 0.024, g_loss 3.704, d_loss 0.062\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 326/390 d_loss_real= 0.000, d_loss_fake= 0.029, g_loss 3.649, d_loss 0.015\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 51 Batch 327/390 d_loss_real= 0.081, d_loss_fake= 0.031, g_loss 3.548, d_loss 0.056\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 328/390 d_loss_real= 0.028, d_loss_fake= 0.033, g_loss 3.434, d_loss 0.030\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 329/390 d_loss_real= 0.128, d_loss_fake= 0.040, g_loss 3.430, d_loss 0.084\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 330/390 d_loss_real= 0.000, d_loss_fake= 0.045, g_loss 3.521, d_loss 0.022\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 331/390 d_loss_real= 0.001, d_loss_fake= 0.031, g_loss 3.886, d_loss 0.016\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 51 Batch 332/390 d_loss_real= 0.099, d_loss_fake= 0.021, g_loss 4.108, d_loss 0.060\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 333/390 d_loss_real= 0.107, d_loss_fake= 0.021, g_loss 4.037, d_loss 0.064\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 51 Batch 334/390 d_loss_real= 0.042, d_loss_fake= 0.021, g_loss 3.929, d_loss 0.032\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 335/390 d_loss_real= 0.016, d_loss_fake= 0.024, g_loss 3.858, d_loss 0.020\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 336/390 d_loss_real= 0.072, d_loss_fake= 0.029, g_loss 3.763, d_loss 0.050\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 337/390 d_loss_real= 0.046, d_loss_fake= 0.035, g_loss 3.712, d_loss 0.041\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 338/390 d_loss_real= 0.033, d_loss_fake= 0.029, g_loss 3.898, d_loss 0.031\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 339/390 d_loss_real= 0.047, d_loss_fake= 0.025, g_loss 3.958, d_loss 0.036\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 340/390 d_loss_real= 0.117, d_loss_fake= 0.018, g_loss 4.158, d_loss 0.068\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 341/390 d_loss_real= 0.062, d_loss_fake= 0.016, g_loss 4.269, d_loss 0.039\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 342/390 d_loss_real= 0.032, d_loss_fake= 0.016, g_loss 4.267, d_loss 0.024\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 51 Batch 343/390 d_loss_real= 0.202, d_loss_fake= 0.016, g_loss 4.104, d_loss 0.109\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 344/390 d_loss_real= 0.062, d_loss_fake= 0.019, g_loss 4.013, d_loss 0.041\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 345/390 d_loss_real= 0.038, d_loss_fake= 0.021, g_loss 3.876, d_loss 0.029\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 346/390 d_loss_real= 0.053, d_loss_fake= 0.025, g_loss 3.726, d_loss 0.039\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 347/390 d_loss_real= 0.024, d_loss_fake= 0.029, g_loss 3.635, d_loss 0.026\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 348/390 d_loss_real= 0.111, d_loss_fake= 0.036, g_loss 3.576, d_loss 0.073\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 51 Batch 349/390 d_loss_real= 0.050, d_loss_fake= 0.032, g_loss 3.659, d_loss 0.041\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 350/390 d_loss_real= 0.059, d_loss_fake= 0.028, g_loss 3.746, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 351/390 d_loss_real= 0.141, d_loss_fake= 0.024, g_loss 3.812, d_loss 0.082\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 352/390 d_loss_real= 0.000, d_loss_fake= 0.026, g_loss 3.911, d_loss 0.013\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 51 Batch 353/390 d_loss_real= 0.112, d_loss_fake= 0.024, g_loss 3.867, d_loss 0.068\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 354/390 d_loss_real= 0.000, d_loss_fake= 0.025, g_loss 3.873, d_loss 0.013\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 355/390 d_loss_real= 0.109, d_loss_fake= 0.026, g_loss 3.823, d_loss 0.067\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 356/390 d_loss_real= 0.175, d_loss_fake= 0.028, g_loss 3.738, d_loss 0.101\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 357/390 d_loss_real= 0.000, d_loss_fake= 0.028, g_loss 3.807, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 358/390 d_loss_real= 0.000, d_loss_fake= 0.026, g_loss 3.745, d_loss 0.013\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 359/390 d_loss_real= 0.033, d_loss_fake= 0.025, g_loss 3.824, d_loss 0.029\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 51 Batch 360/390 d_loss_real= 0.163, d_loss_fake= 0.024, g_loss 3.728, d_loss 0.094\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 361/390 d_loss_real= 0.000, d_loss_fake= 0.029, g_loss 3.698, d_loss 0.015\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 362/390 d_loss_real= 0.011, d_loss_fake= 0.030, g_loss 3.710, d_loss 0.020\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 363/390 d_loss_real= 0.109, d_loss_fake= 0.027, g_loss 3.682, d_loss 0.068\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 51 Batch 364/390 d_loss_real= 0.076, d_loss_fake= 0.029, g_loss 3.644, d_loss 0.053\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 365/390 d_loss_real= 0.063, d_loss_fake= 0.022, g_loss 3.927, d_loss 0.043\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 366/390 d_loss_real= 0.141, d_loss_fake= 0.032, g_loss 3.540, d_loss 0.087\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 367/390 d_loss_real= 0.047, d_loss_fake= 0.023, g_loss 3.787, d_loss 0.035\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 368/390 d_loss_real= 0.002, d_loss_fake= 0.038, g_loss 3.548, d_loss 0.020\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 369/390 d_loss_real= 0.000, d_loss_fake= 0.066, g_loss 3.661, d_loss 0.033\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 370/390 d_loss_real= 0.101, d_loss_fake= 0.022, g_loss 4.169, d_loss 0.062\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 51 Batch 371/390 d_loss_real= 0.170, d_loss_fake= 0.017, g_loss 4.245, d_loss 0.093\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 372/390 d_loss_real= 0.302, d_loss_fake= 0.018, g_loss 3.849, d_loss 0.160\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 373/390 d_loss_real= 0.066, d_loss_fake= 0.028, g_loss 3.841, d_loss 0.047\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 374/390 d_loss_real= 0.107, d_loss_fake= 0.038, g_loss 3.459, d_loss 0.072\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 375/390 d_loss_real= 0.148, d_loss_fake= 0.095, g_loss 3.614, d_loss 0.122\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51 Batch 376/390 d_loss_real= 0.131, d_loss_fake= 0.034, g_loss 4.012, d_loss 0.082\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 377/390 d_loss_real= 0.100, d_loss_fake= 0.021, g_loss 4.109, d_loss 0.060\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 51 Batch 378/390 d_loss_real= 0.076, d_loss_fake= 0.019, g_loss 4.107, d_loss 0.048\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51 Batch 379/390 d_loss_real= 0.000, d_loss_fake= 0.018, g_loss 4.180, d_loss 0.009\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 51 Batch 380/390 d_loss_real= 0.086, d_loss_fake= 0.018, g_loss 4.170, d_loss 0.052\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 381/390 d_loss_real= 0.065, d_loss_fake= 0.020, g_loss 4.053, d_loss 0.042\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 382/390 d_loss_real= 0.096, d_loss_fake= 0.022, g_loss 3.911, d_loss 0.059\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 383/390 d_loss_real= 0.079, d_loss_fake= 0.023, g_loss 3.928, d_loss 0.051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 384/390 d_loss_real= 0.160, d_loss_fake= 0.025, g_loss 3.884, d_loss 0.093\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 385/390 d_loss_real= 0.083, d_loss_fake= 0.023, g_loss 3.932, d_loss 0.053\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51 Batch 386/390 d_loss_real= 0.006, d_loss_fake= 0.024, g_loss 3.896, d_loss 0.015\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51 Batch 387/390 d_loss_real= 0.132, d_loss_fake= 0.028, g_loss 4.059, d_loss 0.080\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 51 Batch 388/390 d_loss_real= 0.000, d_loss_fake= 0.019, g_loss 4.099, d_loss 0.009\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51 Batch 389/390 d_loss_real= 0.019, d_loss_fake= 0.018, g_loss 4.371, d_loss 0.018\n",
            "2/2 [==============================] - 0s 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 51 Batch 390/390 d_loss_real= 0.017, d_loss_fake= 0.019, g_loss 4.219, d_loss 0.018\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 1/390 d_loss_real= 0.003, d_loss_fake= 0.015, g_loss 4.292, d_loss 0.009\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52 Batch 2/390 d_loss_real= 0.096, d_loss_fake= 0.017, g_loss 4.223, d_loss 0.057\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 3/390 d_loss_real= 0.134, d_loss_fake= 0.018, g_loss 4.080, d_loss 0.076\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 4/390 d_loss_real= 0.117, d_loss_fake= 0.028, g_loss 4.050, d_loss 0.073\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 5/390 d_loss_real= 0.120, d_loss_fake= 0.022, g_loss 4.264, d_loss 0.071\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 6/390 d_loss_real= 0.011, d_loss_fake= 0.018, g_loss 4.579, d_loss 0.014\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 7/390 d_loss_real= 0.048, d_loss_fake= 0.010, g_loss 4.846, d_loss 0.029\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 8/390 d_loss_real= 0.061, d_loss_fake= 0.008, g_loss 5.033, d_loss 0.034\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 52 Batch 9/390 d_loss_real= 0.018, d_loss_fake= 0.012, g_loss 4.691, d_loss 0.015\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 52 Batch 10/390 d_loss_real= 0.004, d_loss_fake= 0.007, g_loss 5.182, d_loss 0.006\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 11/390 d_loss_real= 0.000, d_loss_fake= 0.005, g_loss 5.601, d_loss 0.003\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 12/390 d_loss_real= 0.052, d_loss_fake= 0.008, g_loss 4.834, d_loss 0.030\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 13/390 d_loss_real= 0.000, d_loss_fake= 0.008, g_loss 5.070, d_loss 0.004\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 52 Batch 14/390 d_loss_real= 0.022, d_loss_fake= 0.058, g_loss 5.653, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 15/390 d_loss_real= 0.000, d_loss_fake= 0.006, g_loss 5.469, d_loss 0.003\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 16/390 d_loss_real= 0.153, d_loss_fake= 0.008, g_loss 5.124, d_loss 0.080\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 17/390 d_loss_real= 0.072, d_loss_fake= 0.008, g_loss 4.764, d_loss 0.040\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 18/390 d_loss_real= 0.151, d_loss_fake= 0.012, g_loss 4.581, d_loss 0.081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 19/390 d_loss_real= 0.000, d_loss_fake= 0.014, g_loss 4.374, d_loss 0.007\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 52 Batch 20/390 d_loss_real= 0.093, d_loss_fake= 0.019, g_loss 4.152, d_loss 0.056\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 21/390 d_loss_real= 0.154, d_loss_fake= 0.027, g_loss 3.845, d_loss 0.090\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 22/390 d_loss_real= 0.060, d_loss_fake= 0.033, g_loss 3.649, d_loss 0.047\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 23/390 d_loss_real= 0.070, d_loss_fake= 0.045, g_loss 3.288, d_loss 0.057\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 24/390 d_loss_real= 0.170, d_loss_fake= 0.061, g_loss 3.218, d_loss 0.115\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 25/390 d_loss_real= 0.134, d_loss_fake= 0.092, g_loss 2.840, d_loss 0.113\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 52 Batch 26/390 d_loss_real= 0.178, d_loss_fake= 0.089, g_loss 2.943, d_loss 0.133\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 52 Batch 27/390 d_loss_real= 0.162, d_loss_fake= 0.057, g_loss 3.551, d_loss 0.110\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 28/390 d_loss_real= 0.129, d_loss_fake= 0.034, g_loss 3.887, d_loss 0.082\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 29/390 d_loss_real= 0.051, d_loss_fake= 0.025, g_loss 4.029, d_loss 0.038\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 52 Batch 30/390 d_loss_real= 0.153, d_loss_fake= 0.025, g_loss 3.972, d_loss 0.089\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 31/390 d_loss_real= 0.093, d_loss_fake= 0.040, g_loss 3.702, d_loss 0.066\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 32/390 d_loss_real= 0.000, d_loss_fake= 0.059, g_loss 4.122, d_loss 0.030\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 33/390 d_loss_real= 0.162, d_loss_fake= 0.012, g_loss 4.844, d_loss 0.087\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 34/390 d_loss_real= 0.162, d_loss_fake= 0.008, g_loss 5.030, d_loss 0.085\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 52 Batch 35/390 d_loss_real= 0.150, d_loss_fake= 0.007, g_loss 5.144, d_loss 0.079\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52 Batch 36/390 d_loss_real= 0.001, d_loss_fake= 0.007, g_loss 5.103, d_loss 0.004\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 52 Batch 37/390 d_loss_real= 0.100, d_loss_fake= 0.007, g_loss 5.043, d_loss 0.053\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 38/390 d_loss_real= 0.073, d_loss_fake= 0.009, g_loss 4.875, d_loss 0.041\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 52 Batch 39/390 d_loss_real= 0.022, d_loss_fake= 0.009, g_loss 4.904, d_loss 0.016\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 52 Batch 40/390 d_loss_real= 0.008, d_loss_fake= 0.010, g_loss 4.795, d_loss 0.009\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52 Batch 41/390 d_loss_real= 0.000, d_loss_fake= 0.010, g_loss 4.819, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 42/390 d_loss_real= 0.000, d_loss_fake= 0.010, g_loss 4.765, d_loss 0.005\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52 Batch 43/390 d_loss_real= 0.080, d_loss_fake= 0.010, g_loss 4.658, d_loss 0.045\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 52 Batch 44/390 d_loss_real= 0.000, d_loss_fake= 0.011, g_loss 4.592, d_loss 0.005\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 45/390 d_loss_real= 0.079, d_loss_fake= 0.012, g_loss 4.531, d_loss 0.045\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 52 Batch 46/390 d_loss_real= 0.042, d_loss_fake= 0.013, g_loss 4.496, d_loss 0.027\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 47/390 d_loss_real= 0.000, d_loss_fake= 0.013, g_loss 4.354, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 48/390 d_loss_real= 0.000, d_loss_fake= 0.015, g_loss 4.278, d_loss 0.007\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 49/390 d_loss_real= 0.153, d_loss_fake= 0.016, g_loss 4.206, d_loss 0.084\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 50/390 d_loss_real= 0.000, d_loss_fake= 0.017, g_loss 4.149, d_loss 0.009\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 51/390 d_loss_real= 0.093, d_loss_fake= 0.020, g_loss 3.921, d_loss 0.057\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 52/390 d_loss_real= 0.118, d_loss_fake= 0.029, g_loss 3.733, d_loss 0.073\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 52 Batch 53/390 d_loss_real= 0.000, d_loss_fake= 0.049, g_loss 3.556, d_loss 0.025\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 54/390 d_loss_real= 0.099, d_loss_fake= 0.052, g_loss 3.921, d_loss 0.076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 55/390 d_loss_real= 0.003, d_loss_fake= 0.025, g_loss 4.218, d_loss 0.014\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 56/390 d_loss_real= 0.150, d_loss_fake= 0.015, g_loss 4.603, d_loss 0.082\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 57/390 d_loss_real= 0.000, d_loss_fake= 0.012, g_loss 4.641, d_loss 0.006\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52 Batch 58/390 d_loss_real= 0.130, d_loss_fake= 0.011, g_loss 4.651, d_loss 0.070\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52 Batch 59/390 d_loss_real= 0.112, d_loss_fake= 0.011, g_loss 4.527, d_loss 0.062\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 52 Batch 60/390 d_loss_real= 0.082, d_loss_fake= 0.012, g_loss 4.503, d_loss 0.047\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 61/390 d_loss_real= 0.017, d_loss_fake= 0.012, g_loss 4.446, d_loss 0.015\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 62/390 d_loss_real= 0.000, d_loss_fake= 0.016, g_loss 4.270, d_loss 0.008\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 52 Batch 63/390 d_loss_real= 0.000, d_loss_fake= 0.017, g_loss 4.231, d_loss 0.008\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 64/390 d_loss_real= 0.196, d_loss_fake= 0.024, g_loss 3.939, d_loss 0.110\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 65/390 d_loss_real= 0.144, d_loss_fake= 0.037, g_loss 3.748, d_loss 0.091\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 52 Batch 66/390 d_loss_real= 0.000, d_loss_fake= 0.055, g_loss 3.715, d_loss 0.028\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 67/390 d_loss_real= 0.026, d_loss_fake= 0.039, g_loss 3.957, d_loss 0.032\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52 Batch 68/390 d_loss_real= 0.175, d_loss_fake= 0.028, g_loss 4.316, d_loss 0.101\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 69/390 d_loss_real= 0.070, d_loss_fake= 0.016, g_loss 4.686, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 70/390 d_loss_real= 0.201, d_loss_fake= 0.010, g_loss 4.759, d_loss 0.106\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 71/390 d_loss_real= 0.456, d_loss_fake= 0.011, g_loss 4.571, d_loss 0.233\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 72/390 d_loss_real= 0.009, d_loss_fake= 0.014, g_loss 4.344, d_loss 0.012\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 73/390 d_loss_real= 0.084, d_loss_fake= 0.017, g_loss 4.182, d_loss 0.051\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 74/390 d_loss_real= 0.069, d_loss_fake= 0.019, g_loss 4.144, d_loss 0.044\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52 Batch 75/390 d_loss_real= 0.141, d_loss_fake= 0.028, g_loss 3.986, d_loss 0.085\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 76/390 d_loss_real= 0.000, d_loss_fake= 0.019, g_loss 3.990, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 77/390 d_loss_real= 0.066, d_loss_fake= 0.031, g_loss 3.757, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 78/390 d_loss_real= 0.070, d_loss_fake= 0.029, g_loss 3.914, d_loss 0.050\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52 Batch 79/390 d_loss_real= 0.023, d_loss_fake= 0.037, g_loss 3.874, d_loss 0.030\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 52 Batch 80/390 d_loss_real= 0.032, d_loss_fake= 0.021, g_loss 4.268, d_loss 0.027\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 81/390 d_loss_real= 0.155, d_loss_fake= 0.040, g_loss 3.945, d_loss 0.097\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 52 Batch 82/390 d_loss_real= 0.137, d_loss_fake= 0.093, g_loss 4.713, d_loss 0.115\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 83/390 d_loss_real= 0.000, d_loss_fake= 0.015, g_loss 4.803, d_loss 0.008\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 84/390 d_loss_real= 0.174, d_loss_fake= 0.009, g_loss 4.969, d_loss 0.091\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 85/390 d_loss_real= 0.217, d_loss_fake= 0.008, g_loss 4.886, d_loss 0.112\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 86/390 d_loss_real= 0.004, d_loss_fake= 0.008, g_loss 4.862, d_loss 0.006\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 87/390 d_loss_real= 0.053, d_loss_fake= 0.009, g_loss 4.845, d_loss 0.031\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 52 Batch 88/390 d_loss_real= 0.239, d_loss_fake= 0.010, g_loss 4.760, d_loss 0.124\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 89/390 d_loss_real= 0.110, d_loss_fake= 0.010, g_loss 4.544, d_loss 0.060\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 52 Batch 90/390 d_loss_real= 0.104, d_loss_fake= 0.012, g_loss 4.382, d_loss 0.058\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 91/390 d_loss_real= 0.140, d_loss_fake= 0.014, g_loss 4.278, d_loss 0.077\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 92/390 d_loss_real= 0.259, d_loss_fake= 0.016, g_loss 4.125, d_loss 0.137\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 93/390 d_loss_real= 0.000, d_loss_fake= 0.022, g_loss 3.908, d_loss 0.011\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 52 Batch 94/390 d_loss_real= 0.000, d_loss_fake= 0.026, g_loss 3.800, d_loss 0.013\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 95/390 d_loss_real= 0.080, d_loss_fake= 0.032, g_loss 3.632, d_loss 0.056\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 96/390 d_loss_real= 0.065, d_loss_fake= 0.038, g_loss 3.424, d_loss 0.052\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 97/390 d_loss_real= 0.069, d_loss_fake= 0.052, g_loss 3.266, d_loss 0.061\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 98/390 d_loss_real= 0.000, d_loss_fake= 0.100, g_loss 3.459, d_loss 0.050\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 99/390 d_loss_real= 0.122, d_loss_fake= 0.035, g_loss 3.821, d_loss 0.078\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 100/390 d_loss_real= 0.025, d_loss_fake= 0.039, g_loss 3.806, d_loss 0.032\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 101/390 d_loss_real= 0.083, d_loss_fake= 0.027, g_loss 3.988, d_loss 0.055\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 102/390 d_loss_real= 0.194, d_loss_fake= 0.026, g_loss 4.143, d_loss 0.110\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 103/390 d_loss_real= 0.000, d_loss_fake= 0.022, g_loss 4.327, d_loss 0.011\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 104/390 d_loss_real= 0.085, d_loss_fake= 0.018, g_loss 4.399, d_loss 0.051\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 52 Batch 105/390 d_loss_real= 0.217, d_loss_fake= 0.015, g_loss 4.275, d_loss 0.116\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 52 Batch 106/390 d_loss_real= 0.004, d_loss_fake= 0.019, g_loss 4.309, d_loss 0.011\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 107/390 d_loss_real= 0.093, d_loss_fake= 0.024, g_loss 4.223, d_loss 0.059\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 108/390 d_loss_real= 0.071, d_loss_fake= 0.020, g_loss 4.368, d_loss 0.045\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 52 Batch 109/390 d_loss_real= 0.074, d_loss_fake= 0.014, g_loss 4.375, d_loss 0.044\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 110/390 d_loss_real= 0.008, d_loss_fake= 0.015, g_loss 4.469, d_loss 0.011\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 111/390 d_loss_real= 0.074, d_loss_fake= 0.015, g_loss 4.515, d_loss 0.044\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 112/390 d_loss_real= 0.053, d_loss_fake= 0.011, g_loss 4.520, d_loss 0.032\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 52 Batch 113/390 d_loss_real= 0.000, d_loss_fake= 0.013, g_loss 4.560, d_loss 0.007\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 114/390 d_loss_real= 0.066, d_loss_fake= 0.011, g_loss 4.491, d_loss 0.039\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 115/390 d_loss_real= 0.003, d_loss_fake= 0.012, g_loss 4.445, d_loss 0.008\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 116/390 d_loss_real= 0.109, d_loss_fake= 0.015, g_loss 4.375, d_loss 0.062\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 117/390 d_loss_real= 0.012, d_loss_fake= 0.027, g_loss 4.251, d_loss 0.019\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 118/390 d_loss_real= 0.064, d_loss_fake= 0.026, g_loss 4.172, d_loss 0.045\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 52 Batch 119/390 d_loss_real= 0.187, d_loss_fake= 0.099, g_loss 4.468, d_loss 0.143\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 120/390 d_loss_real= 0.121, d_loss_fake= 0.047, g_loss 5.059, d_loss 0.084\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 121/390 d_loss_real= 0.127, d_loss_fake= 0.006, g_loss 5.227, d_loss 0.067\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 122/390 d_loss_real= 0.103, d_loss_fake= 0.006, g_loss 5.295, d_loss 0.054\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 123/390 d_loss_real= 0.229, d_loss_fake= 0.006, g_loss 5.204, d_loss 0.118\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 124/390 d_loss_real= 0.207, d_loss_fake= 0.007, g_loss 5.027, d_loss 0.107\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 52 Batch 125/390 d_loss_real= 0.256, d_loss_fake= 0.008, g_loss 4.888, d_loss 0.132\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 52 Batch 126/390 d_loss_real= 0.122, d_loss_fake= 0.009, g_loss 4.698, d_loss 0.066\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 52 Batch 127/390 d_loss_real= 0.157, d_loss_fake= 0.010, g_loss 4.558, d_loss 0.084\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 52 Batch 128/390 d_loss_real= 0.223, d_loss_fake= 0.012, g_loss 4.385, d_loss 0.118\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52 Batch 129/390 d_loss_real= 0.139, d_loss_fake= 0.014, g_loss 4.243, d_loss 0.076\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 130/390 d_loss_real= 0.110, d_loss_fake= 0.017, g_loss 4.075, d_loss 0.063\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52 Batch 131/390 d_loss_real= 0.074, d_loss_fake= 0.020, g_loss 3.951, d_loss 0.047\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 132/390 d_loss_real= 0.000, d_loss_fake= 0.021, g_loss 3.902, d_loss 0.011\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 52 Batch 133/390 d_loss_real= 0.037, d_loss_fake= 0.023, g_loss 3.809, d_loss 0.030\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52 Batch 134/390 d_loss_real= 0.121, d_loss_fake= 0.024, g_loss 3.763, d_loss 0.072\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 135/390 d_loss_real= 0.073, d_loss_fake= 0.025, g_loss 3.707, d_loss 0.049\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 136/390 d_loss_real= 0.042, d_loss_fake= 0.026, g_loss 3.657, d_loss 0.034\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 137/390 d_loss_real= 0.096, d_loss_fake= 0.028, g_loss 3.567, d_loss 0.062\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 52 Batch 138/390 d_loss_real= 0.045, d_loss_fake= 0.031, g_loss 3.437, d_loss 0.038\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 139/390 d_loss_real= 0.000, d_loss_fake= 0.034, g_loss 3.426, d_loss 0.017\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 52 Batch 140/390 d_loss_real= 0.058, d_loss_fake= 0.038, g_loss 3.279, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 141/390 d_loss_real= 0.013, d_loss_fake= 0.055, g_loss 3.149, d_loss 0.034\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 52 Batch 142/390 d_loss_real= 0.000, d_loss_fake= 0.062, g_loss 3.246, d_loss 0.031\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 52 Batch 143/390 d_loss_real= 0.059, d_loss_fake= 0.043, g_loss 3.461, d_loss 0.051\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 144/390 d_loss_real= 0.111, d_loss_fake= 0.033, g_loss 3.594, d_loss 0.072\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 145/390 d_loss_real= 0.038, d_loss_fake= 0.029, g_loss 3.688, d_loss 0.033\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 146/390 d_loss_real= 0.046, d_loss_fake= 0.028, g_loss 3.766, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 147/390 d_loss_real= 0.067, d_loss_fake= 0.028, g_loss 3.694, d_loss 0.048\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 52 Batch 148/390 d_loss_real= 0.015, d_loss_fake= 0.027, g_loss 3.738, d_loss 0.021\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 149/390 d_loss_real= 0.005, d_loss_fake= 0.027, g_loss 3.775, d_loss 0.016\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 150/390 d_loss_real= 0.028, d_loss_fake= 0.025, g_loss 3.781, d_loss 0.026\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 151/390 d_loss_real= 0.024, d_loss_fake= 0.025, g_loss 3.740, d_loss 0.024\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 152/390 d_loss_real= 0.069, d_loss_fake= 0.025, g_loss 3.760, d_loss 0.047\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52 Batch 153/390 d_loss_real= 0.068, d_loss_fake= 0.028, g_loss 3.707, d_loss 0.048\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 154/390 d_loss_real= 0.000, d_loss_fake= 0.032, g_loss 3.693, d_loss 0.016\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 155/390 d_loss_real= 0.005, d_loss_fake= 0.033, g_loss 3.804, d_loss 0.019\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 156/390 d_loss_real= 0.064, d_loss_fake= 0.032, g_loss 3.944, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 157/390 d_loss_real= 0.115, d_loss_fake= 0.026, g_loss 4.003, d_loss 0.070\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52 Batch 158/390 d_loss_real= 0.075, d_loss_fake= 0.036, g_loss 4.087, d_loss 0.055\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 159/390 d_loss_real= 0.000, d_loss_fake= 0.019, g_loss 4.460, d_loss 0.010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 52 Batch 160/390 d_loss_real= 0.002, d_loss_fake= 0.011, g_loss 4.815, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 161/390 d_loss_real= 0.240, d_loss_fake= 0.008, g_loss 4.956, d_loss 0.124\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 162/390 d_loss_real= 0.000, d_loss_fake= 0.007, g_loss 5.087, d_loss 0.004\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52 Batch 163/390 d_loss_real= 0.239, d_loss_fake= 0.007, g_loss 5.025, d_loss 0.123\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 164/390 d_loss_real= 0.024, d_loss_fake= 0.007, g_loss 4.951, d_loss 0.016\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 52 Batch 165/390 d_loss_real= 0.014, d_loss_fake= 0.008, g_loss 4.847, d_loss 0.011\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 166/390 d_loss_real= 0.115, d_loss_fake= 0.012, g_loss 4.480, d_loss 0.064\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 167/390 d_loss_real= 0.002, d_loss_fake= 0.023, g_loss 4.368, d_loss 0.012\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 52 Batch 168/390 d_loss_real= 0.088, d_loss_fake= 0.041, g_loss 4.146, d_loss 0.065\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 169/390 d_loss_real= 0.081, d_loss_fake= 0.020, g_loss 4.583, d_loss 0.051\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 52 Batch 170/390 d_loss_real= 0.049, d_loss_fake= 0.009, g_loss 5.028, d_loss 0.029\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 171/390 d_loss_real= 0.053, d_loss_fake= 0.007, g_loss 5.025, d_loss 0.030\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 172/390 d_loss_real= 0.127, d_loss_fake= 0.008, g_loss 5.003, d_loss 0.067\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 173/390 d_loss_real= 0.267, d_loss_fake= 0.009, g_loss 4.597, d_loss 0.138\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 52 Batch 174/390 d_loss_real= 0.056, d_loss_fake= 0.021, g_loss 4.358, d_loss 0.039\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 175/390 d_loss_real= 0.221, d_loss_fake= 0.013, g_loss 4.636, d_loss 0.117\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 176/390 d_loss_real= 0.022, d_loss_fake= 0.012, g_loss 4.823, d_loss 0.017\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 177/390 d_loss_real= 0.188, d_loss_fake= 0.056, g_loss 4.770, d_loss 0.122\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 178/390 d_loss_real= 0.090, d_loss_fake= 0.006, g_loss 5.272, d_loss 0.048\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 179/390 d_loss_real= 0.123, d_loss_fake= 0.005, g_loss 5.235, d_loss 0.064\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 180/390 d_loss_real= 0.065, d_loss_fake= 0.007, g_loss 5.057, d_loss 0.036\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52 Batch 181/390 d_loss_real= 0.141, d_loss_fake= 0.008, g_loss 4.844, d_loss 0.074\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch 52 Batch 182/390 d_loss_real= 0.021, d_loss_fake= 0.009, g_loss 4.651, d_loss 0.015\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 52 Batch 183/390 d_loss_real= 0.126, d_loss_fake= 0.011, g_loss 4.561, d_loss 0.068\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 52 Batch 184/390 d_loss_real= 0.010, d_loss_fake= 0.013, g_loss 4.452, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 185/390 d_loss_real= 0.002, d_loss_fake= 0.014, g_loss 4.385, d_loss 0.008\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 186/390 d_loss_real= 0.210, d_loss_fake= 0.014, g_loss 4.253, d_loss 0.112\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52 Batch 187/390 d_loss_real= 0.179, d_loss_fake= 0.015, g_loss 4.179, d_loss 0.097\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 188/390 d_loss_real= 0.102, d_loss_fake= 0.017, g_loss 4.053, d_loss 0.060\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 189/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 3.952, d_loss 0.010\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 52 Batch 190/390 d_loss_real= 0.023, d_loss_fake= 0.022, g_loss 3.807, d_loss 0.022\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 191/390 d_loss_real= 0.018, d_loss_fake= 0.027, g_loss 3.549, d_loss 0.022\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 192/390 d_loss_real= 0.109, d_loss_fake= 0.042, g_loss 3.318, d_loss 0.076\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 52 Batch 193/390 d_loss_real= 0.058, d_loss_fake= 0.070, g_loss 3.349, d_loss 0.064\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 194/390 d_loss_real= 0.112, d_loss_fake= 0.039, g_loss 3.572, d_loss 0.075\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 195/390 d_loss_real= 0.103, d_loss_fake= 0.030, g_loss 3.683, d_loss 0.067\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 196/390 d_loss_real= 0.000, d_loss_fake= 0.025, g_loss 3.803, d_loss 0.013\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 52 Batch 197/390 d_loss_real= 0.071, d_loss_fake= 0.025, g_loss 3.794, d_loss 0.048\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 198/390 d_loss_real= 0.009, d_loss_fake= 0.026, g_loss 3.773, d_loss 0.018\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 199/390 d_loss_real= 0.108, d_loss_fake= 0.024, g_loss 3.743, d_loss 0.066\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 200/390 d_loss_real= 0.063, d_loss_fake= 0.026, g_loss 3.782, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 201/390 d_loss_real= 0.043, d_loss_fake= 0.029, g_loss 3.764, d_loss 0.036\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 52 Batch 202/390 d_loss_real= 0.019, d_loss_fake= 0.029, g_loss 3.669, d_loss 0.024\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 203/390 d_loss_real= 0.000, d_loss_fake= 0.031, g_loss 3.602, d_loss 0.015\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 204/390 d_loss_real= 0.000, d_loss_fake= 0.032, g_loss 3.642, d_loss 0.016\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 52 Batch 205/390 d_loss_real= 0.038, d_loss_fake= 0.028, g_loss 3.700, d_loss 0.033\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 206/390 d_loss_real= 0.000, d_loss_fake= 0.030, g_loss 3.743, d_loss 0.015\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 207/390 d_loss_real= 0.060, d_loss_fake= 0.027, g_loss 3.806, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 208/390 d_loss_real= 0.127, d_loss_fake= 0.026, g_loss 3.802, d_loss 0.077\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 52 Batch 209/390 d_loss_real= 0.125, d_loss_fake= 0.024, g_loss 3.832, d_loss 0.074\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 52 Batch 210/390 d_loss_real= 0.089, d_loss_fake= 0.023, g_loss 3.879, d_loss 0.056\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 211/390 d_loss_real= 0.053, d_loss_fake= 0.023, g_loss 3.869, d_loss 0.038\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 212/390 d_loss_real= 0.044, d_loss_fake= 0.025, g_loss 3.836, d_loss 0.035\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 213/390 d_loss_real= 0.000, d_loss_fake= 0.026, g_loss 3.780, d_loss 0.013\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 52 Batch 214/390 d_loss_real= 0.068, d_loss_fake= 0.025, g_loss 3.795, d_loss 0.047\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 52 Batch 215/390 d_loss_real= 0.080, d_loss_fake= 0.024, g_loss 3.844, d_loss 0.052\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 216/390 d_loss_real= 0.004, d_loss_fake= 0.024, g_loss 3.908, d_loss 0.014\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 52 Batch 217/390 d_loss_real= 0.006, d_loss_fake= 0.022, g_loss 4.012, d_loss 0.014\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 218/390 d_loss_real= 0.150, d_loss_fake= 0.021, g_loss 3.945, d_loss 0.085\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 52 Batch 219/390 d_loss_real= 0.000, d_loss_fake= 0.023, g_loss 4.065, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 220/390 d_loss_real= 0.073, d_loss_fake= 0.025, g_loss 3.987, d_loss 0.049\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 221/390 d_loss_real= 0.146, d_loss_fake= 0.028, g_loss 3.928, d_loss 0.087\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 222/390 d_loss_real= 0.000, d_loss_fake= 0.035, g_loss 4.179, d_loss 0.018\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 223/390 d_loss_real= 0.000, d_loss_fake= 0.022, g_loss 4.334, d_loss 0.011\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 224/390 d_loss_real= 0.107, d_loss_fake= 0.013, g_loss 4.637, d_loss 0.060\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 225/390 d_loss_real= 0.030, d_loss_fake= 0.011, g_loss 4.602, d_loss 0.020\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 226/390 d_loss_real= 0.171, d_loss_fake= 0.010, g_loss 4.459, d_loss 0.090\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 227/390 d_loss_real= 0.187, d_loss_fake= 0.014, g_loss 4.408, d_loss 0.100\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 228/390 d_loss_real= 0.000, d_loss_fake= 0.017, g_loss 4.326, d_loss 0.008\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 229/390 d_loss_real= 0.018, d_loss_fake= 0.025, g_loss 4.297, d_loss 0.021\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 52 Batch 230/390 d_loss_real= 0.127, d_loss_fake= 0.023, g_loss 4.298, d_loss 0.075\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 231/390 d_loss_real= 0.074, d_loss_fake= 0.017, g_loss 4.406, d_loss 0.046\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 232/390 d_loss_real= 0.161, d_loss_fake= 0.014, g_loss 4.587, d_loss 0.088\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 233/390 d_loss_real= 0.000, d_loss_fake= 0.013, g_loss 4.666, d_loss 0.006\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 234/390 d_loss_real= 0.000, d_loss_fake= 0.011, g_loss 4.830, d_loss 0.005\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 235/390 d_loss_real= 0.085, d_loss_fake= 0.009, g_loss 4.869, d_loss 0.047\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52 Batch 236/390 d_loss_real= 0.088, d_loss_fake= 0.008, g_loss 4.959, d_loss 0.048\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 52 Batch 237/390 d_loss_real= 0.198, d_loss_fake= 0.009, g_loss 4.760, d_loss 0.103\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 52 Batch 238/390 d_loss_real= 0.018, d_loss_fake= 0.011, g_loss 4.477, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 239/390 d_loss_real= 0.051, d_loss_fake= 0.017, g_loss 4.133, d_loss 0.034\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 52 Batch 240/390 d_loss_real= 0.066, d_loss_fake= 0.031, g_loss 3.960, d_loss 0.048\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 52 Batch 241/390 d_loss_real= 0.000, d_loss_fake= 0.027, g_loss 3.978, d_loss 0.014\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52 Batch 242/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 4.438, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 243/390 d_loss_real= 0.078, d_loss_fake= 0.014, g_loss 4.584, d_loss 0.046\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 244/390 d_loss_real= 0.128, d_loss_fake= 0.013, g_loss 4.680, d_loss 0.070\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 245/390 d_loss_real= 0.074, d_loss_fake= 0.009, g_loss 4.741, d_loss 0.042\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 52 Batch 246/390 d_loss_real= 0.000, d_loss_fake= 0.010, g_loss 4.808, d_loss 0.005\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 247/390 d_loss_real= 0.422, d_loss_fake= 0.010, g_loss 4.537, d_loss 0.216\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 248/390 d_loss_real= 0.000, d_loss_fake= 0.013, g_loss 4.471, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 249/390 d_loss_real= 0.415, d_loss_fake= 0.015, g_loss 4.160, d_loss 0.215\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 250/390 d_loss_real= 0.000, d_loss_fake= 0.028, g_loss 3.771, d_loss 0.014\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 251/390 d_loss_real= 0.162, d_loss_fake= 0.026, g_loss 3.953, d_loss 0.094\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 252/390 d_loss_real= 0.071, d_loss_fake= 0.025, g_loss 4.039, d_loss 0.048\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 253/390 d_loss_real= 0.086, d_loss_fake= 0.024, g_loss 4.126, d_loss 0.055\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 52 Batch 254/390 d_loss_real= 0.073, d_loss_fake= 0.015, g_loss 4.372, d_loss 0.044\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 255/390 d_loss_real= 0.000, d_loss_fake= 0.012, g_loss 4.483, d_loss 0.006\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 256/390 d_loss_real= 0.015, d_loss_fake= 0.012, g_loss 4.572, d_loss 0.013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 257/390 d_loss_real= 0.332, d_loss_fake= 0.011, g_loss 4.526, d_loss 0.172\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 258/390 d_loss_real= 0.071, d_loss_fake= 0.013, g_loss 4.493, d_loss 0.042\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 52 Batch 259/390 d_loss_real= 0.075, d_loss_fake= 0.012, g_loss 4.445, d_loss 0.044\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 52 Batch 260/390 d_loss_real= 0.136, d_loss_fake= 0.013, g_loss 4.396, d_loss 0.074\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 261/390 d_loss_real= 0.019, d_loss_fake= 0.013, g_loss 4.323, d_loss 0.016\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 262/390 d_loss_real= 0.052, d_loss_fake= 0.017, g_loss 4.101, d_loss 0.035\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 263/390 d_loss_real= 0.059, d_loss_fake= 0.018, g_loss 4.123, d_loss 0.039\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 264/390 d_loss_real= 0.000, d_loss_fake= 0.024, g_loss 3.993, d_loss 0.012\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 265/390 d_loss_real= 0.163, d_loss_fake= 0.021, g_loss 3.968, d_loss 0.092\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 266/390 d_loss_real= 0.005, d_loss_fake= 0.030, g_loss 3.946, d_loss 0.018\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 267/390 d_loss_real= 0.048, d_loss_fake= 0.027, g_loss 4.133, d_loss 0.037\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 52 Batch 268/390 d_loss_real= 0.164, d_loss_fake= 0.023, g_loss 3.933, d_loss 0.093\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 269/390 d_loss_real= 0.074, d_loss_fake= 0.027, g_loss 3.932, d_loss 0.050\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52 Batch 270/390 d_loss_real= 0.003, d_loss_fake= 0.026, g_loss 4.012, d_loss 0.014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 271/390 d_loss_real= 0.131, d_loss_fake= 0.023, g_loss 4.087, d_loss 0.077\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 272/390 d_loss_real= 0.057, d_loss_fake= 0.016, g_loss 4.249, d_loss 0.037\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 273/390 d_loss_real= 0.034, d_loss_fake= 0.017, g_loss 4.197, d_loss 0.026\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 274/390 d_loss_real= 0.065, d_loss_fake= 0.016, g_loss 4.259, d_loss 0.040\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 52 Batch 275/390 d_loss_real= 0.000, d_loss_fake= 0.016, g_loss 4.310, d_loss 0.008\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 276/390 d_loss_real= 0.010, d_loss_fake= 0.014, g_loss 4.442, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 277/390 d_loss_real= 0.057, d_loss_fake= 0.013, g_loss 4.476, d_loss 0.035\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 52 Batch 278/390 d_loss_real= 0.001, d_loss_fake= 0.012, g_loss 4.516, d_loss 0.006\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 279/390 d_loss_real= 0.139, d_loss_fake= 0.011, g_loss 4.557, d_loss 0.075\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 280/390 d_loss_real= 0.028, d_loss_fake= 0.011, g_loss 4.502, d_loss 0.020\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 281/390 d_loss_real= 0.066, d_loss_fake= 0.012, g_loss 4.399, d_loss 0.039\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 282/390 d_loss_real= 0.000, d_loss_fake= 0.013, g_loss 4.425, d_loss 0.006\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 52 Batch 283/390 d_loss_real= 0.121, d_loss_fake= 0.014, g_loss 4.341, d_loss 0.067\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 284/390 d_loss_real= 0.028, d_loss_fake= 0.016, g_loss 4.185, d_loss 0.022\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 52 Batch 285/390 d_loss_real= 0.056, d_loss_fake= 0.018, g_loss 4.130, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 286/390 d_loss_real= 0.146, d_loss_fake= 0.019, g_loss 3.922, d_loss 0.082\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 287/390 d_loss_real= 0.033, d_loss_fake= 0.022, g_loss 3.817, d_loss 0.027\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 52 Batch 288/390 d_loss_real= 0.140, d_loss_fake= 0.028, g_loss 3.757, d_loss 0.084\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 289/390 d_loss_real= 0.062, d_loss_fake= 0.045, g_loss 3.798, d_loss 0.053\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 290/390 d_loss_real= 0.004, d_loss_fake= 0.024, g_loss 4.090, d_loss 0.014\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 291/390 d_loss_real= 0.170, d_loss_fake= 0.018, g_loss 4.222, d_loss 0.094\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 292/390 d_loss_real= 0.100, d_loss_fake= 0.018, g_loss 4.236, d_loss 0.059\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52 Batch 293/390 d_loss_real= 0.064, d_loss_fake= 0.017, g_loss 4.176, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 294/390 d_loss_real= 0.000, d_loss_fake= 0.015, g_loss 4.318, d_loss 0.008\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 295/390 d_loss_real= 0.025, d_loss_fake= 0.015, g_loss 4.259, d_loss 0.020\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 296/390 d_loss_real= 0.032, d_loss_fake= 0.017, g_loss 4.225, d_loss 0.024\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 297/390 d_loss_real= 0.082, d_loss_fake= 0.018, g_loss 4.220, d_loss 0.050\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 52 Batch 298/390 d_loss_real= 0.000, d_loss_fake= 0.017, g_loss 4.176, d_loss 0.009\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 52 Batch 299/390 d_loss_real= 0.070, d_loss_fake= 0.017, g_loss 4.195, d_loss 0.043\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 300/390 d_loss_real= 0.121, d_loss_fake= 0.016, g_loss 4.214, d_loss 0.069\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 301/390 d_loss_real= 0.108, d_loss_fake= 0.018, g_loss 4.122, d_loss 0.063\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 52 Batch 302/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 4.137, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 303/390 d_loss_real= 0.106, d_loss_fake= 0.018, g_loss 4.079, d_loss 0.062\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 304/390 d_loss_real= 0.107, d_loss_fake= 0.018, g_loss 4.029, d_loss 0.063\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52 Batch 305/390 d_loss_real= 0.179, d_loss_fake= 0.021, g_loss 3.851, d_loss 0.100\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 52 Batch 306/390 d_loss_real= 0.046, d_loss_fake= 0.031, g_loss 3.763, d_loss 0.039\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 307/390 d_loss_real= 0.093, d_loss_fake= 0.034, g_loss 3.902, d_loss 0.063\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 308/390 d_loss_real= 0.061, d_loss_fake= 0.027, g_loss 3.752, d_loss 0.044\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 309/390 d_loss_real= 0.061, d_loss_fake= 0.026, g_loss 3.912, d_loss 0.043\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 310/390 d_loss_real= 0.127, d_loss_fake= 0.020, g_loss 4.104, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 311/390 d_loss_real= 0.002, d_loss_fake= 0.016, g_loss 4.189, d_loss 0.009\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 312/390 d_loss_real= 0.064, d_loss_fake= 0.016, g_loss 4.349, d_loss 0.040\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 313/390 d_loss_real= 0.057, d_loss_fake= 0.015, g_loss 4.360, d_loss 0.036\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 314/390 d_loss_real= 0.278, d_loss_fake= 0.014, g_loss 4.329, d_loss 0.146\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 315/390 d_loss_real= 0.061, d_loss_fake= 0.015, g_loss 4.298, d_loss 0.038\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52 Batch 316/390 d_loss_real= 0.152, d_loss_fake= 0.018, g_loss 4.190, d_loss 0.085\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52 Batch 317/390 d_loss_real= 0.000, d_loss_fake= 0.018, g_loss 4.117, d_loss 0.009\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 52 Batch 318/390 d_loss_real= 0.178, d_loss_fake= 0.020, g_loss 3.973, d_loss 0.099\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 319/390 d_loss_real= 0.052, d_loss_fake= 0.023, g_loss 3.830, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 320/390 d_loss_real= 0.143, d_loss_fake= 0.025, g_loss 3.700, d_loss 0.084\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 321/390 d_loss_real= 0.173, d_loss_fake= 0.033, g_loss 3.409, d_loss 0.103\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 322/390 d_loss_real= 0.127, d_loss_fake= 0.044, g_loss 3.483, d_loss 0.085\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52 Batch 323/390 d_loss_real= 0.100, d_loss_fake= 0.037, g_loss 3.610, d_loss 0.069\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 324/390 d_loss_real= 0.017, d_loss_fake= 0.021, g_loss 4.044, d_loss 0.019\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 325/390 d_loss_real= 0.074, d_loss_fake= 0.024, g_loss 3.897, d_loss 0.049\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 52 Batch 326/390 d_loss_real= 0.065, d_loss_fake= 0.021, g_loss 4.035, d_loss 0.043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 327/390 d_loss_real= 0.000, d_loss_fake= 0.020, g_loss 4.039, d_loss 0.010\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52 Batch 328/390 d_loss_real= 0.157, d_loss_fake= 0.022, g_loss 4.004, d_loss 0.089\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 329/390 d_loss_real= 0.177, d_loss_fake= 0.024, g_loss 3.811, d_loss 0.101\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 52 Batch 330/390 d_loss_real= 0.121, d_loss_fake= 0.027, g_loss 3.663, d_loss 0.074\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 331/390 d_loss_real= 0.104, d_loss_fake= 0.033, g_loss 3.482, d_loss 0.069\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 332/390 d_loss_real= 0.238, d_loss_fake= 0.038, g_loss 3.392, d_loss 0.138\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 333/390 d_loss_real= 0.079, d_loss_fake= 0.041, g_loss 3.502, d_loss 0.060\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 334/390 d_loss_real= 0.104, d_loss_fake= 0.037, g_loss 3.350, d_loss 0.071\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 335/390 d_loss_real= 0.000, d_loss_fake= 0.034, g_loss 3.497, d_loss 0.017\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 336/390 d_loss_real= 0.000, d_loss_fake= 0.032, g_loss 3.674, d_loss 0.016\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 337/390 d_loss_real= 0.000, d_loss_fake= 0.027, g_loss 3.837, d_loss 0.013\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 338/390 d_loss_real= 0.000, d_loss_fake= 0.021, g_loss 4.019, d_loss 0.010\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 339/390 d_loss_real= 0.172, d_loss_fake= 0.020, g_loss 4.113, d_loss 0.096\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 340/390 d_loss_real= 0.074, d_loss_fake= 0.018, g_loss 4.210, d_loss 0.046\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 341/390 d_loss_real= 0.068, d_loss_fake= 0.019, g_loss 4.114, d_loss 0.044\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 342/390 d_loss_real= 0.096, d_loss_fake= 0.018, g_loss 4.186, d_loss 0.057\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 343/390 d_loss_real= 0.071, d_loss_fake= 0.019, g_loss 4.087, d_loss 0.045\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 344/390 d_loss_real= 0.158, d_loss_fake= 0.019, g_loss 4.106, d_loss 0.088\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 345/390 d_loss_real= 0.053, d_loss_fake= 0.021, g_loss 3.923, d_loss 0.037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 346/390 d_loss_real= 0.074, d_loss_fake= 0.024, g_loss 3.775, d_loss 0.049\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 347/390 d_loss_real= 0.237, d_loss_fake= 0.029, g_loss 3.586, d_loss 0.133\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 348/390 d_loss_real= 0.113, d_loss_fake= 0.036, g_loss 3.456, d_loss 0.075\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 349/390 d_loss_real= 0.069, d_loss_fake= 0.042, g_loss 3.298, d_loss 0.056\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 350/390 d_loss_real= 0.014, d_loss_fake= 0.055, g_loss 3.328, d_loss 0.034\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 52 Batch 351/390 d_loss_real= 0.000, d_loss_fake= 0.035, g_loss 3.587, d_loss 0.017\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 352/390 d_loss_real= 0.000, d_loss_fake= 0.028, g_loss 3.829, d_loss 0.014\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 52 Batch 353/390 d_loss_real= 0.123, d_loss_fake= 0.024, g_loss 3.963, d_loss 0.073\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 354/390 d_loss_real= 0.000, d_loss_fake= 0.019, g_loss 4.104, d_loss 0.010\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 355/390 d_loss_real= 0.001, d_loss_fake= 0.017, g_loss 4.326, d_loss 0.009\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 356/390 d_loss_real= 0.000, d_loss_fake= 0.014, g_loss 4.452, d_loss 0.007\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 357/390 d_loss_real= 0.106, d_loss_fake= 0.014, g_loss 4.406, d_loss 0.060\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 52 Batch 358/390 d_loss_real= 0.264, d_loss_fake= 0.014, g_loss 4.337, d_loss 0.139\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 52 Batch 359/390 d_loss_real= 0.177, d_loss_fake= 0.015, g_loss 4.227, d_loss 0.096\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 52 Batch 360/390 d_loss_real= 0.189, d_loss_fake= 0.017, g_loss 4.164, d_loss 0.103\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 361/390 d_loss_real= 0.090, d_loss_fake= 0.021, g_loss 3.859, d_loss 0.056\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 52 Batch 362/390 d_loss_real= 0.000, d_loss_fake= 0.026, g_loss 3.692, d_loss 0.013\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 363/390 d_loss_real= 0.000, d_loss_fake= 0.030, g_loss 3.606, d_loss 0.015\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 364/390 d_loss_real= 0.000, d_loss_fake= 0.032, g_loss 3.583, d_loss 0.016\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 365/390 d_loss_real= 0.076, d_loss_fake= 0.029, g_loss 3.630, d_loss 0.052\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52 Batch 366/390 d_loss_real= 0.001, d_loss_fake= 0.030, g_loss 3.691, d_loss 0.015\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 367/390 d_loss_real= 0.000, d_loss_fake= 0.024, g_loss 3.893, d_loss 0.012\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 52 Batch 368/390 d_loss_real= 0.000, d_loss_fake= 0.019, g_loss 4.087, d_loss 0.010\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 52 Batch 369/390 d_loss_real= 0.078, d_loss_fake= 0.017, g_loss 4.248, d_loss 0.047\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 370/390 d_loss_real= 0.114, d_loss_fake= 0.015, g_loss 4.324, d_loss 0.064\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 52 Batch 371/390 d_loss_real= 0.270, d_loss_fake= 0.015, g_loss 4.312, d_loss 0.143\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 372/390 d_loss_real= 0.207, d_loss_fake= 0.015, g_loss 4.228, d_loss 0.111\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 52 Batch 373/390 d_loss_real= 0.053, d_loss_fake= 0.017, g_loss 4.113, d_loss 0.035\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 374/390 d_loss_real= 0.059, d_loss_fake= 0.020, g_loss 3.749, d_loss 0.039\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 375/390 d_loss_real= 0.084, d_loss_fake= 0.031, g_loss 3.353, d_loss 0.058\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 52 Batch 376/390 d_loss_real= 0.000, d_loss_fake= 0.045, g_loss 3.331, d_loss 0.023\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 377/390 d_loss_real= 0.020, d_loss_fake= 0.047, g_loss 3.546, d_loss 0.033\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 52 Batch 378/390 d_loss_real= 0.000, d_loss_fake= 0.030, g_loss 4.002, d_loss 0.015\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 379/390 d_loss_real= 0.066, d_loss_fake= 0.018, g_loss 4.297, d_loss 0.042\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52 Batch 380/390 d_loss_real= 0.159, d_loss_fake= 0.015, g_loss 4.389, d_loss 0.087\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 381/390 d_loss_real= 0.010, d_loss_fake= 0.015, g_loss 4.311, d_loss 0.012\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 382/390 d_loss_real= 0.024, d_loss_fake= 0.016, g_loss 4.269, d_loss 0.020\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52 Batch 383/390 d_loss_real= 0.210, d_loss_fake= 0.017, g_loss 4.094, d_loss 0.114\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 384/390 d_loss_real= 0.077, d_loss_fake= 0.024, g_loss 3.978, d_loss 0.051\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52 Batch 385/390 d_loss_real= 0.003, d_loss_fake= 0.032, g_loss 3.946, d_loss 0.018\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 386/390 d_loss_real= 0.000, d_loss_fake= 0.025, g_loss 4.025, d_loss 0.012\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 52 Batch 387/390 d_loss_real= 0.127, d_loss_fake= 0.029, g_loss 4.138, d_loss 0.078\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52 Batch 388/390 d_loss_real= 0.052, d_loss_fake= 0.021, g_loss 4.334, d_loss 0.037\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52 Batch 389/390 d_loss_real= 0.134, d_loss_fake= 0.011, g_loss 4.685, d_loss 0.072\n",
            "2/2 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 52 Batch 390/390 d_loss_real= 0.231, d_loss_fake= 0.026, g_loss 4.135, d_loss 0.129\n"
          ]
        }
      ],
      "source": [
        "gan_model=define_gan(generator,discriminator)\n",
        "g_array, d_array =train(generator,discriminator,gan_model,X_train_normal,latent_dim,52)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>Loss Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "2rk3Oajf5yN_",
        "outputId": "9ca5180b-2eb9-4e56-cd5e-39dc19d62696"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_loss(gen_loss, disc_loss):\n",
        "    plt.plot(gen_loss, label='Generator Loss')\n",
        "    plt.plot(disc_loss, label='Discriminator Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "gen_losses=g_array\n",
        "discrim_losses=d_array\n",
        "plot_loss(gen_losses,discrim_losses)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>Image Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "W5ruIljEv0YP",
        "outputId": "f90e134a-69d9-45ba-a4fc-bd1cd3a1cbb9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 227ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 25 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "def showplot(examples,n):\n",
        "    for i in range(n*n):\n",
        "        plt.subplot(n,n,1+i)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(examples[i,:,:,:])\n",
        "    plt.show()\n",
        "\n",
        "model=load_model('50base50.h5')\n",
        "#generate img 100 points 100 imgs\n",
        "latent_points=generate_latent_points(100,25)\n",
        "X=model.predict(latent_points)\n",
        "#scale from -1,1 to 0,1 to get pixel values to 0 to 255\n",
        "X=(X+1)/2.0\n",
        "X=(X*255).astype(np.uint8)\n",
        "showplot(X,5)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2>Model improvement is needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3woz7z5F1275"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "tf-gpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "222ffca9ce43879094c17e6b40bc3545027533de975f61fa4f3cf9869f4e486e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
